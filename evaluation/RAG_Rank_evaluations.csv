question,ground_truth,contexts,answer,faithfulness,answer_relevancy,context_relevancy,context_precision,context_recall
What kind of model is the bling-phi-3 model,"The bling-phi-3 model is the newest and most accurate BLING/DRAGON model. BLING models are small CPU-based RAG-optimized, instruct-following 1B-3B parameter models. DRAGON models are production-grade RAG-optimized 6-7B parameter models - ""Delivering RAG on ..."" the leading foundation base models.","['---The Paths through the Underground/Underdark---(9 days of travel)\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\n\nDay 1 goes without issue... sleep.\n\nDay 2 – Ropers\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\n---ENCOUNTER – Ropers x 2---\nDay 3 goes without issue...sleep.\n\nDay 4 - Kobold Trap\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\n\nThey are no more than 2-3 feet wide, and numerous (dozens).\n\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\n\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\n\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\n\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\n“Loud food! Loud meal!”\n\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\n\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\n\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\n\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?'
 'llmware\n\nBuilding Enterprise RAG Pipelines with Small, Specialized Models\nllmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\n\nllmware has two main components:\n\nRAG Pipeline - integrated components for the full lifecycle of connecting knowledge sources to generative AI models; and\n\n50+ small, specialized models fine-tuned for key tasks in enterprise process automation, including fact-based question-answering, classification, summarization, and extraction.\n\nBy bringing together both of these components, along with integrating leading open source models and underlying technologies, llmware offers a comprehensive set of tools to rapidly build knowledge-based enterprise LLM applications.\n\nMost of our examples can be run without a GPU server - get started right away on your laptop.\n\nJoin us on Discord | Watch Youtube Tutorials | Explore our Model Families on Huggingface\n\nNew to RAG? Check out the Fast Start video series\n\nMulti-Model Agents with SLIM Models - Intro-Video\n\nIntro to SLIM Function Call Models\nCan\'t wait? Get SLIMs right away:\n\nfrom llmware.models import ModelCatalog\n\nModelCatalog().get_llm_toolkit()  # get all SLIM models, delivered as small, fast quantized tools\nModelCatalog().tool_test_run(""slim-sentiment-tool"") # see the model in action with test script included\nKey features\nWriting code withllmware is based on a few main concepts:\n\nModel Catalog: Access all models the same way with easy lookup, regardless of underlying implementation.\nLibrary: ingest, organize and index a collection of knowledge at scale - Parse, Text Chunk and Embed.\nQuery: query libraries with mix of text, semantic, hybrid, metadata, and custom filters.\nPrompt with Sources: the easiest way to combine knowledge retrieval with a LLM inference.\nRAG-Optimized Models - 1-7B parameter models designed for RAG workflow integration and running locally.\nSimple-to-Scale Database Options - integrated data stores from laptop to parallelized cluster.\nAgents with Function Calls and SLIM Models\nStart coding - Quick Start for RAG\nWhat\'s New?\n-Best New Small RAG Model - BLING finetune of Phi-3 - ""bling-phi-3-gguf"" - see the video\n\n-Web Services with Agent Calls for Financial Research - end-to-end scenario - video and example\n\n-Voice Transcription with WhisperCPP - getting_started, using_sample_files, and analysis_use_case with great_speeches_video\n\n-Phi-3 GGUF Streaming Local Chatbot with UI - setup your own Phi-3-gguf chatbot on your laptop in minutes - example with video\n\n-Small, specialized, function-calling Extract Model - introducing slim-extract - video and example\n\n-LLM to Answer Yes/No questions - introducing slim-boolean model - video and example\n\n-Natural Language Query to CSV End to End example - using slim-sql model - video and example and now using Custom Tables on Postgres example\n\n-Multi-Model Agents with SLIM models - multi-step Agents with SLIMs on CPU - video - example\n\n-OCR Embedded Document Images Example - systematically extract text from images embedded in documents example\n\n-Enhanced Parser Functions for PDF, Word, Powerpoint and Excel - new text-chunking controls and strategies, extract tables, images, header text - example\n\n-Agent Inference Server - set up multi-model Agents over Inference Server example\n\n-GGUF - Getting Started - check out examples - GGUF (example) and Videos video\n\n-Optimizing Accuracy of RAG Prompts - check out example and videos - part I and part II\n\nGetting Started\nStep 1 - Install llmware - pip3 install llmware or pip3 install \'llmware[full]\'\n\nnote: starting with v0.3.0, we provide options for a core install (minimal set of dependencies) or full install (adds to the core with wider set of related python libraries).\nStep 2- Go to Examples - Get Started Fast with 100+ \'Cut-and-Paste\' Recipes\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\n✍Working with the llmware Github repository\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\n\ngit clone git@github.com:llmware-ai/llmware.git\nWe have provided a welcome_to_llmware automation script in the root of the repository folder. After cloning:\n\nOn Windows command line: .\\welcome_to_llmware_windows.sh\nOn Mac / Linux command line: sh ./welcome_to_llmware.sh\nAlternatively, if you prefer to complete setup without the welcome automation script, then the next steps include:\n\ninstall requirements.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements.txt\n\ninstall requirements_extras.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements_extras.txt (Depending upon your use case, you may not need all or any of these installs, but some of these will be used in the examples.)\n\nrun examples - copy one or more of the example .py files into the root project path. (We have seen several IDEs that will attempt to run interactively from the nested /example path, and then not have access to the /llmware module - the easy fix is to just copy the example you want to run into the root path).\n\ninstall vector db - no-install vector db options include milvus lite, chromadb, faiss and lancedb - which do not require a server install, but do require that you install the python sdk library for that vector db, e.g., pip3 install pymilvus, or pip3 install chromadb. If you look in examples/Embedding, you will see examples for getting started with various vector DB, and in the root of the repo, you will see easy-to-get-started docker compose scripts for installing milvus, postgres/pgvector, mongo, qdrant, neo4j, and redis.\n\nNote: we have seen recently issues with Pytorch==2.3 on some platforms - if you run into any issues, we have seen that uninstalling Pytorch and downleveling to Pytorch==2.1 usually solves the problem.\n\nData Store Options\nFast Start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required\nSpeed + Scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose\nPostgres: use Postgres for both text collection and vector DB - install with Docker Compose\nMix-and-Match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)\nMeet our Models\nSLIM model series: small, specialized models fine-tuned for function calling and multi-step, multi-model Agent workflows.\nDRAGON model series: Production-grade RAG-optimized 6-7B parameter models - ""Delivering RAG on ..."" the leading foundation base models.\nBLING model series: Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models.\nIndustry BERT models: out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC.\nGGUF Quantization: we provide \'gguf\' and \'tool\' versions of many SLIM, DRAGON and BLING models, optimized for CPU deployment.\nUsing LLMs and setting-up API keys & secrets\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\n\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\n\nRoadmap - Where are we going ...\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.\n\nQuestions and discussions are welcome in our github discussions.\n\nRelease notes and Change Log\nSee also additional deployment/install release notes in wheel_archives\n\nThursday, June 6 - v0.3.1-WIP\n\nAdded module 3 to Fast Start example series examples 7-9 on Agents & Function Calls\nAdded reranker Jina model for in-memory semantic similarity RAG - see example\nChanges merged into main branch - expected next pypi release at end of week\nTuesday, June 4 - v0.3.0\n\nAdded support for new Milvus Lite embedded \'no-install\' database - see example.\nAdded two new SLIM models to catalog and agent processes - \'q-gen\' and \'qa-gen\'\nUpdated model class instantiation to provide more extensibility to add new classes in different modules\nNew welcome_to_llmware.sh and welcome_to_llmware_windows.sh fast install scripts\nEnhanced Model class base with new configurable post_init and register methods\nCreated InferenceHistory to track global state of all inferences completed\nMultiple improvements and updates to logging at module level\nNote: starting with v0.3.0, pip install provides two options - a base minimal install pip3 install llmware which will support most use cases, and a larger install pip3 install \'llmware[full]\' with other commonly-used libraries.\nWednesday, May 22 - v0.2.15\n\nImprovements in Model class handling of Pytorch and Transformers dependencies (just-in-time loading, if needed)\nExpanding API endpoint options and inference server functionality - see new client access options and server_launch\nSaturday, May 18 - v0.2.14\n\nNew OCR image parsing methods with example\nAdding first part of logging improvements (WIP) in Configs and Models.\nNew embedding model added to catalog - industry-bert-loans.\nUpdates to model import methods and configurations.\nSunday, May 12 - v0.2.13\n\nNew GGUF streaming method with basic example and phi3 local chatbot\nSignificant cleanups in ancillary imports and dependencies to reduce install complexity - note: the updated requirements.txt and setup.py files.\nDefensive code to provide informative warning of any missing dependencies in specialized parts of the code, e.g., OCR, Web Parser.\nUpdates of tests, notice and documentation.\nOpenAIConfigs created to support Azure OpenAI.\nSunday, May 5 - v0.2.12 Update\n\nLaunched ""bling-phi-3"" and ""bling-phi-3-gguf"" in ModelCatalog - newest and most accurate BLING/DRAGON model\nNew long document summarization method using slim-summary-tool example\nNew Office (Powerpoint, Word, Excel) sample files example\nAdded support for Python 3.12\nDeprecated faiss and replaced with \'no-install\' chromadb in Fast Start examples\nRefactored Datasets, Graph and Web Services classes\nUpdated Voice parsing with WhisperCPP into Library\nMonday, April 29 - v0.2.11 Update\n\nUpdates to gguf libs for Phi-3 and Llama-3\nAdded Phi-3 example and Llama-3 example and Quantized Versions to Model Catalog\nIntegrated WhisperCPP Model class and prebuilt shared libraries - getting-started-example\nNew voice sample files for testing - example\nImproved CUDA detection on Windows and safety checks for older Mac OS versions\nMonday, April 22 - v0.2.10 Update\n\nUpdates to Agent class to support Natural Language queries of Custom Tables on Postgres example\nNew Agent API endpoint implemented with LLMWare Inference Server and new Agent capabilities example\nTuesday, April 16 - v0.2.9 Update\n\nNew CustomTable class to rapidly create custom DB tables in conjunction with LLM-based workflows.\nEnhanced methods for converting CSV and JSON/JSONL files into DB tables.\nSee new examples Creating Custom Table example\nTuesday, April 9 - v0.2.8 Update\n\nOffice Parser (Word Docx, Powerpoint PPTX, and Excel XLSX) - multiple improvements - new libs + Python method.\nIncludes: several fixes, improved text chunking controls, header text extraction and configuration options.\nGenerally, new office parser options conform with the new PDF parser options.\nPlease see Office Parsing Configs example\nWednesday, April 3 - v0.2.7 Update\n\nPDF Parser - multiple improvements - new libs + Python methods.\nIncludes: UTF-8 encoding for European languages.\nIncludes: Better text chunking controls, header text extraction and configuration options.\nPlease see PDF Parsing Configs example for more details.\nNote: deprecating support for aarch64-linux (will use 0.2.6 parsers). Full support going forward for Linux Ubuntu20+ on x86_64 + with CUDA.\nFriday, March 22 - v0.2.6 Update\n\nNew SLIM models: summary, extract, xsum, boolean, tags-3b, and combo sentiment-ner.\nNew logit and sampling analytics.\nNew SLIM examples showing how to use the new models.\nThursday, March 14 - v0.2.5 Update\n\nImproved support for GGUF on CUDA (Windows and Linux), with new prebuilt binaries and exception handling.\nEnhanced model configuration options (sampling, temperature, top logit capture).\nAdded full back-level support for Ubuntu 20+ with parsers and GGUF engine.\nSupport for new Anthropic Claude 3 models.\nNew retrieval methods: document_lookup and aggregate_text.\nNew model: bling-stablelm-3b-tool - fast, accurate 3b quantized question-answering model - one of our new favorites.\nWednesday, February 28 - v0.2.4 Update\n\nMajor upgrade of GGUF Generative Model class - support for Stable-LM-3B, CUDA build options, and better control over sampling strategies.\nNote: new GGUF llama.cpp built libs packaged with build starting in v0.2.4.\nImproved GPU support for HF Embedding Models.\nFriday, February 16 - v0.2.3 Update\n\nAdded 10+ embedding models to ModelCatalog - nomic, jina, bge, gte, ember and uae-large.\nUpdated OpenAI support >=1.0 and new text-3 embedding models.\nSLIM model keys and output_values now accessible in ModelCatalog.\nUpdating encodings to \'utf-8-sig\' to better handle txt/csv files with bom.\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\n\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\n\nSupported Text Index Databases: MongoDB, Postgres, SQLite\n\nOptional\nDocker\n\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.\n\nChange Log\nLatest Updates - 19 Jan 2024 - llmware v0.2.0\n\nAdded new database integration options - Postgres and SQlite\nImproved status update and parser event logging options for parallelized parsing\nSignificant enhancements to interactions between Embedding + Text collection databases\nImproved error exception handling in loading dynamic modules\nLatest Updates - 15 Jan 2024: llmware v0.1.15\n\nEnhancements to dual pass retrieval queries\nExpanded configuration objects and options for endpoint resources\nLatest Updates - 30 Dec 2023: llmware v0.1.14\n\nAdded support for Open Chat inference servers (compatible with OpenAI API)\nImproved capabilities for multiple embedding models and vector DB configurations\nAdded docker-compose install scripts for PGVector and Redis vector databases\nAdded \'bling-tiny-llama\' to model catalog\nLatest Updates - 22 Dec 2023: llmware v0.1.13\n\nAdded 3 new vector databases - Postgres (PG Vector), Redis, and Qdrant\n\nImproved support for integrating sentence transformers directly in the model catalog\n\nImprovements in the model catalog attributes\n\nMultiple new Examples in Models & Embeddings, including GGUF, Vector database, and model catalog\n\n17 Dec 2023: llmware v0.1.12\n\ndragon-deci-7b added to catalog - RAG-finetuned model on high-performance new 7B model base from Deci\nNew GGUFGenerativeModel class for easy integration of GGUF Models\nAdding prebuilt llama_cpp / ctransformer shared libraries for Mac M1, Mac x86, Linux x86 and Windows\n3 DRAGON models packaged as Q4_K_M GGUF models for CPU laptop use (dragon-mistral-7b, dragon-llama-7b, dragon-yi-6b)\n4 leading open source chat models added to default catalog with Q4_K_M\n8 Dec 2023: llmware v0.1.11\n\nNew fast start examples for high volume Document Ingestion and Embeddings with Milvus.\nNew LLMWare \'Pop up\' Inference Server model class and example script.\nNew Invoice Processing example for RAG.\nImproved Windows stack management to support parsing larger documents.\nEnhancing debugging log output mode options for PDF and Office parsers.\n30 Nov 2023: llmware v0.1.10\n\nWindows added as a supported operating system.\nFurther enhancements to native code for stack management.\nMinor defect fixes.\n24 Nov 2023: llmware v0.1.9\n\nMarkdown (.md) files are now parsed and treated as text files.\nPDF and Office parser stack optimizations which should avoid the need to set ulimit -s.\nNew llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.\nNative dependencies (shared libraries and dependencies) now included in repo to faciliate local development.\nUpdates to the Status class to support PDF and Office document parsing status updates.\nMinor defect fixes including image block handling in library exports.\n17 Nov 2023: llmware v0.1.8\n\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\nImproved handling for eos_token_id for llama2 and mistral.\nImproved support for Hugging Face dynamic loading\nNew examples with the new llmware DRAGON models.\n14 Nov 2023: llmware v0.1.7\n\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\nModelCatalog enhancements:\nOpenAI update to include newly announced ‘turbo’ 4 and 3.5 models.\nCohere embedding v3 update to include new Cohere embedding models.\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the “hf=True” flag.\nAbility to register new model names, within existing model classes, with the register method in ModelCatalog.\nPrompt enhancements:\n“evidence_metadata” added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.\nAPI key can now be passed directly in a prompt.load_model(model_name, api_key = “[my-api-key]”)\nLLMWareInference Server - Initial delivery:\nNew Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.\nLLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.\n03 Nov 2023: llmware v0.1.6\n\nUpdated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.\nUpdates in python code needed in anticipation of future Windows support.\n27 Oct 2023: llmware v0.1.5\n\nFour new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (llmware BLING models).\nExpanded options for setting temperature inside a prompt class.\nImprovement in post processing of Hugging Face model generation.\nStreamlined loading of Hugging Face generative models into prompts.\nInitial delivery of a central status class: read/write of embedding status with a consistent interface for callers.\nEnhanced in-memory dictionary search support for multi-key queries.\nRemoved trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.\nMinor defect fixes, updated test scripts, and version update for Werkzeug to address dependency security alert.\n20 Oct 2023: llmware v0.1.4\n\nGPU support for Hugging Face models.\nDefect fixes and additional test scripts.\n13 Oct 2023: llmware v0.1.3\n\nMongoDB Atlas Vector Search support.\nSupport for authentication using a MongoDB connection string.\nDocument summarization methods.\nImprovements in capturing the model context window automatically and passing changes in the expected output length.\nDataset card and description with lookup by name.\nProcessing time added to model inference usage dictionary.\nAdditional test scripts, examples, and defect fixes.\n06 Oct 2023: llmware v0.1.1\n\nAdded test scripts to the github repository for regression testing.\nMinor defect fixes and version update of Pillow to address dependency security alert.\n02 Oct 2023: llmware v0.1.0 Initial release of llmware to open source!!'
 'Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).']","The bling-phi-3 model is a small CPU-based RAG-optimized model designed for generative AI applications. It is part of the BLING model series, which consists of small, specialized models fine-tuned for function calling and multi-step, multi-model agent workflows.",0.8333333333333334,0.9511837829335453,0.01968503937007874,0.49999999995,0.75
What are the advantages and disadvantages of the BM25 algorithm?,"The advantage of BM25 is that it is efficient. The disadvantage of the BM25 algorithm is that it focuses on term frequency and presence for document algorithm, so it often overlooks the semantic information of queries.","['manicfesto proposals\n26m tonnes of waste plastic bottles are discarded every year in the UK of which only 45% are recycled. The Loony Party has the answer.. Stop making them..\n\nBefore you ask…We have found an alternative. Its called glass.\n\nSome of our Proposals for other elections\nAlong with the existing Government policy for levelling up the North with the South             we will provide free Spirit Levels to all\n\nWe will reduce inflation by giving everyone free pins.\n\nTo make trains safer, we will fit them all with cushions on the front.\n\nAny possible schemes thought up by Government, Council , NHS etc,  such as closure of Hosptitals, workplace parking levy etc will be preceded with a Public Consultation which we will then ignore.\n\nWe will combat corruption in public life by taking part in it openly, we will                              introduce the Board of Bribery who will set standardised rates?. #sleaze for the many not just the few\n\nWe propose to prevent identity theft instantly by calling everyone Chris.\n\nAll political and electoral leaflets will be printed on soft paper so that it may be recycled in the appropriate manner.\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce                   pregnancy from nine to seven months ?\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.\n\nWith Government helped finance, AstraZeneca should buy out Pfizer, then, as we would have the rights to Viagra, the economy may stay up longer.\n\nRedundant Red Phones boxes will be converted to bijou accommodation to ease the housing shortage.\n\nTo make things fairer we will introduce a Court of Human Lefts.\n\nGeneral Election 2022 Manicfesto\nGeneral Election 2022 Manicfesto  —— For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nOnce in Government, we will replace the Foreign Secretary with a British one!\n\nWaitng Lists\n\nWe will reduce hospital waiting lists by using a smaller font.\n\nImmigration\n\nWe will reduce net migration by making sure that any nets are secured more firmly to the ground.\n\nInflation\n\nWe will reduce inflation by giving everyone free pins\n\nGovernment Policy\n\nWhen formulating Policies the Government relies heavily on Expert Advise. Remember  – Experts built the Titanic\n\nThe Loony Party will also take into account the opinion of “Dave on Facebook”\n\nEnergy Policy\n\nWe will get rid of the Energy Price Cap and replace it with a Top Hat (This will also help our Millenery Industry)\n2. We will get rid of all Standing Charges. (We are quite capable of sitting down and freezing to death)\n3. All the hot air spoken in Parliament will be redirected to the Gas Distribution Networks.\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P’s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 ½ hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don’t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy’s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\n\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nGeneral Election 2019 Manicfesto\nGeneral Election 2019 Manicfesto  —— For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P’s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 ½ hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don’t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy’s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will rename the current Oyster cards, ‘Sardine Cards’ to better reflect the experience when travelling on public transport\n2. We will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nPolicies\nWe encourage everyone, even current politicians, to submit ideas to our world famous #Manicfesto! The following are some of the most recent from our wonderful Twitter followers…\n\nOnce in Government, anyone applying for 7 figure salary positions with the World Health Organisation or as Govt Health Advisors, will have to answer 15 correct questions on “WHO wants to be a Millionaire”.\nIn Brexit Trade Deals: Germany will be required to pay for treatment of Measles, and Spain will be required to pay for cases of Spanish Flu. The French will pay for all accidents resulting from kissing & broken letters & the Dutch will split all future expenses 50/50.\nWe will place in law measures to stop panic buying as COVID19 restrictions take hold. Shoppers will only be permitted to buy one panic per person.\nIt is evident that the 10pm pub curfew is not working , We propose that pubs ask people to leave in alphabetical order.\nShamefully Lord Sutch has never been allowed to take his place in the House of Lords. Nor were Duke Ellington, Count Basie or Lord Rockingham We will end this discrimination against musicians.\nTo unite the population, we will surround the UK with a large cardboard box so people can be both in and/or out of the EU. This will be known as Schrodinger’s Brexit.\nTo get more children reading, fish and chips will once again be wrapped in newspaper.\nOnce in Government we will introduce the Ministry of Clarity. The role of this Ministry will ensure that only the clearest clarity is made clear and the unclear clarity is cleared out. We hope that our position on this is now clear to all.\nIn Government, we will complete a 5 year Parliament in only 4 years. This policy not only ensures a 20% saving for the public purse but also gives everyone in the UK a year off from listening to our politicians.\nThe MOT is an annual test to ensure that your car is roadworthy. We will introduce a ROT, an annual test to make sure all roads are car worthy.\nAnd from 1st January 2021, passports will be issued in the colour of political voting. Tories will be Blue, Labour will be Red, Greens will be green. Official Loonies will have leopard spots, and Lib Dem’s will be invisible.\nChinners\n\nForeign Policy\nWe will Admit Shamima Begum back to the country only when she accepts Screaming Lord Sutch as her saviour.\n\nMinistry of Info\nWe will create a New Ministry of Information. It shall consist of the former board of directors of Cambridge Analytica. They already know everything.\n\nBrexit Proposals\nWe will Send Noel Edmonds to negotiate Brexit because he understands Deal or No Deal.\nThere will be no need for a backstop to the Brexit negotiations. We’ll have Alec Stewart as wicket-keeper.\nJames Wallace\n\nEducational Funding\nThe Loony Party proposes that all Schools would have a Jumble sale or fete or other fundraising event at least twice per month to help raise funds for those little extras. . . such as Desks, Books, paper, pens , etc\nR.U. Seerius\n\nPensions – triple lock\nIn keeping with the Labour Party’s latest bid to get one or two pensioners to vote for them they have brought out a new policy guaranteeing the Triple lock on pensions until 2025 if they get voted in.\nThe Loony party of course will go one better and buy a padlock, and as its now safer than a bank,  new mattresses for all pensioners on less than 20p per week.\nR.U. Seerius'
 'Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.'
 '---The Paths through the Underground/Underdark---(9 days of travel)\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\n\nDay 1 goes without issue... sleep.\n\nDay 2 – Ropers\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\n---ENCOUNTER – Ropers x 2---\nDay 3 goes without issue...sleep.\n\nDay 4 - Kobold Trap\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\n\nThey are no more than 2-3 feet wide, and numerous (dozens).\n\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\n\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\n\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\n\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\n“Loud food! Loud meal!”\n\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\n\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\n\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\n\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?']",I don't know.,0.0,0.0,0.0030303030303030303,0.0,0.0
Who was Duke Stelmane?,"Duke Stelmane was a major figure of the Knights of the Shield, a lawful and neutral evil conglomerate of politicians and merchants manipulating events behind the scenes, acting as the Emperor's envoy while it secretly kept her enthralled. Duke Belynne Stelmane dies recently.","['The Emperor is a mind flayer who appears in Baldur\'s Gate 3. It[note 1] plays a key role in the main story, but its identity is intentionally obscured until later parts of the game, allowing the player to ultimately decide for themselves if they want to know more about it, and whether or not it is trustworthy.\n\n\nContents\nOverview\nIdentity\nPersonal quest\nRecruitment\nRomance\nHistory\nEvents of Baldur\'s Gate 3\nAct Two finale\nAct Three\nElfsong Tavern\nThe Wyrmway\nEndings\nList of interactions\nConversation scenes\nIdentity revealed\nRegarding Duke Stelmane\nOn conclusion of Visit the Emperor\'s Old Hideout\nRomance\nAchievements\nGallery\nNotes\nFootnotes\nReferences\nOverview\nIdentity\nThe Emperor plays a key role in the main story of Baldur\'s Gate 3, and as part of this role its identity and personal background are kept obfuscated for much of the game. It very carefully divulges information that it deems necessary, sometimes arguing that the player is not ready for the answer yet, or that it will reveal specific information in the future.\n\nDuring Acts One and Two, the Emperor only ""meets"" with the player as the Dream Guardian. At the beginning of Act Three, the player finally meets the Emperor face to face, an event which reveals that it is a mind flayer.\n\nThrough all three Acts, the Emperor generally serves as a guide, and unlikely ally to the party, having the means to protect their minds from the influence of the Absolute, through the use of the prisoner within the Astral Prism.\n\n""Don\'t let my form deceive you. I am the one that\'s been protecting you. I am the one that came to you in your dreams. Help me.\n— The Emperor, during Act 3\nPersonal quest\nAfter reaching the Elfsong Tavern in Act Three, the Emperor will initiate the quest Visit the Emperor\'s Old Hideout, in which the player can better get to know the Emperor. It discloses some of its past, during its time in the city and from before it became illithid.\n\nRecruitment\nThe Emperor can appear in multiple combat encounters as a controllable ally, a neutral ally, or an enemy. It cannot, however, become a full member of the player\'s party or camp.\n\nRomance\nThe Emperor can have a romance with the player during Act Three. See Romance.\n\nHistory\nDetails about the Emperor\'s personal history are intentionally obfuscated during most of the game, but the player has the opportunity to learn more about it through conversations, interactions with other characters, reading books, and completing specific side quests.\n\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur\'s Gate 3.\n\n\nAn Adventurer, I came from Baldur\'s Gate, though I was never one to be constrained by circumstance. I longed for more.\n\nThat longing brought me to Moonrise Towers on a search for treasure. To a colony of mind flayers who caught me and changed me.\nThe Emperor was once Balduran, an adventurer who founded a coastal village called Grey Harbour. After securing enough money to fund the building of the Wall that led to Baldur\'s Gate being founded, he felt the call of the sea once more. On the voyage, and following a shipwreck, Balduran made his way to Moonrise Towers in search of fortune. There, he found a coven of mind flayers who infected him with an illithid tadpole. As a record of his interrogation by Enver Gortash during the planning phases of the Absolute Hoax states, he spent ten years under the thrall of the Moonrise Elder Brain.\n\nAfter Balduran was reborn as an illithid and broke free from the Elder Brain the Absolute, it returned to Baldur\'s Gate, living in the shadows and feeding on the brains of criminals. Initially struggling with its identity as a mind flayer, Balduran eventually embraced its new form.\n\nBalduran\'s new acceptance of its illithid form caused a wedge to form between it and its close companion, the dragon Ansur. Ansur attempted to kill Balduran as it slept, believing this would be a merciful death. The Emperor sensed the attempt, and in its struggle to protect itself from being murdered, it killed Ansur in self-defence. [1]\n\nAfter Ansur\'s death, Balduran came to be called the Emperor as it used its newfound psychic influence to rule Baldur\'s Gate from the shadows. For the next four centuries, it made its haven under the Elfsong tavern, keeping various sentimental knick knacks from its time as Balduran.\n\n\nI had the fortune of meeting Duke Stelmane. We formed a partnership\nDuring those four centuries, it also came to be associated with the Knights of the Shield, a lawful and neutral evil conglomerate of politicians and merchants manipulating events behind the scenes. Duke Stelmane was a major figure of this secret society, acting as the Emperor\'s envoy while it secretly kept her enthralled. [note 2]\n\nSometime before the events of the game, Enver Gortash and the Dark Urge captured the Emperor, and brought it back under the thrall of the Moonrise Elder Brain, who was now wearing the Crown of Karsus and had become the Netherbrain masquerading as the Absolute. The Netherbrain, sought to have all three Chosen of the Dead Three killed, and specifically picked the Emperor, unbeknown to it, to lead a team of illithids on a nautiloid to search for and steal from the Githyanki the Astral Prism containing their prince, Orpheus.[2]\nEvents of Baldur\'s Gate 3\nAct Two finale\nMain article: Help Your Protector\nOn the way to Baldur\'s Gate, the party will be ambushed by a group of Gish\'ra warriors while resting at Wyrm\'s Lookout. Entering the portal to the Astral Prism, the party will hear their Dream Guardian calling out for help. However, when the party reaches them, it is only to discover that the true identity of their visitor is the illithid known as the Emperor.\n\nAfter defending the Emperor, it will explain how it used the power of the Prism and Orpheus to protect the party from the Absolute, and recite to the party its history as an adventurer and finding freedom from the Absolute. The Emperor will offer the party an Astral Touched Tadpole, which causes the user to transform into a partial-illithid. It insists the path of the mind flayer is preferable, regardless of the player\'s view on them.\n\nThough this may seen contradictory to its previous promise as the Dream Guardian; to ensure the party do not become mind flayers, this promise refers to the player becoming a mind flayer unwillingly because of the Elder Brain. The Emperor is in favour of the player becoming a mind flayer of their own volition and without the influence of the Elder Brain.\n\nAct Three\nElfsong Tavern\nMain article: Visit the Emperor\'s Old Hideout\nAs the party nears the Elfsong, the Emperor will remark that the tavern is the location of its old hideout. The hideout proper is in the basement, past the Knights of the Shield\'s hideout. In it, the player will find various sentimental knick knacks from the Emperor\'s previous life, before becoming an illithid.\n\nAround the room is its old dog Rascal\'s collar, its favourite recipe (fiddlehead soup), its first adventuring sword, and part of a cutlery set from its mother; the butter knife having been lost during its last shipwreck on the Isle of Balduran, inside the wreck of the Wandering Eye ship.\n\nThere are also some more illithid-adequate items such as chains for its preferred prey - allegedly criminals and lawbreakers - and jars for brains.\n\nThe Wyrmway\nSee also: Wyrmway and The Blade of Frontiers\nOnce the party completes the Wyrmway trials, they will find the corpse of Ansur the Dragon. Interacting with his body will awaken Ansur\'s spirit, which briefly possesses the player in order to communicate. As Ansur\'s introduction concludes, he will detect the Emperor within the Astral Prism.\n\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur\'s Gate 3.\n\nAnsur will reveal that the Emperor in fact was formerly Balduran, the founder of Baldur\'s Gate. Furthermore, he explains that while the Emperor initially did not want to become a mind flayer, it eventually fully embraced its new form, and its comfort with this caused a rift between the Emperor and Ansur. After ""exhausting all possibility of reversing (the Emperor\'s) condition"", Ansur was agonizing and the Emperor (as seen in the letter on Ansur\'s body) attempted to convince him to leave. Ansur then attempted to murder the Emperor during its sleep as a mercy killing, and the Emperor killed Ansur in self-defense.\n\nThis development is somewhat foreshadowed when the player first meets The Emperor in their true form, as the song that plays during the encounter is a variation of The Elf Song, which prominently features Balduran in its lyrics.\nEndings\nIco knownSpells lvl 03.png Act 3 Spoilers! This section reveals details about the story of Baldur\'s Gate 3.\n\nLet the Emperor use the Netherstones\nThe Emperor unless convinced otherwise is mostly concerned with its survival and prosperity. Should the player allow it to wield the Netherstones, it will follow through on destroying the Elder Brain, at the cost of letting it ""assimilate"" with Orpheus.\nIf the player suggests to the Emperor to take control of the Netherbrain, it will mention that the thought of becoming the Absolute did cross its mind. But unless otherwise persuaded, it will refuse, claiming that whoever becomes the leader of the Cult of the Absolute will be in an open war with the Githyanki, which is a war it is not certain it will survive. The Emperor will destroy the Netherbrain, and the parasites within its control in this ending.\nThe Emperor controls the Netherbrain\nIt is also possible, after suggesting it to take control of the Netherbrain, to persuade it. In this scenario, it does not free the player or their party, instead making them mindless thralls and assuming absolute control of them, continuing the Grand Design.\nOrpheus is freed\nIf the player frees Orpheus, the Emperor will abandon the party, and side with the Netherbrain for the sake of its own survival, as it believes that Orpheus will kill it.\nAttack the Emperor\nThe Emperor can be attacked and killed when it first reveals itself to be a mind flayer. This will result in the influence of the Netherbrain taking over control of the party, ending the game.\nList of interactions\nSee Dream Guardian to read about its previous conversations with the player when it was in disguise.\nCharm Person Icon.png Romance Spoilers This section reveals details about romance and may contain mature themes.\n\nPlayers have a limited number of opportunities to interact with the Emperor, and as such, opportunities for conversation are much more limited compared to that of companions.\n\nConversation scenes are available, but only occur during Act 3, after its ""true"" identity is revealed to the player, and all scenes require a long rest to trigger. The Emperor will occasionally also talk to the player as they walk through different locations in Baldur\'s Gate.\n\nConversation scenes\nKnown conversation opportunities with the Emperor currently include the following cases, but each scene appears to have multiple outcomes that affect the tone of all subsequent conversations.\n\nDepending on the player\'s choices, the Emperor\'s behaviour has many possible states. The more the player treats the Emperor like a ""person"", the more it will act as such, compared to other illithids. The more the player treats The Emperor like a monstrosity with hostile intent, the more it will respond to the player with threatening language and visions of it acting like a hostile illithid.\n\nIdentity revealed\nDuring Help Your Protector at the start of Act 3, a conversation is automatically triggered when the player ventures far enough into the Astral Plane. A combat encounter in some form is inevitable from this conversation, and then another set of conversation options are available after the combat resolves. The Emperor will have nothing further to say when this conversation ends, even if the player tries to interact with it further.\n\nRegarding Duke Stelmane\nWhen the player first explores the Rivington area, being in proximity to certain characters or objects will ""inform"" the player about the recent death of Duke Belynne Stelmane. This will trigger a line of ambient commentary from The Emperor. The next time a Long Rest is triggered, the player may trigger a scene discussing The Emperor\'s reactions in more depth. Certain dialogue choices made during earlier conversations seem to disqualify the player from this scene. If the player does not long rest before completing the quest Visit the Emperor\'s Old Hideout, this scene will be skipped entirely.\n\nOn conclusion of Visit the Emperor\'s Old Hideout\nThis scene may be available to trigger (by long resting) after the player completes the quest Visit the Emperor\'s Old Hideout.\n\nPossible states for this scene appear to vary heavily depending on the player\'s choices in prior conversation scenes, with the general differentiating factor being the ""attitude"" the player appears to express towards illithids, and towards the Emperor, through their selected options in these prior scenes.\n\nIf the player tried to kill the Emperor in Act One, by choosing the dialogue option ""You do a great impression of a human. But you\'re not fooling me."" , the Emperor offers to share memories through a vision. This vision shows Stelmane paralysed in pain, being brainwashed, and turning into the Emperor\'s puppet. Her face emotionless, and the Emperor puppeteering her gestures to get a sense of company. Such was its true relationship with Duke Stelmane. [note 2]\n\nThe Emperor uses this memory to frighten the player. It gives them orders, and threatens to make them half-illithid even if they refuse.\n\nRomance\nIn terms of game mechanics, it is technically possible to romance the Emperor. [note 3]\n\nIf the player chooses to reject its advances, the Emperor\'s attitude in conversation will change in a way that appears to be reactively appropriate to the way it was treated. For example, if the option ""Absolutely not, you freak!"" is chosen at any opportunity, the Emperor\'s treatment of the player takes a much more hostile tone in all future interactions.\n\nPlayers have a limited number of opportunities to interact with the Emperor, and as such, opportunities for romantically-styled interactions are much more limited compared to the other primary companions.\n\nIf the player visits Crèche Y\'llek prior to the start of Act 3, killing the Dream Guardian will subsequently lock the player out of romancing the Emperor, and from interacting with it in general.\n\nThere are many possible ways to interact with the Emperor in the available conversation scenes. It currently seems that the primary way to unlock ""romantic"" options is by choosing dialogue that generally treats the Emperor more like ""any other person"", and does not show explicit hostility towards its actions, or its illithid characteristics.\n\nThe player does not need to accept the powers of the Astral-Touched Tadpole to unlock this option. The Emperor seems to take offence to destroying the tadpole, but more testing is needed to determine if this has any effect on the available scenes.\n\nThe scene that occurs after completing Visit the Emperor\'s Old Hideout is generally regarded as the ""primary"" romantic scene. As long as the player is receptive to the Emperor\'s advances, conclusions to this scene will allow the player to engage in more intimate activities with it.\n\nConversation options that acknowledge this romance (after the primary scene has concluded) appear to exist in a limited number of places. For example, it is possible to tell Raphael ""I don\'t want any part of this — the Emperor is my lover."" during a specific conversation, if initiated after the romance scene has happened.\n\nEngaging in the primary scene has no effect on other ongoing romances, even when romancing Lae\'zel, who is generally hostile to illithids.\n\nAchievements\nA-Mind Blown.jpg\nMind Blown\nRomance the Emperor.\n\n\nGallery\nThey called me The Emperor\nThey called me The Emperor\n\n\nThe Emperor feeding on criminals\nThe Emperor feeding on criminals\n\n\nCharacter portrait by Edward Vanderghote\nCharacter portrait by Edward Vanderghote\n\n\nThe Emperor\'s model\nThe Emperor\'s model\n\nNotes\nThe Emperor\'s existence confirms the Dream Guardian as being an illithid influence, albeit in a different way.\nIn Early Access, the Dream Guardian (known then as Dream Visitor) was implied to be a mental manifestation of the player\'s tadpole, as it eased them towards using their powers more, as well as showing them a future of domination and control.\nIn the Full Release, the Emperor plays a similar role, in the sense that it also encourages the player to expand their potential through using the tadpole\'s power, but it is much more passive. In addition, its interests seem to be aligned against the Absolute.\nFootnotes\n The Emperor, like other mind flayers, is addressed using the ""it"" pronoun. It is incidentally referred to as ""he"" in-game, and ""they"" in the game\'s files, possibly due to an oversight, or characters conflating its current and previous identities.\n The Emperor\'s vision of its control over Belynne Stelmane is corroborated by the 5e module,  Baldur\'s Gate: Descent into Avernus. In it, Stelmane is described as having a secret, mental battle against a mind flayer. This mind flayer is very likely the Emperor itself, and as a result, puts its entire ""alliance"" with Stelmane into question. It is very possible the Emperor and Stelmane did not have a proper alliance at all, and rather, the Emperor enthralled her for its needs. Whether this was always the case, or if they had a genuine alliance beforehand, isn\'t fully clear.\n This romance behaves somewhat differently from that with companions, as the Emperor generally cannot be interacted with outside of cutscenes, and romantic progression is limited to the final act of the game.\nReferences\n Dialogue with Ansur.\n The Netherbrain\'s dialogue to the player at the Morphic Pool.'
 'Space Babies\n\nOriginal Airdate: 11 May 2024\n\n[Tardis]\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\nRUBY: Who are you?\nDOCTOR: I\'m the Doctor. You don\'t have to stand over there. Come and have a look. It\'s called the Tardis.\n(Snaps his fingers and the lighting changes.)\nRUBY: Ooo! Nice! But hold on. I can\'t call you Doctor. No, I want to know your name.\nDOCTOR: Yeah, that\'s er... that\'s tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They\'d use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you\'re a doctor, but you\'re... the police?\nDOCTOR: Police box. No. No, no, no, no, that\'s a disguise.\nRUBY: Oh.\nDOCTOR: Inside, it\'s a Time and Space machine, but outside, it\'s like a chameleon, \'cos once I landed in 1963 and they used to have police boxes on street corners.\nRUBY: 1963?\nDOCTOR: Yep.\nRUBY: Okay. Ooo, jukebox. I like that.\nDOCTOR: Mmm.\nRUBY: Okay, so, back to the planet.\nDOCTOR: My world was called Gallifrey.\nRUBY: Gallifrey? And where\'s that?\nDOCTOR: Gone! Ruby, it\'s gone. It\'s gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\nDOCTOR: Let\'s have a random landing.\nRUBY: Whoa!\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\nRUBY: No!\nDOCTOR: Really.\nRUBY: No, you\'ve got to be k... You are kidding. Don\'t be so ridiculous. Are there dinosaurs out there?\nDOCTOR: I don\'t know. Go and have a look.\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\nDOCTOR: Well, that\'s not going to happen, is it? Who steps on butterflies? You\'d literally have to be like, ""Wait. Come \'ere, butterfly! ""Come \'ere, \'ave it!""\n\n[Prehistoric Earth]\n\nRUBY: Oh, my God. That... that\'s so beautiful.\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we\'ve moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\n(A boot steps on a butterfly.)\nDOCTOR: Oh!\n(Ruby is no longer a human.)\nRUBATHON: What\'s wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\nDOCTOR: But...\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let\'s try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let\'s go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.\nRUBY: Ah, six!\nDOCTOR: Six! Ah! Five numbers! I like it!\n(The Tardis travels the Vortex.)\n\n[Space station]\n\nRUBY: But we\'re indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\nDOCTOR: We\'ve got to visit them one day.\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\nDOCTOR: Oh, it\'s, er... it\'s broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\nRUBY: Oh, it stinks\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\nRUBY: No, you\'ve made it worse.\n(Something snarls nearby. They both jump.)\nDOCTOR: No, that is worse.\nRUBY: Is that a monster?\nDOCTOR: No. No, don\'t be silly, Ruby. There\'s no such thing as monsters, there\'s just... just creatures you haven\'t met yet. Hi there.\n(The creature roars.)\nRUBY: Run?\nDOCTOR: Run! Run! Run!\n(They and the monster are visible on monitors as they run down passages.)\nDOCTOR: Come on! In here, in here, in here, in here.\nRUBY: But...now we\'re trapped! Now we\'re trapped! Push the button! Doctor!\nDOCTOR: Okay.\n(The tiny one-person lift takes them up. The Doctor\'s hand is over Ruby\'s eyes.)\nDOCTOR: Oh, yeah, yeah.\n(The lift abruptly arrives.)\n\n[Birth Zone 6]\n\nDOCTOR: The question is, why did I run?\nRUBY: \'Cos it was scary.\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn\'t run fast enough. I was like whoosh!\nRUBY: Well, it\'d help if we knew where we were.\nDOCTOR: Yet again, push the button.\n(The lights come on so they can see all the glassware, containing...)\nDOCTOR: Oh. Oh, we\'re on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\nRUBY: I was going to say the same thing to you.\nDOCTOR: We\'ve gone from baby to baby. I\'m not saying things are connected, and yet... things connect.\nRUBY: Well, I\'m the one looking for my parents, and you\'ve got a Time and Space machine. So this place grows babies. What for? Food?\nDOCTOR: Food? What? What?! Food? They\'re not tomatoes!\nRUBY: Well, excuse me. There\'s a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don\'t know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday. I don\'t have a people. I don\'t have a home. But I don\'t have a job, either. I don\'t have a boss, or taxes or rent or bills to pay. I don\'t have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\nRUBY: So where\'s this, then?\nDOCTOR: Oh, er...\n(Calls it up on a screen.)\nDOCTOR: Huh. Planet Pacifico del Rio.\nRUBY: Oh, that\'s in English. They speak English here? English exists?\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It\'s got a perception filter, so it helps you fit into every time and place.\nRUBY: Right, and my mum, she\'s long gone now.\nDOCTOR: Can I see your phone?\nRUBY: Yes.\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\nRUBY: What?\nDOCTOR: Carla. Phone her.\nRUBY: But...\nDOCTOR: Your mum, Ruby. Call your mum.\n\n[Ruby\'s home / Birth Zone 6]\n\nCARLA: Well? What is it now?\nRUBY: Mum?\nCARLA: Yes, Mum, obviously. You\'ve just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\nRUBY: Yeah. Yes, I will... I\'ll, er... I\'ll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\n\n[Birth Zone 6]\n\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That\'s the best signal ever. How much does that cost?\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It\'s calm up here, but underneath it is seething, just like downstairs with that creature. There\'s got to be a crew or a captain...\n(Enter a child in a motorised push-chair.)\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I\'ve opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can\'t...\nDOCTOR: Hi.\nRUBY: You all right?\nERIC: But... you. Oh. We\'ve been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we\'re not...\nERIC: Boys-oh-boys, I\'ve got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They\'re here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we\'ve been doing. Make them proud.\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\nMARCEL?: My job is to keep the pipes clean. I\'m proud of the pipes.\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\nSANDRA?: And I pull this string and that string. I\'m not sure what they do, but I pull them very hard.\nERIC: And I made this for you. It\'s a little flower.\nRUBY: Thank you.\nPOPPY: I\'m Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you\'d come back for us one day. We waited.\nDOCTOR: Right. You\'re not supposed to be running this place. This isn\'t Baby World. You got left behind when the adults... ..vamoosed?\nPOPPY: We took over. We were very brave.\nRUBY: Right. That\'s great. That\'s, oh, that\'s good. That\'s amazing. You\'ve done a really great job.\nDOCTOR: I\'m sorry, Poppy, I\'m so sorry, but we are not your mummy and daddy. I wish we were, but we\'re not.\nERIC: They left us. Where did they go?\nRUBY: I don\'t know, darling, but... I\'m Ruby and this... this is the Doctor. And we\'re your friends. Yeah, got you. I\'ve got you, I\'ve got you, I\'ve got you, I\'ve got you.\n(She picks up Eric from his pushchair.)\nBABIES: And me! And me! And me! And me!\nDOCTOR: Oh, gosh.\nBABIES: And me! And me!\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\nPOPPY: Never.\nDOCTOR: Oh. Oh, baby, it\'s okay. Come here, it\'s okay. It\'s okay, it\'s okay. Shh-shh-shh. Aww, never had a hug.\nRUBY: Come on, you can all have a hug.\n(Later, with everyone back in their pushchairs.)\nPOPPY: Did I get things wrong, Doctor\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don\'t know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\nPOPPY: But are we wrong?\nDOCTOR: What do you mean?\nPOPPY: We\'re not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That\'s okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don\'t know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That\'s it, P-P-P-P-Pop. But the point is, is that it doesn\'t matter where I come from, because I am absolutely lovely, aren\'t I?\n(Poppy yawns.)\nDOCTOR: That wasn\'t rhetorical, Pops.\nPOPPY: Yes, you are.\nDOCTOR: And do you want to know my secret? There\'s no one like me in the whole wide universe. No one like me exists, and that\'s true of everyone.\nIt\'s not a problem, Captain Pops. It\'s a superpower. High five. Yeah.\nPOPPY: Yeah!\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\nRUBY: So you\'re Eric. And you\'re Tasha. And Ruben. And then there\'s Saltine and Boo.\nERIC: I love you, Ruby.\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\nERIC: We\'ve got Nanny. Say hello, Nanny.\nNAN-E: Good afternoon, children, and welcome to our new visitors.\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I\'m the Doctor, and this is Ruby.\nNAN-E: We have visitors, children.\nERIC: Nanny!\nNAN-E: Noses must be blown. Activate nose-blow.\nDOCTOR: Er...\nNAN-E: One, two, three and... blow.\n(Mechanical hands on the pushchairs put handkerchiefs to the babies\' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\nRUBY: Oh, can\'t wait to see that.\nDOCTOR: Right. So it\'s you lot? It\'s Nan-E And downstairs, is that your pet dog?\n(Everyone screams and cries.)\nERIC: That\'s not a doggo.\nRUBY: What is it then, Eric?\nERIC: The Bogeyman.\nRUBY: Shush, shush, shush. Shush, shush, shush.\nDOCTOR: No. Gosh.\nERIC: We don\'t like the Bogeyman.\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\nDOCTOR: Bogeyman!\nRUBY: No, stop it! No, stop it! Nan-E, tell them there\'s no such thing as the Bogeyman.\nNAN-E: Nan-E is scared of the Bogeyman.\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I\'m sorry, I\'m sorry. I\'m sorry, babies. Space babies. I\'m sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what\'s that?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: That\'s on this floor. What is it?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\nNAN-E: Oh, for God\'s sakes, 3-5-7. Come on!\nRUBY: Where do you think you\'re going?\nDOCTOR: Portal 3-5-7!\nRUBY: Right. Great. Ok. Coming!\n\n[Corridor]\n\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That\'s like your... purpose?\nDOCTOR: No, no, I\'m just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum\'s still waiting for me.\nDOCTOR: Back home, on your birthday. Yeah, it\'s strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don\'t know anything about your birth mother or your father? They didn\'t leave a note or a scrap of paper...?\nRUBY: Nothing. I was... I was just left.\nDOCTOR: By the church.\nRUBY: In the snow.\nDOCTOR: On Ruby Road.\n(The Doctor sees a figure point at him by the church.)\nRUBY: Doctor...\nDOCTOR: What?\nRUBY: It\'s snowing. Okay, what just happened? I said snow, and we\'ve got... ..snowflakes.\nDOCTOR: It\'s like a memory just came through, from the day that you were born.\nRUBY: But how? Is this the sort of thing that happens with time travel?\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\nRUBY: Then what does it mean?\nDOCTOR: I don\'t know.\n(The snow has stopped.)\nDOCTOR: Oh, I thought my birth was crazy...\nRUBY: Oh, yeah.\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\n(A door opens.)\nJOCELYN: I said Portal 3-5-7. Don\'t just stand there yapping, you pair of idiots. Get inside!\nRUBY: Who\'s she?\nDOCTOR: Nan-E. Ha!\nRUBY: Oh.\n\n[Portal 357]\n\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I\'m signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I\'d like to say for the record, the company\'s actions are appalling. I will be launching an appeal against this as soon as we\'re home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It\'s the recession. The government closed the Babystation to save money, but the law says it\'s illegal to stop the birth machine.\n(Another leak, another thump with the wrench.)\nJOCELYN: But how did you arrive? Have you got a way out of here?\nDOCTOR: I\'ve got a ship, yeah, it\'s er... What is your name - sorry, Nan-E?\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don\'t know how this place works.\n(The Doctor plugs his sonic into the computer.)\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\nJOCELYN: Thank you. Wanna swap?\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they\'re born, they don\'t look after them?\nJOCELYN: It\'s a very strange planet.\nRUBY: It\'s not that strange.\nDOCTOR: But you stayed behind.\nJOCELYN: I couldn\'t leave them. And I tried with this place. But I\'m not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It\'s a mess. And I\'ve been all on my own, watching the kids, for six years.\nDOCTOR: But I don\'t understand. They are gorgeous. Why would you hide?\nJOCELYN: Cos I don\'t want to see them die. And I don\'t want them to see me die. \'Cos that\'s how bad it is. This is a closed station. There\'s only so much air. There\'s only so much food. The last thing I\'ll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\nRUBY: Can\'t you fly somewhere else?\nJOCELYN: What do you mean, fly?\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can\'t move. It\'s just stuck in orbit, which is a shame, because this is a nice little system.\nJOCELYN: The fifth planet out, Mondo Caroon, that\'s a DuBarryDuPlessy world.\nDOCTOR: Oh, that\'s good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\nRUBY: Oh. Well, can\'t we call them for help?\nJOCELYN: They don\'t go and fetch refugees. That\'s the fate of every refugee in the universe. You physically have to turn up on someone else\'s shore. And we can\'t move.\nDOCTOR: But now you have a ship. Plenty of room. It\'s called the Tardis. The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don\'t know?\nJOCELYN: It\'s nothing to do with me. It\'s not part of the manifest. It\'s not like anything I\'ve ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it\'s terrifying.\nDOCTOR: Yeah, but I\'ve met a million ugly bugs. I\'m an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you\'ve got babies, you\'ve got a nanny, and you\'ve got the Bogeyman. You\'ve literally got a monster living down below. It\'s a children\'s story come to life.\nDOCTOR: And every story has its hero.\n(They spot someone on the screen.)\nRUBY: That\'s Eric. Is that Eric?\nJOCELYN: Eric, get out of there.\n\n[Space station]\n\nNAN-E: Eric, please vacate this area.\n\n[Portal 357]\n\nDOCTOR: Oh, is that how it works?\nJOCELYN: Nan-E filter. Eric, get out now.\n\n[Space station]\n\nNAN-E: Eric will leave immediately.\nERIC: No, Nanny! I\'m being brave.\n\n[Portal 357]\n\nJOCELYN: Eric, for God\'s sake, run!\n\n[Space station]\n\nNAN-E: Eric, invoking the deity, accelerate perambulation.\nERIC: I\'m doing what Ruby said.\n\n[Portal 357]\n\nRUBY: What?\n\n[Space station]\n\nERIC: I love Ruby, and she said there\'s no such thing as the Bogeyman. So I\'m going to find the naughty doggo and tell him off.\n(He meets the Bogeyman.)\nERIC: But I\'m so scared.\n\n[Portal 357]\n\nRUBY: Oh, my God, it\'s my fault!\n\n[Birth Zone 6]\n\nRUBY: Eric, I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming!\n\n[Space station]\n\n(Ruby and the Doctor take the little lift down, and find Eric\'s pushchair fallen over.)\nRUBY: Oh.\nDOCTOR: Nan-E, where\'s the Bogeyman?\n\n[Portal 357]\n\nJOCELYN: It\'s about 400 metres north-west of you. But still no sign of Eric. I can\'t get a proper fix. I told you, these systems are a crock of...\n\n[Space station]\n\nNAN-E: ..waste products.\nDOCTOR: Mind your language, Nan-E.\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\nDOCTOR: Yes.\nRUBY: Okay, right.\nDOCTOR: Yes. Yes, yes.\n(They pick up things to hit the pipework with and move off.)\nRUBY: Bogeyman! Bogeyman!\nBOTH: Bogeyman! Bogeyman!\n\n[Portal 357]\n\nJOCELYN: It\'s moving. It\'s heard you.\n\n[Space station]\n\nRUBY: Okay, nice plan, but what now?\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. \'Cos I can detect...\n(In a locker.)\nDOCTOR: Space baby! Oh, Eric.\nRUBY: We\'ve got you, we\'ve got you.\nDOCTOR: Oh, you poor thing. It\'s okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It\'s all right, it\'s all right. It\'s all right, it\'s all right, it\'s all right. All right, all right. It\'s all right.\nRUBY: It\'s okay, it\'s okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don\'t you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It\'s a dead end.\n(The Bogeyman is there.)\nDOCTOR: Whoa! It\'s okay, it\'s okay. You\'re okay.\n(The Bogeyman is attacked by flames. It runs away.)\nPOPPY: Babies to the rescue!\nDOCTOR: Ha! Space babies!\nRUBY: Babies with a flame-thrower!\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\n(He whistles up Eric\'s pushchair.)\nRUBY: Okay, let\'s get you in here, come on. Let\'s get you in there. Nan-E, tell them what to do.\nNAN-E: Children will return to the upper levels or have no expletive dinner.\nBABIES: Goodbye.\nDOCTOR: Okay, er, you... you go with them. I\'ve got to stay here. Not just for the Tardis, but I\'ve got to find out what that thing is.\nRUBY: If that\'s you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\n(They head back through the stinky area.)\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\n\n[Portal 357]\n\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don\'t know how it even exists.\n\n[Space station]\n\nRUBY: And that was six years ago?\nDOCTOR: Shh-shh-shh.\nRUBY: Oh. That\'s the same time the babies were born.\nDOCTOR: It\'s leaving... some sort of spoor. Man, that\'s a good word. Spoor.\nNAN-E: What the bleep-bleep is that?\nRUBY: Oh, Jocelyn, turn the filter off.\n\n[Portal 357]\n\nJOCELYN: What is that stuff?\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\nJOCELYN: The machine\'s got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\n\n[Space station]\n\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\n(She slips then gets dribbled on from a pipe outlet.)\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don\'t call me Rubes!\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let\'s make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We\'ve been saying it all along. It\'s all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It\'s like a story. The teaching software, it told a story.\nDOCTOR: It invented the Bogeyman.\nRUBY: For the babies.\nDOCTOR: For the space babies.\nRUBY: The machine is literal, like a computer. It literally said, ""Babies need fiction, they need stories, they need monsters.""\nDOCTOR: Yes. That is why I\'m so scared. It\'s all deliberate, it\'s infrasound. The Bogeyman is roaring at 17 hertz, that\'s the exact pitch designed to make you scared. It\'s scary because it\'s meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\nRUBY: What.\nDOCTOR: Oh, Ruby.\nRUBY: What?\nDOCTOR: Oh, man.\nRUBY: Tell me what it is.\nDOCTOR: I can\'t.\nRUBY: Doctor!\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\nRUBY: I don\'t know.\nDOCTOR: The machine is literal, and the name is Bogeyman.\nRUBY: So?\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\nRUBY: What?\nDOCTOR: All of this is bogeys.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: No wonder it was shedding its skin. Doesn\'t everyone?\nRUBY: No, no, no, no.\nDOCTOR: It\'s snot.\nRUBY: It\'s not.\nDOCTOR: Oh, Ruby, it is a living sneeze!\nRUBY: But it\'s in my...\nDOCTOR: I know.\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don\'t laugh!\nDOCTOR: Sorry. Oh, isn\'t the universe mad?\nRUBY: Oh yeah, it just made a monster out of snot.\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\n(The monster is in front of them.)\nRUBY: Bogeyman.\nDOCTOR: Run. Run! Go!\n(A barrier blocks their path.)\nDOCTOR: No, no, no, no!\n\n[Portal 357]\n\nJOCELYN: Don\'t worry, it\'s me. Turn right. It\'s your device. It\'s calibrated. It\'s brilliant! I\'ve got control at last. Now trust me. Turn right!\nDOCTOR [on screen]: This isn\'t the way to the lift!\nJOCELYN: Keep going.\n(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I\'m coming, I\'m coming!\n\n[Portal 357]\n\nJOCELYN: It\'s catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I\'ve got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It\'s an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn! I... She\'s got the sonic. Jocelyn, Jocelyn!\nCOMPUTER: Oxygen field at 10%.\nDOCTOR: Okay, okay, okay, okay. We haven\'t got time. Stop Jocelyn, yeah?\nRUBY: Wait...\nDOCTOR: Left, second right, next left, you\'ll get to the lift.\nRUBY: What about you?\nDOCTOR: Left, second right, next left!\nRUBY: Right, okay.\n(She runs off.)\n\n[Control room]\n\nCOMPUTER: Oxygen field at 9%.\nPOPPY: You\'re hurting him.\nERIC: Stop it, Nanny. Stop it!\nCOMPUTER: Oxygen field at 8%.\n\n[Airlock door]\n\nDOCTOR [memory]: I am the last of the Time Lords.\nRUBY [memory]: How do you keep going?\nDOCTOR [memory]: For days like this. I\'m the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\nDOCTOR: The only one of its kind.\nCOMPUTER: Oxygen field at 7%.\n(The Doctor opens the airlock door and holds it open with his body.)\nCOMPUTER: Oxygen field at 6%.\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\nCOMPUTER: Oxygen field at 3%.\nDOCTOR: Push...the button.\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\n\n[Portal 357]\n\n(Ruby runs in and grabs the sonic.)\nJOCELYN: No!\nRUBY: That\'s what you do, Jocelyn. You save them all.\nCOMPUTER: Oxygen field at 1%.\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\nRUBY: You save them all. Come here. It\'s okay, it\'s okay.\n(Jocelyn cries in Ruby\'s arms.)\n\n[Control room]\n\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\nERIC: Nanny was really naughty.\nJOCELYN: I know, and I\'m so sorry. All of you. I was just... on my own for such a very long time.\nERIC: We still love you, Nanny.\nBABIES: Yay! We do!\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\nBABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can\'t get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? \'Cos the system went wrong, and that\'s where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\nDOCTOR: Oh, set sail for your new home. Baby World!\nRUBY: Come here now. Are you happy now, Eric?\nERIC: I\'m very, very happy. I love you, Ruby.\n\n[Outside the Tardis]\n\nRUBY: So that was a normal day for you, then?\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\nRUBY: What for?\nDOCTOR: I have the whole universe at my fingertips, and I\'m all on my own. So I\'d love it if you came with me.\nRUBY: To what, just travel?\nDOCTOR: No job. No boss. Just fun.\nRUBY: We did almost die.\nDOCTOR: Yes. But we lived so much, too.\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\nDOCTOR: Yes?\nRUBY: Yes.\nDOCTOR: Yes?\nRUBY: Yes. Oh, my God.\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\nRUBY: Come on in. Follow me.\nDOCTOR: Oh, come on.\n\n[Tardis]\n\nRUBY: Right, mate, let me tell you where we\'re gonna go.\nDOCTOR: Except...\nRUBY: Oh, terms and conditions.\nDOCTOR: There is one thing that I can never do, Ruby. And that\'s take you to that church on Ruby Road that Christmas. Absolutely never.\nRUBY: But you\'ve got a time machine.\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother\'s story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can\'t. And I won\'t.\nRUBY: Well, that\'s a pity. \'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\n\n[Ruby\'s home]\n\nCARLA: (on phone) And Ruby phoned, she said, ""I love you,"" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What\'s that noise?\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\nCHERRY: What the blinking flip?\n(Tardis door opens.)\nRUBY: Hiya, Mummy.\nCARLA: But... what are you doing? And what the hell is that? What\'s it done to my kitchen?\n\n[Tardis]\n\nRUBY [OC]: Hey! Come and say hello!\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\n(He sonicks up a quick DNA scan of Ruby Sunday.)\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\n(He doesn\'t wait for the results of the scan.)'
 ""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""]","Duke Stelmane was a major figure associated with the Knights of the Shield, a secret society in Baldur's Gate 3. The Emperor, who is a mind flayer, had a partnership with Duke Stelmane and kept her enthralled. The details of their relationship and the nature of their alliance are explored in the game, particularly in relation to the Emperor's past and its influence over Stelmane.",1.0,0.877619325444233,0.001314060446780552,0.9999999999,1.0
What items do Rudolf's family take from the Jews and who takes them?,"Rudolf's wife, Hedwig, often receives luxury and expensive items taken from the Jews. On one occasion, she is seen receiving a fancy fur coat with lipstick lying inside one of the pockets. The Rudolf's children are also seen collecting and playing with gold teeth taken from the remains of the dead Jews.","['The best sci-fi and fantasy books of 2023\nIt’s been a stellar year in speculative fiction\n\nBy Nicole Clark, Sadie Gennis, and Polygon Staff  Updated Dec 8, 2023, 10:00am EST  34 Comments / 34 New\nIf you buy something from a Polygon link, Vox Media may earn a commission. See our ethics statement.\n\nIt’s been another banner year for science fiction and fantasy books. Many of our favorites once again blur the line between sci-fi and fantasy, but this year was a particular standout for books blurring the line between SFF and other genres. This includes everything from historical fiction — both speculative histories and Westerns — to fable retellings to intergenerational sagas in translation.\n\nThough we seem to have crested the wave of pandemic novels, that sense of dread and discoloration has lingered, written into novels of new forms. There’s a preponderance of post-post-apocalyptic science fiction unpacking lofty ideas like sentience and humanity, often set on different planets or among the stars. It has also been a standout year for supernatural horrors and thrillers, particularly ones that mix queer longing with a dose of body horror. Last but not least, it’s been a great year for kissing books set in fantastical worlds.\n\nRELATED\n\nLooking for more recs? Here are our favorite books of 2022\nSo jump in and take your pick. Whichever direction you head in, it will be sure to grip you — and make you think. This list is in reverse chronological order, so the newest releases are listed first. We updated this list throughout 2023, sometimes retroactively adding in entries that we missed from earlier in the year. We’ve also included our favorite runners-up.\n\nHONORABLE MENTIONS\nEmily Wilde’s Encyclopaedia of Faeries by Heather Fawcett, Victory City by Salman Rushdie, The Crane Husband by Kelly Barnhill, The Mimicking of Known Successes by Malka Older, Monstrilio by Gerardo Sámano Córdova, White Cat, Black Dog by Kelly Link, Divine Rivals by Rebecca Ross, Our Hideous Progeny by C.E. McGill, The Cheat Code (Wisdom Revolution #3) by Misba, The Deep Sky by Yume Kitasei, Silver Nitrate by Silvia Moreno-Garcia, Vampires of El Norte by Isabel Cañas, Prophet by Sin Blaché and Helen Macdonald, Terrace Story by Hilary Leichter, Her Radiant Curse by Elizabeth Lim, Starling House by Alix E. Harrow, System Collapse (The Murderbot Diaries #7) by Martha Wells, Dark Heir (Dark Rise #2) by C.S. Pacat\n\nCover image for Ed Park’s Same Bed Different Dreams, a split image between what looks like Earth and Mars.\nImage: Random House\nSAME BED DIFFERENT DREAMS BY ED PARK\nSame Bed Different Dreams is a remarkable achievement, and not for the faint of heart. Through three storylines, the book creates a kind of speculative history of Korea, with an emphasis on World War II and Japan’s colonial rule and aftermath (and, crucially, the United States’ involvement). One story thread builds out a hefty alternative history of the Korean Provisional Government’s role and reach. Another story thread focuses on a Black Korean War vet who wrote a sci-fi epic series called 2333, which is later adapted into a video game. And yet another story thread has a more futuristic flavor, focusing on a has-been writer who now works for a tech company called GLOAT. These threads periodically intersect — for example, GLOAT ends up owning the rights to 2333, and turns it into a kind of edutainment.\n\nIf it sounds like there’s a lot going on, it’s because there is. And it’s made even denser by the author’s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking — like a character’s dog who can’t stop “archiving” by burying found manuscript pages, the fact that GLOAT employees truly don’t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what’s real and what’s Ed Park’s “alternate history” in sections with realistic-sounding combinations of fact and fiction.\n\nIt’s got the same ambitious patchwork as Jennifer Egan’s The Candy House and Namwali Serpell’s The Old Drift. Critics have compared it to everything from David Mitchell’s Cloud Atlas to David Foster Wallace’s Infinite Jest. There’s also, of course, books within the book. It’s a fever dream of a thing, and one I’d heartily recommend, but perhaps with a notebook in hand or some sticky notes to help track the references. (Or perhaps, as I did, just letting the wave of information roll over you, until you’re left with a vast impression and a desire to reread.) —Nicole Clark\n\nCover image for Kylie Lee Baker’s The Scarlet Alchemist, featuring a woman in a red outfit with a large crown set against a dark skyline.\nImage: Inkyard Press\nTHE SCARLET ALCHEMIST (THE SCARLET ALCHEMIST #1) BY KYLIE LEE BAKER\nDo not go into The Scarlet Alchemist expecting typical YA fare. What Kylie Lee Baker delivers is a story of visceral brutality, interlaced with elements of Chinese history and thoughtful meditations on family, race, and belonging. It’s a book that can turn your stomach as easily as it can break your heart.\n\nSet in an alternate Tang dynasty, the novel follows Zilan, a profoundly talented young alchemist who travels to the capital in hopes of landing a coveted position in the royal service. But being a poor, half Scotian girl means the odds are stacked inordinately high against her in the imperial service exams — and that’s before her skills with the illegal art of resurrection catch the prince’s attention and pull her into a dangerous political game. While the premise seems familiar (underdog competes in trials, falls into star-crossed romance), Baker’s skills with immersive world-building, knotty characters, and genuinely gruesome horror make The Scarlet Alchemist a dazzling and singular tale that left me rushing to read her back catalog. —Sadie Gennis\n\nCover image of C Pam Zhang’s Land of Milk and Honey, featuring rollicking hills of white, blue, and yellow.\nImage: Riverhead\nLAND OF MILK AND HONEY BY C PAM ZHANG\nAfter I read How Much of These Hills is Gold in 2020, C Pam Zhang became an instant must-read author in my household. Land of Milk and Honey is entirely unlike her debut — where her debut’s language was sparse and pointed, this book is florid and indulgent — though similar in the extent to which it transported me somewhere entirely new, and more than a little threatening.\n\nIn Land of Milk and Honey the climate apocalypse has rendered fresh produce, at scale, a thing of the past — which is to say a provision of the extremely rich. The protagonist, listless and hungry, applies for a job as a private chef for a mysterious family in the Italian Alps (those who live around it call it “\u200b\u200bla terra di latte e miele”). While there, she unravels the family’s true intentions, while making them delicious meals from rare ingredients.\n\nZhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient — and sometimes the cruelty of that ingredient’s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. —N. Clark\n\nCover image for Megan Kamalei Kakimoto’s Every Drop is a Man’s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN’S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind. Each story weaves together Hawaiian mythology and the everyday lives of the Hawaiian and mixed-race Japanese women who live there.\n\nThese stories range from fabulism to science fiction, all speculative fiction in their own way. In one story, a woman’s encounter with a wild pig ends up foreshadowing a complicated pregnancy later in her life. In another story, a Brazilian waxing company allows people to pay for hairless skin by giving up personality traits. In another story, the narrator falls for a woman who lives with her family — in one of numerous queer stories in the collection — but has to cope with that woman’s decision to return to “what remains of Kaua’i” and join their protests.\n\nThe author’s own words, published in The Guardian, sum it up best: “There is a mythical idealisation of the islands of Hawaii as paradise, peace in the tropics; some even call it a modern utopia. Yet this flattening of Hawaii to a postcard image divests our homeland of its culture and colour, reducing us to a place and history that is easily digestible. But we are not easily digestible, and our stories are not meant to be easy for you.” —N. Clark\n\nCover image for Shelley Parker-Chan’s He Who Drowned the World, a painted image of ships on a yellow sea, with the moon looming over them.\nImage: Tor\nHE WHO DROWNED THE WORLD (THE RADIANT EMPEROR #2) BY SHELLEY PARKER-CHAN\nAn alternate history of the founding of the Ming dynasty, He Who Drowned the World shifts between four tragically ambitious figures willing to pay any price to materialize their destiny, whether that’s revenge on the empire or crowning themselves the ruler of it. They pursue these goals with unshakeable inertia, doing endlessly cruel and sadistic actions with only the occasional doubts as to whether happiness could be possible if they chose a different path.\n\nThis is a relentlessly brutal sequel, and there’s a hopelessness that weighs heavy throughout the book. But Parker-Chan’s penetrating ability to bring empathy and nuance into even the darkest corners of humanity sparks an undeniable connection with these characters, whose self-destructive natures would otherwise be too hard to bear witness to. He Who Drowned the World is a dark and difficult read, yet Parker-Chan’s prose is so brilliant, her character work so complex, that I still found myself sad to leave this world behind. —SG\n\nCover image for M.A. Carricks’s Labyrinth’s Heart, featuring a mask-wearing figure with purple wings sprouting out of the top of the mask.\nImage: Orbit\nLABYRINTH’S HEART (ROOK & ROSE #3) BY M.A. CARRICK\nOne of my favorite fantasy series of the past five years, Rook & Rose is an intricately layered trilogy where there are so many secrets, schemes, and conspiracies that at times it’s admittedly difficult to keep track of them all. Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth’s Heart. (Ren alone was juggling four different identities at the novel’s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series’ end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth’s Heart that feel like they were precisely crafted to cater to fans, but here’s the thing: I don’t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nadežra after a two-year wait. While things may have been tied up a bit too neatly for my usual tastes, that didn’t stop me from whipping through pages and smiling the whole way through. Sometimes it’s nice to simply soak in a happy ending rather than bathe in the bittersweet. —SG\n\nCover art for Kiersten White’s Mister Magic, which features a melting television against a pink background.\nImage: Del Rey Books\nMISTER MAGIC BY KIERSTEN WHITE\nThe latest fantasy-with-an-irresistible-pop-premise from the author of Hide, Mister Magic revolves around a children’s TV show no viewer can forget … or prove it ever existed in the first place. There are no official records of it, no YouTube videos or merchandise or passed-around VHS tapes, and any discussion of it on the internet rapidly disappears. But the people who remember seeing it are convinced the special effects were remarkably vivid and realistic. They agree the central concept is unnerving: a creepy magician-figure leading a group of children in imagination-games aimed at teaching some decidedly non-standard lessons about embracing conformity and meekness. And they’re all sure that something horrible happened while they were watching, though they can’t agree on what.\n\nA reunion between five of the former child cast members, taking place 30 years after the show ended, slowly unravels its mysteries, which are even weirder than the description above suggests. Mister Magic is a startling dark fantasy with a lot of foreboding, foreshadowing, and eerie twists. At heart, though, it’s also an incisive story about the kinds of people who revel in control over other people’s lives, and about what an act of rebellion imagination can be. —Tasha Robinson\n\nCover image for Rebekah Bergman’s The Museum of Human History, featuring a painted image of a naked figure with a red cloud over the top of their head.\nImage: Tin House\nTHE MUSEUM OF HUMAN HISTORY BY REBEKAH BERGMAN\nA poetic reflection on memory, loss, and connection, The Museum of Human History is a stunning debut reminiscent of the work of Emily St. John Mandel. Slipping backward and forward in time, this introspective mosaic weaves between an identical twin whose sister fell asleep at age 8 and has never aged in the 25 years since, a museum director who questions his place within the family legacy, a widower who lost his most cherished memories as a result of an anti-aging treatment, and others equally struggling with the passage of time. There is a lyrical detachment in Bergman’s prose that leaves you feeling like you’re watching events unfold through a pane of thick glass, never fully able to connect with the characters, yet you remain helplessly transfixed by the haunting cycle they’re caught in. It’s an incredibly melancholy book, but the kind of aching sadness you’re happy to sink into. —SG\n\nCover image for Sara Hashem’s The Jasad Heir, featuring what looks like statues of a snake,, a bull, and a griffin.\nImage: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n“Arin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.” This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I’ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens’ innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist’s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl. Using her life as leverage, the calculating Arin strikes a deal with Sylvia to help him capture a group of Jasadi rebels and act as his champion in a series of deadly trials. It’s a familiar setup, but one impeccably done by Hashem, who delivers sharp political intrigue, sparkling banter, and touching friendships on top of Sylvia and Arin’s simmering romance. —SG\n\nCover image for Kritika H. Rao’s The Surviving Sky, featuring a floating island overgrowing with buildings and plant life, above a stormy planet.\nImage: Titan Books\nTHE SURVIVING SKY (THE RAGES TRILOGY #1) BY KRITIKA H. RAO\nAfter I finished The Surviving Sky, I wouldn’t shut up about it and tried (not always successfully) to get everyone I know to read it. So let me try once more, and maybe with less yelling this time:\n\nWith the planet’s surface made unlivable by catastrophic storms, the remains of humanity survive on floating cities constructed of and powered by plants that only a select group of people, known as architects, can control. An archeologist without the ability to traject plants, Ahilya has dedicated her life to finding a way to unshackle humanity’s survival from the architects’ powers and return to the surface. It’s not hard to see why this mission causes friction in her marriage to Iravan, one of the most powerful architects in their city, and one with an arrogance to match his revered status. Though estranged, Ahilya and Iravan come together to help clear his name after he’s accused of pushing his powers dangerously far, an accusation, which if proved true, carries dire consequences for the architect.\n\nBut the deeper they look into trajection and its risks, the more Ahilya and Iravan realize they don’t actually know much about where their people – and their powers – came from. And as the floating cities begin to sink toward the earthrages below, the race to save their civilization may also be the end of society as it stands, as Ahilya and Iravan uncover long-buried truths that previous generations worked hard to keep hidden.\n\nSo did I do it? Did I convince you to read this Hindu philosophy-inspired debut with some of the most inventive world-building and one of the most complex romances I’ve read in years? Please say yes. You’ll be doing us both a favor. —SG\n\nCover image for Alexander Darwin’s The Combat Codes, which features a metallic dragon against a black background.\nImage: Orbit\nTHE COMBAT CODES AND GRIEVAR’S BLOOD (THE COMBAT CODES SAGA #1-2) BY ALEXANDER DARWIN\nIn the world of The Combat Codes, war no longer exists as it used to. Neither does justice — both concepts have been replaced by proxies who fight on behalf of nations or individuals, solving disputes with their fists.\n\nAlexander Darwin’s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic “magical school for gifted youngsters” situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books’ excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar’s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can’t wait for the conclusion next year. —Pete Volk\n\nCover image for Katie Williams’ My Murder, showing a woman’s face peering outside of red vertical lines.\nImage: Riverhead Books\nMY MURDER BY KATIE WILLIAMS\nFans of Sarah Gailey’s The Echo Wife won’t want to miss My Murder, which shares some key elements and themes with Gailey’s novel while also taking them in a unique direction. In a near-future with only a few light sci-fi elements, Lou has been resurrected along with a handful of other women murdered by a single serial killer. The politics of resurrection in her world are complicated, and few people qualify. That leaves her and her fellow victims (whose therapy circle recalls Grady Hendrix’s The Final Girl Support Group) a bit at sea as they try to come to terms with their deaths, which none of them can recall, and their new lives as celebrities for all the wrong reasons.\n\nLike The Echo Wife, My Murder ends up thoughtfully exploring issues around women subjected to violent men — not just the personal and internal response, but the society that shapes that violence, and responds to it in ways that raise endless questions. The victims all respond to their deaths differently, questioning their culpability and the possible failures that might have made them targets, and navigating their families’ unpredictable responses to their revival. There’s one big mystery at the heart of My Murder, and a whole lot of abrupt and compelling surprises. But at the core, it’s a sci-fi twist on the survivor story, letting some very different people explore what it means to be victimized, and how to reclaim the lives that have been abruptly handed back to them. —TR\n\nCover image for Ann Leckie’s Translation State, a minimalist drawing with red, orange, and green, a silhouette of a person, and circular lines.\nImage: Orbit\nTRANSLATION STATE BY ANN LECKIE\nSet in the same universe as Leckie’s Imperial Radch trilogy, Translation State follows Enae, who leaves hir long-standing isolation for what was supposed to be an interstellar goose chase. After hir demanding grandmaman dies, Enae is given a diplomat title and assigned to investigate a missing Presgr translator no one expects to be found (but that the government still wants the goodwill for pretending to look for). Only, Enae doesn’t just pretend to look; sie discovers sie has quite the knack for investigating the 200-year-old cold case.\n\nThis is how hir path crosses that of Reet, an adopted maintenance worker whose mysterious origins and unsettling impulses might be explained by being the child of the fugitive translator, if you ask Enae, or the last descendant of a lost sovereign line, if you ask one particularly zealous diaspora social group. Rounding out the POV characters is Qven, a young Presgr terrified of their species’ ritual of merging with an elder, a rite of passage which will see Qven’s selfhood entirely dissolved. Enae, Reet, and Qven’s explorations of their own identities wind up having interplanetary consequences, but it’s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I’m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie’s world. So don’t hesitate to jump into Translation State if you’re – like me – new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. —SG\n\nCover image for Rita Chang-Eppig’s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.\nImage: Bloomsbury Publishing\nDEEP AS THE SKY, RED AS THE SEA BY RITA CHANG-EPPIG\nI still remember standing in my local bookstore, struck by the cover of this book, and reading the summary. It had me at “Chinese pirate queen.”\n\nIn Deep as the Sky, Red as the Sea, Chang-Eppig writes a historical fantasy about Shek Yeung, a fearsome Chinese pirate who must navigate her fleet after the death of her powerful husband. She marries her late husband’s second-in-command, with the promise of bearing an heir, in order to retain power over the fleet — and stay a major player as the Chinese Emperor seeks to rid the waters of piracy.\n\nThe book isn’t paced like a thriller, so don’t make the mistake of assuming so when you start it. It’s equal parts historical exposition, strategy, and warfare — and it especially excels in its characterization of a complicated woman forced to make difficult decisions and sacrifices in order to protect her power. Fantasy can put its villains and heroes on pedestals, but Deep as the Sky, Red as the Sea never errs in its very human portrayal of Shek Yeung, and how deftly she must play this game of political chess for survival. I was riveted. —N. Clark\n\nCover art for Emma Törzs’ Ink Blood Sister Scribe, featuring a dripping pen growing out of the bottom of a tree against a purple background.\nImage: William Morrow\nINK BLOOD SISTER SCRIBE BY EMMA TÖRZS\nThere’s nothing cozier than a magical book about the magic of books — though this tale bends a little darker, and tells a story about witchcraft and complicated family dynamics. In Ink Blood Sister Scribe, two estranged sisters come together to solve the mystery of their family, and prevent further tragedies. In this world, blood can be concocted into ink — wielded by scribes for the creation of books with arcane powers — though the creation of such books drains a scribe’s health. When others read these books, they create magic; willing flowers to bloom, or making magical carpets that can fly in the air.\n\nInk Blood Sister Scribe is the perfect sister thriller to read in one sitting. It doesn’t reinvent the wheel, but it doesn’t need to — it simply delivers on a wonderfully entertaining premise. —N. Clark\n\nCover art for Martha Wells’ Witch King, featuring a person running across the cover while wearing a cloak and dress fitting for a fantasy setting.\nImage: Tor\nWITCH KING BY MARTHA WELLS\nIn an era where a lot of fantasy fans value quick or cozy reads, Martha Wells’ Witch King feels like a gauntlet thrown at readers’ feet. It’s a complex, meaty fantasy that opens well into what a more linear book would consider the third act, as Kai, the witch king of the title, is exhumed from a watery grave and starts exploring who betrayed him and trapped him there. Readers have to learn everything about Kai’s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a “witch king” is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells’ Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them. Wells packs Witch King with a lot of audacious, expansive world-building for a standalone novel (albeit one that could easily invite sequels or prequels), but what makes Witch King an enjoyable read instead of a frustrating one is the way all the book’s complications and surprises are filtered through Kai’s vivid inner life, giving readers something to hold onto as they’re untangling the puzzlebox aspects of this cleverly structured novel. —TR\n\nCover image for Justin Lee Anderson’s The Lost War, featuring five figures walking through white grass after emerging from a dark green forest. Three of the figures wear green cloaks, while two wear white.\nImage: Orbit\nTHE LOST WAR (THE EIDYN SAGA #1) BY JUSTIN LEE ANDERSON\nOriginally self-published in 2019, The Lost War is a traditional fantasy adventure that follows a rag-tag group of strangers on a mission across a war-torn country, fighting monsters and uncovering mysteries along the way. Despite the strong buzz leading up to the novel’s expanded publication by Orbit this year, I found myself hesitant to pick it up since it seemed so similar to many books I’ve read before. But while it’s true The Lost War doesn’t rewrite the genre – it’s filled with well-worn tropes and classic adventurer archetypes – Anderson’s skillful execution left me completely charmed. There is a real Dungeons and Dragons feel to The Lost War, and though the characters are familiar (the honorable paladin, the hard-drinking haunted soldier), Anderson does a fantastic job developing unique dynamics between the party members that vault the book beyond the sum of its parts. And it all builds up to a massive twist at the end that completely upends your understanding of what you’ve read and any previous expectations for where the second book will go. The delightfully unexpected ending once again has the fantasy community buzzing ahead of Anderson’s next release – only this time I’m right there with them. —SG\n\nCover image for Moniquill Blackgoose’s To Shape a Dragon’s Breath, a red cover with flowers and a dragon’s head/mask on it.\nImage: Del Rey\nTO SHAPE A DRAGON’S BREATH (NAMPESHIWEISIT #1) BY MONIQUILL BLACKGOOSE\nTo Shape a Dragon’s Breath’s description hooked me immediately: It’s got dragons, a magic school, and a strong teenage main character. Moniquill Blackgoose has taken several different fantasy tropes and created a fantasy novel that’s unlike anything I’ve read; To Shape a Dragon’s Breath is set in an evolving steampunk world as Anglish settlers push the Indigenous Masquapaug people out of their land and onto a remote island. Dragons had long been important cultural touchstones to the Indigenous people, but colonization has, too, pushed them away. To Shape a Dragon’s Breath begins as 15-year-old Anequs finds a dragon egg — the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon’s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon’s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered — they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way. Where To Shape a Dragon’s Breath really shines is in that growing relationship between Anequs and Kasaqua; the partnership — and power for both that comes with it — is in stark contrast to the Anglish ways. Bonus: To Shape a Dragon’s Breath has well-written, complex bisexual and neurodivergent characters, too. —Nicole Carpenter\n\nCover image for Melvin Burgess’s Loki, a black cover with a black snake wrapped around gold letters with the title.\nImage: Pegasus\nLOKI BY MELVIN BURGESS\nMelvin Burgess has spent a career writing confrontationally frank children’s literature like Junk, his 1990s book about heroin-addicted teenagers. His first adult book, published at age 69, is a blistering, transgressive, and hugely entertaining reframing of the Norse myths, as told by the most unreliable narrator imaginable: Loki himself, the god of tricks, inventions, and political intrigue. But what does reliable mean, anyway, in the mutable world of myth? Burgess paints Loki (or rather, has him paint himself, as he addresses the reader directly in first person) as an eternal outsider, shaking his head sagely at the follies of the gods, and challenging their might-is-right order. But of course, that’s what he’d want us to think. Burgess’ best trick, though, is the way he rolls together the deeply weird, muddy, shape-shifting mystery of the tales themselves with a bracing modernity in characterization and language, somehow without one clashing with the other. In doing so he brings the wild, ancient power of the Norse myths to vivid life. —Oli Welsh\n\nCover image for Nana Kwame Adjei-Brenyah’s Chain-Gang All-Stars, featuring a scythe chopping through the words with a bright yellow background.\nImage: Pantheon Books\nCHAIN-GANG ALL-STARS BY NANA KWAME ADJEI-BRENYAH\nIn Chain-Gang All-Stars, prison inmates fight to the death in a series of gladiatorial matches — and all of it is televised to a hungry audience. It’s a program called CAPE, the Criminal Action Penal Entertainment, which promises freedom to inmates who survive three years of its brutality. The average life expectancy for anyone who enters is three months. Within this system, Loretta Thurwar and Hammara Stacker (called Hurricane Staxxx by her fans) emerge as two frontrunners.\n\nThis National Book Award finalist takes on the viciousness of the carceral system, with more than a bit of The Hunger Games’ DNA sprinkled in. “Hard action” fans salivate over matches, a self-obsessed announcer resents the fact that contestants don’t offer more banter, and the women who top the leaderboards become sex symbols in pop culture. But where other fight-to-the-death dystopias — among the greats, like Battle Royale or Lord of the Flies — spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn’t entertaining because it wasn’t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply “slavery by another name,” showing all manner of menial labor the contestants are forced to perform. In 2022, the ACLU reported that inmates made between 13 and 52 cents an hour, and sometimes nothing.\n\nCritics have said this book is an “act of protest” but that it doesn’t “straightforwardly preach,” or that it’s more entertaining than “an attempt to convince its readers of the case for prison abolition has any right to be.” I understand why you’d want to say this book is “fun” despite an abolitionist message, especially in a political climate where radical writing is often appreciated only as a teaching tool. But I think that kind of delineation undercuts Adjei-Brenyah’s talent as a novelist, and his skill in heightening the real as a form of storytelling. I’d call it thrilling, over calling it fun. And the fact that it is thrilling is inextricable from its openly abolitionist values — it’s the very knowledge of real life that Adjei-Brenyah wields to craft suspense. —N. Clark\n\nCover image for Rebecca Yarros’ Fourth Wing, which features a circle image behind black text, with clouds and some flying creatures.\nImage: Entangled\nFOURTH WING BY REBECCA YARROS\nThis action-packed, fantasy romance feels like a grown up version of all of my favorite young adult books. It’s got all of the fun nostalgic tropes — a magical school, deadly trials, dragon riding, and a love triangle between the main character, a golden retriever love interest, and a misunderstood emo rival — but it’s also extremely horny, as all fun fantasy romance must be.\n\nViolet Sorrengail is thrown into a series of trials in order to prove whether she can be a dragon rider. There are a few problems with this: she trained as a scribe, never thought she’d be thrust into danger, and she also must deal with Xaden Riorson, her sworn enemy (wink). She also manages a joint condition, which leaves her in chronic pain — a fact the book handles gracefully. In one of my favorite climactic moments of the book, Violet is given a mobility device to help her with her trials; those close to her remind her that it doesn’t diminish her power, but is a tool like any other, and one that allows her to flourish. I’m thrilled to read the next installment, when it comes out in November. —N. Clark\n\nCover art for Adrian Tchaikovsky’s Lords of Uncreation, which shows a spaceship approaching what looks like a space battle next to a planet, with exploding orbs in space and a lot of spaceships in the distance.\nImage: Orbit\nLORDS OF UNCREATION (THE FINAL ARCHITECTURE #3) BY ADRIAN TCHAIKOVSKY\nReading the Final Architecture series, I had to accept long ago that I would never fully grasp the nuances of some of its central concepts, even if I understood them on an instinctual level.\n\nThis acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on – at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God’s crew.\n\nThis is not to say that Tchaikovsky does not deliver an incredibly satisfying conclusion to the mysteries of unspace (he does!). But what I’ll remember most is how he crafted the perfect emotional resolution to this intellectually intricate tale that left me in tears and has stayed with me since. —SG\n\nLead art for Justin Cronin’s The Ferryman, which pictures a cloudy sky over the horizon, as a single sail boat sits on the water.\nImage: Ballantine Books\nTHE FERRYMAN BY JUSTIN CRONIN\nProctor Bennett is a ferryman, whose duty is to guide unhappy citizens from the utopian Propersa to the Nursery, where they retire their old selves before returning in younger bodies with no memories of their former lives. But when Proctor is assigned to retire his own father, the troubling encounter sends him careening off the path of conformity. He begins questioning prescribed truths and confronting the darker side of Prospera, which runs off the work of a disenfranchised support staff whose discontent is building towards a revolution that pulls Proctor into its orbit.\n\nThough this premise may feel familiar, The Ferryman is anything but. This tightly-wound, atmospheric thriller weaves together layers of knotted mystery with Proctor’s haunting POV as he grapples with his relationship to grief, happiness, family, and identity. It’s a sharply complex mystery with a cinematic quality to it. Throughout reading, I couldn’t help but fan-cast who would star in a Christopher Nolan adaptation of it. But even if you aren’t an Inception fan, it’ll be easy to become immersed in The Ferryman’s distinct dystopian world. —SG\n\nCover image for Emily Tesh’s Some Desperate Glory, featuring a woman walking confidently in front of a wall opening to reveal a planetary body.\nImage: Tor\nSOME DESPERATE GLORY BY EMILY TESH\nAround September, as the pile of unpainted plastic miniatures here in my home office began to get particularly deep, I suddenly ran out of Warhammer 40,000 Black Library audiobooks by Games Workshop that I was the least bit interested in listening to. That’s when I stumbled upon Some Desperate Glory by Emily Tesh. Billed as a space opera told from the perspective of one of humanity’s last genetically engineered super soldiers, I fell for the premise hook, line, and sinker. Then, about 50 pages in, I let it sucker-punch me right in the gut.\n\nWith Some Desperate Glory, Tesh has envisioned a deeply affecting reality where the children of a subjugated, war-torn race slowly come to realize that they have been lied to — manipulated into an amoral war of vengeance without end. Tesh shows incredible restraint throughout, reeling out a thick and binding thread of painful realizations from deep within the main character, Kyr. After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest – and a new fixture in the canon of queer science fiction. —Charlie Hall\n\nCover image for Jade Song’s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book — for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid. But she is tethered to land by her human ambition: By the parents who constantly push her to achieve, and by a swim coach who pays inappropriate attention to her — pushing her to swim faster times, while also making her feel uncomfortable in her skin.\n\nRen’s steadfast belief in being a mermaid feels both like a flight of fancy, and increasingly like a means of dissociating from the horrors of everyday life. Being a young girl is hard enough without having to contend with the high expectations of parents, the predation of adult men, and the casual racism of peers. Jade Song’s writing is gruesomely lyrical, contrasting the sublime with the deeply disturbing. There were several points where this book almost made me throw up, and I mean that as a high compliment. —N. Clark\n\nA Black woman stands alone in a field, her face covered by shadow, in the cover art for Lone Women by Victor LaValle.\nImage: One World\nLONE WOMEN BY VICTOR LAVALLE\nAdelaide Henry is traveling to Montana, where she plans on making a new life as a homesteader — leaving the flames of her California home, and the bodies of her parents, behind. But she has a heavy weight to carry. She lugs an enormous steam trunk wherever she goes; whenever the trunk opens, people around her die. In 1915, Montana is in the middle of a homestead boom, and though Adelaide aims to make a new start, not everyone is welcoming to a Black woman traveling alone.\n\nVictor LaValle mixes horror and fantasy in this expertly paced tale. It’s satisfyingly bloody, while making incisive commentary on the price of being an outsider. The Western genre has long fixated on the white imagination, perhaps occasionally making space for the early struggle of the suffragettes. But LaValle’s vision of history emphasizes just how powerful white women are in upholding the interests of their white husbands, and how far these women will go to protect the societal structures that put them in proximity to power. Lone Women also examines how shame, and the family unit, ultimately uphold these unspoken rules — ostracizing those who might otherwise find community support.\n\nThis book was so good that I am now reading my way through every interview LaValle has given on the Lone Women press circuit, too, and then reading every book he references. What a gift! —N. Clark\n\nCover image of Nathan Ballingrud’s The Strange, depicting a diner on Mars.\nImage: Gallery/Saga Press\nTHE STRANGE BY NATHAN BALLINGRUD\nNathan Ballingrud’s debut novel was added to my TBR pile after seeing it marketed as a blend of Ray Bradbury’s The Martian Chronicles and Charles Portis’ True Grit. I’m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp’s mother unknown. When a thief steals Annabelle’s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what’s hers and see justice served. The longer Annabelle’s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can’t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.\n\nAnnabelle can be vengeful and cruel, and though I often disagreed with her choices, Ballingrud makes it impossible not to understand and empathize with her. Annabelle Crisp isn’t a hero and she isn’t a villain, but she is an outstanding protagonist in a wonderfully original sci-fi tale. —SG\n\nCover image for Moses Ose Utomi’s The Lies of the Ajungo, featuring a figure walking upside down on mounds of sand as a castle lurks in front.\nImage: Tor\nTHE LIES OF THE AJUNGO (THE FOREVER DESERT #1) BY MOSES OSE UTOMI\nIn his debut novella, Moses Ose Utomi wields his precise prose to tell a dark, visceral fable about a young boy from the City of Lies, a metropolis reliant on the brutal Ajungo Empire for their supply of water. But the cost of this trade is high: At 13, every child of the City of Lies has their tongue cut out and sent to the Ajungo.\n\nEven with this gruesome tithe, the Ajungo send barely enough water for the population to survive, and far from what they’d need to do so comfortably, let alone thrive. Shortly before his thirteenth birthday, the brave Tutu sets out on a dangerous journey to save his mother and the city by finding their own water supply. As Tutu explores the outside world for the first time, his perception of truth and history is challenged, and he comes to understand how the decisions and deceptions of those in power rewrite the past and shape the future to uphold those with privilege and foster compliance in those who don’t. —SG\n\nCover image for Edward Ashton’s Antimatter Blues, A Mickey7 Novel. It features an astronaut from behind on a rocky planet, looking out at another planet in the distance.\nImage: St. Martin’s Press\nANTIMATTER BLUES BY EDWARD ASHTON\nEdward Ashton’s sequel to Mickey 7, the 2022 novel Parasite director Bong Joon-ho is adapting as a movie starring Robert Pattinson, takes up two years after the first book left off, with “Expendable”-status planetary colonist Mickey still on the outs with the leadership of his struggling colony after a gutsy bluff he made to ensure his own survival. The sixth clone of the original Mickey, who accepted life as a disposable body for suicide missions in exchange for a ticket to space, Mickey 7 has walked off that job. His ongoing draw on the colony’s resources is only tolerated because he’s exaggerated his diplomatic connections with the local aliens. Then the base commander orders him to do something impossible, or the entire colony will die.\n\nAntimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity’s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn’t a pleasant book to read: A lot of Mickey’s co-colonists are bigots, most of them are indifferent to anyone else’s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he’s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity. —TR\n\nCover image for Samantha Shannon’s A Day of Fallen Night, a colorful image with a a dragon swirling around it\nImage: Bloomsbury\nA DAY OF FALLEN NIGHT (THE ROOTS OF CHAOS #0) BY SAMANTHA SHANNON\nSamantha Shannon’s A Day of Fallen Night is her second book in the Roots of Chaos series, but a prequel to The Priory of the Orange Tree. Like The Priory of the Orange Tree, A Day of Fallen Night is an epic, far-flung fantasy novel set in a world of magic and dragons. A Day of Fallen Night is set hundreds of years before The Priory of the Orange Tree, and follows several of the original book’s ancestors as the world fears the return of an evil wyrm, the Nameless One. You don’t have to have read The Priory of the Orange Tree to enjoy A Day of Fallen Night; in fact, it’s likely a good place to start if you’ve been interested in reading Shannon’s original, massive fantasy book. Of course, this is a slow-burn 800-page book that precedes another 800-page book, so it’s definitely a time investment regardless of the path.\n\nThough A Day of Fallen Night deals with a world-shaping, cataclysmic threat and widespread political machinations, the book is rooted within four characters from around the book’s world: Sabran, Glorian, Dumai, and Tunuva Melim. The stories of these characters intertwine as their regional beliefs tied to wyrms and dragons conflict, muddying up the necessary collaboration in fighting off the looming threat. In between all that catastrophe, Shannon gives the women of the book rich stories of personal relationships, sacrifice, and conflicting feelings. Motherhood and bodily autonomy are also strong themes throughout the book; both Sabran and Glorian (mother and daughter) have their bodily autonomy tied to the fate of their region.\n\nIt’s not easy to describe A Day of Fallen Night in a short blurb — it does so many things and goes so many places. Shannon’s created a series that has the scale of The Lord of the Rings, wrapped up in a world of queer, female power. The Roots of Chaos, as a whole, is one of my favorite fantasy series ever. —N. Carpenter\n\nCover image for Mariana Enriquez’s Our Share of Night, featuring a red hand with long yellow fingernails.\nImage: Hogarth Press\nOUR SHARE OF NIGHT BY MARIANA ENRÍQUEZ\nThis literary tome defies categorization, so I’ll paint a scene instead: A father (Juan) whisks his son (Gaspar) away on a trip. Juan is mercurial; at turns terrifying and violent, at turns bewilderingly tender, nearly infinite in love. But he is a closed book. And if you think you’ve seen his hands elongate, spindly fingers yielding to piercing claws — well no, you didn’t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family’s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel’s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enríquez writes next, it’s an absolute joy to experience her work. —N. Clark\n\nCover image for Annalee Newitz’s The Terraformers, which features a futuristic cityscape with lush greenery.\nImage: Tor Books\nTHE TERRAFORMERS BY ANNALEE NEWITZ\nThe Terraformers concerns itself with one question: As a species evolves, what behaviors stick around? Set more than 50,000 years in the future (yes, you read that number right), The Terraformers details the process of terraforming and developing a privatized planet into a tourism joint for the super rich. Technology has advanced in barely fathomable ways, allowing, for instance, the extension of human-level intelligence to animals and robots. But some aspects of society might seem familiar: Real estate developers who jack up rent with no warning? Local governments that abhor public transit? That every video call still has one person who can’t get the camera to work?\n\nEqual parts prescient and absurd, The Terraformers splits its story over three novellas, each 700 years apart. One of those stars a sentient train who teams up with an investigative journalist ... who also happens to be a cat ... who’s also trying to prove this ostensibly privatized planet is in fact public land. Written by a leading science journalist of our era (author Annalee Newitz is the founder of io9 and has written for basically every major science publication under our sun), The Terraformers is unexpectedly one of the most accurate representations of the journalistic process I’ve ever read. And it all culminates in an undeniable stance: That capitalistic power must still be held in check by the truth. Even 50,000 years in the future, a free press is among society’s most essential facets. The more things change... —Ari Notis\n\nThe cover image of Adrian Tchaikovsky’s Children of Memory, which depicts a spaceship approaching a large orange planet.\nImage: Orbit\nCHILDREN OF MEMORY (CHILDREN OF TIME #3) BY ADRIAN TCHAIKOVSKY\nAdrian Tchaikovsky’s highly anticipated third book in the Children of Time trilogy once again delves into some of science fiction’s headiest topics. There are parallels to earlier installments — Tchaikovsky once again uses another hyper-intelligent animal species to examine the idea of what being “alive” really means. But he also takes readers somewhere completely and utterly new, outside the scope of the previous titles, and incredibly difficult to describe without spoiling the premise entirely.\n\nAll I can say is hold on for the ride. This is an author who dives head first into Asimov-esque ideas, and who is willing to take the plot in fanciful directions. I still can’t believe that I have recommended a book about sentient spider colonies to so many friends, but here we are. This finale is worth your time. —N. Clark'
 'My eyes felt like galaxies—holding the swirling glow of countless memories—as I took in our childhood home. Its siding looked like remnants of driftwood after a bonfire. I swore I smelled the smoky char of pine creep into my nostrils. It’s wild how the past stays with you like that. It can feel more visceral and real than the tangible things right in front of you.\n\n“Jesus, it feels like just yesterday.” I placed a trembling hand over my heart, struggling to steady my breath.\n\nMy brother, Perry, pulled me into a tight embrace, his strength grounding me like an anchor.\n\n“The house hasn’t changed much,” he said, his voice steady and comforting. “But we have.” His certainty made me question, Have I really changed?\n\nBetween the two of us, Perry was as solid and stoic as a mountain range. Good thing, because I was like the wind—flighty and unpredictable. Over the years, Perry had learned to handle even my harshest hurricanes.\n\nBeing his older sister—even if only by four minutes—I always wished I’d been his protector rather than the other way around. But that demon burning deep in my belly also flashed a crooked smile, knowing that Perry would never abandon me, especially since I got sober.\n\nI hadn’t had a drink in exactly seven hundred and thirty days, and although it remained unsaid, I knew Perry was terrified of leaving me to my own devices in fear I would relapse.\n\nOur sibling bond was iron-clad. After we lost our parents in the fire (my mother didn’t properly butt out her 2:00 am cigarette and well, the rest is history), all Perry and I had was each other. But let’s call a spade a spade; we were also as fucked up and as co-dependent as it gets. Who mutually decides to visit the catalyst of your alcohol addiction on the anniversary of your sobriety?\n\nThe house’s dilapidated front door creaked as Perry gently pushed it open. The rusted metal hinges were holding it up by a thread.\n\n“After you.” Perry gestured me in, squinting from the sunlight. He was a gentleman, even in such obscurity.\n\nAs he held the door open, the shallow scar on his right cheek taunted me like some kind of schoolyard bully. His wound often pulled me in like that. Some days, I was sure I would dive right into it and drown. Other days, I prayed to God and the Devil himself to just let me fucking drown, already.\n\nThat mark became permanently etched on Perry’s face on the day I quit drinking, exactly seven hundred and thirty days ago. That was the day Perry screamed bloody murder at me from the passenger seat, “Jackie! Stop the fucking car!” But my bloodstream was far too poisoned with Bacardi Limon to listen. All I remember next was my vehicle being wrapped around a tree. I could have died that day, but what truly disturbed me in the middle of the night was the fact that I almost killed Perry.\n\nA lot can happen in seven hundred and thirty days. But I assure you, forgiving yourself isn’t one of them.\n\n“Well? You coming in?” Perry was still holding the door ajar.\n\nI shook it off and gave my brother a knowing glance. I swear, even though we were fraternal, we had twin telepathy. I exhaled and walked in.\n\n“Watch your step,” I warned, my forehead tense.\n\nI imagined the rickety floorboards collapsing, crashing us into what had once been our dad’s “man cave”. That’s where he was passed out, the night of the fire.\n\n“Kids, stay here. Do not move,” our mother demanded after getting us out of the house safely. I remember the black soot on her face and the spiderweb veins in her eyes. She shook us firmly by the forearms. “I’m getting your father.”\n\nPerry and I held each other, shaking. The heat from the inferno felt like standing in a volcano. We never saw our parents again.\n\nTwo decades later, there we were—Perry and I—-making our way through the wreckage of our home. It was midday, yet the inside of the house screamed a tone of pale blue midnight. My shoulders were up to my ears, as though we were walking through a haunted house attraction.\n\nI coughed into my forearm. The ocean of dust was thick like butter. As I cleared my lungs, Perry called out from behind me.\n\n“Jacks, look at this! The fireplace,” Perry\'s voice was filled with awe.\n\n“Unbelievable. It’s still here,” I whispered, a lump forming in my throat.\n\nIt was as though a Fairy Godmother breezed by and brought the decaying living room to life with her magical paintbrush. Kind of like in “Titanic”, when they showed the sunken ship underwater, versus in its prestige as it sailed across the Atlantic.\n\nWe made our way over to the fireplace and sat cross-legged on the floor.\n\n“This was our favorite spot, remember?” I avoided his gaze, overwhelmed by the flood of memories.\n\n“Yeah,” Perry murmured, his eyes softening with nostalgia.\n\nFor a moment, the taste of crispy, fire roasted marshmallows superseded the saturated stench of mildew.\n\n“Remember our s’mores nights?” I asked.\n\n“Duh. What about all our fireplace movie nights?” Perry proceeded to do his best, nasally, childhood impersonation of me, “But mom! I want to watch Beauty and the Beast!! Perry always gets to pick the movie!!”\n\nI punched him in the arm, “First of all, I never sounded like that. And second. So what? I knew what I wanted.”\n\nThe corners of Perry’s mouth lifted. He had such a sincere sparkle about him, as though a storm cloud of confetti followed him overhead wherever he went, “You really did, kiddo.”\n\nMy chest went heavy. How could Perry love me after everything I had done? After all the relationships I’d ruined? All the jobs I’d lost? All of his relationships I’d ruined? How could he still choose me, when so often I had chosen a forty of Jack Daniels over him?\n\nHow could Perry still love me after I almost fucking killed him?\n\nPerry’s gaze widened, “Hey! Remember when Mom would bring out those hot drinks she always made?” He paused, almost as if he was searching for the right term. “Apple… something? Apple ssshhh…”\n\nI snapped my fingers, “Apple-Schnapple!”\n\n“Yes!”\n\n“I mean, looking back it was basically just hot apple cider, but damn it was good.” And it really was.\n\nOur laughs echoed throughout the abandoned asylum we once called home.\n\nPerry leaned back, holding himself up with his hands. “I loved our fireplace hangs. Especially our movie nights down here. But nothing beats our movies up in the projector room.”\n\nI tilted my head, “We never had a projector room.”\n\nPerry playfully “shoo’d” me away.\n\n“No. Perry. I would remember us having a projector room. Our movie nights together were our favorite thing. You even just said it yourself.”\n\nThe house suddenly became pin-drop silent as Perry leaned in. ""Memories are quite something, aren’t they?"" The slight shift in his tone made my skin crawl. Perry was always wistful, but this felt different, almost… clinical, ""We often remember things in ways that are… easier for us to digest.""\n\nI was fidgety. “Gees Perry. You sound like Dr. Lasko.”\n\nHe seemed to enjoy my little joke.\n\nDr. Lasko had been my therapist since the accident, and I would go out on a limb and say that he would not have approved of this self-inflicted exposure therapy I was subjecting myself to by visiting the house.\n\nPerry seemingly snapped out of his little therapist moment and went right back to being his sparkly confetti self. As I watched his amicable face scan the mantle above the fireplace, I felt a sickening uneasiness. Imagine you had actually fucking killed him.\n\n“Man, I can still picture all our family photos up there,” Perry’s childlike wonder destroyed me.\n\nMy face went flush. I could feel the water rising in my eyes like the tides. How pathetic and infuriating was it that after everything I’d done, I was still somehow the victim.\n\n“Hey.” He took my hand.\n\n“Oh Perry,”  I threw myself into him. “I’m so sorry.”\n\nMy brother held me with his usual care that I didn’t deserve.\n\n“Jacks, it’s ok. I’m still here. We’re both still here.”\n\nAs my chin rested on my brother’s shoulder, I looked ahead of me at the remains of the house. Something felt off, and it wasn’t just the overall unsettling environment. My brow furrowed. “Wasn’t the doorway to the kitchen on the other side of the living room?”\n\nI felt Perry shrug, “I don’t think so.”\n\nI was staring into the out of place doorway like I was trying to pull a recollection towards me. And that’s when I saw them in the kitchen: the translucent memory of mom and dad. Mom was getting our Apple-Schnapples ready. She was pacing, unlike Dad, who was sitting motionless at the table. His face was planted on its mahogany surface. His glass of Apple-Schnapple was empty, and so was the bottle of Jim Beam beside it.\n\nMom floated into the living room, our warm beverages in hand and a cigarette in her mouth, “Kids, your father’s not feeling well. Let’s have our Apple-Schnapples in here.”\n\nOh my God. The bruise on her face.\n\nPerry jarred me back to reality with the gut punch of what he had to say next, “You’re remembering the truth about mom and dad, aren’t you?”\n\nI pushed myself off and away from him. “How did you…”\n\nMy brother looked down, delicately tracing the floor with his finger, “We always put them on a pedestal after they died.”\n\nI felt a shiver run down my spine, “What are you talking about?”\n\nAs Perry continued to speak, his words grew even more detached. ""Do you remember that first drink Dad ever gave you?""\n\nMy eyes darted around the room as my jugular pulsed in my neck. As much as I tried to escape what Perry had just said, I did remember.\n\nI could hear my dad’s slurring words of encouragement, “Come on, Jackie. Just one drink. It’ll be our special time, just you and me.”\n\nThe bitterness of that first sip of beer made me squirm, but sharing a “special time” with my dad—and the desperate yearning that maybe he did love me, afterall—was the overwhelm of the full moon swallowing me whole. I was only a child, and much like how my mom turned a blind eye to my father’s drinking, she did the exact same when it came to her daughter.\n\nI’d used the death of my parents as the excuse for my alcoholism for so long, because admitting that they helped create the monster I would eventually become was like a knife to the heart. And knowing I had been too weak to conquer the addiction from my own volition just made the weapon twist in my chest.\n\nThe room was spinning. My face was blistering hot like the night of the fire. Or was that the warm heat from the fireplace when we were kids? The childhood fireplace memories ran through my mind, frame by frame, until…..they eventually vaporized to nothing. I crouched over, thinking I might vomit.\n\n“We never had a fireplace.” Perry was nodding, very matter-of-factly.\n\nMy fingernails dug into my thighs when I looked at the fireplace and: it was gone. Only a blank wall of faded, forest green wallpaper remained. Our house was once on fire, yes, but that was it. There was never a happy childhood fireplace. Ever.\n\nMy hands were cold and clammy. I fell back onto the wall behind me. “Perry. Where are we?”\n\nHe stood up and glided towards the staircase. One hand on the banister, his footsteps creaked, one by one, as he made his way to the second floor.\n\nMy mouth was bone dry, “Perry!”\n\nHe stopped and turned towards me, “Come to the projector room. We love watching movies together, don’t we? There’s a movie I’d like to show you.”\n\nAs my brother disappeared from sight, I did what any classic horror movie trope would tell you to do: I went upstairs.\n\nI found Perry standing at the end of the ominous hallway. Large, empty picture frames lined the oxblood walls leading up to him. Through the doorway where Perry stood, particles in the air danced in the projector’s cone-shaped light. That telltale winding of a film reel was the only sound in the deafening quiet of this house that I no longer recognized.\n\nHalf of Perry’s face—the one with the scar—was perfectly illuminated, as though he was wearing the mask from “The Phantom of the Opera”. “I think you’re ready to see how this movie ends, Jackie. This is the most progress you’ve made since we’ve been coming here.”\n\nI gripped my thumbs in the palms of my hands, “Perry, you’re freaking the fuck out of me!”\n\nI thought my knees might buckle as my brother’s face glitched, like a flash of static snow on a television set. As his face settled back to normal to a deadpan gaze, he disappeared in the innocuous room. I followed, running on nothing but fumes.\n\nClutching the doorway, my mouth fell agape. Perry was gone. I darted to the middle of the room.\n\nAs I frantically searched for my brother, I shielded my eyes with the back of my hand from the projector’s light. And that’s when, from behind me, I heard five words that made my blood run cold, “Jackie! Stop the fucking car!”\n\nI was convulsing yet paralyzed. Moving as slowly as cold molasses, I rotated on the spot towards my worst nightmare, shown on 35 mm. On the projector screen was Perry and me in my car, exactly seven hundred and thirty days ago, the day I almost kill—\n\nOh my God.\n\nMy head pounded as fragmented memories surged. The reality of what happened began to crystallize, unrelenting.\n\nMy joints ached and my stomach churned. Clamping a hand over my mouth to stifle a scream, I stumbled down the hallway as it began caving in on itself. The picture frames were sucked into the walls. The floorboards cracked into distorted peaks and valleys. Wooden beams swung down from the ceiling like pendulums. I tried to spit out the chalky grit of disintegrating drywall that made the hallway look like a winter squall.\n\nPanting heavily, I stopped dead in my tracks at the stained glass window. My body trembled with an all-too-familiar dread. Each time I faced this, I wondered if this fall would be the one that would finally end it all.\n\nMaybe it’d be better if it did.\n\nHolding my breath, I threw myself through the glass, my hands clawing the air for dear life. Free falling two stories feels like an eternity when you’re watching the memory of your childhood home fall apart before your very eyes. But when the weight of my body finally made contact with the earth I—\n\nI gasped. The cold air of the hospital room shocked my lungs. I sat up, ripping the suction cups from my face and body. My gown was clinging to me, soaked in sweat. Medical equipment beeped all around me like a metronome.\n\nDr. Lasko, my therapist since the accident, sat across the stark white room, sighing as he rubbed his forehead. He, too, was connected to a plethora of suction cups and wires. He looked a little worn out in the fluorescent overhead lighting. Ever since I was hospitalized and later incarcerated, Dr. Lasko had been helping me delve into my memories, namely the ones that were too excruciating for me to face. And as such, Dr. Lasko had been appearing in the simulations as my brother Perry, the love of my life who died in the car crash, seven hundred and thirty days prior.\n\nDisoriented, I blinked rapidly, the vividness of the memory contrasting sharply with the sterile, geometric ceiling tiles above me.\n\n“I don’t ever want to do that again!” I was venomous.\n\n“Jackie,” Dr. Lasko started.\n\n“Don’t start,” I pulled up four fingers for air quotes, “‘Jackie, don’t give up. This was the closest you’ve ever come to facing the truth.”\n\nAs the initial burst of adrenal and cortisol left my body, I fell back on my pillow. I was depleted. Quiet rivers flowed down my cheeks.\n\nRemoving his own suction cups, Dr. Lasko approached my bedside and took a seat. He treaded lightly. “Jackie, I understand how challenging this is for you, but you did an incredible job today. If we continue making progress like this, there\'s a real possibility you\'ll gain your freedom sooner.”\n\nI looked at the well-meaning doctor, but all I could see was Perry. Multicolored confetti fell softly around him like that first November snow. His face was the sun. His eyes reflected the whole world back to me.\n\nPerry.\n\nWith a weak grip, I took Dr. Lasko’s hand. My vocal cords were like sandpaper. “I’ll leave this place one day, doc.” A single tear dripped from my chin onto my collarbone. “But I’m not sure if I’ll ever be free.”\n\nDr. Lasko didn’t say a word, but I felt him squeeze my hand, just a little bit tighter.\n\nI licked the cracks on my lips as my eyes closed shut, imagining the oaky comfort of bourbon on my tongue. I felt myself drift, and good thing, because I needed the rest. Dr. Lasko and I would be delving into my memories again the following day.\n\nNo matter how masochistic it felt, I vowed to keep showing up for the simulations. Even if I never forgave myself for what I did, at least in my memories, I got to see Perry.'
 '---The Paths through the Underground/Underdark---(9 days of travel)\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\n\nDay 1 goes without issue... sleep.\n\nDay 2 – Ropers\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\n---ENCOUNTER – Ropers x 2---\nDay 3 goes without issue...sleep.\n\nDay 4 - Kobold Trap\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\n\nThey are no more than 2-3 feet wide, and numerous (dozens).\n\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\n\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\n\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\n\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\n“Loud food! Loud meal!”\n\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\n\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\n\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\n\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?']",I don't know.,0.0,0.7474724261424862,0.0,0.0,0.0
What are the rules for developing general purpose AI models?,"General purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks. 12 months after the AI Act enters into force, the obligations for general purpose AI governance become applicable. Providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption. Providers of free and open-source models are exempted from most of obligations, but this exemption does not cover obligations for providers of general purpose AI models with systemic risks.","[""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 'Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 ""Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning\n2023-01-30 by Tim Dettmers 1,664 Comments\n\nDeep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience. But what features are important if you want to buy a new GPU? GPU RAM, cores, tensor cores, caches? How to make a cost-efficient choice? This blog post will delve into these questions, tackle common misconceptions, give you an intuitive understanding of how to think about GPUs, and will lend you advice, which will help you to make a choice that is right for you.\n\nThis blog post is designed to give you different levels of understanding of GPUs and the new Ampere series GPUs from NVIDIA. You have the choice: (1) If you are not interested in the details of how GPUs work, what makes a GPU fast compared to a CPU, and what is unique about the new NVIDIA RTX 40 Ampere series, you can skip right to the performance and performance per dollar charts and the recommendation section. The cost/performance numbers form the core of the blog post and the content surrounding it explains the details of what makes up GPU performance.\n\n(2) If you worry about specific questions, I have answered and addressed the most common questions and misconceptions in the later part of the blog post.\n\n(3) If you want to get an in-depth understanding of how GPUs, caches, and Tensor Cores work, the best is to read the blog post from start to finish. You might want to skip a section or two based on your understanding of the presented topics.\n\nContents  hide\nOverview\nHow do GPUs work?\nThe Most Important GPU Specs for Deep Learning Processing Speed\nTensor Cores\nMatrix multiplication without Tensor Cores\nMatrix multiplication with Tensor Cores\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nMemory Bandwidth\nL2 Cache / Shared Memory / L1 Cache / Registers\nEstimating Ada / Hopper Deep Learning Performance\nPractical Ada / Hopper Speed Estimates\nPossible Biases in Estimates\nAdvantages and Problems for RTX40 and RTX 30 Series\nSparse Network Training\nLow-precision Computation\nFan Designs and GPUs Temperature Issues\n3-slot Design and Power Issues\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\n8-bit Float Support in H100 and RTX 40 series GPUs\nRaw Performance Ranking of GPUs\nGPU Deep Learning Performance per Dollar\nGPU Recommendations\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nDo I need 8x/16x PCIe lanes?\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nCan I use multiple GPUs of different GPU types?\nWhat is NVLink, and is it useful?\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nWhat do I need to parallelize across two machines?\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nDo I need an Intel CPU to power a multi-GPU setup?\nDoes computer case design matter for cooling?\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nVersion History\nAcknowledgments\nRelated\nRelated Posts\nOverview\nThis blog post is structured in the following way. First, I will explain what makes a GPU fast. I will discuss CPUs vs GPUs, Tensor Cores, memory bandwidth, and the memory hierarchy of GPUs and how these relate to deep learning performance. These explanations might help you get a more intuitive sense of what to look for in a GPU. I discuss the unique features of the new NVIDIA RTX 40 Ampere GPU series that are worth considering if you buy a GPU. From there, I make GPU recommendations for different scenarios. After that follows a Q&A section of common questions posed to me in Twitter threads; in that section, I will also address common misconceptions and some miscellaneous issues, such as cloud vs desktop, cooling, AMD vs NVIDIA, and others.\n\nHow do GPUs work?\nIf you use GPUs frequently, it is useful to understand how they work. This knowledge will help you to undstand cases where are GPUs fast or slow. In turn, you might be able to understand better why you need a GPU in the first place and how other future hardware options might be able to compete. You can skip this section if you just want the useful performance numbers and arguments to help you decide which GPU to buy. The best high-level explanation for the question of how GPUs work is my following Quora answer:\n\nRead Tim Dettmers‘ answer to Why are GPUs well-suited to deep learning? on Quora\nThis is a high-level explanation that explains quite well why GPUs are better than CPUs for deep learning. If we look at the details, we can understand what makes one GPU better than another.\n\nThe Most Important GPU Specs for Deep Learning Processing Speed\nThis section can help you build a more intuitive understanding of how to think about deep learning performance. This understanding will help you to evaluate future GPUs by yourself. This section is sorted by the importance of each component. Tensor Cores are most important, followed by memory bandwidth of a GPU, the cache hierachy, and only then FLOPS of a GPU.\n\nTensor Cores\nTensor Cores are tiny cores that perform very efficient matrix multiplication. Since the most expensive part of any deep neural network is matrix multiplication Tensor Cores are very useful. In fast, they are so powerful, that I do not recommend any GPUs that do not have Tensor Cores.\n\nIt is helpful to understand how they work to appreciate the importance of these computational units specialized for matrix multiplication. Here I will show you a simple example of A*B=C matrix multiplication, where all matrices have a size of 32×32, what a computational pattern looks like with and without Tensor Cores. This is a simplified example, and not the exact way how a high performing matrix multiplication kernel would be written, but it has all the basics. A CUDA programmer would take this as a first “draft” and then optimize it step-by-step with concepts like double buffering, register optimization, occupancy optimization, instruction-level parallelism, and many others, which I will not discuss at this point.\n\nTo understand this example fully, you have to understand the concepts of cycles. If a processor runs at 1GHz, it can do 10^9 cycles per second. Each cycle represents an opportunity for computation. However, most of the time, operations take longer than one cycle. Thus we essentially have a queue where the next operations needs to wait for the next operation to finish. This is also called the latency of the operation.\n\nHere are some important latency cycle timings for operations. These times can change from GPU generation to GPU generation. These numbers are for Ampere GPUs, which have relatively slow caches.\n\nGlobal memory access (up to 80GB): ~380 cycles\nL2 cache: ~200 cycles\nL1 cache or Shared memory access (up to 128 kb per Streaming Multiprocessor): ~34 cycles\nFused multiplication and addition, a*b+c (FFMA): 4 cycles\nTensor Core matrix multiply: 1 cycle\nEach operation is always performed by a pack of 32 threads. This pack is termed a warp of threads. Warps usually operate in a synchronous pattern — threads within a warp have to wait for each other. All memory operations on the GPU are optimized for warps. For example, loading from global memory happens at a granularity of 32*4 bytes, exactly 32 floats, exactly one float for each thread in a warp. We can have up to 32 warps = 1024 threads in a streaming multiprocessor (SM), the GPU-equivalent of a CPU core. The resources of an SM are divided up among all active warps. This means that sometimes we want to run fewer warps to have more registers/shared memory/Tensor Core resources per warp.\n\nFor both of the following examples, we assume we have the same computational resources. For this small example of a 32×32 matrix multiply, we use 8 SMs (about 10% of an RTX 3090) and 8 warps per SM.\n\nTo understand how the cycle latencies play together with resources like threads per SM and shared memory per SM, we now look at examples of matrix multiplication. While the following example roughly follows the sequence of computational steps of matrix multiplication for both with and without Tensor Cores, please note that these are very simplified examples. Real cases of matrix multiplication involve much larger shared memory tiles and slightly different computational patterns.\n\nMatrix multiplication without Tensor Cores\nIf we want to do an A*B=C matrix multiply, where each matrix is of size 32×32, then we want to load memory that we repeatedly access into shared memory because its latency is about five times lower (200 cycles vs 34 cycles). A memory block in shared memory is often referred to as a memory tile or just a tile. Loading two 32×32 floats into a shared memory tile can happen in parallel by using 2*32 warps. We have 8 SMs with 8 warps each, so due to parallelization, we only need to do a single sequential load from global to shared memory, which takes 200 cycles.\n\nTo do the matrix multiplication, we now need to load a vector of 32 numbers from shared memory A and shared memory B and perform a fused multiply-and-accumulate (FFMA). Then store the outputs in registers C. We divide the work so that each SM does 8x dot products (32×32) to compute 8 outputs of C. Why this is exactly 8 (4 in older algorithms) is very technical. I recommend Scott Gray’s blog post on matrix multiplication to understand this. This means we have 8x shared memory accesses at the cost of 34 cycles each and 8 FFMA operations (32 in parallel), which cost 4 cycles each. In total, we thus have a cost of:\n\n200 cycles (global memory) + 8*34 cycles (shared memory) + 8*4 cycles (FFMA) = 504 cycles\n\nLet’s look at the cycle cost of using Tensor Cores.\n\nMatrix multiplication with Tensor Cores\nWith Tensor Cores, we can perform a 4×4 matrix multiplication in one cycle. To do that, we first need to get memory into the Tensor Core. Similarly to the above, we need to read from global memory (200 cycles) and store in shared memory. To do a 32×32 matrix multiply, we need to do 8×8=64 Tensor Cores operations. A single SM has 8 Tensor Cores. So with 8 SMs, we have 64 Tensor Cores — just the number that we need! We can transfer the data from shared memory to the Tensor Cores with 1 memory transfers (34 cycles) and then do those 64 parallel Tensor Core operations (1 cycle). This means the total cost for Tensor Cores matrix multiplication, in this case, is:\n\n200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.\n\nThus we reduce the matrix multiplication cost significantly from 504 cycles to 235 cycles via Tensor Cores. In this simplified case, the Tensor Cores reduced the cost of both shared memory access and FFMA operations.\n\nThis example is simplified, for example, usually each thread needs to calculate which memory to read and write to as you transfer data from global memory to shared memory. With the new Hooper (H100) architectures we additionally have the Tensor Memory Accelerator (TMA) compute these indices in hardware and thus help each thread to focus on more computation rather than computing indices.\n\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nThe RTX 30 Ampere and RTX 40 Ada series GPUs additionally have support to perform asynchronous transfers between global and shared memory. The H100 Hopper GPU extends this further by introducing the Tensor Memory Accelerator (TMA) unit. the TMA unit combines asynchronous copies and index calculation for read and writes simultaneously — so each thread no longer needs to calculate which is the next element to read and each thread can focus on doing more matrix multiplication calculations. This looks as follows.\n\nThe TMA unit fetches memory from global to shared memory (200 cycles). Once the data arrives, the TMA unit fetches the next block of data asynchronously from global memory. While this is happening, the threads load data from shared memory and perform the matrix multiplication via the tensor core. Once the threads are finished they wait for the TMA unit to finish the next data transfer, and the sequence repeats.\n\nAs such, due to the asynchronous nature, the second global memory read by the TMA unit is already progressing as the threads process the current shared memory tile. This means, the second read takes only 200 – 34 – 1 = 165 cycles.\n\nSince we do many reads, only the first memory access will be slow and all other memory accesses will be partially overlapped with the TMA unit. Thus on average, we reduce the time by 35 cycles.\n\n165 cycles (wait for async copy to finish) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 200 cycles.\n\nWhich accelerates the matrix multiplication by another 15%.\n\nFrom these examples, it becomes clear why the next attribute, memory bandwidth, is so crucial for Tensor-Core-equipped GPUs. Since global memory is the by far the largest cycle cost for matrix multiplication with Tensor Cores, we would even have faster GPUs if the global memory latency could be reduced. We can do this by either increasing the clock frequency of the memory (more cycles per second, but also more heat and higher energy requirements) or by increasing the number of elements that can be transferred at any one time (bus width).\n\nMemory Bandwidth\nFrom the previous section, we have seen that Tensor Cores are very fast. So fast, in fact, that they are idle most of the time as they are waiting for memory to arrive from global memory. For example, during GPT-3-sized training, which uses huge matrices — the larger, the better for Tensor Cores — we have a Tensor Core TFLOPS utilization of about 45-65%, meaning that even for the large neural networks about 50% of the time, Tensor Cores are idle.\n\nThis means that when comparing two GPUs with Tensor Cores, one of the single best indicators for each GPU’s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of speedup of an A100 vs V100 is 1555/900 = 1.73x.\n\nL2 Cache / Shared Memory / L1 Cache / Registers\nSince memory transfers to the Tensor Cores are the limiting factor in performance, we are looking for other GPU attributes that enable faster memory transfer to Tensor Cores. L2 cache, shared memory, L1 cache, and amount of registers used are all related. To understand how a memory hierarchy enables faster memory transfers, it helps to understand how matrix multiplication is performed on a GPU.\n\nTo perform matrix multiplication, we exploit the memory hierarchy of a GPU that goes from slow global memory, to faster L2 memory, to fast local shared memory, to lightning-fast registers. However, the faster the memory, the smaller it is.\n\nWhile logically, L2 and L1 memory are the same, L2 cache is larger and thus the average physical distance that need to be traversed to retrieve a cache line is larger. You can see the L1 and L2 caches as organized warehouses where you want to retrieve an item. You know where the item is, but to go there takes on average much longer for the larger warehouse. This is the essential difference between L1 and L2 caches. Large = slow, small = fast.\n\nFor matrix multiplication we can use this hierarchical separate into smaller and smaller and thus faster and faster chunks of memory to perform very fast matrix multiplications. For that, we need to chunk the big matrix multiplication into smaller sub-matrix multiplications. These chunks are called memory tiles, or often for short just tiles.\n\nWe perform matrix multiplication across these smaller tiles in local shared memory that is fast and close to the streaming multiprocessor (SM) — the equivalent of a CPU core. With Tensor Cores, we go a step further: We take each tile and load a part of these tiles into Tensor Cores which is directly addressed by registers. A matrix memory tile in L2 cache is 3-5x faster than global GPU memory (GPU RAM), shared memory is ~7-10x faster than the global GPU memory, whereas the Tensor Cores’ registers are ~200x faster than the global GPU memory.\n\nHaving larger tiles means we can reuse more memory. I wrote about this in detail in my TPU vs GPU blog post. In fact, you can see TPUs as having very, very, large tiles for each Tensor Core. As such, TPUs can reuse much more memory with each transfer from global memory, which makes them a little bit more efficient at matrix multiplications than GPUs.\n\nEach tile size is determined by how much memory we have per streaming multiprocessor (SM) and how much we L2 cache we have across all SMs. We have the following shared memory sizes on the following architectures:\n\nVolta (Titan V): 128kb shared memory / 6 MB L2\nTuring (RTX 20s series): 96 kb shared memory / 5.5 MB L2\nAmpere (RTX 30s series): 128 kb shared memory / 6 MB L2\nAda (RTX 40s series): 128 kb shared memory / 72 MB L2\nWe see that Ada has a much larger L2 cache allowing for larger tile sizes, which reduces global memory access. For example, for BERT large during training, the input and weight matrix of any matrix multiplication fit neatly into the L2 cache of Ada (but not other Us). As such, data needs to be loaded from global memory only once and then data is available throught the L2 cache, making matrix multiplication about 1.5 – 2.0x faster for this architecture for Ada. For larger models the speedups are lower during training but certain sweetspots exist which may make certain models much faster. Inference, with a batch size larger than 8 can also benefit immensely from the larger L2 caches.\n\nEstimating Ada / Hopper Deep Learning Performance\nThis section is for those who want to understand the more technical details of how I derive the performance estimates for Ampere GPUs. If you do not care about these technical aspects, it is safe to skip this section.\n\nPractical Ada / Hopper Speed Estimates\nSuppose we have an estimate for one GPU of a GPU-architecture like Hopper, Ada, Ampere, Turing, or Volta. It is easy to extrapolate these results to other GPUs from the same architecture/series. Luckily, NVIDIA already benchmarked the A100 vs V100 vs H100 across a wide range of computer vision and natural language understanding tasks. Unfortunately, NVIDIA made sure that these numbers are not directly comparable by using different batch sizes and the number of GPUs whenever possible to favor results for the H100 GPU. So in a sense, the benchmark numbers are partially honest, partially marketing numbers. In general, you could argue that using larger batch sizes is fair, as the H100/A100 GPU has more memory. Still, to compare GPU architectures, we should evaluate unbiased memory performance with the same batch size.\n\nTo get an unbiased estimate, we can scale the data center GPU results in two ways: (1) account for the differences in batch size, (2) account for the differences in using 1 vs 8 GPUs. We are lucky that we can find such an estimate for both biases in the data that NVIDIA provides.\n\nDoubling the batch size increases throughput in terms of images/s (CNNs) by 13.6%. I benchmarked the same problem for transformers on my RTX Titan and found, surprisingly, the very same result: 13.5% — it appears that this is a robust estimate.\n\nAs we parallelize networks across more and more GPUs, we lose performance due to some networking overhead. The A100 8x GPU system has better networking (NVLink 3.0) than the V100 8x GPU system (NVLink 2.0) — this is another confounding factor. Looking directly at the data from NVIDIA, we can find that for CNNs, a system with 8x A100 has a 5% lower overhead than a system of 8x V100. This means if going from 1x A100 to 8x A100 gives you a speedup of, say, 7.00x, then going from 1x V100 to 8x V100 only gives you a speedup of 6.67x.  For transformers, the figure is 7%.\n\nUsing these figures, we can estimate the speedup for a few specific deep learning architectures from the direct data that NVIDIA provides. The Tesla A100 offers the following speedup over the Tesla V100:\n\nSE-ResNeXt101: 1.43x\nMasked-R-CNN: 1.47x\nTransformer (12 layer, Machine Translation, WMT14 en-de): 1.70x\nThus, the figures are a bit lower than the theoretical estimate for computer vision. This might be due to smaller tensor dimensions, overhead from operations that are needed to prepare the matrix multiplication like img2col or Fast Fourier Transform (FFT), or operations that cannot saturate the GPU (final layers are often relatively small). It could also be artifacts of the specific architectures (grouped convolution).\n\nThe practical transformer estimate is very close to the theoretical estimate. This is probably because algorithms for huge matrices are very straightforward. I will use these practical estimates to calculate the cost efficiency of GPUs.\n\nPossible Biases in Estimates\nThe estimates above are for H100, A100 , and V100 GPUs. In the past, NVIDIA sneaked unannounced performance degradations into the “gaming” RTX GPUs: (1) Decreased Tensor Core utilization, (2) gaming fans for cooling, (3) disabled peer-to-peer GPU transfers. It might be possible that there are unannounced performance degradations in the RTX 40 series compared to the full Hopper H100.\n\nAs of now, one of these degradations was found for Ampere GPUs: Tensor Core performance was decreased so that RTX 30 series GPUs are not as good as Quadro cards for deep learning purposes. This was also done for the RTX 20 series, so it is nothing new, but this time it was also done for the Titan equivalent card, the RTX 3090. The RTX Titan did not have performance degradation enabled.\n\nCurrently, no degradation for Ada GPUs are known, but I update this post with news on this and let my followers on twitter know.\n\nAdvantages and Problems for RTX40 and RTX 30 Series\nThe new NVIDIA Ampere RTX 30 series has additional benefits over the NVIDIA Turing RTX 20 series, such as sparse network training and inference. Other features, such as the new data types, should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required.\n\nThe Ada RTX 40 series has even further advances like 8-bit Float (FP8) tensor cores. The RTX 40 series also has similar power and temperature issues compared to the RTX 30. The issue of melting power connector cables in the RTX 40 can be easily prevented by connecting the power cable correctly.\n\nSparse Network Training\nAmpere allows for fine-grained structure automatic sparse matrix multiplication at dense speeds. How does this work? Take a weight matrix and slice it into pieces of 4 elements. Now imagine 2 elements of these 4 to be zero. Figure 1 shows how this could look like.\n\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool's GTC 2020 presentation on  Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nWhen you multiply this sparse weight matrix with some dense inputs, the sparse matrix tensor core feature in Ampere automatically compresses the sparse matrix to a dense representation that is half the size as can be seen in Figure 2. After this compression, the densely compressed matrix tile is fed into the tensor core which computes a matrix multiplication of twice the usual size. This effectively yields a 2x speedup since the bandwidth requirements during matrix multiplication from shared memory are halved.\n\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed.\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nI was working on sparse network training in my research and I also wrote a blog post about sparse training. One criticism of my work was that “You reduce the FLOPS required for the network, but it does not yield speedups because GPUs cannot do fast sparse matrix multiplication.” Well, with the addition of the sparse matrix multiplication feature for Tensor Cores, my algorithm, or other sparse training algorithms, now actually provide speedups of up to 2x during training.\n\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nWhile this feature is still experimental and training sparse networks are not commonplace yet, having this feature on your GPU means you are ready for the future of sparse training.\n\nLow-precision Computation\nIn my work, I’ve previously shown that new data types can improve stability during low-precision backpropagation.\n\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nCurrently, if you want to have stable backpropagation with 16-bit floating-point numbers (FP16), the big problem is that ordinary FP16 data types only support numbers in the range [-65,504, 65,504]. If your gradient slips past this range, your gradients explode into NaN values. To prevent this during FP16 training, we usually perform loss scaling where you multiply the loss by a small number before backpropagating to prevent this gradient explosion.\n\nThe BrainFloat 16 format (BF16) uses more bits for the exponent such that the range of possible numbers is the same as for FP32: [-3*10^38, 3*10^38]. BF16 has less precision, that is significant digits, but gradient precision is not that important for learning. So what BF16 does is that you no longer need to do any loss scaling or worry about the gradient blowing up quickly. As such, we should see an increase in training stability by using the BF16 format as a slight loss of precision.\n\nWhat this means for you: With BF16 precision, training might be more stable than with FP16 precision while providing the same speedups. With 32-bit TensorFloat (TF32) precision, you get near FP32 stability while giving the speedups close to FP16. The good thing is, to use these data types, you can just replace FP32 with TF32 and FP16 with BF16 — no code changes required!\n\nOverall, though, these new data types can be seen as lazy data types in the sense that you could have gotten all the benefits with the old data types with some additional programming efforts (proper loss scaling, initialization, normalization, using Apex). As such, these data types do not provide speedups but rather improve ease of use of low precision for training.\n\nFan Designs and GPUs Temperature Issues\nWhile the new fan design of the RTX 30 series performs very well to cool the GPU, different fan designs of non-founders edition GPUs might be more problematic. If your GPU heats up beyond 80C, it will throttle itself and slow down its computational speed / power. This overheating can happen in particular if you stack multiple GPUs next to each other. A solution to this is to use PCIe extenders to create space between GPUs.\n\nSpreading GPUs with PCIe extenders is very effective for cooling, and other fellow PhD students at the University of Washington and I use this setup with great success. It does not look pretty, but it keeps your GPUs cool! This has been running with no problems at all for 4 years now. It can also help if you do not have enough space to fit all GPUs in the PCIe slots. For example, if you can find the space within a desktop computer case, it might be possible to buy standard 3-slot-width RTX 4090 and spread them with PCIe extenders within the case. With this, you might solve both the space issue and cooling issue for a 4x RTX 4090 setup with a single simple solution.\n\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 2 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 4 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\n3-slot Design and Power Issues\nThe RTX 3090 and RTX 4090 are 3-slot GPUs, so one will not be able to use it in a 4x setup with the default fan design from NVIDIA. This is kind of justified because it runs at over 350W TDP, and it will be difficult to cool in a multi-GPU 2-slot setting. The RTX 3080 is only slightly better at 320W TDP, and cooling a 4x RTX 3080 setup will also be very difficult.\n\nIt is also difficult to power a 4x 350W = 1400W or 4x 450W = 1800W system in the 4x RTX 3090 or 4x RTX 4090 case. Power supply units (PSUs) of 1600W are readily available, but having only 200W to power the CPU and motherboard can be too tight. The components’ maximum power is only used if the components are fully utilized, and in deep learning, the CPU is usually only under weak load. With that, a 1600W PSU might work quite well with a 4x RTX 3080 build, but for a 4x RTX 3090 build, it is better to look for high wattage PSUs (+1700W). Some of my followers have had great success with cryptomining PSUs — have a look in the comment section for more info about that. Otherwise, it is important to note that not all outlets support PSUs above 1600W, especially in the US. This is the reason why in the US, there are currently few standard desktop PSUs above 1600W on the market. If you get a server or cryptomining PSUs, beware of the form factor — make sure it fits into your computer case.\n\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nIt is possible to set a power limit on your GPUs. So you would be able to programmatically set the power limit of an RTX 3090 to 300W instead of their standard 350W. In a 4x GPU system, that is a saving of 200W, which might just be enough to build a 4x RTX 3090 system with a 1600W PSU feasible. It also helps to keep the GPUs cool. So setting a power limit can solve the two major problems of a 4x RTX 3080 or 4x RTX 3090 setups, cooling, and power, at the same time. For a 4x setup, you still need effective blower GPUs (and the standard design may prove adequate for this), but this resolves the PSU problem.\n\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nYou might ask, “Doesn’t this slow down the GPU?” Yes, it does, but the question is by how much. I benchmarked the 4x RTX 2080 Ti system shown in Figure 5 under different power limits to test this. I benchmarked the time for 500 mini-batches for BERT Large during inference (excluding the softmax layer). I choose BERT Large inference since, from my experience, this is the deep learning model that stresses the GPU the most. As such, I would expect power limiting to have the most massive slowdown for this model. As such, the slowdowns reported here are probably close to the maximum slowdowns that you can expect. The results are shown in Figure 7.\n\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nAs we can see, setting the power limit does not seriously affect performance. Limiting the power by 50W — more than enough to handle 4x RTX 3090 — decreases performance by only 7%.\n\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\nThere was a misconception that RTX 4090 power cables melt because they were bent. However, it was found that only 0.1% of users had this problem and the problem occured due to user error. Here a video that shows that the main problem is that cables were not inserted correctly.\n\nSo using RTX 4090 cards is perfectly safe if you follow the following install instructions:\n\nIf you use an old cable or old GPU make sure the contacts are free of debri / dust.\nUse the power connector and stick it into the socket until you hear a *click* — this is the most important part.\nTest for good fit by wiggling the power cable left to right. The cable should not move.\nCheck the contact with the socket visually, there should be no gap between cable and socket.\n8-bit Float Support in H100 and RTX 40 series GPUs\nThe support of the 8-bit Float (FP8) is a huge advantage for the RTX 40 series and H100 GPUs. With 8-bit inputs it allows you to load the data for matrix multiplication twice as fast, you can store twice as much matrix elements in your caches which in the Ada and Hopper architecture are very large, and now with FP8 tensor cores you get 0.66 PFLOPS of compute for a RTX 4090 — this is more FLOPS then the entirety of the worlds fastest supercomputer in year 2007. 4x RTX 4090 with FP8 compute rival the faster supercomputer in the world in year 2010 (deep learning started to work just in 2009).\n\nThe main problem with using 8-bit precision is that transformers can get very unstable with so few bits and crash during training or generate non-sense during inference. I have written a paper about the emergence of instabilities in large language models and I also written a more accessible blog post.\n\nThe main take-way is this: Using 8-bit instead of 16-bit makes things very unstable, but if you keep a couple of dimensions in high precision everything works just fine.\n\n\nMain results from my work on 8-bit matrix multiplication for Large Language Models (LLMs). We can see that the best 8-bit baseline fails to deliver good zero-shot performance. The method that I developed, LLM.int8(), can perform Int8 matrix multiplication with the same results as the 16-bit baseline.\nBut Int8 was already supported by the RTX 30 / A100 / Ampere generation GPUs, why is FP8 in the RTX 40 another big upgrade? The FP8 data type is much more stable than the Int8 data type and its easy to use it in functions like layer norm or non-linear functions, which are difficult to do with Integer data types. This will make it very straightforward to use it in training and inference. I think this will make FP8 training and inference relatively common in a couple of months.\n\nIf you want to read more about the advantages of Float vs Integer data types you can read my recent paper about k-bit inference scaling laws. Below you can see one relevant main result for Float vs Integer data types from this paper. We can see that bit-by-bit, the FP4 data type preserve more information than Int4 data type and thus improves the mean LLM zeroshot accuracy across 4 tasks.\n\n\n4-bit Inference scaling laws for Pythia Large Language Models for different data types. We see that bit-by-bit, 4-bit float data types have better zeroshot accuracy compared to the Int4 data types.\nRaw Performance Ranking of GPUs\nBelow we see a chart of raw relevative performance across all GPUs. We see that there is a gigantic gap in 8-bit performance of H100 GPUs and old cards that are optimized for 16-bit performance.\n\n\nShown is raw relative transformer performance of GPUs. For example, an RTX 4090 has about 0.33x performance of a H100 SMX for 8-bit inference. In other words, a H100 SMX is three times faster for 8-bit inference compared to a RTX 4090.\nFor this data, I did not model 8-bit compute for older GPUs. I did so, because 8-bit Inference and training are much more effective on Ada/Hopper GPUs because of the 8-bit Float data type and Tensor Memory Accelerator (TMA) which saves the overhead of computing read/write indices which is particularly helpful for 8-bit matrix multiplication. Ada/Hopper also have FP8 support, which makes in particular 8-bit training much more effective.\n\nI did not model numbers for 8-bit training because to model that I need to know the latency of L1 and L2 caches on Hopper/Ada GPUs, and they are unknown and I do not have access to such GPUs. On Hopper/Ada, 8-bit training performance can well be 3-4x of 16-bit training performance if the caches are as fast as rumored.\n\nBut even with the new FP8 tensor cores there are some additional issues which are difficult to take into account when modeling GPU performance. For example, FP8 tensor cores do not support transposed matrix multiplication which means backpropagation needs either a separate transpose before multiplication or one needs to hold two sets of weights — one transposed and one non-transposed — in memory. I used two sets of weight when I experimented with Int8 training in my LLM.int8() project and this reduced the overall speedups quite significantly. I think one can do better with the right algorithms/software, but this shows that missing features like a transposed matrix multiplication for tensor cores can affect performance.\n\nFor old GPUs, Int8 inference performance is close to the 16-bit inference performance for models below 13B parameters. Int8 performance on old GPUs is only relevant if you have relatively large models with 175B parameters or more. If you are interested in 8-bit performance of older GPUs, you can read the Appendix D of my LLM.int8() paper where I benchmark Int8 performance.\n\nGPU Deep Learning Performance per Dollar\nBelow we see the chart for the performance per US dollar for all GPUs sorted by 8-bit inference performance. How to use the chart to find a suitable GPU for you is as follows:\n\nDetermine the amount of GPU memory that you need (rough heuristic: at least 12 GB for image generation; at least 24 GB for work with transformers)\nWhile 8-bit inference and training is experimental, it will become standard within 6 months. You might need to do some extra difficult coding to work with 8-bit in the meantime. Is that OK for you? If not, select for 16-bit performance.\nUsing the metric determined in (2), find the GPU with the highest relative performance/dollar that has the amount of memory you need.\nWe can see that the RTX 4070 Ti is most cost-effective for 8-bit and 16-bit inference while the RTX 3080 remains most cost-effective for 16-bit training. While these GPUs are most cost-effective, they are not necessarily recommended as they do not have sufficient memory for many use-cases. However, it might be the ideal cards to get started on your deep learning journey. Some of these GPUs are excellent for Kaggle competition where one can often rely on smaller models. Since to do well in Kaggle competitions the method of how you work is more important than the models size, many of these smaller GPUs are excellent for Kaggle competitions.\n\nThe best GPUs for academic and startup servers seem to be A6000 Ada GPUs (not to be confused with A6000 Turing). The H100 SXM GPU is also very cost effective and has high memory and very strong performance. If I would build a small cluster for a company/academic lab, I would use 66-80% A6000 GPUs and 20-33% H100 SXM GPUs. If I get a good deal on L40 GPUs, I would also pick them instead of A6000, so you can always ask for a quote on these.\n\n\nShown is relative performance per US Dollar of GPUs normalized by the cost for a desktop computer and the average Amazon and eBay price for each GPU. Additionally, the electricity cost of ownership for 5 years is added with an electricity price of 0.175 USD per kWh and a 15% GPU utilization rate. The electricity cost for a RTX 4090 is about $100 per year. How to read and interpret the chart: a desktop computer with RTX 4070 Ti cards owned for 5 years yields about 2x more 8-bit inference performance per dollar compared to a RTX 3090 GPU.\nGPU Recommendations\nI have a create a recommendation flow-chart that you can see below (click here for interactive app from Nan Xiao). While this chart will help you in 80% of cases, it might not quite work for you because the options might be too expensive. In that case, try to look at the benchmarks above and pick the most cost effective GPU that still has enough GPU memory for your use-case. You can estimate the GPU memory needed by running your problem in the vast.ai or Lambda Cloud for a while so you know what you need. The vast.ai or Lambda Cloud might also work well if you only need a GPU very sporadically (every couple of days for a few hours) and you do not need to download and process large dataset to get started. However, cloud GPUs are usually not a good option if you use your GPU for many months with a high usage rate each day (12 hours each day). You can use the example in the “When is it better to use the cloud vs a dedicated GPU desktop/server?” section below to determine if cloud GPUs are good for you.\n\n\nGPU recommendation chart for Ada/Hopper GPUs. Follow the answers to the Yes/No questions to find the GPU that is most suitable for you. While this chart works well in about 80% of cases, you might end up with a GPU that is too expensive. Use the cost/performance charts above to make a selection instead. [interactive app]\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nTo understand if it makes sense to skip this generation and buy the next generation of GPUs, it makes sense to talk a bit about what improvements in the future will look like.\n\nIn the past it was possible to shrink the size of transistors to improve speed of a processor. This is coming to an end now. For example, while shrinking SRAM increased its speed (smaller distance, faster memory access), this is no longer the case. Current improvements in SRAM do not improve its performance anymore and might even be negative. While logic such as Tensor Cores get smaller, this does not necessarily make GPU faster since the main problem for matrix multiplication is to get memory to the tensor cores which is dictated by SRAM and GPU RAM speed and size. GPU RAM still increases in speed if we stack memory modules into high-bandwidth modules (HBM3+), but these are too expensive to manufacture for consumer applications. The main way to improve raw speed of GPUs is to use more power and more cooling as we have seen in the RTX 30s and 40s series. But this cannot go on for much longer.\n\nChiplets such as used by AMD CPUs are another straightforward way forward. AMD beat Intel by developing CPU chiplets. Chiplets are small chips that are fused together with a high speed on-chip network. You can think about them as two GPUs that are so physically close together that you can almost consider them a single big GPU. They are cheaper to manufacture, but more difficult to combine into one big chip. So you need know-how and fast connectivity between chiplets. AMD has a lot of experience with chiplet design. AMD’s next generation GPUs are going to be chiplet designs, while NVIDIA currently has no public plans for such designs. This may mean that the next generation of AMD GPUs might be better in terms of cost/performance compared to NVIDIA GPUs.\n\nHowever, the main performance boost for GPUs is currently specialized logic. For example, the asynchronous copy hardware units on the Ampere generation (RTX 30 / A100 / RTX 40) or the extension, the Tensor Memory Accelerator (TMA), both reduce the overhead of copying memory from the slow global memory to fast shared memory (caches) through specialized hardware and so each thread can do more computation. The TMA also reduces overhead by performing automatic calculations of read/write indices which is particularly important for 8-bit computation where one has double the elements for the same amount of memory compared to 16-bit computation. So specialized hardware logic can accelerate matrix multiplication further.\nLow-bit precision is another straightforward way forward for a couple of years. We will see widespread adoption of 8-bit inference and training in the next months. We will see widespread 4-bit inference in the next year. Currently, the technology for 4-bit training does not exists, but research looks promising and I expect the first high performance FP4 Large Language Model (LLM) with competitive predictive performance to be trained in 1-2 years time.\n\nGoing to 2-bit precision for training currently looks pretty impossible, but it is a much easier problem than shrinking transistors further. So progress in hardware mostly depends on software and algorithms that make it possible to use specialized features offered by the hardware.\n\nWe will probably be able to still improve the combination of algorithms + hardware to the year 2032, but after that will hit the end of GPU improvements (similar to smartphones). The wave of performance improvements after 2032 will come from better networking algorithms and mass hardware. It is uncertain if consumer GPUs will be relevant at this point. It might be that you need an RTX 9090 to run run Super HyperStableDiffusion Ultra Plus 9000 Extra or OpenChatGPT 5.0, but it might also be that some company will offer a high-quality API that is cheaper than the electricity cost for a RTX 9090 and you want to use a laptop + API for image generation and other tasks.\n\nOverall, I think investing into a 8-bit capable GPU will be a very solid investment for the next 9 years. Improvements at 4-bit and 2-bit are likely small and other features like Sort Cores would only become relevant once sparse matrix multiplication can be leveraged well. We will probably see some kind of other advancement in 2-3 years which will make it into the next GPU 4 years from now, but we are running out of steam if we keep relying on matrix multiplication. This makes investments into new GPUs last longer.\n\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nGenerally, no. PCIe 5.0 or 4.0 is great if you have a GPU cluster. It is okay if you have an 8x GPU machine, but otherwise, it does not yield many benefits. It allows better parallelization and a bit faster data transfer. Data transfers are not a bottleneck in any application. In computer vision, in the data transfer pipeline, the data storage can be a bottleneck, but not the PCIe transfer from CPU to GPU. So there is no real reason to get a PCIe 5.0 or 4.0 setup for most people. The benefits will be maybe 1-7% better parallelization in a 4 GPU setup.\n\nDo I need 8x/16x PCIe lanes?\nSame as with PCIe 4.0 — generally, no. PCIe lanes are needed for parallelization and fast data transfers, which are seldom a bottleneck. Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.\n\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nYou need to get one of the two-slot variants, or you can try to spread them out with PCIe extenders. Besides space, you should also immediately think about cooling and a suitable PSU.\n\nPCIe extenders might also solve both space and cooling issues, but you need to make sure that you have enough space in your case to spread out the GPUs. Make sure your PCIe extenders are long enough!\n\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nSee the previous section.\n\nCan I use multiple GPUs of different GPU types?\nYes, you can! But you cannot parallelize efficiently across GPUs of different types since you will often go at the speed of the slowest GPU (data and fully sharded parallelism). So different GPUs work just fine, but parallelization across those GPUs will be inefficient since the fastest GPU will wait for the slowest GPU to catch up to a synchronization point (usually gradient update).\n\nWhat is NVLink, and is it useful?\nGenerally, NVLink is not useful. NVLink is a high speed interconnect between GPUs. It is useful if you have a GPU cluster with +128 GPUs. Otherwise, it yields almost no benefits over standard PCIe transfers.\n\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nDefinitely buy used GPUs. You can buy a small cheap GPU for prototyping and testing and then roll out for full experiments to the cloud like vast.ai or Lambda Cloud. This can be cheap if you train/fine-tune/inference on large models only every now and then and spent more time protoyping on smaller models.\n\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nI built a carbon calculator for calculating your carbon footprint for academics (carbon from flights to conferences + GPU time). The calculator can also be used to calculate a pure GPU carbon footprint. You will find that GPUs produce much, much more carbon than international flights. As such, you should make sure you have a green source of energy if you do not want to have an astronomical carbon footprint. If no electricity provider in our area provides green energy, the best way is to buy carbon offsets. Many people are skeptical about carbon offsets. Do they work? Are they scams?\n\nI believe skepticism just hurts in this case, because not doing anything would be more harmful than risking the probability of getting scammed. If you worry about scams, just invest in a portfolio of offsets to minimize risk.\n\nI worked on a project that produced carbon offsets about ten years ago. The carbon offsets were generated by burning leaking methane from mines in China. UN officials tracked the process, and they required clean digital data and physical inspections of the project site. In that case, the carbon offsets that were produced were highly reliable. I believe many other projects have similar quality standards.\n\nWhat do I need to parallelize across two machines?\nIf you want to be on the safe side, you should get at least +50Gbits/s network cards to gain speedups if you want to parallelize across machines. I recommend having at least an EDR Infiniband setup, meaning a network card with at least 50 GBit/s bandwidth. Two EDR cards with cable are about $500 on eBay.\n\nIn some cases, you might be able to get away with 10 Gbit/s Ethernet, but this is usually only the case for special networks (certain convolutional networks) or if you use certain algorithms (Microsoft DeepSpeed).\n\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nIt does not seem so. Since the granularity of the sparse matrix needs to have 2 zero-valued elements, every 4 elements, the sparse matrices need to be quite structured. It might be possible to adjust the algorithm slightly, which involves that you pool 4 values into a compressed representation of 2 values, but this also means that precise arbitrary sparse matrix multiplication is not possible with Ampere GPUs.\n\nDo I need an Intel CPU to power a multi-GPU setup?\nI do not recommend Intel CPUs unless you heavily use CPUs in Kaggle competitions (heavy linear algebra on the CPU). Even for Kaggle competitions AMD CPUs are still great, though. AMD CPUs are cheaper and better than Intel CPUs in general for deep learning. For a 4x GPU built, my go-to CPU would be a Threadripper. We built dozens of systems at our university with Threadrippers, and they all work great — no complaints yet. For 8x GPU systems, I would usually go with CPUs that your vendor has experience with. CPU and PCIe/system reliability is more important in 8x systems than straight performance or straight cost-effectiveness.\n\nDoes computer case design matter for cooling?\nNo. GPUs are usually perfectly cooled if there is at least a small gap between GPUs. Case design will give you 1-3 C better temperatures, space between GPUs will provide you with 10-30 C improvements. The bottom line, if you have space between GPUs, cooling does not matter. If you have no space between GPUs, you need the right cooler design (blower fan) or another solution (water cooling, PCIe extenders), but in either case, case design and case fans do not matter.\n\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nNot in the next 1-2 years. It is a three-way problem: Tensor Cores, software, and community.\n\nAMD GPUs are great in terms of pure silicon: Great FP16 performance, great memory bandwidth. However, their lack of Tensor Cores or the equivalent makes their deep learning performance poor compared to NVIDIA GPUs. Packed low-precision math does not cut it. Without this hardware feature, AMD GPUs will never be competitive. Rumors show that some data center card with Tensor Core equivalent is planned for 2020, but no new data emerged since then. Just having data center cards with a Tensor Core equivalent would also mean that few would be able to afford such AMD GPUs, which would give NVIDIA a competitive advantage.\n\nLet’s say AMD introduces a Tensor-Core-like-hardware feature in the future. Then many people would say, “But there is no software that works for AMD GPUs! How am I supposed to use them?” This is mostly a misconception. The AMD software via ROCm has come to a long way, and support via PyTorch is excellent. While I have not seen many experience reports for AMD GPUs + PyTorch, all the software features are integrated. It seems, if you pick any network, you will be just fine running it on AMD GPUs. So here AMD has come a long way, and this issue is more or less solved.\n\nHowever, if you solve software and the lack of Tensor Cores, AMD still has a problem: the lack of community. If you have a problem with NVIDIA GPUs, you can Google the problem and find a solution. That builds a lot of trust in NVIDIA GPUs. You have the infrastructure that makes using NVIDIA GPUs easy (any deep learning framework works, any scientific problem is well supported). You have the hacks and tricks that make usage of NVIDIA GPUs a breeze (e.g., apex). You can find experts on NVIDIA GPUs and programming around every other corner while I knew much less AMD GPU experts.\n\nIn the community aspect, AMD is a bit like Julia vs Python. Julia has a lot of potential, and many would say, and rightly so, that it is the superior programming language for scientific computing. Yet, Julia is barely used compared to Python. This is because the Python community is very strong. Numpy, SciPy, Pandas are powerful software packages that a large number of people congregate around. This is very similar to the NVIDIA vs AMD issue.\n\nThus, it is likely that AMD will not catch up until Tensor Core equivalent is introduced (1/2 to 1 year?) and a strong community is built around ROCm (2 years?). AMD will always snatch a part of the market share in specific subgroups (e.g., cryptocurrency mining, data centers). Still, in deep learning, NVIDIA will likely keep its monopoly for at least a couple more years.\n\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nRule-of-thumb: If you expect to do deep learning for longer than a year, it is cheaper to get a desktop GPU. Otherwise, cloud instances are preferable unless you have extensive cloud computing skills and want the benefits of scaling the number of GPUs up and down at will.\n\nNumbers in the following paragraphs are going to change, but it serves as a scenario that helps you to understand the rough costs. You can use similar math to determine if cloud GPUs are the best solution for you.\n\nFor the exact point in time when a cloud GPU is more expensive than a desktop depends highly on the service that you are using, and it is best to do a little math on this yourself. Below I do an example calculation for an AWS V100 spot instance with 1x V100 and compare it to the price of a desktop with a single RTX 3090 (similar performance). The desktop with RTX 3090 costs $2,200 (2-GPU barebone + RTX 3090). Additionally, assuming you are in the US, there is an additional $0.12 per kWh for electricity. This compares to $2.14 per hour for the AWS on-demand instance.\n\nAt 15% utilization per year, the desktop uses:\n\n(350 W (GPU) + 100 W (CPU))*0.15 (utilization) * 24 hours * 365 days = 591 kWh per year\n\nSo 591 kWh of electricity per year, that is an additional $71.\n\nThe break-even point for a desktop vs a cloud instance at 15% utilization (you use the cloud instance 15% of time during the day), would be about 300 days ($2,311 vs $2,270):\n\n$2.14/h * 0.15 (utilization) * 24 hours * 300 days = $2,311\n\nSo if you expect to run deep learning models after 300 days, it is better to buy a desktop instead of using AWS on-demand instances.\n\nYou can do similar calculations for any cloud service to make the decision if you go for a cloud service or a desktop.\n\nCommon utilization rates are the following:\n\nPhD student personal desktop: < 15%\nPhD student slurm GPU cluster: > 35%\nCompany-wide slurm research cluster: > 60%\nIn general, utilization rates are lower for professions where thinking about cutting edge ideas is more important than developing practical products. Some areas have low utilization rates (interpretability research), while other areas have much higher rates (machine translation, language modeling). In general, the utilization of personal machines is almost always overestimated. Commonly, most personal systems have a utilization rate between 5-10%. This is why I would highly recommend slurm GPU clusters for research groups and companies instead of individual desktop GPU machines.\n\nVersion History\n2023-01-30: Improved font and recommendation chart. Added 5 years cost of ownership electricity perf/USD chart. Updated Async copy and TMA functionality. Slight update to FP8 training. General improvements.\n2023-01-16: Added Hopper and Ada GPUs. Added GPU recommendation chart. Added information about the TMA unit and L2 cache.\n2020-09-20: Added discussion of using power limiting to run 4x RTX 3090 systems. Added older GPUs to the performance and cost/performance charts. Added figures for sparse matrix multiplication.\n2020-09-07: Added NVIDIA Ampere series GPUs. Included lots of good-to-know GPU details.\n2019-04-03: Added RTX Titan and GTX 1660 Ti. Updated TPU section. Added startup hardware discussion.\n2018-11-26: Added discussion of overheating issues of RTX cards.\n2018-11-05: Added RTX 2070 and updated recommendations. Updated charts with hard performance data. Updated TPU section.\n2018-08-21: Added RTX 2080 and RTX 2080 Ti; reworked performance analysis\n2017-04-09: Added cost-efficiency analysis; updated recommendation with NVIDIA Titan Xp\n2017-03-19: Cleaned up blog post; added GTX 1080 Ti\n2016-07-23: Added Titan X Pascal and GTX 1060; updated recommendations\n2016-06-25: Reworked multi-GPU section; removed simple neural network memory section as no longer relevant; expanded convolutional memory section; truncated AWS section due to not being efficient anymore; added my opinion about the Xeon Phi; added updates for the GTX 1000 series\n2015-08-20: Added section for AWS GPU instances; added GTX 980 Ti to the comparison relation\n2015-04-22: GTX 580 no longer recommended; added performance relationships between cards\n2015-03-16: Updated GPU recommendations: GTX 970 and GTX 580\n2015-02-23: Updated GPU recommendations and memory calculations\n2014-09-28: Added emphasis for memory requirement of CNNs\nAcknowledgments\nI thank Suhail for making me aware of outdated prices on H100 GPUs, Gjorgji Kjosev for pointing out font issues, Anonymous for pointing out that the TMA unit does not exist on Ada GPUs, Scott Gray for pointing out that FP8 tensor cores have no transposed matrix multiplication, and reddit and HackerNews users for pointing out many other improvements.\n\nFor past updates of this blog post, I want to thank Mat Kelcey for helping me to debug and test custom code for the GTX 970; I want to thank Sander Dieleman for making me aware of the shortcomings of my GPU memory advice for convolutional nets; I want to thank Hannes Bretschneider for pointing out software dependency problems for the GTX 580; and I want to thank Oliver Griesel for pointing out notebook solutions for AWS instances. I want to thank Brad Nemire for providing me with an RTX Titan for benchmarking purposes. I want to thank Agrin Hilmkil, Ari Holtzman, Gabriel Ilharco, Nam Pho for their excellent feedback on the previous version of this blog post.""]","The AI Act imposes certain obligations on providers of general-purpose AI models, particularly those that may pose systemic risks. Here are the key rules for developing general-purpose AI models:

1. **Transparency Requirements**: Providers must disclose specific information to downstream system providers to ensure that they understand the capabilities and limitations of the general-purpose AI model.

2. **Risk Assessment and Mitigation**: Providers of models that are identified as carrying systemic risks are required to assess and mitigate those risks. This includes implementing policies to ensure compliance with the AI Act.

3. **Incident Reporting**: Providers must report serious incidents related to the use of their models to the relevant authorities.

4. **Testing and Evaluation**: Providers are mandated to conduct state-of-the-art tests and evaluations of their models to ensure they meet safety and performance standards.

5. **Energy Consumption Disclosure**: Providers must provide information on the energy consumption of their models, especially for those that are trained on large datasets and may have high energy requirements.

6. **Engagement with the European AI Office**: Providers are encouraged to engage with the European AI Office to develop Codes of Conduct that detail the rules and ensure compliance with the AI Act.

These rules aim to ensure that general-purpose AI models are developed responsibly, with attention to safety, transparency, and compliance with legal standards.",0.8421052631578947,0.9144388840245075,0.0,0.9999999999,1.0
What can moss be used for?,Harvesting moss gives 1 foraging exp per moss and speed gro requires five moss.,"[""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 ""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 'Semantic and Textual Inference Chatbot Interface (STICI-Note) - Part 1: Planning and Prototyping\n\nThe start of my RAG to riches story\n\nSTICI-note\n\nPublished: Mon, 27 May 2024\n\nLast modified: Tue, 04 Jun 2024\n\nIntroduction\n\nIn this three-part series, I will be talking you through how I built the Semantic and Textual Inference Chatbot Interface (or STICI-note for short), a locally run RAG chatbot that uses unstructured text documents to enhance its responses. I came up with the name when I was discussing this project with a friend and asked him whether he had any ideas of what to call it. He said, ""You should call it sticky because it sounds funny."" The name... stuck...\n\nThe code for this project is available here.\n\nIn this part, I will be planning the project from the tech stack to the techniques I will use, and I will be building a prototype. I will be discussing all of the choices I made and all of the choices I didn’t make, so I hope you find this insightful. Without further ado, let’s get started.\n\nThe Problem\n\nIn my spare time, I occasionally play Dungeons and Dragons (DnD), a tabletop roleplaying game, and the stories are often told over several months, so details can be easily lost or forgotten over time. I can write notes on my laptop, but sometimes regular text search does not always provide me with the results I want when trying to search for specific notes. Some common examples include when a keyword is used often (e.g., I might write a lot about the actions of “Miles Lawson,” but only one segment of text might describe who he is, making searching for information on his character like finding a needle in a haystack) or when I simply cannot think of the correct keyword to search (e.g., what if I search “silver” instead of “gold”?).\n\nOne day, I thought to myself that it’d be great if I had a tool that I could write my DnD notes into in an unstructured way and retrieve the information at any time with simple questions like “Who is Miles Lawson?” or “How much silver did I pay for a stay in ye olde tavern?”. This tool could be extended to be used for querying my notes on many things that are not available online (and therefore not searchable on a search engine), such as documentation on software that I build, notes on things that I’m learning about, such as AWS cloud infrastructure, and my diary of my deepest thoughts and feelings (at least I hope this is not available online). And thus, I decided to start working on STICI-note because the tools available online that do this cost money and run on the cloud, and I’m a tight-fisted guy who’s very sceptical about company promises to not sell your data.\n\nNarrowing Down Features\n\nAs with all projects, I began by deciding what features I needed from this tool.\n\nRequired features:\n\nChatbot that you can ask questions and get answers in response (conversational memory is not required).\nInformation is taken from an unstructured text file.\nIt must be able to tell me if it doesn’t know the answer to my question.\nFast.\nEfficient enough to run on my MacBook with other programs without any performance issues.\nLocally run for privacy and to ensure it will always be free, runnable, and consistent.\nConversational memory is the memory of previous interactions given to an LLM. I decided not to require it as a feature because I just need the AI to answer my questions about the given text. It might be added as a feature in the future if I feel like I need it, but I do not plan to include it in the initial version of STICI-note.\n\nI knew that limiting it to running on my M1 MacBook with 8 GB of memory would greatly limit the performance of the tool as I would not be able to access truly large language models like GPT-4 and Claude 3 Opus, but I decided to do it anyway primarily for privacy but also to remove dependencies on external organisations to reduce the maintenance required for the tool in the future.\n\nPlanning How to Evaluate and Compare Solutions\n\nIf you don’t evaluate a solution, how do you know whether it’s an effective solution? You don’t.\n\nI next planned how I would evaluate different variations of the tool. While I do not evaluate anything in this part, I decided to sketch out a rough plan of how I would evaluate different solutions to encourage designing a testable AI in the same way that Test-Driven Development (TDD) encourages you to write testable code.\n\nAt first, I considered using Wikipedia pages as the data source and making my own questions about the content of the pages before I realised that this would lead to data leakage as many LLMs are trained on Wikipedia data.\n\nAn alternative dataset that I considered using for evaluation is the TREC 2024 RAG Corpus. This is a 28 GB corpus of text documents scraped from the internet. This corpus comes with thousands of queries, and the relevant documents for each query have been tagged as such. This is an amazing corpus for training and evaluating vector DataBase (DBs). Ignoring the fact that its questions do not come with answers, meaning I would have to write my own answers to use the document, there is one glaring flaw that makes it unusable for my use case: the documents are generally relatively short and describe a large variety of things. In my use case, I expect documents to be long and typically written about the same topic. If I were to use the corpus, I would have to stick documents together to present a realistic challenge in the semantic search of the vector DB vector space, but as each document will likely be about very different topics (e.g., one might be about aviation while another might be about economics), context retrieval would be unrealistically easy.\n\nAnother alternative evaluation dataset that I considered using was a synthetic dataset. By following a method like this, I can use an LLM to generate synthetic context and questions automatically. I decided not to do this as I was concerned that this would produce bad-quality data with a massive bias towards things an LLM might already know, despite the use case expecting data that the LLM does not already know.\n\nBecause the documents in my evaluation corpus need to be thousands of words in length while staying relevant to a topic and they need to include information that will not be in the LLM’s training data, I decided that it would be best to manually curate a small dataset to evaluate my models. I plan to create documents from sources on the internet like videogame wikis, people’s blogs, and scientific journals and write my own pairs of questions and answers about them. I will then evaluate the difference between the model’s answer and my answer using a semantic similarity score.\n\nRAG vs a Really Big Context Window vs Infinite Context\n\nTo be able to answer questions about documents, the LLM would need to have access to information from the documents. I thought of three potential solutions for this:\n\nRetrieval Augmented Generation (RAG)\nAn LLM with a really big context window\nAn LLM that supports infinite context length\nUsing an LLM with a really big context window such as Anthropic’s Claude 3 and Google’s Gemini 1.5 would certainly give me the best results as it would allow inference using completely unfiltered and uncompressed context as they can handle inputs of over 700,000 words, but these models are closed-source, and there is absolutely no chance of a model of this size fitting into my tiny M1 MacBook with 8 GB of memory.\n\nBy “an LLM that supports infinite context length,” I mean models like Mamba, Megalodon, and Infini-attention that compress context into a finite space. I decided not to use a model like this for two main reasons. Firstly, I have concerns about the performance. These architectures are in their infancy, and I do not expect them to outperform equivalently-sized traditional transformers. Secondly, as these architectures are very new and experimental, I do not expect much support for them, especially for Apple’s M-series of chips, which have their own graphics API, metal, that is required for GPU acceleration on my MacBook. These architectures are very interesting, and I would love to try them out, but for this project, I will have to settle for a more tried-and-tested approach.\n\nThe more tried and tested approach that I settled with is RAG. It is an incredibly popular technique for allowing LLMs to make use of information that is too big to fit in their context windows. This technique is known to perform very well, is incredibly well supported by LLM frameworks like LangChain and llamaindex, and works well in resource-constrained environments like on my laptop. Given all this, RAG was an obvious choice.\n\nOptimising Models for Limited Memory Environments\n\nNext, I decided to investigate what kinds of optimisation strategies were available to use to try to fit bigger models into my M1 chip, as bigger LLMs typically perform better (I know, a groundbreaking revelation). To optimise the LLMs that I use, I considered four different techniques:\n\nQuantisation\nModel pruning\nModel/knowledge distillation\nAirLLM\nQuantisation is the most common method for making ML models smaller (and therefore faster and more capable of fitting into smaller spaces). It’s well known for improving speed and memory usage with little loss in accuracy in return, which makes it very popular for production-level AI. Quantising a model would require being able to fit it into your GPU, but I’m trying to quantise a model so that it can fit into my GPU, so without additional computing power, it’s a bit of a chicken and egg problem. Luckily, because this is such a popular technique, there are many quantised versions of large, high-performance LLMs available on HuggingFace that I can use, so there is no need to do this myself.\n\nModel pruning is a less common method for reducing model sizes, but it is not a technique that one should overlook. This is a technique that can be combined with quantisation (or used on its own) to further reduce models at the expense of accuracy, but I do not plan to apply it myself due to its complexity and the fact that quantisation has the same effect. There are pruned models available on HuggingFace, but they don’t typically perform as well as equivalently sized quantised models, so I do not plan to use any unless they have particularly good evaluation results on a common LLM benchmark.\n\nModel/knowledge distillation is another size reduction technique that I considered. Unlike the previous techniques, model distillation can actually improve accuracy in domain-specific tasks while making a smaller model. As with quantisation and model pruning, I will use pre-distiled models, but I will not distil any models myself due to the computing power it requires (which admittedly is far less than training a model from scratch) and the complexity it would add to the project.\n\nThe final optimisation technique that I considered, AirLLM, is quite different from the others in that instead of optimising the model weights, it optimises the model inference. Typically, LLMs are loaded onto the GPU in their entirety, requiring a lot of VRAM to run the larger, better-performing models. AirLLM is an open-source library that tackles this problem by using layered inference, an inference technique that involves loading layers individually when they are needed instead of all at once. This allows larger models to fit into smaller memory spaces without degrading performance. This method definitely has a high potential for accuracy, but I decided not to use it as I am concerned about compatibility and reliability issues as it is a new tool and the GitHub repo has been developed by a single person, so support for it is likely to be limited. Additionally, my M1 chip only has 8 GB of memory shared between the CPU and GPU, which is excellent for reducing data loading overhead costs, but it means that larger models that require AirLLM will be loaded directly from the SSD, so I am concerned that the model layer loading and unloading will become a massive bottleneck when doing inference on larger models. I will reconsider this option if I find that the models that can run on my MacBook do not have satisfactory accuracy.\n\nWhat Models Even Run on My MacBook?\n\nAfter getting an idea of what kinds of optimisation techniques were available, I decided to conduct some tests to find out what LLMs would actually run on my MacBook. You could argue that since I am only building a prototype right now, I only need to find one LLM that performs well on my MacBook, but I decided to find five models instead to give me an idea of what kinds of models I will be able to use. In particular, I wanted to know how big the models I could run were and what precision the weights would likely be.\n\nI tested models that I had heard were good or showed decent results on the Hugging Face H4 Open LLM Leaderboard. I found LM Studio incredibly useful for testing out LLMs without having to write any code, which saved me a lot of time. Below are the five suitable models that I found that could run on my MacBook and were fast enough to satisfy me:\n\ntinyllama-1.1b-chat-v1.0 Q6_K\nPhi 3 Q4_K_M\nbartowski/dolphin-2.8-experiment26-7b-GGUF Q3_K_L\nmgonzs13/Mistroll-7B-v2.2-GGU\nQuantFactory/Meta-Llama-3-8B-Instruct Q3_K_M\nThese models range from 1.17 GB up to 4.02 GB in size. I chose not to use any models that were any larger than 4 GB, as with only 8 GB of memory available, I expect that models that are any bigger would seriously impact the other applications that the user (i.e., me) is running on their device.\n\nI will likely test out more models than this while testing out different configurations for the tool, but for the prototype, this is enough.\n\nA Model Without a Framework is Like a Car Engine Without a Chassis\n\nTo run my models, I could have written a framework for loading, unloading, and executing the models, passing context and queries to the models, and integrating the vector DB (more on that later) with the inference model from scratch, but I didn’t because I’m not insane and I am not trying to learn how to make ML frameworks. A lot of university students (myself included) are conditioned to try to build things from scratch for fear of plagiarism and because they are used to building things from scratch as a learning exercise (a very effective one in my opinion), so it’s difficult to unlearn the DIY mindset, but it’s simply a lot quicker and a lot more reliable to use libraries than to reinvent the wheel. Saying that, I decided to use a relatively simple tech stack.\n\nPython was an obvious choice for me, given that I have a lot of experience with it and that it has an abundance of support for machine learning applications. I decided to use LangChain to orchestrate my RAG process from the vector DB to the inference, as it is a flexible tool for composing NLP pipelines. It is very popular and reliable, and it includes a lot of tools that make developing NLP applications easier. I considered using LlamaIndex as it is built more specifically for RAG applications, but LangChain is more general-purpose, which I expect will make it more extensible for times when I might want to add more features in the future. Additionally, I am more likely to use LangChain again for other applications in the future, so the experience will be more useful. I also considered using LitGPT, but I had some issues getting it to work with the M1 chip’s Metal Performance Shaders (MPS), so I decided not to use it for fear of incompatibility. LitGPT is also intended more for training and fine-tuning LLMs, so it is likely not the best tool for simply deploying them in an application.\n\nTo run inference on my models, I will need another library to actually execute the model. As I am using a range of pre-trained models, I will mainly use HuggingFace’s transformers library and the Python bindings for llama.cpp library to load and execute models, as these provide simple interfaces for inference, and I don’t need the additional control that deep learning frameworks like TensorFlow, PyTorch, and JAX provide as I’m using pre-trained models. As I mentioned earlier, AirLLM is still on the table if I need better performance, but I will find out while evaluating models whether this is necessary.\n\nMagnitude + Direction DBs\n\nSince I was using RAG, I needed a vector DB. Deciding which one to use was the final step of the research and also the most difficult one, as vector DBs are the technology that I am least familiar with. For the vector DB, my main requirements were simple: it needed to be lightweight, locally runnable on a laptop, fast, and compatible with my MacBook. Lightweight and locally runnable sound like similar things, but I mean different things by each phrase. The locally runnable one is quite self-explanatory, but by lightweight, I mean quite minimal computation requirements that don’t add features like heavy amounts of redundancy and heavy caching, which are useful for large-scale systems, but will simply drain resources in my application that is designed to run alongside an LLM and the user’s other applications on 8 GB of memory shared between the CPU and GPU.\n\nI considered sixteen different vector DBs, but there were three different solutions that stood out to me for my use case: Chroma, Qdrant, and Vespa. These were all lightweight vector DBs that fit all of my requirements, but I decided to pick Chroma out of the three of them because it has a very batteries included approach, which is very useful for getting an application working quickly.\n\nBelow is an overview of my planned tech stack. I did not include any UI, as there are many options for this, and I plan to decide on the UI when building the final product.\n\nThe tech stack and data flow that I plan to use for STICI-note.\nThe tech stack and data flow that I plan to use for STICI-note.\n\nMaking the Prototype (A.K.A. the Easy Part)\n\nThe final step was to actually build the prototype/proof of concept (PoC) to find out whether this idea can actually be implemented using the tech stack that I have picked. I decided to implement it using the smallest of the 5 models that I had found earlier, tinyllama-1.1b-chat-v1.0 Q6_K, to minimise the chances of having any memory issues.\n\nYou can find my prototype code here.\n\nFor the prototype, I decided to make very basic configurations for everything to develop it quickly, and I tested it by asking a question about Grace Hopper, one of the most influential programmers to have ever lived, in two versions of the prototype: one with Grace Hopper’s Wikipedia page in its vector DB and one with Alan Turing’s Wikipedia page in its vector DB.\n\nThe question was:\n\n“What programming language was Grace Hopper known for creating?”\n\nAs expected, the version with Alan Turing’s Wikipedia page failed miserably, hallucinating its entire response:\n\nGrace Hopper was a computer scientist who is best known for her work on developing an early version of BASIC, which was one of the first low-level programming languages designed for mainframe computers. Hopper worked at Digital Equipment Corporation (DEC) in the mid-1960s and was responsible for creating several key BASIC versions that were used by DEC\'s mainframe computers. In 1973, she left DEC to work on a new low-level programming language called PASCAL, which became one of the most popular programming languages of its time. However, her contributions to BASIC are still remembered today as it was one of the first widely used and easy-to-understand programming languages for mainframe computers.\n\nThis behaviour of hallucinating will need to be fixed in the final product, likely through prompt engineering.\n\nAs expected, the version with Grace Hopper’s Wikipedia page gave a much more accurate response but it unexpectedly contained far more spelling errors:\n\nGrace Hopper is credited with creating the first computer programming languaige called FLOW-MATIC. This language was developed in 1954 and was based on English words. Hopper\'s work on this languaige led to a machine-indepenent programming language, COBOL, which used English words instead of symbols for input and output. Her compiler, A-0, also utilized the FLOW-MATIIC language as its basis for compiling programs into executable code. In 1952, Hopper published her first paper on the topic of compiler design, ""The Compiler"" in the IEEE Transactions on Computers, in which she discussed her work with A-0 and other programming languaiges.\n\nUnfortunately, this response was not free from hallucinations either. Hopper’s A-0 compiler did not use the FLOW-MATIC programming language, and she never published a paper called “The Compiler” in IEEE Transactions on Computers (a real journal that is not mentioned in the Wikipedia page). It looks like hallucinations are likely to be a major issue for this tool, but that is a problem I will solve when refining the AI.\n\nOn the bright side, inference was ~120 tokens/second, so at least this model will output words much faster than I can read them.\n\nConclusion\n\nIn this blog, I built a locally run prototype for my chatbot for querying unstructured text documents. It doesn’t have a UI, and it hallucinates a lot, but it is nonetheless capable of querying unstructured text.\n\nIt’s such a shame that after I had done the research and written all of the code, while I was writing this blog, I read about llmware, a very promising Python framework for building RAG pipelines with small models (sound familiar?). It was even chosen for GitHub Accelerator 2024, a competition for open-source projects on GitHub where chosen projects are given funding, mentorship, and access to resources to help them grow their project. Since I had already built the prototype in LangChain, it didn’t make much sense to tear it down and rebuild it in a fancy new framework that wasn’t as tried-and-tested. I’d love to try the framework out one day if I build another RAG application after this one.\n\nIn the next part of the STICI-note blog series, I will be building an evaluation suite to test and compare different inference models and vector DB configurations, so stay tuned and follow me on LinkedIn to be notified when it comes out!']",I don't know.,0.0,0.0,0.0017452006980802793,0.0,0.0
In what contexts is BERT mentioned?,"It is mentioned that for BERT large during training, the input and weight matrix of any matrix multiplication fit neatly into the L2 cache of Ada (but not other Us). The author also mentions that they benchmarked the time for 500 mini-batches for BERT Large during inference (excluding the softmax layer) on the 4x RTX 2080 Ti system. They chose BERT Large inference since, from their experience, this is the deep learning model that stresses the GPU the most.","[""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 'Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 '‘The Zone Of Interest’ Ending Explained & Film Summary: What Happens To Rudolf And Hedwig Hoss?\nPUBLISHED\n\nFEBRUARY 21, 2024\nBY\nSOURYA SUR ROY\n0COMMENTS\nThe Zone Of Interest Ending Explained Film Summary Hedwig Ross, Rudolph Ross\nCredits: A24\nThe Zone of Interest is a new historical drama film by English filmmaker Jonathan Glazer that manages to recreate a terrible moment from history with a unique and devastating effect. Loosely adapted from Martin Amis’ novel of the same name, the film’s plot follows the Hoss family, who live right beside the Auschwitz concentration camp, going about their usual lives with no concern for the terrible crimes being committed right outside. The Zone of Interest is all about subtle, indirect expressions that are poignant enough to pierce through the visual layer, successfully making the viewer all the more uncomfortable with every passing minute.\n\nSpoiler Alert\n\nPlot Summary: What Is The Film About?\nThe Zone of Interest opens with a noticeably long black screen, with only a soft sound being eerily stretched in the background, perhaps preparing us for what is to unfold on screen over the next hundred or so minutes. When the visuals come on, though, there is nothing unusual or out of the ordinary, as a family is seen spending some personal time by the forested banks of a river. This is a secluded spot reserved only for the family, and it seems to be their most common way of spending leisure time. As the girls are led by a nanny through the bushes, possibly for some lesson in gardening and wildlife, the boys jump into the river along with their father. Sometime later, the family reunites and leaves the riverbank, driving away in two black, sinister-looking cars. On that very night, the father of the house is seen going around, switching off all the lights, before going to bed.\n\nWhile there is really nothing odd in this whole presentation of a family spending a day with themselves, the chilling reality of the matter is revealed when the film introduces the particular lot. The family is that of Rudolf Hoss, a notorious real figure from history, infamous for being a distinguished SS officer and the commander of the Auschwitz concentration camp. Most of the entire film, and the whole of the opening scene, actually takes place in Auschwitz, meaning that the leisurely picnic of the big family literally took place only a few miles away from the spot of the ongoing genocide. This is the very premise of The Zone of Interest, for it shows the tumultuous time of history from the perspective of the Hoss family, mainly the patriarch Rudolf and his wife, Hedwig.\n\nThe couple lives in an idyllic resort with their two sons and three daughters, the youngest still a baby, right on the other side of the high walls of the concentration camp. Despite the inhuman torture and killing going on right outside the walls that separate their lives, the Hoss family members are not perturbed by the matter at all. Instead, they are rather accustomed to Auschwitz, cherishing their time and accepting it as their new home.\n\nHow Does The Film Powerfully Present The Harrowing Events Of The Holocaust?\nThe most remarkable thing about The Zone of Interest is how it manages to say so much without directly saying it, combining the visual and the aural through a unique dissonance. With regards to the visuals, meaning scenes that play out to take forward the mostly simple and common story, the camera hardly ever leaves the confines of the host house. While some exceptions take place towards the latter part of the film, when Rudolf is transferred to a different concentration camp and he is seen at his new post, almost no scene of the camp in Auschwitz is seen. But the audio track picks up on numerous cries, lashes, and sounds that clearly come from the outside world but are heavily ignored. There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf’s family and his subordinates celebrate the man’s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers. But nobody seems to notice, or rather, everyone pretends to look through the entire matter, as if nothing shocking is in the works. Rudolf is also seen meeting with a businessman in his house, who comes to show the commander plans and designs for a new, more effective gas chamber that he wants to build for his government. Rudolf goes through the plans without any hesitation and then also reports about this businessman’s portfolio to his higher authorities, convinced that sturdier and better-designed gas chambers are needed to take his beloved nation and his government forward. The Zone of Interest does not really differentiate between evil-doers and those supporting such evil, but Rudolf is definitely in the first category, as he clearly enjoys the torture and killing of people.\n\nWhat comes as even a bigger shock is the reaction of his wife, Hedwig, for she does not react to any of these massacres either. Rather, the woman is extremely accustomed to the life of the commander’s wife, and she enjoys the perks it brings along. She often receives luxury and expensive items that have been taken away from the prisoners, and on one particular occasion, she is seen receiving a fancy fur coat, since the Nazis did not differentiate between the rich and the poor among their targets. Hedwig immediately throws the coat on her body and tries it out in front of the mirror, only to realize that there is still lipstick lying inside one of the pockets. The presence of the lipstick would obviously be a bold reminder to anyone of the previous owner of the coat and the atrocious torture she must be subjected to at present. However, Hedwig has been wired to not think like that, and instead of any guilt or remorse, she feels rather excited to try on the lipstick, which is now hers as well.\n\nHedwig maintains a calm and composed nature, without any worry in the world, as she focuses on her gardening and getting a pool built for her children in their compound. The thick, dark smoke from the chimneys of the gas chambers on one side and from the steam engine train that brings in Jewish prisoners every day on the other does not affect the woman at all. The irony of the matter is all the more glaring when Hedwig is absolutely livid that her husband has to be transferred away from Auschwitz. She decides to stay back at the place along with her children because she is unwilling to uproot the life she had built there, including the fancy garden and the greenhouse, and shift somewhere else, which is probably too cold for her comfort as well. The fact that thousands were being faced with worse persecution and millions more would be uprooted, killed, or left disbanded very easily eludes her thought. In this regard, Jonathan Glazer’s film is a really fascinating note on not just the Holocaust but also the effect of systematized violence and the tendency of the masses to side with the oppressors in any given scenario.\n\nThe Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people. As soon as Rudolf finds a skull and some ashes in the river that he and his sons were bathing in, he scurries back to his house, and the children are scrubbed clean with utmost precision. In another instance, it is suggested that Rudolf forces himself upon a helpless prisoner woman, but he ensures that he scrubs his private parts before retiring for the night.\n\nThe only exception to the unaffected response by the entire family is by Hedwig’s mother, who finds it bizarre that her daughter, her husband, and their children can really live at such a place. The elderly woman definitely has no sympathies for the prisoners, though, but she is rather unable to live with so many signs and reminders of death all around. The stench of burning human bodies and the ash flying around keep her up all night, but the very same elements are like playthings for the two young boys who still lay awake in their room. On a similar night, filled with reminders of the ongoing genocide, Hedwig is seen asking Rudolf to take her on a romantic trip, in the most romantic conversation between the couple in the film. Ultimately, the mother leaves the house unannounced very early the next morning, only leaving behind a note for her daughter. Hedwig simply tosses the note into her furnace insignificantly, almost insulted that someone would find her beloved home distasteful or discomforting. Even after Rudolf leaves for Oranienburg, Hedwig stays at their Auschwitz house with the children.\n\nWhat Do The Scenes In Infrared Signify?\nThe Zone of Interest also sparsely presents a few scenes, in which an unacquainted young girl is seen going around Auschwitz, hiding apples and other meager food items inside the trenches. She is clearly doing this extremely dangerous work only to help the prisoners and ease their suffering in whatever little way she can. But interestingly, these scenes are in infrared, or negative, although only as long as the girl is in the outside world. As soon as she returns home, the visuals turn normal, then switch to infrared when she or her mother step out on the balcony. The family is revealed to be Polish locals who have no interest in Nazi ideals and dream of liberation one day. However, the mere fact that the family is still alive, irrespective of whether they are Jewish or not, suggests that they also have to work as collaborators for the Nazis to a certain degree. This was definitely the case with numerous non-Jews during the Nazi occupation who had to work for the horrific authorities despite not wanting to. Going by that logic, the significance of the use of infrared might be in stating how the family cannot be themselves as soon as they step out of their house or into the open balcony as well. Although the girl takes on the dangerous responsibility of helping the prisoners, she still cannot express her true self in public, leading to her being shown in infrared. Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the “normal” people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest‘s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions. In the middle of these two instances, The Zone of Interest briefly moves to modern times, and various reminders of the Holocaust are seen being maintained at the Auschwitz-Birkenau State Museum, right before the place is opened to public visitors. The last scene returns to the past once more, and Rudolf is seen feeling slightly odd, as if someone is watching him, as he continues down the stairs.\n\nThe Zone of Interest‘s ending scene seems to suggest that deep in his conscience, Rudolf Hoss does know that his actions can only make one retch, and almost like a fortune-teller, he has an uneasy feeling that his legacy will go down terribly in history. The scene of the museum is a fast jolt back to the right perspective, which had been missing throughout the film. Throughout the entire duration of The Zone of Interest, Rudolf, his family, and his professional associates had all been extremely invested in hiding the evidence and changing the narrative, but ultimately, the thousands of shoes or the torn, ragged uniforms still exist as reminders of the horrible genocide.']",I don't know.,0.0,0.0,0.0018148820326678765,0.0,0.0
What enemies are encountered in the second encounter?,26 kobolds and 1 kobold inventor are encountered in the second encounter.,"['Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.'
 '---The Paths through the Underground/Underdark---(9 days of travel)\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\n\nDay 1 goes without issue... sleep.\n\nDay 2 – Ropers\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\n---ENCOUNTER – Ropers x 2---\nDay 3 goes without issue...sleep.\n\nDay 4 - Kobold Trap\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\n\nThey are no more than 2-3 feet wide, and numerous (dozens).\n\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\n\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\n\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\n\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\n“Loud food! Loud meal!”\n\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\n\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\n\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\n\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?'
 ""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""]","In the second encounter, you will face 26 Kobolds and 1 Kobold Inventor.",1.0,0.9265358906730926,0.008955223880597015,0.49999999995,1.0
What colour is Nan-E?,No answer,"['The best sci-fi and fantasy books of 2023\nIt’s been a stellar year in speculative fiction\n\nBy Nicole Clark, Sadie Gennis, and Polygon Staff  Updated Dec 8, 2023, 10:00am EST  34 Comments / 34 New\nIf you buy something from a Polygon link, Vox Media may earn a commission. See our ethics statement.\n\nIt’s been another banner year for science fiction and fantasy books. Many of our favorites once again blur the line between sci-fi and fantasy, but this year was a particular standout for books blurring the line between SFF and other genres. This includes everything from historical fiction — both speculative histories and Westerns — to fable retellings to intergenerational sagas in translation.\n\nThough we seem to have crested the wave of pandemic novels, that sense of dread and discoloration has lingered, written into novels of new forms. There’s a preponderance of post-post-apocalyptic science fiction unpacking lofty ideas like sentience and humanity, often set on different planets or among the stars. It has also been a standout year for supernatural horrors and thrillers, particularly ones that mix queer longing with a dose of body horror. Last but not least, it’s been a great year for kissing books set in fantastical worlds.\n\nRELATED\n\nLooking for more recs? Here are our favorite books of 2022\nSo jump in and take your pick. Whichever direction you head in, it will be sure to grip you — and make you think. This list is in reverse chronological order, so the newest releases are listed first. We updated this list throughout 2023, sometimes retroactively adding in entries that we missed from earlier in the year. We’ve also included our favorite runners-up.\n\nHONORABLE MENTIONS\nEmily Wilde’s Encyclopaedia of Faeries by Heather Fawcett, Victory City by Salman Rushdie, The Crane Husband by Kelly Barnhill, The Mimicking of Known Successes by Malka Older, Monstrilio by Gerardo Sámano Córdova, White Cat, Black Dog by Kelly Link, Divine Rivals by Rebecca Ross, Our Hideous Progeny by C.E. McGill, The Cheat Code (Wisdom Revolution #3) by Misba, The Deep Sky by Yume Kitasei, Silver Nitrate by Silvia Moreno-Garcia, Vampires of El Norte by Isabel Cañas, Prophet by Sin Blaché and Helen Macdonald, Terrace Story by Hilary Leichter, Her Radiant Curse by Elizabeth Lim, Starling House by Alix E. Harrow, System Collapse (The Murderbot Diaries #7) by Martha Wells, Dark Heir (Dark Rise #2) by C.S. Pacat\n\nCover image for Ed Park’s Same Bed Different Dreams, a split image between what looks like Earth and Mars.\nImage: Random House\nSAME BED DIFFERENT DREAMS BY ED PARK\nSame Bed Different Dreams is a remarkable achievement, and not for the faint of heart. Through three storylines, the book creates a kind of speculative history of Korea, with an emphasis on World War II and Japan’s colonial rule and aftermath (and, crucially, the United States’ involvement). One story thread builds out a hefty alternative history of the Korean Provisional Government’s role and reach. Another story thread focuses on a Black Korean War vet who wrote a sci-fi epic series called 2333, which is later adapted into a video game. And yet another story thread has a more futuristic flavor, focusing on a has-been writer who now works for a tech company called GLOAT. These threads periodically intersect — for example, GLOAT ends up owning the rights to 2333, and turns it into a kind of edutainment.\n\nIf it sounds like there’s a lot going on, it’s because there is. And it’s made even denser by the author’s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking — like a character’s dog who can’t stop “archiving” by burying found manuscript pages, the fact that GLOAT employees truly don’t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what’s real and what’s Ed Park’s “alternate history” in sections with realistic-sounding combinations of fact and fiction.\n\nIt’s got the same ambitious patchwork as Jennifer Egan’s The Candy House and Namwali Serpell’s The Old Drift. Critics have compared it to everything from David Mitchell’s Cloud Atlas to David Foster Wallace’s Infinite Jest. There’s also, of course, books within the book. It’s a fever dream of a thing, and one I’d heartily recommend, but perhaps with a notebook in hand or some sticky notes to help track the references. (Or perhaps, as I did, just letting the wave of information roll over you, until you’re left with a vast impression and a desire to reread.) —Nicole Clark\n\nCover image for Kylie Lee Baker’s The Scarlet Alchemist, featuring a woman in a red outfit with a large crown set against a dark skyline.\nImage: Inkyard Press\nTHE SCARLET ALCHEMIST (THE SCARLET ALCHEMIST #1) BY KYLIE LEE BAKER\nDo not go into The Scarlet Alchemist expecting typical YA fare. What Kylie Lee Baker delivers is a story of visceral brutality, interlaced with elements of Chinese history and thoughtful meditations on family, race, and belonging. It’s a book that can turn your stomach as easily as it can break your heart.\n\nSet in an alternate Tang dynasty, the novel follows Zilan, a profoundly talented young alchemist who travels to the capital in hopes of landing a coveted position in the royal service. But being a poor, half Scotian girl means the odds are stacked inordinately high against her in the imperial service exams — and that’s before her skills with the illegal art of resurrection catch the prince’s attention and pull her into a dangerous political game. While the premise seems familiar (underdog competes in trials, falls into star-crossed romance), Baker’s skills with immersive world-building, knotty characters, and genuinely gruesome horror make The Scarlet Alchemist a dazzling and singular tale that left me rushing to read her back catalog. —Sadie Gennis\n\nCover image of C Pam Zhang’s Land of Milk and Honey, featuring rollicking hills of white, blue, and yellow.\nImage: Riverhead\nLAND OF MILK AND HONEY BY C PAM ZHANG\nAfter I read How Much of These Hills is Gold in 2020, C Pam Zhang became an instant must-read author in my household. Land of Milk and Honey is entirely unlike her debut — where her debut’s language was sparse and pointed, this book is florid and indulgent — though similar in the extent to which it transported me somewhere entirely new, and more than a little threatening.\n\nIn Land of Milk and Honey the climate apocalypse has rendered fresh produce, at scale, a thing of the past — which is to say a provision of the extremely rich. The protagonist, listless and hungry, applies for a job as a private chef for a mysterious family in the Italian Alps (those who live around it call it “\u200b\u200bla terra di latte e miele”). While there, she unravels the family’s true intentions, while making them delicious meals from rare ingredients.\n\nZhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient — and sometimes the cruelty of that ingredient’s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. —N. Clark\n\nCover image for Megan Kamalei Kakimoto’s Every Drop is a Man’s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN’S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind. Each story weaves together Hawaiian mythology and the everyday lives of the Hawaiian and mixed-race Japanese women who live there.\n\nThese stories range from fabulism to science fiction, all speculative fiction in their own way. In one story, a woman’s encounter with a wild pig ends up foreshadowing a complicated pregnancy later in her life. In another story, a Brazilian waxing company allows people to pay for hairless skin by giving up personality traits. In another story, the narrator falls for a woman who lives with her family — in one of numerous queer stories in the collection — but has to cope with that woman’s decision to return to “what remains of Kaua’i” and join their protests.\n\nThe author’s own words, published in The Guardian, sum it up best: “There is a mythical idealisation of the islands of Hawaii as paradise, peace in the tropics; some even call it a modern utopia. Yet this flattening of Hawaii to a postcard image divests our homeland of its culture and colour, reducing us to a place and history that is easily digestible. But we are not easily digestible, and our stories are not meant to be easy for you.” —N. Clark\n\nCover image for Shelley Parker-Chan’s He Who Drowned the World, a painted image of ships on a yellow sea, with the moon looming over them.\nImage: Tor\nHE WHO DROWNED THE WORLD (THE RADIANT EMPEROR #2) BY SHELLEY PARKER-CHAN\nAn alternate history of the founding of the Ming dynasty, He Who Drowned the World shifts between four tragically ambitious figures willing to pay any price to materialize their destiny, whether that’s revenge on the empire or crowning themselves the ruler of it. They pursue these goals with unshakeable inertia, doing endlessly cruel and sadistic actions with only the occasional doubts as to whether happiness could be possible if they chose a different path.\n\nThis is a relentlessly brutal sequel, and there’s a hopelessness that weighs heavy throughout the book. But Parker-Chan’s penetrating ability to bring empathy and nuance into even the darkest corners of humanity sparks an undeniable connection with these characters, whose self-destructive natures would otherwise be too hard to bear witness to. He Who Drowned the World is a dark and difficult read, yet Parker-Chan’s prose is so brilliant, her character work so complex, that I still found myself sad to leave this world behind. —SG\n\nCover image for M.A. Carricks’s Labyrinth’s Heart, featuring a mask-wearing figure with purple wings sprouting out of the top of the mask.\nImage: Orbit\nLABYRINTH’S HEART (ROOK & ROSE #3) BY M.A. CARRICK\nOne of my favorite fantasy series of the past five years, Rook & Rose is an intricately layered trilogy where there are so many secrets, schemes, and conspiracies that at times it’s admittedly difficult to keep track of them all. Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth’s Heart. (Ren alone was juggling four different identities at the novel’s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series’ end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth’s Heart that feel like they were precisely crafted to cater to fans, but here’s the thing: I don’t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nadežra after a two-year wait. While things may have been tied up a bit too neatly for my usual tastes, that didn’t stop me from whipping through pages and smiling the whole way through. Sometimes it’s nice to simply soak in a happy ending rather than bathe in the bittersweet. —SG\n\nCover art for Kiersten White’s Mister Magic, which features a melting television against a pink background.\nImage: Del Rey Books\nMISTER MAGIC BY KIERSTEN WHITE\nThe latest fantasy-with-an-irresistible-pop-premise from the author of Hide, Mister Magic revolves around a children’s TV show no viewer can forget … or prove it ever existed in the first place. There are no official records of it, no YouTube videos or merchandise or passed-around VHS tapes, and any discussion of it on the internet rapidly disappears. But the people who remember seeing it are convinced the special effects were remarkably vivid and realistic. They agree the central concept is unnerving: a creepy magician-figure leading a group of children in imagination-games aimed at teaching some decidedly non-standard lessons about embracing conformity and meekness. And they’re all sure that something horrible happened while they were watching, though they can’t agree on what.\n\nA reunion between five of the former child cast members, taking place 30 years after the show ended, slowly unravels its mysteries, which are even weirder than the description above suggests. Mister Magic is a startling dark fantasy with a lot of foreboding, foreshadowing, and eerie twists. At heart, though, it’s also an incisive story about the kinds of people who revel in control over other people’s lives, and about what an act of rebellion imagination can be. —Tasha Robinson\n\nCover image for Rebekah Bergman’s The Museum of Human History, featuring a painted image of a naked figure with a red cloud over the top of their head.\nImage: Tin House\nTHE MUSEUM OF HUMAN HISTORY BY REBEKAH BERGMAN\nA poetic reflection on memory, loss, and connection, The Museum of Human History is a stunning debut reminiscent of the work of Emily St. John Mandel. Slipping backward and forward in time, this introspective mosaic weaves between an identical twin whose sister fell asleep at age 8 and has never aged in the 25 years since, a museum director who questions his place within the family legacy, a widower who lost his most cherished memories as a result of an anti-aging treatment, and others equally struggling with the passage of time. There is a lyrical detachment in Bergman’s prose that leaves you feeling like you’re watching events unfold through a pane of thick glass, never fully able to connect with the characters, yet you remain helplessly transfixed by the haunting cycle they’re caught in. It’s an incredibly melancholy book, but the kind of aching sadness you’re happy to sink into. —SG\n\nCover image for Sara Hashem’s The Jasad Heir, featuring what looks like statues of a snake,, a bull, and a griffin.\nImage: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n“Arin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.” This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I’ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens’ innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist’s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl. Using her life as leverage, the calculating Arin strikes a deal with Sylvia to help him capture a group of Jasadi rebels and act as his champion in a series of deadly trials. It’s a familiar setup, but one impeccably done by Hashem, who delivers sharp political intrigue, sparkling banter, and touching friendships on top of Sylvia and Arin’s simmering romance. —SG\n\nCover image for Kritika H. Rao’s The Surviving Sky, featuring a floating island overgrowing with buildings and plant life, above a stormy planet.\nImage: Titan Books\nTHE SURVIVING SKY (THE RAGES TRILOGY #1) BY KRITIKA H. RAO\nAfter I finished The Surviving Sky, I wouldn’t shut up about it and tried (not always successfully) to get everyone I know to read it. So let me try once more, and maybe with less yelling this time:\n\nWith the planet’s surface made unlivable by catastrophic storms, the remains of humanity survive on floating cities constructed of and powered by plants that only a select group of people, known as architects, can control. An archeologist without the ability to traject plants, Ahilya has dedicated her life to finding a way to unshackle humanity’s survival from the architects’ powers and return to the surface. It’s not hard to see why this mission causes friction in her marriage to Iravan, one of the most powerful architects in their city, and one with an arrogance to match his revered status. Though estranged, Ahilya and Iravan come together to help clear his name after he’s accused of pushing his powers dangerously far, an accusation, which if proved true, carries dire consequences for the architect.\n\nBut the deeper they look into trajection and its risks, the more Ahilya and Iravan realize they don’t actually know much about where their people – and their powers – came from. And as the floating cities begin to sink toward the earthrages below, the race to save their civilization may also be the end of society as it stands, as Ahilya and Iravan uncover long-buried truths that previous generations worked hard to keep hidden.\n\nSo did I do it? Did I convince you to read this Hindu philosophy-inspired debut with some of the most inventive world-building and one of the most complex romances I’ve read in years? Please say yes. You’ll be doing us both a favor. —SG\n\nCover image for Alexander Darwin’s The Combat Codes, which features a metallic dragon against a black background.\nImage: Orbit\nTHE COMBAT CODES AND GRIEVAR’S BLOOD (THE COMBAT CODES SAGA #1-2) BY ALEXANDER DARWIN\nIn the world of The Combat Codes, war no longer exists as it used to. Neither does justice — both concepts have been replaced by proxies who fight on behalf of nations or individuals, solving disputes with their fists.\n\nAlexander Darwin’s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic “magical school for gifted youngsters” situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books’ excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar’s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can’t wait for the conclusion next year. —Pete Volk\n\nCover image for Katie Williams’ My Murder, showing a woman’s face peering outside of red vertical lines.\nImage: Riverhead Books\nMY MURDER BY KATIE WILLIAMS\nFans of Sarah Gailey’s The Echo Wife won’t want to miss My Murder, which shares some key elements and themes with Gailey’s novel while also taking them in a unique direction. In a near-future with only a few light sci-fi elements, Lou has been resurrected along with a handful of other women murdered by a single serial killer. The politics of resurrection in her world are complicated, and few people qualify. That leaves her and her fellow victims (whose therapy circle recalls Grady Hendrix’s The Final Girl Support Group) a bit at sea as they try to come to terms with their deaths, which none of them can recall, and their new lives as celebrities for all the wrong reasons.\n\nLike The Echo Wife, My Murder ends up thoughtfully exploring issues around women subjected to violent men — not just the personal and internal response, but the society that shapes that violence, and responds to it in ways that raise endless questions. The victims all respond to their deaths differently, questioning their culpability and the possible failures that might have made them targets, and navigating their families’ unpredictable responses to their revival. There’s one big mystery at the heart of My Murder, and a whole lot of abrupt and compelling surprises. But at the core, it’s a sci-fi twist on the survivor story, letting some very different people explore what it means to be victimized, and how to reclaim the lives that have been abruptly handed back to them. —TR\n\nCover image for Ann Leckie’s Translation State, a minimalist drawing with red, orange, and green, a silhouette of a person, and circular lines.\nImage: Orbit\nTRANSLATION STATE BY ANN LECKIE\nSet in the same universe as Leckie’s Imperial Radch trilogy, Translation State follows Enae, who leaves hir long-standing isolation for what was supposed to be an interstellar goose chase. After hir demanding grandmaman dies, Enae is given a diplomat title and assigned to investigate a missing Presgr translator no one expects to be found (but that the government still wants the goodwill for pretending to look for). Only, Enae doesn’t just pretend to look; sie discovers sie has quite the knack for investigating the 200-year-old cold case.\n\nThis is how hir path crosses that of Reet, an adopted maintenance worker whose mysterious origins and unsettling impulses might be explained by being the child of the fugitive translator, if you ask Enae, or the last descendant of a lost sovereign line, if you ask one particularly zealous diaspora social group. Rounding out the POV characters is Qven, a young Presgr terrified of their species’ ritual of merging with an elder, a rite of passage which will see Qven’s selfhood entirely dissolved. Enae, Reet, and Qven’s explorations of their own identities wind up having interplanetary consequences, but it’s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I’m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie’s world. So don’t hesitate to jump into Translation State if you’re – like me – new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. —SG\n\nCover image for Rita Chang-Eppig’s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.\nImage: Bloomsbury Publishing\nDEEP AS THE SKY, RED AS THE SEA BY RITA CHANG-EPPIG\nI still remember standing in my local bookstore, struck by the cover of this book, and reading the summary. It had me at “Chinese pirate queen.”\n\nIn Deep as the Sky, Red as the Sea, Chang-Eppig writes a historical fantasy about Shek Yeung, a fearsome Chinese pirate who must navigate her fleet after the death of her powerful husband. She marries her late husband’s second-in-command, with the promise of bearing an heir, in order to retain power over the fleet — and stay a major player as the Chinese Emperor seeks to rid the waters of piracy.\n\nThe book isn’t paced like a thriller, so don’t make the mistake of assuming so when you start it. It’s equal parts historical exposition, strategy, and warfare — and it especially excels in its characterization of a complicated woman forced to make difficult decisions and sacrifices in order to protect her power. Fantasy can put its villains and heroes on pedestals, but Deep as the Sky, Red as the Sea never errs in its very human portrayal of Shek Yeung, and how deftly she must play this game of political chess for survival. I was riveted. —N. Clark\n\nCover art for Emma Törzs’ Ink Blood Sister Scribe, featuring a dripping pen growing out of the bottom of a tree against a purple background.\nImage: William Morrow\nINK BLOOD SISTER SCRIBE BY EMMA TÖRZS\nThere’s nothing cozier than a magical book about the magic of books — though this tale bends a little darker, and tells a story about witchcraft and complicated family dynamics. In Ink Blood Sister Scribe, two estranged sisters come together to solve the mystery of their family, and prevent further tragedies. In this world, blood can be concocted into ink — wielded by scribes for the creation of books with arcane powers — though the creation of such books drains a scribe’s health. When others read these books, they create magic; willing flowers to bloom, or making magical carpets that can fly in the air.\n\nInk Blood Sister Scribe is the perfect sister thriller to read in one sitting. It doesn’t reinvent the wheel, but it doesn’t need to — it simply delivers on a wonderfully entertaining premise. —N. Clark\n\nCover art for Martha Wells’ Witch King, featuring a person running across the cover while wearing a cloak and dress fitting for a fantasy setting.\nImage: Tor\nWITCH KING BY MARTHA WELLS\nIn an era where a lot of fantasy fans value quick or cozy reads, Martha Wells’ Witch King feels like a gauntlet thrown at readers’ feet. It’s a complex, meaty fantasy that opens well into what a more linear book would consider the third act, as Kai, the witch king of the title, is exhumed from a watery grave and starts exploring who betrayed him and trapped him there. Readers have to learn everything about Kai’s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a “witch king” is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells’ Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them. Wells packs Witch King with a lot of audacious, expansive world-building for a standalone novel (albeit one that could easily invite sequels or prequels), but what makes Witch King an enjoyable read instead of a frustrating one is the way all the book’s complications and surprises are filtered through Kai’s vivid inner life, giving readers something to hold onto as they’re untangling the puzzlebox aspects of this cleverly structured novel. —TR\n\nCover image for Justin Lee Anderson’s The Lost War, featuring five figures walking through white grass after emerging from a dark green forest. Three of the figures wear green cloaks, while two wear white.\nImage: Orbit\nTHE LOST WAR (THE EIDYN SAGA #1) BY JUSTIN LEE ANDERSON\nOriginally self-published in 2019, The Lost War is a traditional fantasy adventure that follows a rag-tag group of strangers on a mission across a war-torn country, fighting monsters and uncovering mysteries along the way. Despite the strong buzz leading up to the novel’s expanded publication by Orbit this year, I found myself hesitant to pick it up since it seemed so similar to many books I’ve read before. But while it’s true The Lost War doesn’t rewrite the genre – it’s filled with well-worn tropes and classic adventurer archetypes – Anderson’s skillful execution left me completely charmed. There is a real Dungeons and Dragons feel to The Lost War, and though the characters are familiar (the honorable paladin, the hard-drinking haunted soldier), Anderson does a fantastic job developing unique dynamics between the party members that vault the book beyond the sum of its parts. And it all builds up to a massive twist at the end that completely upends your understanding of what you’ve read and any previous expectations for where the second book will go. The delightfully unexpected ending once again has the fantasy community buzzing ahead of Anderson’s next release – only this time I’m right there with them. —SG\n\nCover image for Moniquill Blackgoose’s To Shape a Dragon’s Breath, a red cover with flowers and a dragon’s head/mask on it.\nImage: Del Rey\nTO SHAPE A DRAGON’S BREATH (NAMPESHIWEISIT #1) BY MONIQUILL BLACKGOOSE\nTo Shape a Dragon’s Breath’s description hooked me immediately: It’s got dragons, a magic school, and a strong teenage main character. Moniquill Blackgoose has taken several different fantasy tropes and created a fantasy novel that’s unlike anything I’ve read; To Shape a Dragon’s Breath is set in an evolving steampunk world as Anglish settlers push the Indigenous Masquapaug people out of their land and onto a remote island. Dragons had long been important cultural touchstones to the Indigenous people, but colonization has, too, pushed them away. To Shape a Dragon’s Breath begins as 15-year-old Anequs finds a dragon egg — the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon’s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon’s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered — they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way. Where To Shape a Dragon’s Breath really shines is in that growing relationship between Anequs and Kasaqua; the partnership — and power for both that comes with it — is in stark contrast to the Anglish ways. Bonus: To Shape a Dragon’s Breath has well-written, complex bisexual and neurodivergent characters, too. —Nicole Carpenter\n\nCover image for Melvin Burgess’s Loki, a black cover with a black snake wrapped around gold letters with the title.\nImage: Pegasus\nLOKI BY MELVIN BURGESS\nMelvin Burgess has spent a career writing confrontationally frank children’s literature like Junk, his 1990s book about heroin-addicted teenagers. His first adult book, published at age 69, is a blistering, transgressive, and hugely entertaining reframing of the Norse myths, as told by the most unreliable narrator imaginable: Loki himself, the god of tricks, inventions, and political intrigue. But what does reliable mean, anyway, in the mutable world of myth? Burgess paints Loki (or rather, has him paint himself, as he addresses the reader directly in first person) as an eternal outsider, shaking his head sagely at the follies of the gods, and challenging their might-is-right order. But of course, that’s what he’d want us to think. Burgess’ best trick, though, is the way he rolls together the deeply weird, muddy, shape-shifting mystery of the tales themselves with a bracing modernity in characterization and language, somehow without one clashing with the other. In doing so he brings the wild, ancient power of the Norse myths to vivid life. —Oli Welsh\n\nCover image for Nana Kwame Adjei-Brenyah’s Chain-Gang All-Stars, featuring a scythe chopping through the words with a bright yellow background.\nImage: Pantheon Books\nCHAIN-GANG ALL-STARS BY NANA KWAME ADJEI-BRENYAH\nIn Chain-Gang All-Stars, prison inmates fight to the death in a series of gladiatorial matches — and all of it is televised to a hungry audience. It’s a program called CAPE, the Criminal Action Penal Entertainment, which promises freedom to inmates who survive three years of its brutality. The average life expectancy for anyone who enters is three months. Within this system, Loretta Thurwar and Hammara Stacker (called Hurricane Staxxx by her fans) emerge as two frontrunners.\n\nThis National Book Award finalist takes on the viciousness of the carceral system, with more than a bit of The Hunger Games’ DNA sprinkled in. “Hard action” fans salivate over matches, a self-obsessed announcer resents the fact that contestants don’t offer more banter, and the women who top the leaderboards become sex symbols in pop culture. But where other fight-to-the-death dystopias — among the greats, like Battle Royale or Lord of the Flies — spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn’t entertaining because it wasn’t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply “slavery by another name,” showing all manner of menial labor the contestants are forced to perform. In 2022, the ACLU reported that inmates made between 13 and 52 cents an hour, and sometimes nothing.\n\nCritics have said this book is an “act of protest” but that it doesn’t “straightforwardly preach,” or that it’s more entertaining than “an attempt to convince its readers of the case for prison abolition has any right to be.” I understand why you’d want to say this book is “fun” despite an abolitionist message, especially in a political climate where radical writing is often appreciated only as a teaching tool. But I think that kind of delineation undercuts Adjei-Brenyah’s talent as a novelist, and his skill in heightening the real as a form of storytelling. I’d call it thrilling, over calling it fun. And the fact that it is thrilling is inextricable from its openly abolitionist values — it’s the very knowledge of real life that Adjei-Brenyah wields to craft suspense. —N. Clark\n\nCover image for Rebecca Yarros’ Fourth Wing, which features a circle image behind black text, with clouds and some flying creatures.\nImage: Entangled\nFOURTH WING BY REBECCA YARROS\nThis action-packed, fantasy romance feels like a grown up version of all of my favorite young adult books. It’s got all of the fun nostalgic tropes — a magical school, deadly trials, dragon riding, and a love triangle between the main character, a golden retriever love interest, and a misunderstood emo rival — but it’s also extremely horny, as all fun fantasy romance must be.\n\nViolet Sorrengail is thrown into a series of trials in order to prove whether she can be a dragon rider. There are a few problems with this: she trained as a scribe, never thought she’d be thrust into danger, and she also must deal with Xaden Riorson, her sworn enemy (wink). She also manages a joint condition, which leaves her in chronic pain — a fact the book handles gracefully. In one of my favorite climactic moments of the book, Violet is given a mobility device to help her with her trials; those close to her remind her that it doesn’t diminish her power, but is a tool like any other, and one that allows her to flourish. I’m thrilled to read the next installment, when it comes out in November. —N. Clark\n\nCover art for Adrian Tchaikovsky’s Lords of Uncreation, which shows a spaceship approaching what looks like a space battle next to a planet, with exploding orbs in space and a lot of spaceships in the distance.\nImage: Orbit\nLORDS OF UNCREATION (THE FINAL ARCHITECTURE #3) BY ADRIAN TCHAIKOVSKY\nReading the Final Architecture series, I had to accept long ago that I would never fully grasp the nuances of some of its central concepts, even if I understood them on an instinctual level.\n\nThis acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on – at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God’s crew.\n\nThis is not to say that Tchaikovsky does not deliver an incredibly satisfying conclusion to the mysteries of unspace (he does!). But what I’ll remember most is how he crafted the perfect emotional resolution to this intellectually intricate tale that left me in tears and has stayed with me since. —SG\n\nLead art for Justin Cronin’s The Ferryman, which pictures a cloudy sky over the horizon, as a single sail boat sits on the water.\nImage: Ballantine Books\nTHE FERRYMAN BY JUSTIN CRONIN\nProctor Bennett is a ferryman, whose duty is to guide unhappy citizens from the utopian Propersa to the Nursery, where they retire their old selves before returning in younger bodies with no memories of their former lives. But when Proctor is assigned to retire his own father, the troubling encounter sends him careening off the path of conformity. He begins questioning prescribed truths and confronting the darker side of Prospera, which runs off the work of a disenfranchised support staff whose discontent is building towards a revolution that pulls Proctor into its orbit.\n\nThough this premise may feel familiar, The Ferryman is anything but. This tightly-wound, atmospheric thriller weaves together layers of knotted mystery with Proctor’s haunting POV as he grapples with his relationship to grief, happiness, family, and identity. It’s a sharply complex mystery with a cinematic quality to it. Throughout reading, I couldn’t help but fan-cast who would star in a Christopher Nolan adaptation of it. But even if you aren’t an Inception fan, it’ll be easy to become immersed in The Ferryman’s distinct dystopian world. —SG\n\nCover image for Emily Tesh’s Some Desperate Glory, featuring a woman walking confidently in front of a wall opening to reveal a planetary body.\nImage: Tor\nSOME DESPERATE GLORY BY EMILY TESH\nAround September, as the pile of unpainted plastic miniatures here in my home office began to get particularly deep, I suddenly ran out of Warhammer 40,000 Black Library audiobooks by Games Workshop that I was the least bit interested in listening to. That’s when I stumbled upon Some Desperate Glory by Emily Tesh. Billed as a space opera told from the perspective of one of humanity’s last genetically engineered super soldiers, I fell for the premise hook, line, and sinker. Then, about 50 pages in, I let it sucker-punch me right in the gut.\n\nWith Some Desperate Glory, Tesh has envisioned a deeply affecting reality where the children of a subjugated, war-torn race slowly come to realize that they have been lied to — manipulated into an amoral war of vengeance without end. Tesh shows incredible restraint throughout, reeling out a thick and binding thread of painful realizations from deep within the main character, Kyr. After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest – and a new fixture in the canon of queer science fiction. —Charlie Hall\n\nCover image for Jade Song’s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book — for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid. But she is tethered to land by her human ambition: By the parents who constantly push her to achieve, and by a swim coach who pays inappropriate attention to her — pushing her to swim faster times, while also making her feel uncomfortable in her skin.\n\nRen’s steadfast belief in being a mermaid feels both like a flight of fancy, and increasingly like a means of dissociating from the horrors of everyday life. Being a young girl is hard enough without having to contend with the high expectations of parents, the predation of adult men, and the casual racism of peers. Jade Song’s writing is gruesomely lyrical, contrasting the sublime with the deeply disturbing. There were several points where this book almost made me throw up, and I mean that as a high compliment. —N. Clark\n\nA Black woman stands alone in a field, her face covered by shadow, in the cover art for Lone Women by Victor LaValle.\nImage: One World\nLONE WOMEN BY VICTOR LAVALLE\nAdelaide Henry is traveling to Montana, where she plans on making a new life as a homesteader — leaving the flames of her California home, and the bodies of her parents, behind. But she has a heavy weight to carry. She lugs an enormous steam trunk wherever she goes; whenever the trunk opens, people around her die. In 1915, Montana is in the middle of a homestead boom, and though Adelaide aims to make a new start, not everyone is welcoming to a Black woman traveling alone.\n\nVictor LaValle mixes horror and fantasy in this expertly paced tale. It’s satisfyingly bloody, while making incisive commentary on the price of being an outsider. The Western genre has long fixated on the white imagination, perhaps occasionally making space for the early struggle of the suffragettes. But LaValle’s vision of history emphasizes just how powerful white women are in upholding the interests of their white husbands, and how far these women will go to protect the societal structures that put them in proximity to power. Lone Women also examines how shame, and the family unit, ultimately uphold these unspoken rules — ostracizing those who might otherwise find community support.\n\nThis book was so good that I am now reading my way through every interview LaValle has given on the Lone Women press circuit, too, and then reading every book he references. What a gift! —N. Clark\n\nCover image of Nathan Ballingrud’s The Strange, depicting a diner on Mars.\nImage: Gallery/Saga Press\nTHE STRANGE BY NATHAN BALLINGRUD\nNathan Ballingrud’s debut novel was added to my TBR pile after seeing it marketed as a blend of Ray Bradbury’s The Martian Chronicles and Charles Portis’ True Grit. I’m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp’s mother unknown. When a thief steals Annabelle’s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what’s hers and see justice served. The longer Annabelle’s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can’t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.\n\nAnnabelle can be vengeful and cruel, and though I often disagreed with her choices, Ballingrud makes it impossible not to understand and empathize with her. Annabelle Crisp isn’t a hero and she isn’t a villain, but she is an outstanding protagonist in a wonderfully original sci-fi tale. —SG\n\nCover image for Moses Ose Utomi’s The Lies of the Ajungo, featuring a figure walking upside down on mounds of sand as a castle lurks in front.\nImage: Tor\nTHE LIES OF THE AJUNGO (THE FOREVER DESERT #1) BY MOSES OSE UTOMI\nIn his debut novella, Moses Ose Utomi wields his precise prose to tell a dark, visceral fable about a young boy from the City of Lies, a metropolis reliant on the brutal Ajungo Empire for their supply of water. But the cost of this trade is high: At 13, every child of the City of Lies has their tongue cut out and sent to the Ajungo.\n\nEven with this gruesome tithe, the Ajungo send barely enough water for the population to survive, and far from what they’d need to do so comfortably, let alone thrive. Shortly before his thirteenth birthday, the brave Tutu sets out on a dangerous journey to save his mother and the city by finding their own water supply. As Tutu explores the outside world for the first time, his perception of truth and history is challenged, and he comes to understand how the decisions and deceptions of those in power rewrite the past and shape the future to uphold those with privilege and foster compliance in those who don’t. —SG\n\nCover image for Edward Ashton’s Antimatter Blues, A Mickey7 Novel. It features an astronaut from behind on a rocky planet, looking out at another planet in the distance.\nImage: St. Martin’s Press\nANTIMATTER BLUES BY EDWARD ASHTON\nEdward Ashton’s sequel to Mickey 7, the 2022 novel Parasite director Bong Joon-ho is adapting as a movie starring Robert Pattinson, takes up two years after the first book left off, with “Expendable”-status planetary colonist Mickey still on the outs with the leadership of his struggling colony after a gutsy bluff he made to ensure his own survival. The sixth clone of the original Mickey, who accepted life as a disposable body for suicide missions in exchange for a ticket to space, Mickey 7 has walked off that job. His ongoing draw on the colony’s resources is only tolerated because he’s exaggerated his diplomatic connections with the local aliens. Then the base commander orders him to do something impossible, or the entire colony will die.\n\nAntimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity’s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn’t a pleasant book to read: A lot of Mickey’s co-colonists are bigots, most of them are indifferent to anyone else’s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he’s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity. —TR\n\nCover image for Samantha Shannon’s A Day of Fallen Night, a colorful image with a a dragon swirling around it\nImage: Bloomsbury\nA DAY OF FALLEN NIGHT (THE ROOTS OF CHAOS #0) BY SAMANTHA SHANNON\nSamantha Shannon’s A Day of Fallen Night is her second book in the Roots of Chaos series, but a prequel to The Priory of the Orange Tree. Like The Priory of the Orange Tree, A Day of Fallen Night is an epic, far-flung fantasy novel set in a world of magic and dragons. A Day of Fallen Night is set hundreds of years before The Priory of the Orange Tree, and follows several of the original book’s ancestors as the world fears the return of an evil wyrm, the Nameless One. You don’t have to have read The Priory of the Orange Tree to enjoy A Day of Fallen Night; in fact, it’s likely a good place to start if you’ve been interested in reading Shannon’s original, massive fantasy book. Of course, this is a slow-burn 800-page book that precedes another 800-page book, so it’s definitely a time investment regardless of the path.\n\nThough A Day of Fallen Night deals with a world-shaping, cataclysmic threat and widespread political machinations, the book is rooted within four characters from around the book’s world: Sabran, Glorian, Dumai, and Tunuva Melim. The stories of these characters intertwine as their regional beliefs tied to wyrms and dragons conflict, muddying up the necessary collaboration in fighting off the looming threat. In between all that catastrophe, Shannon gives the women of the book rich stories of personal relationships, sacrifice, and conflicting feelings. Motherhood and bodily autonomy are also strong themes throughout the book; both Sabran and Glorian (mother and daughter) have their bodily autonomy tied to the fate of their region.\n\nIt’s not easy to describe A Day of Fallen Night in a short blurb — it does so many things and goes so many places. Shannon’s created a series that has the scale of The Lord of the Rings, wrapped up in a world of queer, female power. The Roots of Chaos, as a whole, is one of my favorite fantasy series ever. —N. Carpenter\n\nCover image for Mariana Enriquez’s Our Share of Night, featuring a red hand with long yellow fingernails.\nImage: Hogarth Press\nOUR SHARE OF NIGHT BY MARIANA ENRÍQUEZ\nThis literary tome defies categorization, so I’ll paint a scene instead: A father (Juan) whisks his son (Gaspar) away on a trip. Juan is mercurial; at turns terrifying and violent, at turns bewilderingly tender, nearly infinite in love. But he is a closed book. And if you think you’ve seen his hands elongate, spindly fingers yielding to piercing claws — well no, you didn’t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family’s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel’s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enríquez writes next, it’s an absolute joy to experience her work. —N. Clark\n\nCover image for Annalee Newitz’s The Terraformers, which features a futuristic cityscape with lush greenery.\nImage: Tor Books\nTHE TERRAFORMERS BY ANNALEE NEWITZ\nThe Terraformers concerns itself with one question: As a species evolves, what behaviors stick around? Set more than 50,000 years in the future (yes, you read that number right), The Terraformers details the process of terraforming and developing a privatized planet into a tourism joint for the super rich. Technology has advanced in barely fathomable ways, allowing, for instance, the extension of human-level intelligence to animals and robots. But some aspects of society might seem familiar: Real estate developers who jack up rent with no warning? Local governments that abhor public transit? That every video call still has one person who can’t get the camera to work?\n\nEqual parts prescient and absurd, The Terraformers splits its story over three novellas, each 700 years apart. One of those stars a sentient train who teams up with an investigative journalist ... who also happens to be a cat ... who’s also trying to prove this ostensibly privatized planet is in fact public land. Written by a leading science journalist of our era (author Annalee Newitz is the founder of io9 and has written for basically every major science publication under our sun), The Terraformers is unexpectedly one of the most accurate representations of the journalistic process I’ve ever read. And it all culminates in an undeniable stance: That capitalistic power must still be held in check by the truth. Even 50,000 years in the future, a free press is among society’s most essential facets. The more things change... —Ari Notis\n\nThe cover image of Adrian Tchaikovsky’s Children of Memory, which depicts a spaceship approaching a large orange planet.\nImage: Orbit\nCHILDREN OF MEMORY (CHILDREN OF TIME #3) BY ADRIAN TCHAIKOVSKY\nAdrian Tchaikovsky’s highly anticipated third book in the Children of Time trilogy once again delves into some of science fiction’s headiest topics. There are parallels to earlier installments — Tchaikovsky once again uses another hyper-intelligent animal species to examine the idea of what being “alive” really means. But he also takes readers somewhere completely and utterly new, outside the scope of the previous titles, and incredibly difficult to describe without spoiling the premise entirely.\n\nAll I can say is hold on for the ride. This is an author who dives head first into Asimov-esque ideas, and who is willing to take the plot in fanciful directions. I still can’t believe that I have recommended a book about sentient spider colonies to so many friends, but here we are. This finale is worth your time. —N. Clark'
 'llmware\n\nBuilding Enterprise RAG Pipelines with Small, Specialized Models\nllmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\n\nllmware has two main components:\n\nRAG Pipeline - integrated components for the full lifecycle of connecting knowledge sources to generative AI models; and\n\n50+ small, specialized models fine-tuned for key tasks in enterprise process automation, including fact-based question-answering, classification, summarization, and extraction.\n\nBy bringing together both of these components, along with integrating leading open source models and underlying technologies, llmware offers a comprehensive set of tools to rapidly build knowledge-based enterprise LLM applications.\n\nMost of our examples can be run without a GPU server - get started right away on your laptop.\n\nJoin us on Discord | Watch Youtube Tutorials | Explore our Model Families on Huggingface\n\nNew to RAG? Check out the Fast Start video series\n\nMulti-Model Agents with SLIM Models - Intro-Video\n\nIntro to SLIM Function Call Models\nCan\'t wait? Get SLIMs right away:\n\nfrom llmware.models import ModelCatalog\n\nModelCatalog().get_llm_toolkit()  # get all SLIM models, delivered as small, fast quantized tools\nModelCatalog().tool_test_run(""slim-sentiment-tool"") # see the model in action with test script included\nKey features\nWriting code withllmware is based on a few main concepts:\n\nModel Catalog: Access all models the same way with easy lookup, regardless of underlying implementation.\nLibrary: ingest, organize and index a collection of knowledge at scale - Parse, Text Chunk and Embed.\nQuery: query libraries with mix of text, semantic, hybrid, metadata, and custom filters.\nPrompt with Sources: the easiest way to combine knowledge retrieval with a LLM inference.\nRAG-Optimized Models - 1-7B parameter models designed for RAG workflow integration and running locally.\nSimple-to-Scale Database Options - integrated data stores from laptop to parallelized cluster.\nAgents with Function Calls and SLIM Models\nStart coding - Quick Start for RAG\nWhat\'s New?\n-Best New Small RAG Model - BLING finetune of Phi-3 - ""bling-phi-3-gguf"" - see the video\n\n-Web Services with Agent Calls for Financial Research - end-to-end scenario - video and example\n\n-Voice Transcription with WhisperCPP - getting_started, using_sample_files, and analysis_use_case with great_speeches_video\n\n-Phi-3 GGUF Streaming Local Chatbot with UI - setup your own Phi-3-gguf chatbot on your laptop in minutes - example with video\n\n-Small, specialized, function-calling Extract Model - introducing slim-extract - video and example\n\n-LLM to Answer Yes/No questions - introducing slim-boolean model - video and example\n\n-Natural Language Query to CSV End to End example - using slim-sql model - video and example and now using Custom Tables on Postgres example\n\n-Multi-Model Agents with SLIM models - multi-step Agents with SLIMs on CPU - video - example\n\n-OCR Embedded Document Images Example - systematically extract text from images embedded in documents example\n\n-Enhanced Parser Functions for PDF, Word, Powerpoint and Excel - new text-chunking controls and strategies, extract tables, images, header text - example\n\n-Agent Inference Server - set up multi-model Agents over Inference Server example\n\n-GGUF - Getting Started - check out examples - GGUF (example) and Videos video\n\n-Optimizing Accuracy of RAG Prompts - check out example and videos - part I and part II\n\nGetting Started\nStep 1 - Install llmware - pip3 install llmware or pip3 install \'llmware[full]\'\n\nnote: starting with v0.3.0, we provide options for a core install (minimal set of dependencies) or full install (adds to the core with wider set of related python libraries).\nStep 2- Go to Examples - Get Started Fast with 100+ \'Cut-and-Paste\' Recipes\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\n✍Working with the llmware Github repository\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\n\ngit clone git@github.com:llmware-ai/llmware.git\nWe have provided a welcome_to_llmware automation script in the root of the repository folder. After cloning:\n\nOn Windows command line: .\\welcome_to_llmware_windows.sh\nOn Mac / Linux command line: sh ./welcome_to_llmware.sh\nAlternatively, if you prefer to complete setup without the welcome automation script, then the next steps include:\n\ninstall requirements.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements.txt\n\ninstall requirements_extras.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements_extras.txt (Depending upon your use case, you may not need all or any of these installs, but some of these will be used in the examples.)\n\nrun examples - copy one or more of the example .py files into the root project path. (We have seen several IDEs that will attempt to run interactively from the nested /example path, and then not have access to the /llmware module - the easy fix is to just copy the example you want to run into the root path).\n\ninstall vector db - no-install vector db options include milvus lite, chromadb, faiss and lancedb - which do not require a server install, but do require that you install the python sdk library for that vector db, e.g., pip3 install pymilvus, or pip3 install chromadb. If you look in examples/Embedding, you will see examples for getting started with various vector DB, and in the root of the repo, you will see easy-to-get-started docker compose scripts for installing milvus, postgres/pgvector, mongo, qdrant, neo4j, and redis.\n\nNote: we have seen recently issues with Pytorch==2.3 on some platforms - if you run into any issues, we have seen that uninstalling Pytorch and downleveling to Pytorch==2.1 usually solves the problem.\n\nData Store Options\nFast Start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required\nSpeed + Scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose\nPostgres: use Postgres for both text collection and vector DB - install with Docker Compose\nMix-and-Match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)\nMeet our Models\nSLIM model series: small, specialized models fine-tuned for function calling and multi-step, multi-model Agent workflows.\nDRAGON model series: Production-grade RAG-optimized 6-7B parameter models - ""Delivering RAG on ..."" the leading foundation base models.\nBLING model series: Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models.\nIndustry BERT models: out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC.\nGGUF Quantization: we provide \'gguf\' and \'tool\' versions of many SLIM, DRAGON and BLING models, optimized for CPU deployment.\nUsing LLMs and setting-up API keys & secrets\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\n\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\n\nRoadmap - Where are we going ...\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.\n\nQuestions and discussions are welcome in our github discussions.\n\nRelease notes and Change Log\nSee also additional deployment/install release notes in wheel_archives\n\nThursday, June 6 - v0.3.1-WIP\n\nAdded module 3 to Fast Start example series examples 7-9 on Agents & Function Calls\nAdded reranker Jina model for in-memory semantic similarity RAG - see example\nChanges merged into main branch - expected next pypi release at end of week\nTuesday, June 4 - v0.3.0\n\nAdded support for new Milvus Lite embedded \'no-install\' database - see example.\nAdded two new SLIM models to catalog and agent processes - \'q-gen\' and \'qa-gen\'\nUpdated model class instantiation to provide more extensibility to add new classes in different modules\nNew welcome_to_llmware.sh and welcome_to_llmware_windows.sh fast install scripts\nEnhanced Model class base with new configurable post_init and register methods\nCreated InferenceHistory to track global state of all inferences completed\nMultiple improvements and updates to logging at module level\nNote: starting with v0.3.0, pip install provides two options - a base minimal install pip3 install llmware which will support most use cases, and a larger install pip3 install \'llmware[full]\' with other commonly-used libraries.\nWednesday, May 22 - v0.2.15\n\nImprovements in Model class handling of Pytorch and Transformers dependencies (just-in-time loading, if needed)\nExpanding API endpoint options and inference server functionality - see new client access options and server_launch\nSaturday, May 18 - v0.2.14\n\nNew OCR image parsing methods with example\nAdding first part of logging improvements (WIP) in Configs and Models.\nNew embedding model added to catalog - industry-bert-loans.\nUpdates to model import methods and configurations.\nSunday, May 12 - v0.2.13\n\nNew GGUF streaming method with basic example and phi3 local chatbot\nSignificant cleanups in ancillary imports and dependencies to reduce install complexity - note: the updated requirements.txt and setup.py files.\nDefensive code to provide informative warning of any missing dependencies in specialized parts of the code, e.g., OCR, Web Parser.\nUpdates of tests, notice and documentation.\nOpenAIConfigs created to support Azure OpenAI.\nSunday, May 5 - v0.2.12 Update\n\nLaunched ""bling-phi-3"" and ""bling-phi-3-gguf"" in ModelCatalog - newest and most accurate BLING/DRAGON model\nNew long document summarization method using slim-summary-tool example\nNew Office (Powerpoint, Word, Excel) sample files example\nAdded support for Python 3.12\nDeprecated faiss and replaced with \'no-install\' chromadb in Fast Start examples\nRefactored Datasets, Graph and Web Services classes\nUpdated Voice parsing with WhisperCPP into Library\nMonday, April 29 - v0.2.11 Update\n\nUpdates to gguf libs for Phi-3 and Llama-3\nAdded Phi-3 example and Llama-3 example and Quantized Versions to Model Catalog\nIntegrated WhisperCPP Model class and prebuilt shared libraries - getting-started-example\nNew voice sample files for testing - example\nImproved CUDA detection on Windows and safety checks for older Mac OS versions\nMonday, April 22 - v0.2.10 Update\n\nUpdates to Agent class to support Natural Language queries of Custom Tables on Postgres example\nNew Agent API endpoint implemented with LLMWare Inference Server and new Agent capabilities example\nTuesday, April 16 - v0.2.9 Update\n\nNew CustomTable class to rapidly create custom DB tables in conjunction with LLM-based workflows.\nEnhanced methods for converting CSV and JSON/JSONL files into DB tables.\nSee new examples Creating Custom Table example\nTuesday, April 9 - v0.2.8 Update\n\nOffice Parser (Word Docx, Powerpoint PPTX, and Excel XLSX) - multiple improvements - new libs + Python method.\nIncludes: several fixes, improved text chunking controls, header text extraction and configuration options.\nGenerally, new office parser options conform with the new PDF parser options.\nPlease see Office Parsing Configs example\nWednesday, April 3 - v0.2.7 Update\n\nPDF Parser - multiple improvements - new libs + Python methods.\nIncludes: UTF-8 encoding for European languages.\nIncludes: Better text chunking controls, header text extraction and configuration options.\nPlease see PDF Parsing Configs example for more details.\nNote: deprecating support for aarch64-linux (will use 0.2.6 parsers). Full support going forward for Linux Ubuntu20+ on x86_64 + with CUDA.\nFriday, March 22 - v0.2.6 Update\n\nNew SLIM models: summary, extract, xsum, boolean, tags-3b, and combo sentiment-ner.\nNew logit and sampling analytics.\nNew SLIM examples showing how to use the new models.\nThursday, March 14 - v0.2.5 Update\n\nImproved support for GGUF on CUDA (Windows and Linux), with new prebuilt binaries and exception handling.\nEnhanced model configuration options (sampling, temperature, top logit capture).\nAdded full back-level support for Ubuntu 20+ with parsers and GGUF engine.\nSupport for new Anthropic Claude 3 models.\nNew retrieval methods: document_lookup and aggregate_text.\nNew model: bling-stablelm-3b-tool - fast, accurate 3b quantized question-answering model - one of our new favorites.\nWednesday, February 28 - v0.2.4 Update\n\nMajor upgrade of GGUF Generative Model class - support for Stable-LM-3B, CUDA build options, and better control over sampling strategies.\nNote: new GGUF llama.cpp built libs packaged with build starting in v0.2.4.\nImproved GPU support for HF Embedding Models.\nFriday, February 16 - v0.2.3 Update\n\nAdded 10+ embedding models to ModelCatalog - nomic, jina, bge, gte, ember and uae-large.\nUpdated OpenAI support >=1.0 and new text-3 embedding models.\nSLIM model keys and output_values now accessible in ModelCatalog.\nUpdating encodings to \'utf-8-sig\' to better handle txt/csv files with bom.\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\n\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\n\nSupported Text Index Databases: MongoDB, Postgres, SQLite\n\nOptional\nDocker\n\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.\n\nChange Log\nLatest Updates - 19 Jan 2024 - llmware v0.2.0\n\nAdded new database integration options - Postgres and SQlite\nImproved status update and parser event logging options for parallelized parsing\nSignificant enhancements to interactions between Embedding + Text collection databases\nImproved error exception handling in loading dynamic modules\nLatest Updates - 15 Jan 2024: llmware v0.1.15\n\nEnhancements to dual pass retrieval queries\nExpanded configuration objects and options for endpoint resources\nLatest Updates - 30 Dec 2023: llmware v0.1.14\n\nAdded support for Open Chat inference servers (compatible with OpenAI API)\nImproved capabilities for multiple embedding models and vector DB configurations\nAdded docker-compose install scripts for PGVector and Redis vector databases\nAdded \'bling-tiny-llama\' to model catalog\nLatest Updates - 22 Dec 2023: llmware v0.1.13\n\nAdded 3 new vector databases - Postgres (PG Vector), Redis, and Qdrant\n\nImproved support for integrating sentence transformers directly in the model catalog\n\nImprovements in the model catalog attributes\n\nMultiple new Examples in Models & Embeddings, including GGUF, Vector database, and model catalog\n\n17 Dec 2023: llmware v0.1.12\n\ndragon-deci-7b added to catalog - RAG-finetuned model on high-performance new 7B model base from Deci\nNew GGUFGenerativeModel class for easy integration of GGUF Models\nAdding prebuilt llama_cpp / ctransformer shared libraries for Mac M1, Mac x86, Linux x86 and Windows\n3 DRAGON models packaged as Q4_K_M GGUF models for CPU laptop use (dragon-mistral-7b, dragon-llama-7b, dragon-yi-6b)\n4 leading open source chat models added to default catalog with Q4_K_M\n8 Dec 2023: llmware v0.1.11\n\nNew fast start examples for high volume Document Ingestion and Embeddings with Milvus.\nNew LLMWare \'Pop up\' Inference Server model class and example script.\nNew Invoice Processing example for RAG.\nImproved Windows stack management to support parsing larger documents.\nEnhancing debugging log output mode options for PDF and Office parsers.\n30 Nov 2023: llmware v0.1.10\n\nWindows added as a supported operating system.\nFurther enhancements to native code for stack management.\nMinor defect fixes.\n24 Nov 2023: llmware v0.1.9\n\nMarkdown (.md) files are now parsed and treated as text files.\nPDF and Office parser stack optimizations which should avoid the need to set ulimit -s.\nNew llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.\nNative dependencies (shared libraries and dependencies) now included in repo to faciliate local development.\nUpdates to the Status class to support PDF and Office document parsing status updates.\nMinor defect fixes including image block handling in library exports.\n17 Nov 2023: llmware v0.1.8\n\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\nImproved handling for eos_token_id for llama2 and mistral.\nImproved support for Hugging Face dynamic loading\nNew examples with the new llmware DRAGON models.\n14 Nov 2023: llmware v0.1.7\n\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\nModelCatalog enhancements:\nOpenAI update to include newly announced ‘turbo’ 4 and 3.5 models.\nCohere embedding v3 update to include new Cohere embedding models.\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the “hf=True” flag.\nAbility to register new model names, within existing model classes, with the register method in ModelCatalog.\nPrompt enhancements:\n“evidence_metadata” added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.\nAPI key can now be passed directly in a prompt.load_model(model_name, api_key = “[my-api-key]”)\nLLMWareInference Server - Initial delivery:\nNew Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.\nLLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.\n03 Nov 2023: llmware v0.1.6\n\nUpdated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.\nUpdates in python code needed in anticipation of future Windows support.\n27 Oct 2023: llmware v0.1.5\n\nFour new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (llmware BLING models).\nExpanded options for setting temperature inside a prompt class.\nImprovement in post processing of Hugging Face model generation.\nStreamlined loading of Hugging Face generative models into prompts.\nInitial delivery of a central status class: read/write of embedding status with a consistent interface for callers.\nEnhanced in-memory dictionary search support for multi-key queries.\nRemoved trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.\nMinor defect fixes, updated test scripts, and version update for Werkzeug to address dependency security alert.\n20 Oct 2023: llmware v0.1.4\n\nGPU support for Hugging Face models.\nDefect fixes and additional test scripts.\n13 Oct 2023: llmware v0.1.3\n\nMongoDB Atlas Vector Search support.\nSupport for authentication using a MongoDB connection string.\nDocument summarization methods.\nImprovements in capturing the model context window automatically and passing changes in the expected output length.\nDataset card and description with lookup by name.\nProcessing time added to model inference usage dictionary.\nAdditional test scripts, examples, and defect fixes.\n06 Oct 2023: llmware v0.1.1\n\nAdded test scripts to the github repository for regression testing.\nMinor defect fixes and version update of Pillow to address dependency security alert.\n02 Oct 2023: llmware v0.1.0 Initial release of llmware to open source!!'
 ""Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning\n2023-01-30 by Tim Dettmers 1,664 Comments\n\nDeep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience. But what features are important if you want to buy a new GPU? GPU RAM, cores, tensor cores, caches? How to make a cost-efficient choice? This blog post will delve into these questions, tackle common misconceptions, give you an intuitive understanding of how to think about GPUs, and will lend you advice, which will help you to make a choice that is right for you.\n\nThis blog post is designed to give you different levels of understanding of GPUs and the new Ampere series GPUs from NVIDIA. You have the choice: (1) If you are not interested in the details of how GPUs work, what makes a GPU fast compared to a CPU, and what is unique about the new NVIDIA RTX 40 Ampere series, you can skip right to the performance and performance per dollar charts and the recommendation section. The cost/performance numbers form the core of the blog post and the content surrounding it explains the details of what makes up GPU performance.\n\n(2) If you worry about specific questions, I have answered and addressed the most common questions and misconceptions in the later part of the blog post.\n\n(3) If you want to get an in-depth understanding of how GPUs, caches, and Tensor Cores work, the best is to read the blog post from start to finish. You might want to skip a section or two based on your understanding of the presented topics.\n\nContents  hide\nOverview\nHow do GPUs work?\nThe Most Important GPU Specs for Deep Learning Processing Speed\nTensor Cores\nMatrix multiplication without Tensor Cores\nMatrix multiplication with Tensor Cores\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nMemory Bandwidth\nL2 Cache / Shared Memory / L1 Cache / Registers\nEstimating Ada / Hopper Deep Learning Performance\nPractical Ada / Hopper Speed Estimates\nPossible Biases in Estimates\nAdvantages and Problems for RTX40 and RTX 30 Series\nSparse Network Training\nLow-precision Computation\nFan Designs and GPUs Temperature Issues\n3-slot Design and Power Issues\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\n8-bit Float Support in H100 and RTX 40 series GPUs\nRaw Performance Ranking of GPUs\nGPU Deep Learning Performance per Dollar\nGPU Recommendations\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nDo I need 8x/16x PCIe lanes?\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nCan I use multiple GPUs of different GPU types?\nWhat is NVLink, and is it useful?\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nWhat do I need to parallelize across two machines?\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nDo I need an Intel CPU to power a multi-GPU setup?\nDoes computer case design matter for cooling?\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nVersion History\nAcknowledgments\nRelated\nRelated Posts\nOverview\nThis blog post is structured in the following way. First, I will explain what makes a GPU fast. I will discuss CPUs vs GPUs, Tensor Cores, memory bandwidth, and the memory hierarchy of GPUs and how these relate to deep learning performance. These explanations might help you get a more intuitive sense of what to look for in a GPU. I discuss the unique features of the new NVIDIA RTX 40 Ampere GPU series that are worth considering if you buy a GPU. From there, I make GPU recommendations for different scenarios. After that follows a Q&A section of common questions posed to me in Twitter threads; in that section, I will also address common misconceptions and some miscellaneous issues, such as cloud vs desktop, cooling, AMD vs NVIDIA, and others.\n\nHow do GPUs work?\nIf you use GPUs frequently, it is useful to understand how they work. This knowledge will help you to undstand cases where are GPUs fast or slow. In turn, you might be able to understand better why you need a GPU in the first place and how other future hardware options might be able to compete. You can skip this section if you just want the useful performance numbers and arguments to help you decide which GPU to buy. The best high-level explanation for the question of how GPUs work is my following Quora answer:\n\nRead Tim Dettmers‘ answer to Why are GPUs well-suited to deep learning? on Quora\nThis is a high-level explanation that explains quite well why GPUs are better than CPUs for deep learning. If we look at the details, we can understand what makes one GPU better than another.\n\nThe Most Important GPU Specs for Deep Learning Processing Speed\nThis section can help you build a more intuitive understanding of how to think about deep learning performance. This understanding will help you to evaluate future GPUs by yourself. This section is sorted by the importance of each component. Tensor Cores are most important, followed by memory bandwidth of a GPU, the cache hierachy, and only then FLOPS of a GPU.\n\nTensor Cores\nTensor Cores are tiny cores that perform very efficient matrix multiplication. Since the most expensive part of any deep neural network is matrix multiplication Tensor Cores are very useful. In fast, they are so powerful, that I do not recommend any GPUs that do not have Tensor Cores.\n\nIt is helpful to understand how they work to appreciate the importance of these computational units specialized for matrix multiplication. Here I will show you a simple example of A*B=C matrix multiplication, where all matrices have a size of 32×32, what a computational pattern looks like with and without Tensor Cores. This is a simplified example, and not the exact way how a high performing matrix multiplication kernel would be written, but it has all the basics. A CUDA programmer would take this as a first “draft” and then optimize it step-by-step with concepts like double buffering, register optimization, occupancy optimization, instruction-level parallelism, and many others, which I will not discuss at this point.\n\nTo understand this example fully, you have to understand the concepts of cycles. If a processor runs at 1GHz, it can do 10^9 cycles per second. Each cycle represents an opportunity for computation. However, most of the time, operations take longer than one cycle. Thus we essentially have a queue where the next operations needs to wait for the next operation to finish. This is also called the latency of the operation.\n\nHere are some important latency cycle timings for operations. These times can change from GPU generation to GPU generation. These numbers are for Ampere GPUs, which have relatively slow caches.\n\nGlobal memory access (up to 80GB): ~380 cycles\nL2 cache: ~200 cycles\nL1 cache or Shared memory access (up to 128 kb per Streaming Multiprocessor): ~34 cycles\nFused multiplication and addition, a*b+c (FFMA): 4 cycles\nTensor Core matrix multiply: 1 cycle\nEach operation is always performed by a pack of 32 threads. This pack is termed a warp of threads. Warps usually operate in a synchronous pattern — threads within a warp have to wait for each other. All memory operations on the GPU are optimized for warps. For example, loading from global memory happens at a granularity of 32*4 bytes, exactly 32 floats, exactly one float for each thread in a warp. We can have up to 32 warps = 1024 threads in a streaming multiprocessor (SM), the GPU-equivalent of a CPU core. The resources of an SM are divided up among all active warps. This means that sometimes we want to run fewer warps to have more registers/shared memory/Tensor Core resources per warp.\n\nFor both of the following examples, we assume we have the same computational resources. For this small example of a 32×32 matrix multiply, we use 8 SMs (about 10% of an RTX 3090) and 8 warps per SM.\n\nTo understand how the cycle latencies play together with resources like threads per SM and shared memory per SM, we now look at examples of matrix multiplication. While the following example roughly follows the sequence of computational steps of matrix multiplication for both with and without Tensor Cores, please note that these are very simplified examples. Real cases of matrix multiplication involve much larger shared memory tiles and slightly different computational patterns.\n\nMatrix multiplication without Tensor Cores\nIf we want to do an A*B=C matrix multiply, where each matrix is of size 32×32, then we want to load memory that we repeatedly access into shared memory because its latency is about five times lower (200 cycles vs 34 cycles). A memory block in shared memory is often referred to as a memory tile or just a tile. Loading two 32×32 floats into a shared memory tile can happen in parallel by using 2*32 warps. We have 8 SMs with 8 warps each, so due to parallelization, we only need to do a single sequential load from global to shared memory, which takes 200 cycles.\n\nTo do the matrix multiplication, we now need to load a vector of 32 numbers from shared memory A and shared memory B and perform a fused multiply-and-accumulate (FFMA). Then store the outputs in registers C. We divide the work so that each SM does 8x dot products (32×32) to compute 8 outputs of C. Why this is exactly 8 (4 in older algorithms) is very technical. I recommend Scott Gray’s blog post on matrix multiplication to understand this. This means we have 8x shared memory accesses at the cost of 34 cycles each and 8 FFMA operations (32 in parallel), which cost 4 cycles each. In total, we thus have a cost of:\n\n200 cycles (global memory) + 8*34 cycles (shared memory) + 8*4 cycles (FFMA) = 504 cycles\n\nLet’s look at the cycle cost of using Tensor Cores.\n\nMatrix multiplication with Tensor Cores\nWith Tensor Cores, we can perform a 4×4 matrix multiplication in one cycle. To do that, we first need to get memory into the Tensor Core. Similarly to the above, we need to read from global memory (200 cycles) and store in shared memory. To do a 32×32 matrix multiply, we need to do 8×8=64 Tensor Cores operations. A single SM has 8 Tensor Cores. So with 8 SMs, we have 64 Tensor Cores — just the number that we need! We can transfer the data from shared memory to the Tensor Cores with 1 memory transfers (34 cycles) and then do those 64 parallel Tensor Core operations (1 cycle). This means the total cost for Tensor Cores matrix multiplication, in this case, is:\n\n200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.\n\nThus we reduce the matrix multiplication cost significantly from 504 cycles to 235 cycles via Tensor Cores. In this simplified case, the Tensor Cores reduced the cost of both shared memory access and FFMA operations.\n\nThis example is simplified, for example, usually each thread needs to calculate which memory to read and write to as you transfer data from global memory to shared memory. With the new Hooper (H100) architectures we additionally have the Tensor Memory Accelerator (TMA) compute these indices in hardware and thus help each thread to focus on more computation rather than computing indices.\n\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nThe RTX 30 Ampere and RTX 40 Ada series GPUs additionally have support to perform asynchronous transfers between global and shared memory. The H100 Hopper GPU extends this further by introducing the Tensor Memory Accelerator (TMA) unit. the TMA unit combines asynchronous copies and index calculation for read and writes simultaneously — so each thread no longer needs to calculate which is the next element to read and each thread can focus on doing more matrix multiplication calculations. This looks as follows.\n\nThe TMA unit fetches memory from global to shared memory (200 cycles). Once the data arrives, the TMA unit fetches the next block of data asynchronously from global memory. While this is happening, the threads load data from shared memory and perform the matrix multiplication via the tensor core. Once the threads are finished they wait for the TMA unit to finish the next data transfer, and the sequence repeats.\n\nAs such, due to the asynchronous nature, the second global memory read by the TMA unit is already progressing as the threads process the current shared memory tile. This means, the second read takes only 200 – 34 – 1 = 165 cycles.\n\nSince we do many reads, only the first memory access will be slow and all other memory accesses will be partially overlapped with the TMA unit. Thus on average, we reduce the time by 35 cycles.\n\n165 cycles (wait for async copy to finish) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 200 cycles.\n\nWhich accelerates the matrix multiplication by another 15%.\n\nFrom these examples, it becomes clear why the next attribute, memory bandwidth, is so crucial for Tensor-Core-equipped GPUs. Since global memory is the by far the largest cycle cost for matrix multiplication with Tensor Cores, we would even have faster GPUs if the global memory latency could be reduced. We can do this by either increasing the clock frequency of the memory (more cycles per second, but also more heat and higher energy requirements) or by increasing the number of elements that can be transferred at any one time (bus width).\n\nMemory Bandwidth\nFrom the previous section, we have seen that Tensor Cores are very fast. So fast, in fact, that they are idle most of the time as they are waiting for memory to arrive from global memory. For example, during GPT-3-sized training, which uses huge matrices — the larger, the better for Tensor Cores — we have a Tensor Core TFLOPS utilization of about 45-65%, meaning that even for the large neural networks about 50% of the time, Tensor Cores are idle.\n\nThis means that when comparing two GPUs with Tensor Cores, one of the single best indicators for each GPU’s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of speedup of an A100 vs V100 is 1555/900 = 1.73x.\n\nL2 Cache / Shared Memory / L1 Cache / Registers\nSince memory transfers to the Tensor Cores are the limiting factor in performance, we are looking for other GPU attributes that enable faster memory transfer to Tensor Cores. L2 cache, shared memory, L1 cache, and amount of registers used are all related. To understand how a memory hierarchy enables faster memory transfers, it helps to understand how matrix multiplication is performed on a GPU.\n\nTo perform matrix multiplication, we exploit the memory hierarchy of a GPU that goes from slow global memory, to faster L2 memory, to fast local shared memory, to lightning-fast registers. However, the faster the memory, the smaller it is.\n\nWhile logically, L2 and L1 memory are the same, L2 cache is larger and thus the average physical distance that need to be traversed to retrieve a cache line is larger. You can see the L1 and L2 caches as organized warehouses where you want to retrieve an item. You know where the item is, but to go there takes on average much longer for the larger warehouse. This is the essential difference between L1 and L2 caches. Large = slow, small = fast.\n\nFor matrix multiplication we can use this hierarchical separate into smaller and smaller and thus faster and faster chunks of memory to perform very fast matrix multiplications. For that, we need to chunk the big matrix multiplication into smaller sub-matrix multiplications. These chunks are called memory tiles, or often for short just tiles.\n\nWe perform matrix multiplication across these smaller tiles in local shared memory that is fast and close to the streaming multiprocessor (SM) — the equivalent of a CPU core. With Tensor Cores, we go a step further: We take each tile and load a part of these tiles into Tensor Cores which is directly addressed by registers. A matrix memory tile in L2 cache is 3-5x faster than global GPU memory (GPU RAM), shared memory is ~7-10x faster than the global GPU memory, whereas the Tensor Cores’ registers are ~200x faster than the global GPU memory.\n\nHaving larger tiles means we can reuse more memory. I wrote about this in detail in my TPU vs GPU blog post. In fact, you can see TPUs as having very, very, large tiles for each Tensor Core. As such, TPUs can reuse much more memory with each transfer from global memory, which makes them a little bit more efficient at matrix multiplications than GPUs.\n\nEach tile size is determined by how much memory we have per streaming multiprocessor (SM) and how much we L2 cache we have across all SMs. We have the following shared memory sizes on the following architectures:\n\nVolta (Titan V): 128kb shared memory / 6 MB L2\nTuring (RTX 20s series): 96 kb shared memory / 5.5 MB L2\nAmpere (RTX 30s series): 128 kb shared memory / 6 MB L2\nAda (RTX 40s series): 128 kb shared memory / 72 MB L2\nWe see that Ada has a much larger L2 cache allowing for larger tile sizes, which reduces global memory access. For example, for BERT large during training, the input and weight matrix of any matrix multiplication fit neatly into the L2 cache of Ada (but not other Us). As such, data needs to be loaded from global memory only once and then data is available throught the L2 cache, making matrix multiplication about 1.5 – 2.0x faster for this architecture for Ada. For larger models the speedups are lower during training but certain sweetspots exist which may make certain models much faster. Inference, with a batch size larger than 8 can also benefit immensely from the larger L2 caches.\n\nEstimating Ada / Hopper Deep Learning Performance\nThis section is for those who want to understand the more technical details of how I derive the performance estimates for Ampere GPUs. If you do not care about these technical aspects, it is safe to skip this section.\n\nPractical Ada / Hopper Speed Estimates\nSuppose we have an estimate for one GPU of a GPU-architecture like Hopper, Ada, Ampere, Turing, or Volta. It is easy to extrapolate these results to other GPUs from the same architecture/series. Luckily, NVIDIA already benchmarked the A100 vs V100 vs H100 across a wide range of computer vision and natural language understanding tasks. Unfortunately, NVIDIA made sure that these numbers are not directly comparable by using different batch sizes and the number of GPUs whenever possible to favor results for the H100 GPU. So in a sense, the benchmark numbers are partially honest, partially marketing numbers. In general, you could argue that using larger batch sizes is fair, as the H100/A100 GPU has more memory. Still, to compare GPU architectures, we should evaluate unbiased memory performance with the same batch size.\n\nTo get an unbiased estimate, we can scale the data center GPU results in two ways: (1) account for the differences in batch size, (2) account for the differences in using 1 vs 8 GPUs. We are lucky that we can find such an estimate for both biases in the data that NVIDIA provides.\n\nDoubling the batch size increases throughput in terms of images/s (CNNs) by 13.6%. I benchmarked the same problem for transformers on my RTX Titan and found, surprisingly, the very same result: 13.5% — it appears that this is a robust estimate.\n\nAs we parallelize networks across more and more GPUs, we lose performance due to some networking overhead. The A100 8x GPU system has better networking (NVLink 3.0) than the V100 8x GPU system (NVLink 2.0) — this is another confounding factor. Looking directly at the data from NVIDIA, we can find that for CNNs, a system with 8x A100 has a 5% lower overhead than a system of 8x V100. This means if going from 1x A100 to 8x A100 gives you a speedup of, say, 7.00x, then going from 1x V100 to 8x V100 only gives you a speedup of 6.67x.  For transformers, the figure is 7%.\n\nUsing these figures, we can estimate the speedup for a few specific deep learning architectures from the direct data that NVIDIA provides. The Tesla A100 offers the following speedup over the Tesla V100:\n\nSE-ResNeXt101: 1.43x\nMasked-R-CNN: 1.47x\nTransformer (12 layer, Machine Translation, WMT14 en-de): 1.70x\nThus, the figures are a bit lower than the theoretical estimate for computer vision. This might be due to smaller tensor dimensions, overhead from operations that are needed to prepare the matrix multiplication like img2col or Fast Fourier Transform (FFT), or operations that cannot saturate the GPU (final layers are often relatively small). It could also be artifacts of the specific architectures (grouped convolution).\n\nThe practical transformer estimate is very close to the theoretical estimate. This is probably because algorithms for huge matrices are very straightforward. I will use these practical estimates to calculate the cost efficiency of GPUs.\n\nPossible Biases in Estimates\nThe estimates above are for H100, A100 , and V100 GPUs. In the past, NVIDIA sneaked unannounced performance degradations into the “gaming” RTX GPUs: (1) Decreased Tensor Core utilization, (2) gaming fans for cooling, (3) disabled peer-to-peer GPU transfers. It might be possible that there are unannounced performance degradations in the RTX 40 series compared to the full Hopper H100.\n\nAs of now, one of these degradations was found for Ampere GPUs: Tensor Core performance was decreased so that RTX 30 series GPUs are not as good as Quadro cards for deep learning purposes. This was also done for the RTX 20 series, so it is nothing new, but this time it was also done for the Titan equivalent card, the RTX 3090. The RTX Titan did not have performance degradation enabled.\n\nCurrently, no degradation for Ada GPUs are known, but I update this post with news on this and let my followers on twitter know.\n\nAdvantages and Problems for RTX40 and RTX 30 Series\nThe new NVIDIA Ampere RTX 30 series has additional benefits over the NVIDIA Turing RTX 20 series, such as sparse network training and inference. Other features, such as the new data types, should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required.\n\nThe Ada RTX 40 series has even further advances like 8-bit Float (FP8) tensor cores. The RTX 40 series also has similar power and temperature issues compared to the RTX 30. The issue of melting power connector cables in the RTX 40 can be easily prevented by connecting the power cable correctly.\n\nSparse Network Training\nAmpere allows for fine-grained structure automatic sparse matrix multiplication at dense speeds. How does this work? Take a weight matrix and slice it into pieces of 4 elements. Now imagine 2 elements of these 4 to be zero. Figure 1 shows how this could look like.\n\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool's GTC 2020 presentation on  Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nWhen you multiply this sparse weight matrix with some dense inputs, the sparse matrix tensor core feature in Ampere automatically compresses the sparse matrix to a dense representation that is half the size as can be seen in Figure 2. After this compression, the densely compressed matrix tile is fed into the tensor core which computes a matrix multiplication of twice the usual size. This effectively yields a 2x speedup since the bandwidth requirements during matrix multiplication from shared memory are halved.\n\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed.\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nI was working on sparse network training in my research and I also wrote a blog post about sparse training. One criticism of my work was that “You reduce the FLOPS required for the network, but it does not yield speedups because GPUs cannot do fast sparse matrix multiplication.” Well, with the addition of the sparse matrix multiplication feature for Tensor Cores, my algorithm, or other sparse training algorithms, now actually provide speedups of up to 2x during training.\n\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nWhile this feature is still experimental and training sparse networks are not commonplace yet, having this feature on your GPU means you are ready for the future of sparse training.\n\nLow-precision Computation\nIn my work, I’ve previously shown that new data types can improve stability during low-precision backpropagation.\n\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nCurrently, if you want to have stable backpropagation with 16-bit floating-point numbers (FP16), the big problem is that ordinary FP16 data types only support numbers in the range [-65,504, 65,504]. If your gradient slips past this range, your gradients explode into NaN values. To prevent this during FP16 training, we usually perform loss scaling where you multiply the loss by a small number before backpropagating to prevent this gradient explosion.\n\nThe BrainFloat 16 format (BF16) uses more bits for the exponent such that the range of possible numbers is the same as for FP32: [-3*10^38, 3*10^38]. BF16 has less precision, that is significant digits, but gradient precision is not that important for learning. So what BF16 does is that you no longer need to do any loss scaling or worry about the gradient blowing up quickly. As such, we should see an increase in training stability by using the BF16 format as a slight loss of precision.\n\nWhat this means for you: With BF16 precision, training might be more stable than with FP16 precision while providing the same speedups. With 32-bit TensorFloat (TF32) precision, you get near FP32 stability while giving the speedups close to FP16. The good thing is, to use these data types, you can just replace FP32 with TF32 and FP16 with BF16 — no code changes required!\n\nOverall, though, these new data types can be seen as lazy data types in the sense that you could have gotten all the benefits with the old data types with some additional programming efforts (proper loss scaling, initialization, normalization, using Apex). As such, these data types do not provide speedups but rather improve ease of use of low precision for training.\n\nFan Designs and GPUs Temperature Issues\nWhile the new fan design of the RTX 30 series performs very well to cool the GPU, different fan designs of non-founders edition GPUs might be more problematic. If your GPU heats up beyond 80C, it will throttle itself and slow down its computational speed / power. This overheating can happen in particular if you stack multiple GPUs next to each other. A solution to this is to use PCIe extenders to create space between GPUs.\n\nSpreading GPUs with PCIe extenders is very effective for cooling, and other fellow PhD students at the University of Washington and I use this setup with great success. It does not look pretty, but it keeps your GPUs cool! This has been running with no problems at all for 4 years now. It can also help if you do not have enough space to fit all GPUs in the PCIe slots. For example, if you can find the space within a desktop computer case, it might be possible to buy standard 3-slot-width RTX 4090 and spread them with PCIe extenders within the case. With this, you might solve both the space issue and cooling issue for a 4x RTX 4090 setup with a single simple solution.\n\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 2 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 4 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\n3-slot Design and Power Issues\nThe RTX 3090 and RTX 4090 are 3-slot GPUs, so one will not be able to use it in a 4x setup with the default fan design from NVIDIA. This is kind of justified because it runs at over 350W TDP, and it will be difficult to cool in a multi-GPU 2-slot setting. The RTX 3080 is only slightly better at 320W TDP, and cooling a 4x RTX 3080 setup will also be very difficult.\n\nIt is also difficult to power a 4x 350W = 1400W or 4x 450W = 1800W system in the 4x RTX 3090 or 4x RTX 4090 case. Power supply units (PSUs) of 1600W are readily available, but having only 200W to power the CPU and motherboard can be too tight. The components’ maximum power is only used if the components are fully utilized, and in deep learning, the CPU is usually only under weak load. With that, a 1600W PSU might work quite well with a 4x RTX 3080 build, but for a 4x RTX 3090 build, it is better to look for high wattage PSUs (+1700W). Some of my followers have had great success with cryptomining PSUs — have a look in the comment section for more info about that. Otherwise, it is important to note that not all outlets support PSUs above 1600W, especially in the US. This is the reason why in the US, there are currently few standard desktop PSUs above 1600W on the market. If you get a server or cryptomining PSUs, beware of the form factor — make sure it fits into your computer case.\n\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nIt is possible to set a power limit on your GPUs. So you would be able to programmatically set the power limit of an RTX 3090 to 300W instead of their standard 350W. In a 4x GPU system, that is a saving of 200W, which might just be enough to build a 4x RTX 3090 system with a 1600W PSU feasible. It also helps to keep the GPUs cool. So setting a power limit can solve the two major problems of a 4x RTX 3080 or 4x RTX 3090 setups, cooling, and power, at the same time. For a 4x setup, you still need effective blower GPUs (and the standard design may prove adequate for this), but this resolves the PSU problem.\n\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nYou might ask, “Doesn’t this slow down the GPU?” Yes, it does, but the question is by how much. I benchmarked the 4x RTX 2080 Ti system shown in Figure 5 under different power limits to test this. I benchmarked the time for 500 mini-batches for BERT Large during inference (excluding the softmax layer). I choose BERT Large inference since, from my experience, this is the deep learning model that stresses the GPU the most. As such, I would expect power limiting to have the most massive slowdown for this model. As such, the slowdowns reported here are probably close to the maximum slowdowns that you can expect. The results are shown in Figure 7.\n\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nAs we can see, setting the power limit does not seriously affect performance. Limiting the power by 50W — more than enough to handle 4x RTX 3090 — decreases performance by only 7%.\n\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\nThere was a misconception that RTX 4090 power cables melt because they were bent. However, it was found that only 0.1% of users had this problem and the problem occured due to user error. Here a video that shows that the main problem is that cables were not inserted correctly.\n\nSo using RTX 4090 cards is perfectly safe if you follow the following install instructions:\n\nIf you use an old cable or old GPU make sure the contacts are free of debri / dust.\nUse the power connector and stick it into the socket until you hear a *click* — this is the most important part.\nTest for good fit by wiggling the power cable left to right. The cable should not move.\nCheck the contact with the socket visually, there should be no gap between cable and socket.\n8-bit Float Support in H100 and RTX 40 series GPUs\nThe support of the 8-bit Float (FP8) is a huge advantage for the RTX 40 series and H100 GPUs. With 8-bit inputs it allows you to load the data for matrix multiplication twice as fast, you can store twice as much matrix elements in your caches which in the Ada and Hopper architecture are very large, and now with FP8 tensor cores you get 0.66 PFLOPS of compute for a RTX 4090 — this is more FLOPS then the entirety of the worlds fastest supercomputer in year 2007. 4x RTX 4090 with FP8 compute rival the faster supercomputer in the world in year 2010 (deep learning started to work just in 2009).\n\nThe main problem with using 8-bit precision is that transformers can get very unstable with so few bits and crash during training or generate non-sense during inference. I have written a paper about the emergence of instabilities in large language models and I also written a more accessible blog post.\n\nThe main take-way is this: Using 8-bit instead of 16-bit makes things very unstable, but if you keep a couple of dimensions in high precision everything works just fine.\n\n\nMain results from my work on 8-bit matrix multiplication for Large Language Models (LLMs). We can see that the best 8-bit baseline fails to deliver good zero-shot performance. The method that I developed, LLM.int8(), can perform Int8 matrix multiplication with the same results as the 16-bit baseline.\nBut Int8 was already supported by the RTX 30 / A100 / Ampere generation GPUs, why is FP8 in the RTX 40 another big upgrade? The FP8 data type is much more stable than the Int8 data type and its easy to use it in functions like layer norm or non-linear functions, which are difficult to do with Integer data types. This will make it very straightforward to use it in training and inference. I think this will make FP8 training and inference relatively common in a couple of months.\n\nIf you want to read more about the advantages of Float vs Integer data types you can read my recent paper about k-bit inference scaling laws. Below you can see one relevant main result for Float vs Integer data types from this paper. We can see that bit-by-bit, the FP4 data type preserve more information than Int4 data type and thus improves the mean LLM zeroshot accuracy across 4 tasks.\n\n\n4-bit Inference scaling laws for Pythia Large Language Models for different data types. We see that bit-by-bit, 4-bit float data types have better zeroshot accuracy compared to the Int4 data types.\nRaw Performance Ranking of GPUs\nBelow we see a chart of raw relevative performance across all GPUs. We see that there is a gigantic gap in 8-bit performance of H100 GPUs and old cards that are optimized for 16-bit performance.\n\n\nShown is raw relative transformer performance of GPUs. For example, an RTX 4090 has about 0.33x performance of a H100 SMX for 8-bit inference. In other words, a H100 SMX is three times faster for 8-bit inference compared to a RTX 4090.\nFor this data, I did not model 8-bit compute for older GPUs. I did so, because 8-bit Inference and training are much more effective on Ada/Hopper GPUs because of the 8-bit Float data type and Tensor Memory Accelerator (TMA) which saves the overhead of computing read/write indices which is particularly helpful for 8-bit matrix multiplication. Ada/Hopper also have FP8 support, which makes in particular 8-bit training much more effective.\n\nI did not model numbers for 8-bit training because to model that I need to know the latency of L1 and L2 caches on Hopper/Ada GPUs, and they are unknown and I do not have access to such GPUs. On Hopper/Ada, 8-bit training performance can well be 3-4x of 16-bit training performance if the caches are as fast as rumored.\n\nBut even with the new FP8 tensor cores there are some additional issues which are difficult to take into account when modeling GPU performance. For example, FP8 tensor cores do not support transposed matrix multiplication which means backpropagation needs either a separate transpose before multiplication or one needs to hold two sets of weights — one transposed and one non-transposed — in memory. I used two sets of weight when I experimented with Int8 training in my LLM.int8() project and this reduced the overall speedups quite significantly. I think one can do better with the right algorithms/software, but this shows that missing features like a transposed matrix multiplication for tensor cores can affect performance.\n\nFor old GPUs, Int8 inference performance is close to the 16-bit inference performance for models below 13B parameters. Int8 performance on old GPUs is only relevant if you have relatively large models with 175B parameters or more. If you are interested in 8-bit performance of older GPUs, you can read the Appendix D of my LLM.int8() paper where I benchmark Int8 performance.\n\nGPU Deep Learning Performance per Dollar\nBelow we see the chart for the performance per US dollar for all GPUs sorted by 8-bit inference performance. How to use the chart to find a suitable GPU for you is as follows:\n\nDetermine the amount of GPU memory that you need (rough heuristic: at least 12 GB for image generation; at least 24 GB for work with transformers)\nWhile 8-bit inference and training is experimental, it will become standard within 6 months. You might need to do some extra difficult coding to work with 8-bit in the meantime. Is that OK for you? If not, select for 16-bit performance.\nUsing the metric determined in (2), find the GPU with the highest relative performance/dollar that has the amount of memory you need.\nWe can see that the RTX 4070 Ti is most cost-effective for 8-bit and 16-bit inference while the RTX 3080 remains most cost-effective for 16-bit training. While these GPUs are most cost-effective, they are not necessarily recommended as they do not have sufficient memory for many use-cases. However, it might be the ideal cards to get started on your deep learning journey. Some of these GPUs are excellent for Kaggle competition where one can often rely on smaller models. Since to do well in Kaggle competitions the method of how you work is more important than the models size, many of these smaller GPUs are excellent for Kaggle competitions.\n\nThe best GPUs for academic and startup servers seem to be A6000 Ada GPUs (not to be confused with A6000 Turing). The H100 SXM GPU is also very cost effective and has high memory and very strong performance. If I would build a small cluster for a company/academic lab, I would use 66-80% A6000 GPUs and 20-33% H100 SXM GPUs. If I get a good deal on L40 GPUs, I would also pick them instead of A6000, so you can always ask for a quote on these.\n\n\nShown is relative performance per US Dollar of GPUs normalized by the cost for a desktop computer and the average Amazon and eBay price for each GPU. Additionally, the electricity cost of ownership for 5 years is added with an electricity price of 0.175 USD per kWh and a 15% GPU utilization rate. The electricity cost for a RTX 4090 is about $100 per year. How to read and interpret the chart: a desktop computer with RTX 4070 Ti cards owned for 5 years yields about 2x more 8-bit inference performance per dollar compared to a RTX 3090 GPU.\nGPU Recommendations\nI have a create a recommendation flow-chart that you can see below (click here for interactive app from Nan Xiao). While this chart will help you in 80% of cases, it might not quite work for you because the options might be too expensive. In that case, try to look at the benchmarks above and pick the most cost effective GPU that still has enough GPU memory for your use-case. You can estimate the GPU memory needed by running your problem in the vast.ai or Lambda Cloud for a while so you know what you need. The vast.ai or Lambda Cloud might also work well if you only need a GPU very sporadically (every couple of days for a few hours) and you do not need to download and process large dataset to get started. However, cloud GPUs are usually not a good option if you use your GPU for many months with a high usage rate each day (12 hours each day). You can use the example in the “When is it better to use the cloud vs a dedicated GPU desktop/server?” section below to determine if cloud GPUs are good for you.\n\n\nGPU recommendation chart for Ada/Hopper GPUs. Follow the answers to the Yes/No questions to find the GPU that is most suitable for you. While this chart works well in about 80% of cases, you might end up with a GPU that is too expensive. Use the cost/performance charts above to make a selection instead. [interactive app]\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nTo understand if it makes sense to skip this generation and buy the next generation of GPUs, it makes sense to talk a bit about what improvements in the future will look like.\n\nIn the past it was possible to shrink the size of transistors to improve speed of a processor. This is coming to an end now. For example, while shrinking SRAM increased its speed (smaller distance, faster memory access), this is no longer the case. Current improvements in SRAM do not improve its performance anymore and might even be negative. While logic such as Tensor Cores get smaller, this does not necessarily make GPU faster since the main problem for matrix multiplication is to get memory to the tensor cores which is dictated by SRAM and GPU RAM speed and size. GPU RAM still increases in speed if we stack memory modules into high-bandwidth modules (HBM3+), but these are too expensive to manufacture for consumer applications. The main way to improve raw speed of GPUs is to use more power and more cooling as we have seen in the RTX 30s and 40s series. But this cannot go on for much longer.\n\nChiplets such as used by AMD CPUs are another straightforward way forward. AMD beat Intel by developing CPU chiplets. Chiplets are small chips that are fused together with a high speed on-chip network. You can think about them as two GPUs that are so physically close together that you can almost consider them a single big GPU. They are cheaper to manufacture, but more difficult to combine into one big chip. So you need know-how and fast connectivity between chiplets. AMD has a lot of experience with chiplet design. AMD’s next generation GPUs are going to be chiplet designs, while NVIDIA currently has no public plans for such designs. This may mean that the next generation of AMD GPUs might be better in terms of cost/performance compared to NVIDIA GPUs.\n\nHowever, the main performance boost for GPUs is currently specialized logic. For example, the asynchronous copy hardware units on the Ampere generation (RTX 30 / A100 / RTX 40) or the extension, the Tensor Memory Accelerator (TMA), both reduce the overhead of copying memory from the slow global memory to fast shared memory (caches) through specialized hardware and so each thread can do more computation. The TMA also reduces overhead by performing automatic calculations of read/write indices which is particularly important for 8-bit computation where one has double the elements for the same amount of memory compared to 16-bit computation. So specialized hardware logic can accelerate matrix multiplication further.\nLow-bit precision is another straightforward way forward for a couple of years. We will see widespread adoption of 8-bit inference and training in the next months. We will see widespread 4-bit inference in the next year. Currently, the technology for 4-bit training does not exists, but research looks promising and I expect the first high performance FP4 Large Language Model (LLM) with competitive predictive performance to be trained in 1-2 years time.\n\nGoing to 2-bit precision for training currently looks pretty impossible, but it is a much easier problem than shrinking transistors further. So progress in hardware mostly depends on software and algorithms that make it possible to use specialized features offered by the hardware.\n\nWe will probably be able to still improve the combination of algorithms + hardware to the year 2032, but after that will hit the end of GPU improvements (similar to smartphones). The wave of performance improvements after 2032 will come from better networking algorithms and mass hardware. It is uncertain if consumer GPUs will be relevant at this point. It might be that you need an RTX 9090 to run run Super HyperStableDiffusion Ultra Plus 9000 Extra or OpenChatGPT 5.0, but it might also be that some company will offer a high-quality API that is cheaper than the electricity cost for a RTX 9090 and you want to use a laptop + API for image generation and other tasks.\n\nOverall, I think investing into a 8-bit capable GPU will be a very solid investment for the next 9 years. Improvements at 4-bit and 2-bit are likely small and other features like Sort Cores would only become relevant once sparse matrix multiplication can be leveraged well. We will probably see some kind of other advancement in 2-3 years which will make it into the next GPU 4 years from now, but we are running out of steam if we keep relying on matrix multiplication. This makes investments into new GPUs last longer.\n\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nGenerally, no. PCIe 5.0 or 4.0 is great if you have a GPU cluster. It is okay if you have an 8x GPU machine, but otherwise, it does not yield many benefits. It allows better parallelization and a bit faster data transfer. Data transfers are not a bottleneck in any application. In computer vision, in the data transfer pipeline, the data storage can be a bottleneck, but not the PCIe transfer from CPU to GPU. So there is no real reason to get a PCIe 5.0 or 4.0 setup for most people. The benefits will be maybe 1-7% better parallelization in a 4 GPU setup.\n\nDo I need 8x/16x PCIe lanes?\nSame as with PCIe 4.0 — generally, no. PCIe lanes are needed for parallelization and fast data transfers, which are seldom a bottleneck. Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.\n\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nYou need to get one of the two-slot variants, or you can try to spread them out with PCIe extenders. Besides space, you should also immediately think about cooling and a suitable PSU.\n\nPCIe extenders might also solve both space and cooling issues, but you need to make sure that you have enough space in your case to spread out the GPUs. Make sure your PCIe extenders are long enough!\n\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nSee the previous section.\n\nCan I use multiple GPUs of different GPU types?\nYes, you can! But you cannot parallelize efficiently across GPUs of different types since you will often go at the speed of the slowest GPU (data and fully sharded parallelism). So different GPUs work just fine, but parallelization across those GPUs will be inefficient since the fastest GPU will wait for the slowest GPU to catch up to a synchronization point (usually gradient update).\n\nWhat is NVLink, and is it useful?\nGenerally, NVLink is not useful. NVLink is a high speed interconnect between GPUs. It is useful if you have a GPU cluster with +128 GPUs. Otherwise, it yields almost no benefits over standard PCIe transfers.\n\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nDefinitely buy used GPUs. You can buy a small cheap GPU for prototyping and testing and then roll out for full experiments to the cloud like vast.ai or Lambda Cloud. This can be cheap if you train/fine-tune/inference on large models only every now and then and spent more time protoyping on smaller models.\n\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nI built a carbon calculator for calculating your carbon footprint for academics (carbon from flights to conferences + GPU time). The calculator can also be used to calculate a pure GPU carbon footprint. You will find that GPUs produce much, much more carbon than international flights. As such, you should make sure you have a green source of energy if you do not want to have an astronomical carbon footprint. If no electricity provider in our area provides green energy, the best way is to buy carbon offsets. Many people are skeptical about carbon offsets. Do they work? Are they scams?\n\nI believe skepticism just hurts in this case, because not doing anything would be more harmful than risking the probability of getting scammed. If you worry about scams, just invest in a portfolio of offsets to minimize risk.\n\nI worked on a project that produced carbon offsets about ten years ago. The carbon offsets were generated by burning leaking methane from mines in China. UN officials tracked the process, and they required clean digital data and physical inspections of the project site. In that case, the carbon offsets that were produced were highly reliable. I believe many other projects have similar quality standards.\n\nWhat do I need to parallelize across two machines?\nIf you want to be on the safe side, you should get at least +50Gbits/s network cards to gain speedups if you want to parallelize across machines. I recommend having at least an EDR Infiniband setup, meaning a network card with at least 50 GBit/s bandwidth. Two EDR cards with cable are about $500 on eBay.\n\nIn some cases, you might be able to get away with 10 Gbit/s Ethernet, but this is usually only the case for special networks (certain convolutional networks) or if you use certain algorithms (Microsoft DeepSpeed).\n\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nIt does not seem so. Since the granularity of the sparse matrix needs to have 2 zero-valued elements, every 4 elements, the sparse matrices need to be quite structured. It might be possible to adjust the algorithm slightly, which involves that you pool 4 values into a compressed representation of 2 values, but this also means that precise arbitrary sparse matrix multiplication is not possible with Ampere GPUs.\n\nDo I need an Intel CPU to power a multi-GPU setup?\nI do not recommend Intel CPUs unless you heavily use CPUs in Kaggle competitions (heavy linear algebra on the CPU). Even for Kaggle competitions AMD CPUs are still great, though. AMD CPUs are cheaper and better than Intel CPUs in general for deep learning. For a 4x GPU built, my go-to CPU would be a Threadripper. We built dozens of systems at our university with Threadrippers, and they all work great — no complaints yet. For 8x GPU systems, I would usually go with CPUs that your vendor has experience with. CPU and PCIe/system reliability is more important in 8x systems than straight performance or straight cost-effectiveness.\n\nDoes computer case design matter for cooling?\nNo. GPUs are usually perfectly cooled if there is at least a small gap between GPUs. Case design will give you 1-3 C better temperatures, space between GPUs will provide you with 10-30 C improvements. The bottom line, if you have space between GPUs, cooling does not matter. If you have no space between GPUs, you need the right cooler design (blower fan) or another solution (water cooling, PCIe extenders), but in either case, case design and case fans do not matter.\n\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nNot in the next 1-2 years. It is a three-way problem: Tensor Cores, software, and community.\n\nAMD GPUs are great in terms of pure silicon: Great FP16 performance, great memory bandwidth. However, their lack of Tensor Cores or the equivalent makes their deep learning performance poor compared to NVIDIA GPUs. Packed low-precision math does not cut it. Without this hardware feature, AMD GPUs will never be competitive. Rumors show that some data center card with Tensor Core equivalent is planned for 2020, but no new data emerged since then. Just having data center cards with a Tensor Core equivalent would also mean that few would be able to afford such AMD GPUs, which would give NVIDIA a competitive advantage.\n\nLet’s say AMD introduces a Tensor-Core-like-hardware feature in the future. Then many people would say, “But there is no software that works for AMD GPUs! How am I supposed to use them?” This is mostly a misconception. The AMD software via ROCm has come to a long way, and support via PyTorch is excellent. While I have not seen many experience reports for AMD GPUs + PyTorch, all the software features are integrated. It seems, if you pick any network, you will be just fine running it on AMD GPUs. So here AMD has come a long way, and this issue is more or less solved.\n\nHowever, if you solve software and the lack of Tensor Cores, AMD still has a problem: the lack of community. If you have a problem with NVIDIA GPUs, you can Google the problem and find a solution. That builds a lot of trust in NVIDIA GPUs. You have the infrastructure that makes using NVIDIA GPUs easy (any deep learning framework works, any scientific problem is well supported). You have the hacks and tricks that make usage of NVIDIA GPUs a breeze (e.g., apex). You can find experts on NVIDIA GPUs and programming around every other corner while I knew much less AMD GPU experts.\n\nIn the community aspect, AMD is a bit like Julia vs Python. Julia has a lot of potential, and many would say, and rightly so, that it is the superior programming language for scientific computing. Yet, Julia is barely used compared to Python. This is because the Python community is very strong. Numpy, SciPy, Pandas are powerful software packages that a large number of people congregate around. This is very similar to the NVIDIA vs AMD issue.\n\nThus, it is likely that AMD will not catch up until Tensor Core equivalent is introduced (1/2 to 1 year?) and a strong community is built around ROCm (2 years?). AMD will always snatch a part of the market share in specific subgroups (e.g., cryptocurrency mining, data centers). Still, in deep learning, NVIDIA will likely keep its monopoly for at least a couple more years.\n\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nRule-of-thumb: If you expect to do deep learning for longer than a year, it is cheaper to get a desktop GPU. Otherwise, cloud instances are preferable unless you have extensive cloud computing skills and want the benefits of scaling the number of GPUs up and down at will.\n\nNumbers in the following paragraphs are going to change, but it serves as a scenario that helps you to understand the rough costs. You can use similar math to determine if cloud GPUs are the best solution for you.\n\nFor the exact point in time when a cloud GPU is more expensive than a desktop depends highly on the service that you are using, and it is best to do a little math on this yourself. Below I do an example calculation for an AWS V100 spot instance with 1x V100 and compare it to the price of a desktop with a single RTX 3090 (similar performance). The desktop with RTX 3090 costs $2,200 (2-GPU barebone + RTX 3090). Additionally, assuming you are in the US, there is an additional $0.12 per kWh for electricity. This compares to $2.14 per hour for the AWS on-demand instance.\n\nAt 15% utilization per year, the desktop uses:\n\n(350 W (GPU) + 100 W (CPU))*0.15 (utilization) * 24 hours * 365 days = 591 kWh per year\n\nSo 591 kWh of electricity per year, that is an additional $71.\n\nThe break-even point for a desktop vs a cloud instance at 15% utilization (you use the cloud instance 15% of time during the day), would be about 300 days ($2,311 vs $2,270):\n\n$2.14/h * 0.15 (utilization) * 24 hours * 300 days = $2,311\n\nSo if you expect to run deep learning models after 300 days, it is better to buy a desktop instead of using AWS on-demand instances.\n\nYou can do similar calculations for any cloud service to make the decision if you go for a cloud service or a desktop.\n\nCommon utilization rates are the following:\n\nPhD student personal desktop: < 15%\nPhD student slurm GPU cluster: > 35%\nCompany-wide slurm research cluster: > 60%\nIn general, utilization rates are lower for professions where thinking about cutting edge ideas is more important than developing practical products. Some areas have low utilization rates (interpretability research), while other areas have much higher rates (machine translation, language modeling). In general, the utilization of personal machines is almost always overestimated. Commonly, most personal systems have a utilization rate between 5-10%. This is why I would highly recommend slurm GPU clusters for research groups and companies instead of individual desktop GPU machines.\n\nVersion History\n2023-01-30: Improved font and recommendation chart. Added 5 years cost of ownership electricity perf/USD chart. Updated Async copy and TMA functionality. Slight update to FP8 training. General improvements.\n2023-01-16: Added Hopper and Ada GPUs. Added GPU recommendation chart. Added information about the TMA unit and L2 cache.\n2020-09-20: Added discussion of using power limiting to run 4x RTX 3090 systems. Added older GPUs to the performance and cost/performance charts. Added figures for sparse matrix multiplication.\n2020-09-07: Added NVIDIA Ampere series GPUs. Included lots of good-to-know GPU details.\n2019-04-03: Added RTX Titan and GTX 1660 Ti. Updated TPU section. Added startup hardware discussion.\n2018-11-26: Added discussion of overheating issues of RTX cards.\n2018-11-05: Added RTX 2070 and updated recommendations. Updated charts with hard performance data. Updated TPU section.\n2018-08-21: Added RTX 2080 and RTX 2080 Ti; reworked performance analysis\n2017-04-09: Added cost-efficiency analysis; updated recommendation with NVIDIA Titan Xp\n2017-03-19: Cleaned up blog post; added GTX 1080 Ti\n2016-07-23: Added Titan X Pascal and GTX 1060; updated recommendations\n2016-06-25: Reworked multi-GPU section; removed simple neural network memory section as no longer relevant; expanded convolutional memory section; truncated AWS section due to not being efficient anymore; added my opinion about the Xeon Phi; added updates for the GTX 1000 series\n2015-08-20: Added section for AWS GPU instances; added GTX 980 Ti to the comparison relation\n2015-04-22: GTX 580 no longer recommended; added performance relationships between cards\n2015-03-16: Updated GPU recommendations: GTX 970 and GTX 580\n2015-02-23: Updated GPU recommendations and memory calculations\n2014-09-28: Added emphasis for memory requirement of CNNs\nAcknowledgments\nI thank Suhail for making me aware of outdated prices on H100 GPUs, Gjorgji Kjosev for pointing out font issues, Anonymous for pointing out that the TMA unit does not exist on Ada GPUs, Scott Gray for pointing out that FP8 tensor cores have no transposed matrix multiplication, and reddit and HackerNews users for pointing out many other improvements.\n\nFor past updates of this blog post, I want to thank Mat Kelcey for helping me to debug and test custom code for the GTX 970; I want to thank Sander Dieleman for making me aware of the shortcomings of my GPU memory advice for convolutional nets; I want to thank Hannes Bretschneider for pointing out software dependency problems for the GTX 580; and I want to thank Oliver Griesel for pointing out notebook solutions for AWS instances. I want to thank Brad Nemire for providing me with an RTX Titan for benchmarking purposes. I want to thank Agrin Hilmkil, Ari Holtzman, Gabriel Ilharco, Nam Pho for their excellent feedback on the previous version of this blog post.""]",I don't know.,0.0,0.0,0.0007446016381236039,0.0,0.0
How do sets in Python compare to sets in Gleam?,No answer,"[""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 'Gleam for Python users\nHello productive pragmatic Pythonistas!\n\na soft wavey boundary between two sections of the website\nComments\nVariables\nMatch operator\nVariables type annotations\nFunctions\nExporting functions\nFunction type annotations\nReferencing functions\nLabelled arguments\nOperators\nConstants\nBlocks\nData types\nStrings\nTuples\nLists\nDicts\nFlow control\nCase\nTry\nType aliases\nCustom types\nRecords\nUnions\nOpaque custom types\nModules\nImports\nNamed imports\nUnqualified imports\nComments\nPython\nIn Python, comments are written with a # prefix.\n\n# Hello, Joe!\nA docstring (matching “””) that occurs as the first statement in a module, function, class, or method definition will become the __doc__ attribute of that object.\n\ndef a_function():\n    """"""Return some important data.""""""\n    pass\nGleam\nIn Gleam, comments are written with a // prefix.\n\n// Hello, Joe!\nComments starting with /// are used to document the following statement. Comments starting with //// are used to document the current module.\n\n//// This module is very important.\n\n/// The answer to life, the universe, and everything.\nconst answer: Int = 42\nVariables\nYou can reassign variables in both languages.\n\nPython\nsize = 50\nsize = size + 100\nsize = 1\nPython has no specific variable keyword. You choose a name and that’s it!\n\nGleam\nGleam has the let keyword before its variable names.\n\nlet size = 50\nlet size = size + 100\nlet size = 1\nMatch operator\nPython\nPython supports basic, one directional destructuring (also called unpacking). Tuple of values can be unpacked and inner values can be assigned to left-hand variable names.\n\n(a, b) = (1, 2)\n# a == 1\n# b == 2\n\n# works also for for-loops\nfor key, value in enumerate(a_dict):\n    print(key, value)\nGleam\nIn Gleam, let and = can be used for pattern matching, but you’ll get compile errors if there’s a type mismatch, and a runtime error if there’s a value mismatch. For assertions, the equivalent let assert keyword is preferred.\n\nlet #(x, _) = #(1, 2)\nlet assert [] = [1] // runtime error\nlet assert [y] = ""Hello"" // compile error, type mismatch\nVariables type annotations\nPython\nPython is a dynamically typed language. Types are only checked at runtime and a variable can have different types in its lifetime.\n\nType hints (Python 3+) are optional annotations that document the code with type information. These annotations are accessible at runtime via the __annotations__ module-level variable.\n\nThese hints will mainly be used to inform static analysis tools like IDEs, linters…\n\nsome_list: list[int] = [1, 2, 3]\nGleam\nIn Gleam type annotations can optionally be given when binding variables.\n\nlet some_list: List(Int) = [1, 2, 3]\nGleam will check the type annotation to ensure that it matches the type of the assigned value. It does not need annotations to type check your code, but you may find it useful to annotate variables to hint to the compiler that you want a specific type to be inferred.\n\nFunctions\nPython\nIn Python, you can define functions with the def keyword. In that case, the return keyword is mandatory.\n\ndef sum(x, y):\n    return x + y\nAnonymous functions returning a single expression can also be defined with the lambda keyword and be assigned into variables.\n\nmul = lambda x, y: x * y\nmul(1, 2)\nGleam\nGleam’s functions are declared using a syntax similar to Rust or JavaScript. Gleam’s anonymous functions have a similar syntax and don’t need a . when called.\n\npub fn sum(x, y) {\n  x + y\n}\n\nlet mul = fn(x, y) { x * y }\nmul(1, 2)\nExporting functions\nPython\nIn Python, top level functions are exported by default. There is no notion of private module-level functions.\n\nGleam\nIn Gleam, functions are private by default and need the pub keyword to be public.\n\n// this is public\npub fn sum(x, y) {\n  x + y\n}\n\n// this is private\nfn mul(x, y) {\n  x * y\n}\nFunction type annotations\nPython\nType hints can be used to optionally annotate function arguments and return types.\n\nDiscrepancies between type hints and actual values at runtime do not prevent interpretation of the code.\n\nStatic code analysers (IDE tooling, type checkers like mypy) will be required to detect those errors.\n\ndef sum(x: int, y: int) -> int:\n    return x + y\n\ndef mul(x: int, y: int) -> bool:\n    # no errors from the interpreter.\n    return x * y\nGleam\nFunctions can optionally have their argument and return types annotated in Gleam. These type annotations will always be checked by the compiler and throw a compilation error if not valid. The compiler will still type check your program using type inference if annotations are omitted.\n\npub fn add(x: Int, y: Int) -> Int {\n  x + y\n}\n\npub fn mul(x: Int, y: Int) -> Bool { // compile error, type mismatch\n  x * y\n}\nReferencing functions\nPython\nAs long as functions are in scope they can be assigned to a new variable. There is no special syntax to assign a module function to a variable.\n\nGleam\nGleam has a single namespace for value and functions within a module, so there is no need for a special syntax to assign a module function to a variable.\n\nfn identity(x) {\n  x\n}\n\nfn main() {\n  let func = identity\n  func(100)\n}\nLabelled arguments\nBoth Python and Gleam have ways to give arguments names and in any order.\n\nPython\nKeyword arguments are evaluated once at function definition time, and there is no evidence showing a noticeable performance penalty when using named arguments.\n\nWhen calling a function, arguments can be passed\n\npositionally, in the same order of the function declaration\nby name, in any order\ndef replace(inside: str, each: str, with_string: str):\n    pass\n\n# equivalent calls\nreplace(\'hello world\', \'world\', \'you\')\nreplace(each=\'world\', inside=\'hello world\',  with_string=\'you\')\nGleam\nIn Gleam arguments can be given a label as well as an internal name. Contrary to Python, the name used at the call-site does not have to match the name used for the variable inside the function.\n\npub fn replace(inside string, each pattern, with replacement) {\n  go(string, pattern, replacement)\n}\nreplace(each: "","", with: "" "", inside: ""A,B,C"")\nThere is no performance cost to Gleam’s labelled arguments as they are optimised to regular function calls at compile time, and all the arguments are fully type checked.\n\nOperators\nOperator\tPython\tGleam\tNotes\nEqual\t==\t==\tIn Gleam both values must be of the same type\nStrictly equal to\t==\t==\tComparison in Gleam is always strict. (see note for Python)\nReference equality\tis\t \tTrue only if the two objects have the same reference\nNot equal\t!=\t!=\tIn Gleam both values must be of the same type\nGreater than\t>\t>\tIn Gleam both values must be ints\nGreater than\t>\t>.\tIn Gleam both values must be floats\nGreater or equal\t>=\t>=\tIn Gleam both values must be ints\nGreater or equal\t>=\t>=.\tIn Gleam both values must be floats\nLess than\t<\t<\tIn Gleam both values must be ints\nLess than\t<\t<.\tIn Gleam both values must be floats\nLess or equal\t<=\t<=\tIn Gleam both values must be ints\nLess or equal\t<=\t<=.\tIn Gleam both values must be floats\nBoolean and\tand\t&&\tIn Gleam both values must be bools\nLogical and\tand\t \tNot available in Gleam\nBoolean or\tor\t||\tIn Gleam both values must be bools\nLogical or\tor\t \tNot available in Gleam\nAdd\t+\t+\tIn Gleam both values must be ints\nAdd\t+\t+.\tIn Gleam both values must be floats\nSubtract\t-\t-\tIn Gleam both values must be ints\nSubtract\t-\t-.\tIn Gleam both values must be floats\nMultiply\t*\t*\tIn Gleam both values must be ints\nMultiply\t*\t*.\tIn Gleam both values must be floats\nDivide\t/\t/\tIn Gleam both values must be ints\nDivide\t/\t/.\tIn Gleam both values must be floats\nRemainder\t%\t%\tIn Gleam both values must be ints, in Gleam negative values behave differently: Use int.modulo to mimick Python’s behavior.\nConcatenate\t+\t<>\tIn Gleam both values must be strings\nPipe\t \t|>\tGleam’s pipe can pipe into anonymous functions. This operator does not exist in python\nSome notes for Python:\n\n== is by default comparing by value:\n\nscalars will have their value compared\nthe only type cast will be for 0 and 1 that will be coerced to False and True respectively\nvariables that point to the same object will be equal with ==\ntwo objects with the same members values won’t be equal:\n\nno structural equality, unless the __eq__ operator is redefined.\nPython operators are short-circuiting as in Gleam.\nPython operators can be overloaded and be applied to any types with potential custom behaviors\nConstants\nPython\nIn Python, top-level declarations are in the global/module scope is the highest possible scope. Any variables and functions defined will be accessible from anywhere in the code.\n\nThere is no notion of constant variables in Python.\n\n# in the global scope\nTHE_ANSWER = 42\nGleam\nIn Gleam constants can be created using the const keyword.\n\nconst the_answer = 42\n\npub fn main() {\n  the_answer\n}\nBlocks\nPython\nPython blocks are always associated with a function / conditional / class declarations… There is no way to create multi-line expressions blocks like in Gleam.\n\nBlocks are declared via indentation.\n\ndef a_func():\n    # A block here\n    pass\nGleam\nIn Gleam braces { } are used to group expressions.\n\npub fn main() {\n  let x = {\n    some_function(1)\n    2\n  }\n  let y = x * {x + 10} // braces are used to change arithmetic operations order\n  y\n}\nData types\nStrings\nIn Python, strings are stored as unicode code-points sequence. Strings can be encoded or decoded to/from a specific encoding.\n\nIn Gleam all strings are UTF-8 encoded binaries.\n\nPython\n""Hellø, world!""\nGleam\n""Hellø, world!""\nTuples\nTuples are very useful in Gleam as they’re the only collection data type that allows mixed types in the collection.\n\nPython\nPython tuples are immutable, fixed-size lists that can contain mixed value types. Unpacking can be used to bind a name to a specific value of the tuple.\n\nmy_tuple = (""username"", ""password"", 10)\n_, password, _ = my_tuple\nGleam\nlet my_tuple = #(""username"", ""password"", 10)\nlet #(_, password, _) = my_tuple\nLists\nLists in Python are allowed to have values of mixed types, but not in Gleam.\n\nPython\nPython can emulate the cons operator of Gleam using the * operator and unpacking:\n\nlist = [2, 3, 4]\n[head, *tail] = list\n# head == 2\n# tail == [3, 4]\nGleam\nGleam has a cons operator that works for lists destructuring and pattern matching. In Gleam lists are immutable so adding and removing elements from the start of a list is highly efficient.\n\nlet list = [2, 3, 4]\nlet list = [1, ..list]\nlet [1, second_element, ..] = list\n[1.0, ..list] // compile error, type mismatch\nDictionaries\nIn Python, dictionaries can have keys of any type as long as:\n\nthe key type is hashable, such as integers, strings, tuples (due to their immutable values), functions… and custom mutable objects implementing the __hash__ method.\nthe key is unique in the dictionary. and values of any type.\nIn Gleam, dicts can have keys and values of any type, but all keys must be of the same type in a given dict and all values must be of the same type in a given dict.\n\nThere is no dict literal syntax in Gleam, and you cannot pattern match on a dict. Dicts are generally not used much in Gleam, custom types are more common.\n\nPython\n{""key1"": ""value1"", ""key2"": ""value2""}\n{""key1"":  ""1"", ""key2"": 2}\nGleam\nimport gleam/dict\n\ndict.from_list([#(""key1"", ""value1""), #(""key2"", ""value2"")])\ndict.from_list([#(""key1"", ""value1""), #(""key2"", 2)]) // Type error!\nFlow control\nCase\nCase is one of the most used control flows in Gleam. It can be seen as a switch statement on steroids. It provides a terse way to match a value type to an expression. Gleam’s case expression is fairly similar to Python’s match statement.\n\nPython\nMatching on primitive types:\n\ndef http_error(status):\n    match status:\n        case 400:\n            return ""Bad request""\n        case 404:\n            return ""Not found""\n        case 418:\n            return ""I\'m a teapot""\nMatching on tuples with variable capturing:\n\nmatch point:\n    case (0, 0):\n        print(""Origin"")\n    case (0, y):\n        print(f""Y={y}"")\n    case (x, 0):\n        print(f""X={x}"")\n    case (x, y):\n        print(f""""X={x}, Y={y}"""")\n    case _:\n        raise ValueError(""Not a point"")\nMatching on type constructors:\n\nmatch point:\n    case Point(x=0, y=0):\n        print(""Origin is the point\'s location."")\n    case Point(x=0, y=y):\n        print(f""Y={y} and the point is on the y-axis."")\n    case Point(x=x, y=0):\n        print(f""X={x} and the point is on the x-axis."")\n    case Point():\n        print(""The point is located somewhere else on the plane."")\n    case _:\n        print(""Not a point"")\nThe match expression supports guards, similar to Gleam:\n\nmatch point:\n    case Point(x, y) if x == y:\n        print(f""The point is located on the diagonal Y=X at {x}."")\n    case Point(x, y):\n        print(f""Point is not on the diagonal."")\nGleam\nThe case operator is a top level construct in Gleam:\n\ncase some_number {\n  0 -> ""Zero""\n  1 -> ""One""\n  2 -> ""Two""\n  n -> ""Some other number"" // This matches anything\n}\nThe case operator especially coupled with destructuring to provide native pattern matching:\n\ncase xs {\n  [] -> ""This list is empty""\n  [a] -> ""This list has 1 element""\n  [a, b] -> ""This list has 2 elements""\n  _other -> ""This list has more than 2 elements""\n}\nThe case operator supports guards:\n\ncase xs {\n  [a, b, c] if a >. b && a <=. c -> ""ok""\n  _other -> ""ko""\n}\nand disjoint union matching:\n\ncase number {\n  2 | 4 | 6 | 8 -> ""This is an even number""\n  1 | 3 | 5 | 7 -> ""This is an odd number""\n  _ -> ""I\'m not sure""\n}\nTry\nError management is approached differently in Python and Gleam.\n\nPython\nPython uses the notion of exceptions to interrupt the current code flow and pop up the error to the caller.\n\nAn exception is raised using the keyword raise.\n\ndef a_function_that_fails():\n    raise Exception(""an error"")\nThe callee block will be able to capture any exception raised in the block using a try/except set of blocks:\n\ntry:\n    print(""executed"")\n    a_function_that_fails()\n    print(""not_executed"")\nexcept Exception as e:\n    print(""doing something with the exception"", e)\n\nGleam\nIn contrast in Gleam, errors are just containers with an associated value.\n\nA common container to model an operation result is Result(ReturnType, ErrorType).\n\nA Result is either:\n\nan Error(ErrorValue)\nor an Ok(Data) record\nHandling errors actually means to match the return value against those two scenarios, using a case for instance:\n\ncase int.parse(""123"") {\n  Error(e) -> io.println(""That wasn\'t an Int"")\n  Ok(i) -> io.println(""We parsed the Int"")\n}\nIn order to simplify this construct, we can use the use expression with the try function from the gleam/result module.\n\nbind a value to the providing name if Ok(Something) is matched\ninterrupt the flow and return Error(Something)\nlet a_number = ""1""\nlet an_error = ""ouch""\nlet another_number = ""3""\n\nuse int_a_number <- try(parse_int(a_number))\nuse attempt_int <- try(parse_int(an_error)) // Error will be returned\nuse int_another_number <- try(parse_int(another_number)) // never gets executed\n\nOk(int_a_number + attempt_int + int_another_number) // never gets executed\nType aliases\nType aliases allow for easy referencing of arbitrary complex types. Even though their type systems does not serve the same function, both Python and Gleam provide this feature.\n\nPython\nA simple variable can store the result of a compound set of types.\n\ntype Headers = list[tuple[str, str]]\n\n# can now be used to annotate a variable\nheaders: Headers = [(""Content-Type"", ""application/json"")]\nGleam\nThe type keyword can be used to create aliases:\n\npub type Headers =\n  List(#(String, String))\n\nlet headers: Headers = [#(""Content-Type"", ""application/json"")]\nCustom types\nRecords\nCustom type allows you to define a collection data type with a fixed number of named fields, and the values in those fields can be of differing types.\n\nPython\nPython uses classes to define user-defined, record-like types. Properties are defined as class members and initial values are generally set in the constructor.\n\nBy default the constructor does not provide base initializers in the constructor so some boilerplate is needed:\n\nclass Person:\n    name: str\n    age: int\n\n    def __init__(name: str, age: int) -> None:\n        self.name = name\n        self.age = age\n\nperson = Person(name=""Jake"", age=20)\n# or with positional arguments Person(""Jake"", 20)\nname = person.name\nMore recent alternatives are to use dataclasses or to leverage the NamedTuple base type to generate a constructor with initializers.\n\nBy default a class created with the dataclass decorator is mutable (although you can pass options to the dataclass decorator to change the behavior):\n\nfrom dataclasses import dataclasses\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\nperson = Person(name=""Jake"", age=20)\nname = person.name\nperson.name = ""John""  # The name is now ""John""\nNamedTuples on the other hand are immutable:\n\nfrom typing import NamedTuple\n\nclass Person(NamedTuple):\n    name: str\n    age: int\n\nperson = Person(name=""Jake"", age=20)\nname = person.name\n\n# cannot reassign a value\nperson.name = ""John""  # error\nGleam\nGleam’s custom types can be used in much the same way that structs are used in Elixir. At runtime, they have a tuple representation and are compatible with Erlang records.\n\ntype Person {\n  Person(name: String, age: Int)\n}\n\nlet person = Person(name: ""Jake"", age: 35)\nlet name = person.name\nAn important difference to note is there is no OOP in Gleam. Methods can not be added to types.\n\nUnions\nIn Python unions can be declared with the | operator.\n\nIn Gleam functions must always take and receive one type. To have a union of two different types they must be wrapped in a new custom type.\n\nPython\ndef int_or_float(x: int | float) -> str:\n    if isinstance(x, int):\n        return f""It\'s an integer: {x}""\n    else:\n        return f""It\'s a float: {x}""\nGleam\ntype IntOrFloat {\n  AnInt(Int)\n  AFloat(Float)\n}\n\nfn int_or_float(x) {\n  case x {\n    AnInt(1) -> ""It\'s an integer: 1""\n    AFloat(1.0) -> ""It\'s a float: 1.0""\n  }\n}\nOpaque custom types\nIn Python, constructors cannot be marked as private. Opaque types can be imperfectly emulated using a class method and some magic property that only updates via the class factory method.\n\nIn Gleam, custom types can be defined as being opaque, which causes the constructors for the custom type not to be exported from the module. Without any constructors to import other modules can only interact with opaque types using the intended API.\n\nPython\nclass OnlyCreatable:\n\n    __create_key = object()\n\n    @classmethod\n    def create(cls, value):\n        return OnlyCreatable(cls.__create_key, value)\n\n    def __init__(self, create_key, value):\n        assert(create_key == OnlyCreatable.__create_key), \\\n            ""OnlyCreatable objects must be created using OnlyCreatable.create""\n        self.value = value\nGleam\npub opaque type Identifier {\n  Identifier(Int)\n}\n\npub fn get_id() {\n  Identifier(100)\n}\nModules\nPython\nThere is no special syntax to define modules as files are modules in Python\n\nGleam\nGleam’s file is a module and named by the file name (and its directory path). Since there is no special syntax to create a module, there can be only one module in a file.\n\n// in file foo.gleam\npub fn identity(x) {\n  x\n}\n// in file main.gleam\nimport foo // if foo was in a folder called `lib` the import would be `lib/foo`\npub fn main() {\n  foo.identity(1)\n}\nImports\nPython\n# inside module src/nasa/moon_base.py\n# imports module src/nasa/rocket_ship.py\nfrom nasa import rocket_ship\n\ndef explore_space():\n    rocket_ship.launch()\nGleam\nImports are relative to the root src folder.\n\nModules in the same directory will need to reference the entire path from src for the target module, even if the target module is in the same folder.\n\n// inside module src/nasa/moon_base.gleam\n// imports module src/nasa/rocket_ship.gleam\nimport nasa/rocket_ship\n\npub fn explore_space() {\n  rocket_ship.launch()\n}\nNamed imports\nPython\nimport unix.cat as kitty\nGleam\nimport unix/cat as kitty\nUnqualified imports\nPython\nfrom animal.cat import Cat, stroke\n\ndef main():\n    kitty = Cat(name=""Nubi"")\n    stroke(kitty)\nGleam\nimport animal/cat.{Cat, stroke}\n\npub fn main() {\n  let kitty = Cat(name: ""Nubi"")\n  stroke(kitty)\n}'
 ""Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning\n2023-01-30 by Tim Dettmers 1,664 Comments\n\nDeep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience. But what features are important if you want to buy a new GPU? GPU RAM, cores, tensor cores, caches? How to make a cost-efficient choice? This blog post will delve into these questions, tackle common misconceptions, give you an intuitive understanding of how to think about GPUs, and will lend you advice, which will help you to make a choice that is right for you.\n\nThis blog post is designed to give you different levels of understanding of GPUs and the new Ampere series GPUs from NVIDIA. You have the choice: (1) If you are not interested in the details of how GPUs work, what makes a GPU fast compared to a CPU, and what is unique about the new NVIDIA RTX 40 Ampere series, you can skip right to the performance and performance per dollar charts and the recommendation section. The cost/performance numbers form the core of the blog post and the content surrounding it explains the details of what makes up GPU performance.\n\n(2) If you worry about specific questions, I have answered and addressed the most common questions and misconceptions in the later part of the blog post.\n\n(3) If you want to get an in-depth understanding of how GPUs, caches, and Tensor Cores work, the best is to read the blog post from start to finish. You might want to skip a section or two based on your understanding of the presented topics.\n\nContents  hide\nOverview\nHow do GPUs work?\nThe Most Important GPU Specs for Deep Learning Processing Speed\nTensor Cores\nMatrix multiplication without Tensor Cores\nMatrix multiplication with Tensor Cores\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nMemory Bandwidth\nL2 Cache / Shared Memory / L1 Cache / Registers\nEstimating Ada / Hopper Deep Learning Performance\nPractical Ada / Hopper Speed Estimates\nPossible Biases in Estimates\nAdvantages and Problems for RTX40 and RTX 30 Series\nSparse Network Training\nLow-precision Computation\nFan Designs and GPUs Temperature Issues\n3-slot Design and Power Issues\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\n8-bit Float Support in H100 and RTX 40 series GPUs\nRaw Performance Ranking of GPUs\nGPU Deep Learning Performance per Dollar\nGPU Recommendations\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nDo I need 8x/16x PCIe lanes?\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nCan I use multiple GPUs of different GPU types?\nWhat is NVLink, and is it useful?\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nWhat do I need to parallelize across two machines?\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nDo I need an Intel CPU to power a multi-GPU setup?\nDoes computer case design matter for cooling?\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nVersion History\nAcknowledgments\nRelated\nRelated Posts\nOverview\nThis blog post is structured in the following way. First, I will explain what makes a GPU fast. I will discuss CPUs vs GPUs, Tensor Cores, memory bandwidth, and the memory hierarchy of GPUs and how these relate to deep learning performance. These explanations might help you get a more intuitive sense of what to look for in a GPU. I discuss the unique features of the new NVIDIA RTX 40 Ampere GPU series that are worth considering if you buy a GPU. From there, I make GPU recommendations for different scenarios. After that follows a Q&A section of common questions posed to me in Twitter threads; in that section, I will also address common misconceptions and some miscellaneous issues, such as cloud vs desktop, cooling, AMD vs NVIDIA, and others.\n\nHow do GPUs work?\nIf you use GPUs frequently, it is useful to understand how they work. This knowledge will help you to undstand cases where are GPUs fast or slow. In turn, you might be able to understand better why you need a GPU in the first place and how other future hardware options might be able to compete. You can skip this section if you just want the useful performance numbers and arguments to help you decide which GPU to buy. The best high-level explanation for the question of how GPUs work is my following Quora answer:\n\nRead Tim Dettmers‘ answer to Why are GPUs well-suited to deep learning? on Quora\nThis is a high-level explanation that explains quite well why GPUs are better than CPUs for deep learning. If we look at the details, we can understand what makes one GPU better than another.\n\nThe Most Important GPU Specs for Deep Learning Processing Speed\nThis section can help you build a more intuitive understanding of how to think about deep learning performance. This understanding will help you to evaluate future GPUs by yourself. This section is sorted by the importance of each component. Tensor Cores are most important, followed by memory bandwidth of a GPU, the cache hierachy, and only then FLOPS of a GPU.\n\nTensor Cores\nTensor Cores are tiny cores that perform very efficient matrix multiplication. Since the most expensive part of any deep neural network is matrix multiplication Tensor Cores are very useful. In fast, they are so powerful, that I do not recommend any GPUs that do not have Tensor Cores.\n\nIt is helpful to understand how they work to appreciate the importance of these computational units specialized for matrix multiplication. Here I will show you a simple example of A*B=C matrix multiplication, where all matrices have a size of 32×32, what a computational pattern looks like with and without Tensor Cores. This is a simplified example, and not the exact way how a high performing matrix multiplication kernel would be written, but it has all the basics. A CUDA programmer would take this as a first “draft” and then optimize it step-by-step with concepts like double buffering, register optimization, occupancy optimization, instruction-level parallelism, and many others, which I will not discuss at this point.\n\nTo understand this example fully, you have to understand the concepts of cycles. If a processor runs at 1GHz, it can do 10^9 cycles per second. Each cycle represents an opportunity for computation. However, most of the time, operations take longer than one cycle. Thus we essentially have a queue where the next operations needs to wait for the next operation to finish. This is also called the latency of the operation.\n\nHere are some important latency cycle timings for operations. These times can change from GPU generation to GPU generation. These numbers are for Ampere GPUs, which have relatively slow caches.\n\nGlobal memory access (up to 80GB): ~380 cycles\nL2 cache: ~200 cycles\nL1 cache or Shared memory access (up to 128 kb per Streaming Multiprocessor): ~34 cycles\nFused multiplication and addition, a*b+c (FFMA): 4 cycles\nTensor Core matrix multiply: 1 cycle\nEach operation is always performed by a pack of 32 threads. This pack is termed a warp of threads. Warps usually operate in a synchronous pattern — threads within a warp have to wait for each other. All memory operations on the GPU are optimized for warps. For example, loading from global memory happens at a granularity of 32*4 bytes, exactly 32 floats, exactly one float for each thread in a warp. We can have up to 32 warps = 1024 threads in a streaming multiprocessor (SM), the GPU-equivalent of a CPU core. The resources of an SM are divided up among all active warps. This means that sometimes we want to run fewer warps to have more registers/shared memory/Tensor Core resources per warp.\n\nFor both of the following examples, we assume we have the same computational resources. For this small example of a 32×32 matrix multiply, we use 8 SMs (about 10% of an RTX 3090) and 8 warps per SM.\n\nTo understand how the cycle latencies play together with resources like threads per SM and shared memory per SM, we now look at examples of matrix multiplication. While the following example roughly follows the sequence of computational steps of matrix multiplication for both with and without Tensor Cores, please note that these are very simplified examples. Real cases of matrix multiplication involve much larger shared memory tiles and slightly different computational patterns.\n\nMatrix multiplication without Tensor Cores\nIf we want to do an A*B=C matrix multiply, where each matrix is of size 32×32, then we want to load memory that we repeatedly access into shared memory because its latency is about five times lower (200 cycles vs 34 cycles). A memory block in shared memory is often referred to as a memory tile or just a tile. Loading two 32×32 floats into a shared memory tile can happen in parallel by using 2*32 warps. We have 8 SMs with 8 warps each, so due to parallelization, we only need to do a single sequential load from global to shared memory, which takes 200 cycles.\n\nTo do the matrix multiplication, we now need to load a vector of 32 numbers from shared memory A and shared memory B and perform a fused multiply-and-accumulate (FFMA). Then store the outputs in registers C. We divide the work so that each SM does 8x dot products (32×32) to compute 8 outputs of C. Why this is exactly 8 (4 in older algorithms) is very technical. I recommend Scott Gray’s blog post on matrix multiplication to understand this. This means we have 8x shared memory accesses at the cost of 34 cycles each and 8 FFMA operations (32 in parallel), which cost 4 cycles each. In total, we thus have a cost of:\n\n200 cycles (global memory) + 8*34 cycles (shared memory) + 8*4 cycles (FFMA) = 504 cycles\n\nLet’s look at the cycle cost of using Tensor Cores.\n\nMatrix multiplication with Tensor Cores\nWith Tensor Cores, we can perform a 4×4 matrix multiplication in one cycle. To do that, we first need to get memory into the Tensor Core. Similarly to the above, we need to read from global memory (200 cycles) and store in shared memory. To do a 32×32 matrix multiply, we need to do 8×8=64 Tensor Cores operations. A single SM has 8 Tensor Cores. So with 8 SMs, we have 64 Tensor Cores — just the number that we need! We can transfer the data from shared memory to the Tensor Cores with 1 memory transfers (34 cycles) and then do those 64 parallel Tensor Core operations (1 cycle). This means the total cost for Tensor Cores matrix multiplication, in this case, is:\n\n200 cycles (global memory) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 235 cycles.\n\nThus we reduce the matrix multiplication cost significantly from 504 cycles to 235 cycles via Tensor Cores. In this simplified case, the Tensor Cores reduced the cost of both shared memory access and FFMA operations.\n\nThis example is simplified, for example, usually each thread needs to calculate which memory to read and write to as you transfer data from global memory to shared memory. With the new Hooper (H100) architectures we additionally have the Tensor Memory Accelerator (TMA) compute these indices in hardware and thus help each thread to focus on more computation rather than computing indices.\n\nMatrix multiplication with Tensor Cores and Asynchronous copies (RTX 30/RTX 40) and TMA (H100)\nThe RTX 30 Ampere and RTX 40 Ada series GPUs additionally have support to perform asynchronous transfers between global and shared memory. The H100 Hopper GPU extends this further by introducing the Tensor Memory Accelerator (TMA) unit. the TMA unit combines asynchronous copies and index calculation for read and writes simultaneously — so each thread no longer needs to calculate which is the next element to read and each thread can focus on doing more matrix multiplication calculations. This looks as follows.\n\nThe TMA unit fetches memory from global to shared memory (200 cycles). Once the data arrives, the TMA unit fetches the next block of data asynchronously from global memory. While this is happening, the threads load data from shared memory and perform the matrix multiplication via the tensor core. Once the threads are finished they wait for the TMA unit to finish the next data transfer, and the sequence repeats.\n\nAs such, due to the asynchronous nature, the second global memory read by the TMA unit is already progressing as the threads process the current shared memory tile. This means, the second read takes only 200 – 34 – 1 = 165 cycles.\n\nSince we do many reads, only the first memory access will be slow and all other memory accesses will be partially overlapped with the TMA unit. Thus on average, we reduce the time by 35 cycles.\n\n165 cycles (wait for async copy to finish) + 34 cycles (shared memory) + 1 cycle (Tensor Core) = 200 cycles.\n\nWhich accelerates the matrix multiplication by another 15%.\n\nFrom these examples, it becomes clear why the next attribute, memory bandwidth, is so crucial for Tensor-Core-equipped GPUs. Since global memory is the by far the largest cycle cost for matrix multiplication with Tensor Cores, we would even have faster GPUs if the global memory latency could be reduced. We can do this by either increasing the clock frequency of the memory (more cycles per second, but also more heat and higher energy requirements) or by increasing the number of elements that can be transferred at any one time (bus width).\n\nMemory Bandwidth\nFrom the previous section, we have seen that Tensor Cores are very fast. So fast, in fact, that they are idle most of the time as they are waiting for memory to arrive from global memory. For example, during GPT-3-sized training, which uses huge matrices — the larger, the better for Tensor Cores — we have a Tensor Core TFLOPS utilization of about 45-65%, meaning that even for the large neural networks about 50% of the time, Tensor Cores are idle.\n\nThis means that when comparing two GPUs with Tensor Cores, one of the single best indicators for each GPU’s performance is their memory bandwidth. For example, The A100 GPU has 1,555 GB/s memory bandwidth vs the 900 GB/s of the V100. As such, a basic estimate of speedup of an A100 vs V100 is 1555/900 = 1.73x.\n\nL2 Cache / Shared Memory / L1 Cache / Registers\nSince memory transfers to the Tensor Cores are the limiting factor in performance, we are looking for other GPU attributes that enable faster memory transfer to Tensor Cores. L2 cache, shared memory, L1 cache, and amount of registers used are all related. To understand how a memory hierarchy enables faster memory transfers, it helps to understand how matrix multiplication is performed on a GPU.\n\nTo perform matrix multiplication, we exploit the memory hierarchy of a GPU that goes from slow global memory, to faster L2 memory, to fast local shared memory, to lightning-fast registers. However, the faster the memory, the smaller it is.\n\nWhile logically, L2 and L1 memory are the same, L2 cache is larger and thus the average physical distance that need to be traversed to retrieve a cache line is larger. You can see the L1 and L2 caches as organized warehouses where you want to retrieve an item. You know where the item is, but to go there takes on average much longer for the larger warehouse. This is the essential difference between L1 and L2 caches. Large = slow, small = fast.\n\nFor matrix multiplication we can use this hierarchical separate into smaller and smaller and thus faster and faster chunks of memory to perform very fast matrix multiplications. For that, we need to chunk the big matrix multiplication into smaller sub-matrix multiplications. These chunks are called memory tiles, or often for short just tiles.\n\nWe perform matrix multiplication across these smaller tiles in local shared memory that is fast and close to the streaming multiprocessor (SM) — the equivalent of a CPU core. With Tensor Cores, we go a step further: We take each tile and load a part of these tiles into Tensor Cores which is directly addressed by registers. A matrix memory tile in L2 cache is 3-5x faster than global GPU memory (GPU RAM), shared memory is ~7-10x faster than the global GPU memory, whereas the Tensor Cores’ registers are ~200x faster than the global GPU memory.\n\nHaving larger tiles means we can reuse more memory. I wrote about this in detail in my TPU vs GPU blog post. In fact, you can see TPUs as having very, very, large tiles for each Tensor Core. As such, TPUs can reuse much more memory with each transfer from global memory, which makes them a little bit more efficient at matrix multiplications than GPUs.\n\nEach tile size is determined by how much memory we have per streaming multiprocessor (SM) and how much we L2 cache we have across all SMs. We have the following shared memory sizes on the following architectures:\n\nVolta (Titan V): 128kb shared memory / 6 MB L2\nTuring (RTX 20s series): 96 kb shared memory / 5.5 MB L2\nAmpere (RTX 30s series): 128 kb shared memory / 6 MB L2\nAda (RTX 40s series): 128 kb shared memory / 72 MB L2\nWe see that Ada has a much larger L2 cache allowing for larger tile sizes, which reduces global memory access. For example, for BERT large during training, the input and weight matrix of any matrix multiplication fit neatly into the L2 cache of Ada (but not other Us). As such, data needs to be loaded from global memory only once and then data is available throught the L2 cache, making matrix multiplication about 1.5 – 2.0x faster for this architecture for Ada. For larger models the speedups are lower during training but certain sweetspots exist which may make certain models much faster. Inference, with a batch size larger than 8 can also benefit immensely from the larger L2 caches.\n\nEstimating Ada / Hopper Deep Learning Performance\nThis section is for those who want to understand the more technical details of how I derive the performance estimates for Ampere GPUs. If you do not care about these technical aspects, it is safe to skip this section.\n\nPractical Ada / Hopper Speed Estimates\nSuppose we have an estimate for one GPU of a GPU-architecture like Hopper, Ada, Ampere, Turing, or Volta. It is easy to extrapolate these results to other GPUs from the same architecture/series. Luckily, NVIDIA already benchmarked the A100 vs V100 vs H100 across a wide range of computer vision and natural language understanding tasks. Unfortunately, NVIDIA made sure that these numbers are not directly comparable by using different batch sizes and the number of GPUs whenever possible to favor results for the H100 GPU. So in a sense, the benchmark numbers are partially honest, partially marketing numbers. In general, you could argue that using larger batch sizes is fair, as the H100/A100 GPU has more memory. Still, to compare GPU architectures, we should evaluate unbiased memory performance with the same batch size.\n\nTo get an unbiased estimate, we can scale the data center GPU results in two ways: (1) account for the differences in batch size, (2) account for the differences in using 1 vs 8 GPUs. We are lucky that we can find such an estimate for both biases in the data that NVIDIA provides.\n\nDoubling the batch size increases throughput in terms of images/s (CNNs) by 13.6%. I benchmarked the same problem for transformers on my RTX Titan and found, surprisingly, the very same result: 13.5% — it appears that this is a robust estimate.\n\nAs we parallelize networks across more and more GPUs, we lose performance due to some networking overhead. The A100 8x GPU system has better networking (NVLink 3.0) than the V100 8x GPU system (NVLink 2.0) — this is another confounding factor. Looking directly at the data from NVIDIA, we can find that for CNNs, a system with 8x A100 has a 5% lower overhead than a system of 8x V100. This means if going from 1x A100 to 8x A100 gives you a speedup of, say, 7.00x, then going from 1x V100 to 8x V100 only gives you a speedup of 6.67x.  For transformers, the figure is 7%.\n\nUsing these figures, we can estimate the speedup for a few specific deep learning architectures from the direct data that NVIDIA provides. The Tesla A100 offers the following speedup over the Tesla V100:\n\nSE-ResNeXt101: 1.43x\nMasked-R-CNN: 1.47x\nTransformer (12 layer, Machine Translation, WMT14 en-de): 1.70x\nThus, the figures are a bit lower than the theoretical estimate for computer vision. This might be due to smaller tensor dimensions, overhead from operations that are needed to prepare the matrix multiplication like img2col or Fast Fourier Transform (FFT), or operations that cannot saturate the GPU (final layers are often relatively small). It could also be artifacts of the specific architectures (grouped convolution).\n\nThe practical transformer estimate is very close to the theoretical estimate. This is probably because algorithms for huge matrices are very straightforward. I will use these practical estimates to calculate the cost efficiency of GPUs.\n\nPossible Biases in Estimates\nThe estimates above are for H100, A100 , and V100 GPUs. In the past, NVIDIA sneaked unannounced performance degradations into the “gaming” RTX GPUs: (1) Decreased Tensor Core utilization, (2) gaming fans for cooling, (3) disabled peer-to-peer GPU transfers. It might be possible that there are unannounced performance degradations in the RTX 40 series compared to the full Hopper H100.\n\nAs of now, one of these degradations was found for Ampere GPUs: Tensor Core performance was decreased so that RTX 30 series GPUs are not as good as Quadro cards for deep learning purposes. This was also done for the RTX 20 series, so it is nothing new, but this time it was also done for the Titan equivalent card, the RTX 3090. The RTX Titan did not have performance degradation enabled.\n\nCurrently, no degradation for Ada GPUs are known, but I update this post with news on this and let my followers on twitter know.\n\nAdvantages and Problems for RTX40 and RTX 30 Series\nThe new NVIDIA Ampere RTX 30 series has additional benefits over the NVIDIA Turing RTX 20 series, such as sparse network training and inference. Other features, such as the new data types, should be seen more as an ease-of-use-feature as they provide the same performance boost as Turing does but without any extra programming required.\n\nThe Ada RTX 40 series has even further advances like 8-bit Float (FP8) tensor cores. The RTX 40 series also has similar power and temperature issues compared to the RTX 30. The issue of melting power connector cables in the RTX 40 can be easily prevented by connecting the power cable correctly.\n\nSparse Network Training\nAmpere allows for fine-grained structure automatic sparse matrix multiplication at dense speeds. How does this work? Take a weight matrix and slice it into pieces of 4 elements. Now imagine 2 elements of these 4 to be zero. Figure 1 shows how this could look like.\n\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool's GTC 2020 presentation on  Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nFigure 1: Structure supported by the sparse matrix multiplication feature in Ampere GPUs. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nWhen you multiply this sparse weight matrix with some dense inputs, the sparse matrix tensor core feature in Ampere automatically compresses the sparse matrix to a dense representation that is half the size as can be seen in Figure 2. After this compression, the densely compressed matrix tile is fed into the tensor core which computes a matrix multiplication of twice the usual size. This effectively yields a 2x speedup since the bandwidth requirements during matrix multiplication from shared memory are halved.\n\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed.\nFigure 2: The sparse matrix is compressed to a dense representation before the matrix multiplication is performed. The figure is taken from Jeff Pool’s GTC 2020 presentation on Accelerating Sparsity in the NVIDIA Ampere Architecture by the courtesy of NVIDIA.\nI was working on sparse network training in my research and I also wrote a blog post about sparse training. One criticism of my work was that “You reduce the FLOPS required for the network, but it does not yield speedups because GPUs cannot do fast sparse matrix multiplication.” Well, with the addition of the sparse matrix multiplication feature for Tensor Cores, my algorithm, or other sparse training algorithms, now actually provide speedups of up to 2x during training.\n\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nFigure 3: The sparse training algorithm that I developed has three stages: (1) Determine the importance of each layer. (2) Remove the smallest, unimportant weights. (3) Grow new weights proportional to the importance of each layer. Read more about my work in my sparse training blog post.\nWhile this feature is still experimental and training sparse networks are not commonplace yet, having this feature on your GPU means you are ready for the future of sparse training.\n\nLow-precision Computation\nIn my work, I’ve previously shown that new data types can improve stability during low-precision backpropagation.\n\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nFigure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range [0, 0.9] while all previous bits are used for the exponent. This allows to dynamically represent numbers that are both large and small with high precision.\nCurrently, if you want to have stable backpropagation with 16-bit floating-point numbers (FP16), the big problem is that ordinary FP16 data types only support numbers in the range [-65,504, 65,504]. If your gradient slips past this range, your gradients explode into NaN values. To prevent this during FP16 training, we usually perform loss scaling where you multiply the loss by a small number before backpropagating to prevent this gradient explosion.\n\nThe BrainFloat 16 format (BF16) uses more bits for the exponent such that the range of possible numbers is the same as for FP32: [-3*10^38, 3*10^38]. BF16 has less precision, that is significant digits, but gradient precision is not that important for learning. So what BF16 does is that you no longer need to do any loss scaling or worry about the gradient blowing up quickly. As such, we should see an increase in training stability by using the BF16 format as a slight loss of precision.\n\nWhat this means for you: With BF16 precision, training might be more stable than with FP16 precision while providing the same speedups. With 32-bit TensorFloat (TF32) precision, you get near FP32 stability while giving the speedups close to FP16. The good thing is, to use these data types, you can just replace FP32 with TF32 and FP16 with BF16 — no code changes required!\n\nOverall, though, these new data types can be seen as lazy data types in the sense that you could have gotten all the benefits with the old data types with some additional programming efforts (proper loss scaling, initialization, normalization, using Apex). As such, these data types do not provide speedups but rather improve ease of use of low precision for training.\n\nFan Designs and GPUs Temperature Issues\nWhile the new fan design of the RTX 30 series performs very well to cool the GPU, different fan designs of non-founders edition GPUs might be more problematic. If your GPU heats up beyond 80C, it will throttle itself and slow down its computational speed / power. This overheating can happen in particular if you stack multiple GPUs next to each other. A solution to this is to use PCIe extenders to create space between GPUs.\n\nSpreading GPUs with PCIe extenders is very effective for cooling, and other fellow PhD students at the University of Washington and I use this setup with great success. It does not look pretty, but it keeps your GPUs cool! This has been running with no problems at all for 4 years now. It can also help if you do not have enough space to fit all GPUs in the PCIe slots. For example, if you can find the space within a desktop computer case, it might be possible to buy standard 3-slot-width RTX 4090 and spread them with PCIe extenders within the case. With this, you might solve both the space issue and cooling issue for a 4x RTX 4090 setup with a single simple solution.\n\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 2 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\nFigure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 4 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs.\n3-slot Design and Power Issues\nThe RTX 3090 and RTX 4090 are 3-slot GPUs, so one will not be able to use it in a 4x setup with the default fan design from NVIDIA. This is kind of justified because it runs at over 350W TDP, and it will be difficult to cool in a multi-GPU 2-slot setting. The RTX 3080 is only slightly better at 320W TDP, and cooling a 4x RTX 3080 setup will also be very difficult.\n\nIt is also difficult to power a 4x 350W = 1400W or 4x 450W = 1800W system in the 4x RTX 3090 or 4x RTX 4090 case. Power supply units (PSUs) of 1600W are readily available, but having only 200W to power the CPU and motherboard can be too tight. The components’ maximum power is only used if the components are fully utilized, and in deep learning, the CPU is usually only under weak load. With that, a 1600W PSU might work quite well with a 4x RTX 3080 build, but for a 4x RTX 3090 build, it is better to look for high wattage PSUs (+1700W). Some of my followers have had great success with cryptomining PSUs — have a look in the comment section for more info about that. Otherwise, it is important to note that not all outlets support PSUs above 1600W, especially in the US. This is the reason why in the US, there are currently few standard desktop PSUs above 1600W on the market. If you get a server or cryptomining PSUs, beware of the form factor — make sure it fits into your computer case.\n\nPower Limiting: An Elegant Solution to Solve the Power Problem?\nIt is possible to set a power limit on your GPUs. So you would be able to programmatically set the power limit of an RTX 3090 to 300W instead of their standard 350W. In a 4x GPU system, that is a saving of 200W, which might just be enough to build a 4x RTX 3090 system with a 1600W PSU feasible. It also helps to keep the GPUs cool. So setting a power limit can solve the two major problems of a 4x RTX 3080 or 4x RTX 3090 setups, cooling, and power, at the same time. For a 4x setup, you still need effective blower GPUs (and the standard design may prove adequate for this), but this resolves the PSU problem.\n\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nFigure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent.\nYou might ask, “Doesn’t this slow down the GPU?” Yes, it does, but the question is by how much. I benchmarked the 4x RTX 2080 Ti system shown in Figure 5 under different power limits to test this. I benchmarked the time for 500 mini-batches for BERT Large during inference (excluding the softmax layer). I choose BERT Large inference since, from my experience, this is the deep learning model that stresses the GPU the most. As such, I would expect power limiting to have the most massive slowdown for this model. As such, the slowdowns reported here are probably close to the maximum slowdowns that you can expect. The results are shown in Figure 7.\n\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nFigure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference (excluding softmax layer).\nAs we can see, setting the power limit does not seriously affect performance. Limiting the power by 50W — more than enough to handle 4x RTX 3090 — decreases performance by only 7%.\n\nRTX 4090s and Melting Power Connectors: How to Prevent Problems\nThere was a misconception that RTX 4090 power cables melt because they were bent. However, it was found that only 0.1% of users had this problem and the problem occured due to user error. Here a video that shows that the main problem is that cables were not inserted correctly.\n\nSo using RTX 4090 cards is perfectly safe if you follow the following install instructions:\n\nIf you use an old cable or old GPU make sure the contacts are free of debri / dust.\nUse the power connector and stick it into the socket until you hear a *click* — this is the most important part.\nTest for good fit by wiggling the power cable left to right. The cable should not move.\nCheck the contact with the socket visually, there should be no gap between cable and socket.\n8-bit Float Support in H100 and RTX 40 series GPUs\nThe support of the 8-bit Float (FP8) is a huge advantage for the RTX 40 series and H100 GPUs. With 8-bit inputs it allows you to load the data for matrix multiplication twice as fast, you can store twice as much matrix elements in your caches which in the Ada and Hopper architecture are very large, and now with FP8 tensor cores you get 0.66 PFLOPS of compute for a RTX 4090 — this is more FLOPS then the entirety of the worlds fastest supercomputer in year 2007. 4x RTX 4090 with FP8 compute rival the faster supercomputer in the world in year 2010 (deep learning started to work just in 2009).\n\nThe main problem with using 8-bit precision is that transformers can get very unstable with so few bits and crash during training or generate non-sense during inference. I have written a paper about the emergence of instabilities in large language models and I also written a more accessible blog post.\n\nThe main take-way is this: Using 8-bit instead of 16-bit makes things very unstable, but if you keep a couple of dimensions in high precision everything works just fine.\n\n\nMain results from my work on 8-bit matrix multiplication for Large Language Models (LLMs). We can see that the best 8-bit baseline fails to deliver good zero-shot performance. The method that I developed, LLM.int8(), can perform Int8 matrix multiplication with the same results as the 16-bit baseline.\nBut Int8 was already supported by the RTX 30 / A100 / Ampere generation GPUs, why is FP8 in the RTX 40 another big upgrade? The FP8 data type is much more stable than the Int8 data type and its easy to use it in functions like layer norm or non-linear functions, which are difficult to do with Integer data types. This will make it very straightforward to use it in training and inference. I think this will make FP8 training and inference relatively common in a couple of months.\n\nIf you want to read more about the advantages of Float vs Integer data types you can read my recent paper about k-bit inference scaling laws. Below you can see one relevant main result for Float vs Integer data types from this paper. We can see that bit-by-bit, the FP4 data type preserve more information than Int4 data type and thus improves the mean LLM zeroshot accuracy across 4 tasks.\n\n\n4-bit Inference scaling laws for Pythia Large Language Models for different data types. We see that bit-by-bit, 4-bit float data types have better zeroshot accuracy compared to the Int4 data types.\nRaw Performance Ranking of GPUs\nBelow we see a chart of raw relevative performance across all GPUs. We see that there is a gigantic gap in 8-bit performance of H100 GPUs and old cards that are optimized for 16-bit performance.\n\n\nShown is raw relative transformer performance of GPUs. For example, an RTX 4090 has about 0.33x performance of a H100 SMX for 8-bit inference. In other words, a H100 SMX is three times faster for 8-bit inference compared to a RTX 4090.\nFor this data, I did not model 8-bit compute for older GPUs. I did so, because 8-bit Inference and training are much more effective on Ada/Hopper GPUs because of the 8-bit Float data type and Tensor Memory Accelerator (TMA) which saves the overhead of computing read/write indices which is particularly helpful for 8-bit matrix multiplication. Ada/Hopper also have FP8 support, which makes in particular 8-bit training much more effective.\n\nI did not model numbers for 8-bit training because to model that I need to know the latency of L1 and L2 caches on Hopper/Ada GPUs, and they are unknown and I do not have access to such GPUs. On Hopper/Ada, 8-bit training performance can well be 3-4x of 16-bit training performance if the caches are as fast as rumored.\n\nBut even with the new FP8 tensor cores there are some additional issues which are difficult to take into account when modeling GPU performance. For example, FP8 tensor cores do not support transposed matrix multiplication which means backpropagation needs either a separate transpose before multiplication or one needs to hold two sets of weights — one transposed and one non-transposed — in memory. I used two sets of weight when I experimented with Int8 training in my LLM.int8() project and this reduced the overall speedups quite significantly. I think one can do better with the right algorithms/software, but this shows that missing features like a transposed matrix multiplication for tensor cores can affect performance.\n\nFor old GPUs, Int8 inference performance is close to the 16-bit inference performance for models below 13B parameters. Int8 performance on old GPUs is only relevant if you have relatively large models with 175B parameters or more. If you are interested in 8-bit performance of older GPUs, you can read the Appendix D of my LLM.int8() paper where I benchmark Int8 performance.\n\nGPU Deep Learning Performance per Dollar\nBelow we see the chart for the performance per US dollar for all GPUs sorted by 8-bit inference performance. How to use the chart to find a suitable GPU for you is as follows:\n\nDetermine the amount of GPU memory that you need (rough heuristic: at least 12 GB for image generation; at least 24 GB for work with transformers)\nWhile 8-bit inference and training is experimental, it will become standard within 6 months. You might need to do some extra difficult coding to work with 8-bit in the meantime. Is that OK for you? If not, select for 16-bit performance.\nUsing the metric determined in (2), find the GPU with the highest relative performance/dollar that has the amount of memory you need.\nWe can see that the RTX 4070 Ti is most cost-effective for 8-bit and 16-bit inference while the RTX 3080 remains most cost-effective for 16-bit training. While these GPUs are most cost-effective, they are not necessarily recommended as they do not have sufficient memory for many use-cases. However, it might be the ideal cards to get started on your deep learning journey. Some of these GPUs are excellent for Kaggle competition where one can often rely on smaller models. Since to do well in Kaggle competitions the method of how you work is more important than the models size, many of these smaller GPUs are excellent for Kaggle competitions.\n\nThe best GPUs for academic and startup servers seem to be A6000 Ada GPUs (not to be confused with A6000 Turing). The H100 SXM GPU is also very cost effective and has high memory and very strong performance. If I would build a small cluster for a company/academic lab, I would use 66-80% A6000 GPUs and 20-33% H100 SXM GPUs. If I get a good deal on L40 GPUs, I would also pick them instead of A6000, so you can always ask for a quote on these.\n\n\nShown is relative performance per US Dollar of GPUs normalized by the cost for a desktop computer and the average Amazon and eBay price for each GPU. Additionally, the electricity cost of ownership for 5 years is added with an electricity price of 0.175 USD per kWh and a 15% GPU utilization rate. The electricity cost for a RTX 4090 is about $100 per year. How to read and interpret the chart: a desktop computer with RTX 4070 Ti cards owned for 5 years yields about 2x more 8-bit inference performance per dollar compared to a RTX 3090 GPU.\nGPU Recommendations\nI have a create a recommendation flow-chart that you can see below (click here for interactive app from Nan Xiao). While this chart will help you in 80% of cases, it might not quite work for you because the options might be too expensive. In that case, try to look at the benchmarks above and pick the most cost effective GPU that still has enough GPU memory for your use-case. You can estimate the GPU memory needed by running your problem in the vast.ai or Lambda Cloud for a while so you know what you need. The vast.ai or Lambda Cloud might also work well if you only need a GPU very sporadically (every couple of days for a few hours) and you do not need to download and process large dataset to get started. However, cloud GPUs are usually not a good option if you use your GPU for many months with a high usage rate each day (12 hours each day). You can use the example in the “When is it better to use the cloud vs a dedicated GPU desktop/server?” section below to determine if cloud GPUs are good for you.\n\n\nGPU recommendation chart for Ada/Hopper GPUs. Follow the answers to the Yes/No questions to find the GPU that is most suitable for you. While this chart works well in about 80% of cases, you might end up with a GPU that is too expensive. Use the cost/performance charts above to make a selection instead. [interactive app]\nIs it better to wait for future GPUs for an upgrade? The future of GPUs.\nTo understand if it makes sense to skip this generation and buy the next generation of GPUs, it makes sense to talk a bit about what improvements in the future will look like.\n\nIn the past it was possible to shrink the size of transistors to improve speed of a processor. This is coming to an end now. For example, while shrinking SRAM increased its speed (smaller distance, faster memory access), this is no longer the case. Current improvements in SRAM do not improve its performance anymore and might even be negative. While logic such as Tensor Cores get smaller, this does not necessarily make GPU faster since the main problem for matrix multiplication is to get memory to the tensor cores which is dictated by SRAM and GPU RAM speed and size. GPU RAM still increases in speed if we stack memory modules into high-bandwidth modules (HBM3+), but these are too expensive to manufacture for consumer applications. The main way to improve raw speed of GPUs is to use more power and more cooling as we have seen in the RTX 30s and 40s series. But this cannot go on for much longer.\n\nChiplets such as used by AMD CPUs are another straightforward way forward. AMD beat Intel by developing CPU chiplets. Chiplets are small chips that are fused together with a high speed on-chip network. You can think about them as two GPUs that are so physically close together that you can almost consider them a single big GPU. They are cheaper to manufacture, but more difficult to combine into one big chip. So you need know-how and fast connectivity between chiplets. AMD has a lot of experience with chiplet design. AMD’s next generation GPUs are going to be chiplet designs, while NVIDIA currently has no public plans for such designs. This may mean that the next generation of AMD GPUs might be better in terms of cost/performance compared to NVIDIA GPUs.\n\nHowever, the main performance boost for GPUs is currently specialized logic. For example, the asynchronous copy hardware units on the Ampere generation (RTX 30 / A100 / RTX 40) or the extension, the Tensor Memory Accelerator (TMA), both reduce the overhead of copying memory from the slow global memory to fast shared memory (caches) through specialized hardware and so each thread can do more computation. The TMA also reduces overhead by performing automatic calculations of read/write indices which is particularly important for 8-bit computation where one has double the elements for the same amount of memory compared to 16-bit computation. So specialized hardware logic can accelerate matrix multiplication further.\nLow-bit precision is another straightforward way forward for a couple of years. We will see widespread adoption of 8-bit inference and training in the next months. We will see widespread 4-bit inference in the next year. Currently, the technology for 4-bit training does not exists, but research looks promising and I expect the first high performance FP4 Large Language Model (LLM) with competitive predictive performance to be trained in 1-2 years time.\n\nGoing to 2-bit precision for training currently looks pretty impossible, but it is a much easier problem than shrinking transistors further. So progress in hardware mostly depends on software and algorithms that make it possible to use specialized features offered by the hardware.\n\nWe will probably be able to still improve the combination of algorithms + hardware to the year 2032, but after that will hit the end of GPU improvements (similar to smartphones). The wave of performance improvements after 2032 will come from better networking algorithms and mass hardware. It is uncertain if consumer GPUs will be relevant at this point. It might be that you need an RTX 9090 to run run Super HyperStableDiffusion Ultra Plus 9000 Extra or OpenChatGPT 5.0, but it might also be that some company will offer a high-quality API that is cheaper than the electricity cost for a RTX 9090 and you want to use a laptop + API for image generation and other tasks.\n\nOverall, I think investing into a 8-bit capable GPU will be a very solid investment for the next 9 years. Improvements at 4-bit and 2-bit are likely small and other features like Sort Cores would only become relevant once sparse matrix multiplication can be leveraged well. We will probably see some kind of other advancement in 2-3 years which will make it into the next GPU 4 years from now, but we are running out of steam if we keep relying on matrix multiplication. This makes investments into new GPUs last longer.\n\nQuestion & Answers & Misconceptions\nDo I need PCIe 4.0 or PCIe 5.0?\nGenerally, no. PCIe 5.0 or 4.0 is great if you have a GPU cluster. It is okay if you have an 8x GPU machine, but otherwise, it does not yield many benefits. It allows better parallelization and a bit faster data transfer. Data transfers are not a bottleneck in any application. In computer vision, in the data transfer pipeline, the data storage can be a bottleneck, but not the PCIe transfer from CPU to GPU. So there is no real reason to get a PCIe 5.0 or 4.0 setup for most people. The benefits will be maybe 1-7% better parallelization in a 4 GPU setup.\n\nDo I need 8x/16x PCIe lanes?\nSame as with PCIe 4.0 — generally, no. PCIe lanes are needed for parallelization and fast data transfers, which are seldom a bottleneck. Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.\n\nHow do I fit 4x RTX 4090 or 3090 if they take up 3 PCIe slots each?\nYou need to get one of the two-slot variants, or you can try to spread them out with PCIe extenders. Besides space, you should also immediately think about cooling and a suitable PSU.\n\nPCIe extenders might also solve both space and cooling issues, but you need to make sure that you have enough space in your case to spread out the GPUs. Make sure your PCIe extenders are long enough!\n\nHow do I cool 4x RTX 3090 or 4x RTX 3080?\nSee the previous section.\n\nCan I use multiple GPUs of different GPU types?\nYes, you can! But you cannot parallelize efficiently across GPUs of different types since you will often go at the speed of the slowest GPU (data and fully sharded parallelism). So different GPUs work just fine, but parallelization across those GPUs will be inefficient since the fastest GPU will wait for the slowest GPU to catch up to a synchronization point (usually gradient update).\n\nWhat is NVLink, and is it useful?\nGenerally, NVLink is not useful. NVLink is a high speed interconnect between GPUs. It is useful if you have a GPU cluster with +128 GPUs. Otherwise, it yields almost no benefits over standard PCIe transfers.\n\nI do not have enough money, even for the cheapest GPUs you recommend. What can I do?\nDefinitely buy used GPUs. You can buy a small cheap GPU for prototyping and testing and then roll out for full experiments to the cloud like vast.ai or Lambda Cloud. This can be cheap if you train/fine-tune/inference on large models only every now and then and spent more time protoyping on smaller models.\n\nWhat is the carbon footprint of GPUs? How can I use GPUs without polluting the environment?\nI built a carbon calculator for calculating your carbon footprint for academics (carbon from flights to conferences + GPU time). The calculator can also be used to calculate a pure GPU carbon footprint. You will find that GPUs produce much, much more carbon than international flights. As such, you should make sure you have a green source of energy if you do not want to have an astronomical carbon footprint. If no electricity provider in our area provides green energy, the best way is to buy carbon offsets. Many people are skeptical about carbon offsets. Do they work? Are they scams?\n\nI believe skepticism just hurts in this case, because not doing anything would be more harmful than risking the probability of getting scammed. If you worry about scams, just invest in a portfolio of offsets to minimize risk.\n\nI worked on a project that produced carbon offsets about ten years ago. The carbon offsets were generated by burning leaking methane from mines in China. UN officials tracked the process, and they required clean digital data and physical inspections of the project site. In that case, the carbon offsets that were produced were highly reliable. I believe many other projects have similar quality standards.\n\nWhat do I need to parallelize across two machines?\nIf you want to be on the safe side, you should get at least +50Gbits/s network cards to gain speedups if you want to parallelize across machines. I recommend having at least an EDR Infiniband setup, meaning a network card with at least 50 GBit/s bandwidth. Two EDR cards with cable are about $500 on eBay.\n\nIn some cases, you might be able to get away with 10 Gbit/s Ethernet, but this is usually only the case for special networks (certain convolutional networks) or if you use certain algorithms (Microsoft DeepSpeed).\n\nIs the sparse matrix multiplication features suitable for sparse matrices in general?\nIt does not seem so. Since the granularity of the sparse matrix needs to have 2 zero-valued elements, every 4 elements, the sparse matrices need to be quite structured. It might be possible to adjust the algorithm slightly, which involves that you pool 4 values into a compressed representation of 2 values, but this also means that precise arbitrary sparse matrix multiplication is not possible with Ampere GPUs.\n\nDo I need an Intel CPU to power a multi-GPU setup?\nI do not recommend Intel CPUs unless you heavily use CPUs in Kaggle competitions (heavy linear algebra on the CPU). Even for Kaggle competitions AMD CPUs are still great, though. AMD CPUs are cheaper and better than Intel CPUs in general for deep learning. For a 4x GPU built, my go-to CPU would be a Threadripper. We built dozens of systems at our university with Threadrippers, and they all work great — no complaints yet. For 8x GPU systems, I would usually go with CPUs that your vendor has experience with. CPU and PCIe/system reliability is more important in 8x systems than straight performance or straight cost-effectiveness.\n\nDoes computer case design matter for cooling?\nNo. GPUs are usually perfectly cooled if there is at least a small gap between GPUs. Case design will give you 1-3 C better temperatures, space between GPUs will provide you with 10-30 C improvements. The bottom line, if you have space between GPUs, cooling does not matter. If you have no space between GPUs, you need the right cooler design (blower fan) or another solution (water cooling, PCIe extenders), but in either case, case design and case fans do not matter.\n\nWill AMD GPUs + ROCm ever catch up with NVIDIA GPUs + CUDA?\nNot in the next 1-2 years. It is a three-way problem: Tensor Cores, software, and community.\n\nAMD GPUs are great in terms of pure silicon: Great FP16 performance, great memory bandwidth. However, their lack of Tensor Cores or the equivalent makes their deep learning performance poor compared to NVIDIA GPUs. Packed low-precision math does not cut it. Without this hardware feature, AMD GPUs will never be competitive. Rumors show that some data center card with Tensor Core equivalent is planned for 2020, but no new data emerged since then. Just having data center cards with a Tensor Core equivalent would also mean that few would be able to afford such AMD GPUs, which would give NVIDIA a competitive advantage.\n\nLet’s say AMD introduces a Tensor-Core-like-hardware feature in the future. Then many people would say, “But there is no software that works for AMD GPUs! How am I supposed to use them?” This is mostly a misconception. The AMD software via ROCm has come to a long way, and support via PyTorch is excellent. While I have not seen many experience reports for AMD GPUs + PyTorch, all the software features are integrated. It seems, if you pick any network, you will be just fine running it on AMD GPUs. So here AMD has come a long way, and this issue is more or less solved.\n\nHowever, if you solve software and the lack of Tensor Cores, AMD still has a problem: the lack of community. If you have a problem with NVIDIA GPUs, you can Google the problem and find a solution. That builds a lot of trust in NVIDIA GPUs. You have the infrastructure that makes using NVIDIA GPUs easy (any deep learning framework works, any scientific problem is well supported). You have the hacks and tricks that make usage of NVIDIA GPUs a breeze (e.g., apex). You can find experts on NVIDIA GPUs and programming around every other corner while I knew much less AMD GPU experts.\n\nIn the community aspect, AMD is a bit like Julia vs Python. Julia has a lot of potential, and many would say, and rightly so, that it is the superior programming language for scientific computing. Yet, Julia is barely used compared to Python. This is because the Python community is very strong. Numpy, SciPy, Pandas are powerful software packages that a large number of people congregate around. This is very similar to the NVIDIA vs AMD issue.\n\nThus, it is likely that AMD will not catch up until Tensor Core equivalent is introduced (1/2 to 1 year?) and a strong community is built around ROCm (2 years?). AMD will always snatch a part of the market share in specific subgroups (e.g., cryptocurrency mining, data centers). Still, in deep learning, NVIDIA will likely keep its monopoly for at least a couple more years.\n\nWhen is it better to use the cloud vs a dedicated GPU desktop/server?\nRule-of-thumb: If you expect to do deep learning for longer than a year, it is cheaper to get a desktop GPU. Otherwise, cloud instances are preferable unless you have extensive cloud computing skills and want the benefits of scaling the number of GPUs up and down at will.\n\nNumbers in the following paragraphs are going to change, but it serves as a scenario that helps you to understand the rough costs. You can use similar math to determine if cloud GPUs are the best solution for you.\n\nFor the exact point in time when a cloud GPU is more expensive than a desktop depends highly on the service that you are using, and it is best to do a little math on this yourself. Below I do an example calculation for an AWS V100 spot instance with 1x V100 and compare it to the price of a desktop with a single RTX 3090 (similar performance). The desktop with RTX 3090 costs $2,200 (2-GPU barebone + RTX 3090). Additionally, assuming you are in the US, there is an additional $0.12 per kWh for electricity. This compares to $2.14 per hour for the AWS on-demand instance.\n\nAt 15% utilization per year, the desktop uses:\n\n(350 W (GPU) + 100 W (CPU))*0.15 (utilization) * 24 hours * 365 days = 591 kWh per year\n\nSo 591 kWh of electricity per year, that is an additional $71.\n\nThe break-even point for a desktop vs a cloud instance at 15% utilization (you use the cloud instance 15% of time during the day), would be about 300 days ($2,311 vs $2,270):\n\n$2.14/h * 0.15 (utilization) * 24 hours * 300 days = $2,311\n\nSo if you expect to run deep learning models after 300 days, it is better to buy a desktop instead of using AWS on-demand instances.\n\nYou can do similar calculations for any cloud service to make the decision if you go for a cloud service or a desktop.\n\nCommon utilization rates are the following:\n\nPhD student personal desktop: < 15%\nPhD student slurm GPU cluster: > 35%\nCompany-wide slurm research cluster: > 60%\nIn general, utilization rates are lower for professions where thinking about cutting edge ideas is more important than developing practical products. Some areas have low utilization rates (interpretability research), while other areas have much higher rates (machine translation, language modeling). In general, the utilization of personal machines is almost always overestimated. Commonly, most personal systems have a utilization rate between 5-10%. This is why I would highly recommend slurm GPU clusters for research groups and companies instead of individual desktop GPU machines.\n\nVersion History\n2023-01-30: Improved font and recommendation chart. Added 5 years cost of ownership electricity perf/USD chart. Updated Async copy and TMA functionality. Slight update to FP8 training. General improvements.\n2023-01-16: Added Hopper and Ada GPUs. Added GPU recommendation chart. Added information about the TMA unit and L2 cache.\n2020-09-20: Added discussion of using power limiting to run 4x RTX 3090 systems. Added older GPUs to the performance and cost/performance charts. Added figures for sparse matrix multiplication.\n2020-09-07: Added NVIDIA Ampere series GPUs. Included lots of good-to-know GPU details.\n2019-04-03: Added RTX Titan and GTX 1660 Ti. Updated TPU section. Added startup hardware discussion.\n2018-11-26: Added discussion of overheating issues of RTX cards.\n2018-11-05: Added RTX 2070 and updated recommendations. Updated charts with hard performance data. Updated TPU section.\n2018-08-21: Added RTX 2080 and RTX 2080 Ti; reworked performance analysis\n2017-04-09: Added cost-efficiency analysis; updated recommendation with NVIDIA Titan Xp\n2017-03-19: Cleaned up blog post; added GTX 1080 Ti\n2016-07-23: Added Titan X Pascal and GTX 1060; updated recommendations\n2016-06-25: Reworked multi-GPU section; removed simple neural network memory section as no longer relevant; expanded convolutional memory section; truncated AWS section due to not being efficient anymore; added my opinion about the Xeon Phi; added updates for the GTX 1000 series\n2015-08-20: Added section for AWS GPU instances; added GTX 980 Ti to the comparison relation\n2015-04-22: GTX 580 no longer recommended; added performance relationships between cards\n2015-03-16: Updated GPU recommendations: GTX 970 and GTX 580\n2015-02-23: Updated GPU recommendations and memory calculations\n2014-09-28: Added emphasis for memory requirement of CNNs\nAcknowledgments\nI thank Suhail for making me aware of outdated prices on H100 GPUs, Gjorgji Kjosev for pointing out font issues, Anonymous for pointing out that the TMA unit does not exist on Ada GPUs, Scott Gray for pointing out that FP8 tensor cores have no transposed matrix multiplication, and reddit and HackerNews users for pointing out many other improvements.\n\nFor past updates of this blog post, I want to thank Mat Kelcey for helping me to debug and test custom code for the GTX 970; I want to thank Sander Dieleman for making me aware of the shortcomings of my GPU memory advice for convolutional nets; I want to thank Hannes Bretschneider for pointing out software dependency problems for the GTX 580; and I want to thank Oliver Griesel for pointing out notebook solutions for AWS instances. I want to thank Brad Nemire for providing me with an RTX Titan for benchmarking purposes. I want to thank Agrin Hilmkil, Ari Holtzman, Gabriel Ilharco, Nam Pho for their excellent feedback on the previous version of this blog post.""]",I don't know.,0.0,0.0,0.0007309941520467836,0.0,0.0
Which masked language model was chosen for the AI?,No answer,"[""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 'Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 'A Survey on Retrieval-Augmented Text Generation for Large Language\nModels\nYizheng Huang\nYork University\nhyz@yorku.ca\nJimmy X. Huang\nYork University\njhuang@yorku.ca\nAbstract\nRetrieval-Augmented Generation (RAG)\nmerges retrieval methods with deep learning\nadvancements to address the static limitations\nof large language models (LLMs) by enabling\nthe dynamic integration of up-to-date external\ninformation. This methodology, focusing\nprimarily on the text domain, provides a\ncost-effective solution to the generation of\nplausible but incorrect responses by LLMs,\nthereby enhancing the accuracy and reliability\nof their outputs through the use of real-world\ndata. As RAG grows in complexity and\nincorporates multiple concepts that can\ninfluence its performance, this paper organizes\nthe RAG paradigm into four categories:\npre-retrieval, retrieval, post-retrieval, and\ngeneration, offering a detailed perspective\nfrom the retrieval viewpoint. It outlines\nRAG’s evolution and discusses the field’s\nprogression through the analysis of significant\nstudies. Additionally, the paper introduces\nevaluation methods for RAG, addressing\nthe challenges faced and proposing future\nresearch directions. By offering an organized\nframework and categorization, the study\naims to consolidate existing research on\nRAG, clarify its technological underpinnings,\nand highlight its potential to broaden the\nadaptability and applications of LLMs.\n1 Introduction\nThe advent of ChatGPT has significantly impacted\nboth academia and industry due to its interactive\ncapabilities and widespread application, establishing itself as a leading artificial intelligence tool\n(Laskar et al., 2023; Jahan et al., 2023; Huang\nand Huang, 2024). At the core of ChatGPT is the\nlarge language model (LLM) GPT-4, as detailed by\n(OpenAI et al., 2023), which has seen numerous\nenhancements to its predecessors, showcasing exceptional abilities in a variety of Natural Language\nProcessing (NLP) tasks (Laskar et al., 2020). Despite these advancements, the adoption of LLMs\nFigure 1: An example of RAG benefits ChatGPT resolves questions that cannot be answered beyond the\nscope of the training data and generates correct results.\nhas highlighted several critical issues primarily due\nto their reliance on extensive datasets. This reliance\nrestricts their ability to incorporate new information post-training, leading to three primary challenges. First, the focus on broad and general data\nto maximize accessibility and applicability results\nin subpar performance in specialized areas. Second,\nthe rapid creation of online data, combined with the\nsignificant resources required for data annotation\nand model training, hinders LLMs’ ability to stay\nupdated. Third, LLMs are susceptible to generating convincing yet inaccurate responses, known as\n“hallucinations”, which can mislead users.\nAddressing these challenges is crucial for LLMs\nto be effectively utilized across various domains. A\npromising solution is the integration of RetrievalAugmented Generation (RAG) technology, which\nsupplements models by fetching external data in\nresponse to queries, thus ensuring more accurate\nand current outputs. Figure 1 illustrates how RAG\ncan enable ChatGPT to provide precise answers\nbeyond its initial training data.\nSince its introduction by Lewis et al. (Lewis\net al., 2020b) in 2020, RAG technology has undergone significant advancements, particularly influenced by ChatGPT’s success. However, there is a\nnoticeable gap in the literature regarding a thorough\nanalysis of RAG’s mechanisms and the progress\nmade by subsequent studies. Furthermore, the field\nis characterized by diverse research focuses and the\nuse of ambiguous terminology for similar methods,\nleading to confusion. This paper aims to clarify these aspects by offering a structured overview of\nRAG, categorizing various methods, and delivering an in-depth understanding of this research area.\nThis survey will primarily focus on textual applications of RAG, reflecting the current emphasis of\nresearch efforts in this area.\nRAG combines retrieval methods and advanced\ndeep learning to address two main questions: effectively retrieving relevant information and generating accurate responses. The workflow of RAG\nis outlined in Section 2, categorizing the methodologies into pre-retrieval, retrieval, post-retrieval,\nand generation phases. These sections, from 3 to\n6, provide an in-depth analysis of the technologies\nwithin these phases. Section 7 offers summaries of\nthe reviewed studies, along with the retrievers and\ngenerators utilized. Section 8 details the evaluation\nmethodologies for RAG. Section 9 explores future\nresearch directions, concentrating on text-based\nstudies and extending to image and multimodal\ndata considerations. The conclusion is presented in\nSection 10.\nThe contributions of this paper are threefold:\nThis paper offers a comprehensive framework for\nunderstanding the RAG domain, identifying areas\nfor improvement and challenges for future research.\nIt provides a detailed analysis of RAG’s core technologies, examining their strengths in addressing\nretrieval and generation. Additionally, it introduces\nthe evaluation methods used in RAG research, highlighting current challenges and suggesting promising directions for future studies.\n2 RAG Framework\nThe hallucinations are largely attributed to LLMs’\ninability to access up-to-date information. This\nlimitation stems from the models’ reliance on their\ntraining datasets. RAG proposes a solution to this\nissue by supplementing the LLM’s training data\nwith current information from external sources\nthrough a retrieval model, thereby enabling the generation of accurate responses. RAG presents a more\ncost-effective alternative to the extensive training\nand fine-tuning processes typically required for\nLLMs. It allows for the dynamic incorporation\nof fresh information via traditional retrieval methods or pre-trained LMs, without the need to directly\nintegrate this new data into the LLM. This feature\nmakes RAG both flexible and scalable, facilitating its application across different LLMs for various purposes. The information retrieved through\nRAG is derived from real-world data, authored\nby humans, which not only simplifies the generation process but also increases the reliability of\nthe generated responses. Figure 2 represents the\nunified RAG framework with basic workflow and\nparadigm.\nResearch by Khandelwal et al. (Khandelwal\net al., 2020) demonstrates that accessing relevant\ninformation from the training dataset itself can significantly improve LLM performance, highlighting the effectiveness of RAG. Over time, RAG\nhas evolved from a means of providing supplementary information to enabling multiple interactions\nbetween the retrieval and generation components.\nThis involves conducting several rounds of retrieval\nto refine the accuracy of the information retrieved\nand iteratively improve the quality of the generated output. Platforms such as LangChain1\nand\nLlamaIndex2 have modularized the RAG approach,\nenhancing its adaptability and expanding its range\nof applications. Despite these platforms employing\ndiverse methodologies to tackle different aspects of\nRAG—from multiple search iterations to iterative\ngeneration—they maintain adherence to the fundamental RAG workflow. This consistency is crucial\nfor understanding their operation and pinpointing\nopportunities for further development.\n2.1 Basic RAG Workflow\nThe foundational workflow of RAG begins with the\ncreation of an index comprising external sources.\nThis index serves as the basis for retrieving relevant\ninformation through a retriever model based on a\nspecific query. The final step involves a generator\nmodel, which combines the retrieved information\nwith the query to produce the desired output.\n2.1.1 Indexing\nEfficient retrieval begins with comprehensive indexing, where data preparation is key. This stage\ninvolves text normalization processes such as tokenization, stemming, and the removal of stop words\nto enhance the text’s suitability for indexing (Manning et al., 2008). Text segments are then organized\ninto sentences or paragraphs to facilitate more focused searches, allowing for the pinpointing of segments containing pertinent keywords. The integration of deep learning has revolutionized indexing\nthrough the use of pretrained LMs for generating\nsemantic vector representations of texts. These vectors are stored, enabling rapid and precise retrieval from extensive data collections, significantly\nenhancing retrieval efficiency.\n2.1.2 Retrieval\nWhile traditional retrieval methods, such as the\nBM25 algorithm (Hancock-Beaulieu et al., 1996),\nfocus on term frequency and presence for document\nranking, they often overlook the semantic information of queries. Current strategies leverage pretrained LMs like BERT (Devlin et al., 2019), which\ncapture the semantic essence of queries more effectively. These models improve search accuracy by\nconsidering synonyms and the structure of phrases,\nthereby refining document ranking through the detection of semantic similarities. This is typically\nachieved by measuring vector distances between\ndocuments and queries, combining traditional retrieval metrics with semantic understanding to yield\nsearch results that are both relevant and aligned\nwith user intent.\n2.1.3 Generation\nThe generation phase is tasked with producing text\nthat is both relevant to the query and reflective of\nthe information found in the retrieved documents.\nThe usual method involves concatenating the query\nwith the retrieved information, which is then fed\ninto an LLM for text generation (Li et al., 2022).\nAlthough ensuring the generated text’s alignment\nand accuracy with the retrieved content presents\nchallenges, it is also essential to strike a balance between adhering closely to the source material and\ninfusing the output with creativity. The generated\ntext should accurately convey the information from\nthe retrieved documents and align with the query’s\nintent, while also offering the flexibility to introduce new insights or perspectives not explicitly\ncontained within the retrieved data.\n2.2 RAG Paradigm\nThe RAG paradigm organizes research within\nthe domain, offering a straightforward yet robust\nframework to enhance LLM performance. Central to RAG is its search mechanism, crucial for\ngenerating high-quality outcomes. Therefore, this\nparadigm is structured into four main phases from\na retrieval perspective: pre-retrieval, retrieval, postretrieval, and generation. Both single-hop and\nmulti-hop retrieval approaches, encompassing iterative retrieve-generate cycles, follow this four-phase\nstructure. Figure 3 is the taxonomy tree of RAG’s\ncore techniques.\n2.2.1 Pre-Retrieval\nThe pre-retrieval phase of retrieval-augmented generation lays the foundation for successful data and\nquery preparation, ensuring efficient information\nretrieval. This phase includes essential tasks to\nprepare for effective data access.\nIndexing The process starts with indexing, which\nestablishes an organized system to enable fast and\naccurate retrieval of information. The specificity\nof indexing depends on the task and data type.\nFor example, sentence-level indexing is beneficial\nfor question-answering systems to precisely locate\nanswers, while document-level indexing is more\nappropriate for summarizing documents to understand their main concepts and ideas.\nQuery Manipulation After indexing, query manipulation is performed to adjust user queries for\na better match with the indexed data. This involves query reformulation (Jansen et al., 2009;\nYu et al., 2020), which rewrites the query to align\nmore closely with the user’s intention; query expansion (Huang et al., 2013), which extends the query\nto capture more relevant results through synonyms\nor related terms; and query normalization, which\nresolves differences in spelling or terminology for\nconsistent query matching.\nData Modification Data modification is also critical in enhancing retrieval efficiency. This step\nincludes preprocessing techniques like removing\nirrelevant or redundant information to improve the\nquality of results and enriching the data with additional information such as metadata to boost the\nrelevance and diversity of the retrieved content\n(Bevilacqua et al., 2022a).\n2.2.2 Retrieval\nSearch & Ranking The retrieval stage is the\ncombination of search and ranking. It focuses on\nselecting and prioritizing documents from a dataset\nto enhance the quality of the generation model’s\noutputs. This stage employs search algorithms to\nnavigate through the indexed data, finding documents that match a user’s query. After identifying\nrelevant documents, the process of initially ranking\nthese documents starts to sort them according to\ntheir relevance to the query.\n2.2.3 Post-Retrieval\nThe post-retrieval phase serves to refine the initially\nretrieved documents to improve the quality of text\ngeneration. This phase consists of re-ranking and\nfiltering, each aimed at optimizing the document\nselection for the final generation task.\nRe-Ranking In the re-ranking step, the documents previously retrieved are reassessed, scored,\nand reorganized. The objective is to more accurately highlight the documents most relevant to\nthe query and diminish the importance of the less\nrelevant ones. This step involves incorporating additional metrics and external knowledge sources\nto enhance precision. In this context, pre-trained\nmodels with superior accuracy but lower efficiency\ncan be effectively employed due to the limited set\nof candidate documents available (Huang and Hu,\n2009).\nFiltering Filtering aims to remove documents\nthat fail to meet specified quality or relevance\nstandards. This can be done through several approaches, such as establishing a minimum relevance score threshold to exclude documents below\na certain relevance level. Furthermore, the use of\nfeedback from users or prior relevance evaluations\nassists in adjusting the filtering process, guaranteeing that only the most relevant documents are\nretained for text generation (Khattab and Zaharia,\n2020; Huang and Huang, 2023).\n2.2.4 Generation\nThe generation stage is a crucial component of the\nRAG process, responsible for leveraging retrieved\ninformation to enhance the quality of the generated\nresponse. This stage encompasses several sub-steps\naimed at producing content that is readable, engaging, and informative.\nEnhancing At the heart of the generation phase\nis the enhancement step, where the objective is\nto merge the retrieved information with the user’s\nquery to create a coherent and relevant response.\nThis includes the process of elaboration, adding\nextra details to the retrieved content to enrich it. Efforts are focused on improving the output’s quality\nby increasing its clarity, coherence, and stylistic\nappeal through methods such as rephrasing and\nrestructuring. Information from various sources\nis combined to offer a comprehensive perspective,\nand verification is conducted to ensure the accuracy\nand relevance of the content.\nCustomization Customization is an optional\nstep, involving the adjustment of content to align\nwith the user’s specific preferences or the context\nof the request. This tailoring includes adapting the\ncontent to meet the needs of the target audience or\nthe format in which it will be presented and condensing the information to succinctly convey the\nessence of the content. The process also entails\ncreating summaries or abstracts that emphasize the\nkey points or arguments, ensuring the output is both\ninformative and concise.\n3 Pre-Retrieval\n3.1 Indexing\nThe integration of the k-nearest neighbor (kNN)\nalgorithm with pre-trained neural LMs, as demonstrated in kNN-LMs (Khandelwal et al., 2020), represents significant progress in language modeling. This method employs a datastore created from collections of texts, enabling the dynamic retrieval of\ncontextually relevant examples to improve perplexity without necessitating additional training.\nKnown for its efficiency, FAISS (Johnson et al.,\n2021) has been adopted in many studies for indexing purposes (Khandelwal et al., 2020; Lewis et al.,\n2020b; Khattab et al., 2022). Some research integrates enhancements like the Hierarchical Navigable Small World (HNSW) approximation (Malkov\nand Yashunin, 2020) to achieve faster retrieval\n(Lewis et al., 2020b). In addition, alternative tools\nlike utilizing the Bing API 3\nfor indexing based\non actual user search histories as outlined in Webgpt (Nakano et al., 2021), illustrate the variety of\nindexing techniques under investigation.\nFurthermore, MEMWALKER (Chen et al.,\n2023a) introduces an innovative method to overcome the limitations of context window size in\nLLMs by creating a memory tree from the input\ntext. This tree is formed by initially segmenting\nthe text into smaller pieces and then summarizing these segments into a hierarchical structure of\nsummary nodes, facilitating efficient indexing and\nmanagement of large volumes of information.\n3.2 Query Manipulation\nStudies such as FiD (Izacard and Grave, 2021),\nCOK(Li et al., 2023), and Query2doc (Wang et al.,\n2023a) emphasize the significance of creating new\nqueries or refining existing ones to achieve more\n3\nhttps://www.microsoft.com/en-us/bing/apis/bing-websearch-api\npertinent retrieval results. These research efforts\nhighlight the necessity of efficiently gathering evidence from multiple passages and tailoring queries\nto suit various knowledge sources, whether structured or unstructured. Techniques ranging from the\ncreation of pseudo-documents to enhance queries\nhave shown to bolster retrieval performance across\ndiverse information retrieval datasets.\nFurther exploration into query manipulation has\nbeen conducted by Step-Back (Zheng et al., 2023)\nand PROMPTAGATOR (Dai et al., 2023), which\nfocus on abstracting high-level concepts or utilizing LLMs for prompt-based query generation.\nThese strategies strive to better align queries with\nthe retrieval system’s functionality by rephrasing\ntasks into more generalized versions or crafting\ntask-specific queries from limited examples. Such\nmethodologies enhance the consistency between\nqueries and indexed data, facilitating the retrieval\nof more pertinent and insightful information.\nMoreover, KnowledGPT (Wang et al., 2023b)\nand Rewrite-Retrieve-Read (Ma et al., 2023) introduce approaches for query manipulation through\n“program of thought” prompting and innovative\nquery rewriting techniques. KnowledGPT innovates by generating code to interface with knowledge bases, converting user queries into structured\nsearch commands. In contrast, Rewrite-RetrieveRead utilizes a trainable compact LM for query\nreformulation, adjusting them to more effectively\nreflect the user’s intent and context.\nLastly, FLARE (Jiang et al., 2023) presents a\nstrategy based on confidence for query formulation, which focuses on crafting queries that precisely\nreflect the information needs. This method incorporates the use of generated sentences or fragments\nthereof as a foundation for search queries. By opting to directly use sentences, obscuring tokens of\nlow confidence, or formulating explicit questions,\nthis approach aims to boost the efficiency of the\nretrieval process, ensuring that the retrieved information faithfully satisfies the requirements of the\ngeneration process.\n3.3 Data Modification\nRA-DIT (Lin et al., 2023b) and RECITE (Sun et al.,\n2023) emphasize enhancements through internal\ndata modifications. RA-DIT distinguishes between\nfine-tuning datasets for LLMs and retrievers, aiming to bolster the LLM’s contextual comprehension\nand the retriever’s ability to align with queries. RECITE, on the other hand, utilizes passage hints and\nsynthetic question-passage pairs to increase the\nvariety and relevance of its generated recitations\nand responses. This approach seeks to broaden the\nmodel’s knowledge base and improve its response\naccuracy.\nUPRISE (Cheng et al., 2023a) and GENREAD\n(Yu et al., 2023a) target the refinement of external\ndata. UPRISE converts raw task data into a structured format and refines the selection of prompts\nto enhance retrieval outcomes. In contrast, the\nClustering-Based Prompts method employed by\nGENREAD generates documents from questions\nand clusters them to eliminate irrelevant data, enriching the input with varied contextual insights.\nThis technique aims to improve the performance of\nthe generative model by providing it with a richer\nset of information.\nFurthermore, KnowledGPT (Wang et al., 2023b)\nis dedicated to augmenting raw text data with structured, semantically rich information through entity\nlinking. This enrichment process not only structures the data more cohesively and makes it more\namenable to queries but also boosts the model’s\nretrieval efficiency. It leverages precise, linked\nknowledge to enhance the model’s understanding and its ability to generate relevant responses,\nthereby improving its overall performance.\n4 Retrieval\n4.1 Search & Ranking\nAtlas (Izacard et al., 2023) investigates few-shot\nlearning approaches, including Attention Distillation and Perplexity Distillation, to steer the retriever toward retrieving more relevant documents.\nIRCOT (Trivedi et al., 2023) integrates retrieval\nwith reasoning to improve the effectiveness of retrieval. SURGE (Kang et al., 2023) employs a\nsubgraph retriever to extract relevant subgraphs\nfrom a knowledge graph, while AAR (Yu et al.,\n2023b) modifies search preferences to help LLMs\nin fetching pertinent documents.\nPRCA (Yang et al., 2023a) focuses on employing domain-specific abstractive summarization to\nextract relevant and context-rich information from\ndocuments, using a supervised learning strategy\nto prioritize content crucial for accurate query responses. Meanwhile, MEMWALKER (Chen et al.,\n2023a) leverages an internal search and ranking\nmechanism in the constructed memory tree to identify pertinent information for long-context question\nanswering. Additionally, the Confidence-based Active Retrieval approach of FLARE (Jiang et al.,\n2023) dynamically triggers information retrieval\nbased on the confidence levels of generated sentences, utilizing the insight that low-confidence\ntokens signal a need for external knowledge.\n5 Post-Retrieval\n5.1 Re-Ranking\nRe2G (Glass et al., 2022) introduces a sequencepair classification approach for re-ranking, utilizing a BERT transformer to simultaneously analyze\nthe query and passage. This interaction model, employing cross-attention between sequences, offers a\ncontrast to the representation model typically used\nin initial retrieval phases. PROMPTAGATOR (Dai\net al., 2023) also employs a cross-attention model\nfor re-scoring. Its “Lift Yourself Up” strategy iteratively selects the best candidate from a pool for\nfurther generation rounds, progressively improving\ncontent quality via self-generated content.\nRe-ranking is also a significant focus of InContext RALM (Ram et al., 2023). Two approaches to reranking are explored: zero-shot\nreranking using language models and predictive\nreranking through trained models. This step is\naimed at refining the selection of documents based\non their expected utility for improving language\nmodel performance. ITER-RETGEN (Shao et al.,\n2023), in particular, leverages knowledge distillation from the re-ranker to the dense retriever, finetuning retrieval efforts based on relevance signals\nfrom LLM outputs. This optimization of the retrieval model aims to more accurately capture query\nnuances, thereby improving document selection.\nDKS-RAC (Huang et al., 2023) presents the\nDense Knowledge Similarity (DKS) for aligning\nthe knowledge between answers and retrieved passages at the sequence level. This approach is categorized under re-ranking due to its direct impact on\npassage selection based on knowledge similarity,\nrefining the match between queries and documents.\nFiD-light (Hofstätter et al., 2023) introduces a\nlistwise autoregressive re-ranking method that employs source pointers to optimize the ranking order.\nThis method maintains a link between the generated text and source passages, enabling a more\nstructured generation process. By incorporating\ntextual citations within the model’s output as pointers to relevant information sources, this approach\nfacilitates an organized retrieval and generation\nprocess, enhancing the overall coherence and relevance of the generated content.\n5.2 Filtering\nCOK (Li et al., 2023) presents the Progressive Rationale Correction technique, aimed at iteratively\nrefining rationales with retrieved knowledge. This\nmethod constitutes a continuous optimization process, significantly enhancing the relevance and\nquality of information used in content generation.\nSelf-RAG (Asai et al., 2023) introduces a selfreflection mechanism to efficiently filter out irrelevant content. By employing critique tokens, this\napproach evaluates the relevance, supportiveness,\nand utility of retrieved passages, ensuring the integration of only high-quality information into the\ncontent generation process.\nAdditionally, FiD-TF (Berchansky et al., 2023)\nand RECOMP (Xu et al., 2023) are dedicated to the\nremoval of irrelevant or redundant tokens and information from retrieved documents. FiD-TF employs\na dynamic mechanism to identify and eliminate unnecessary tokens, enhancing the efficiency of information processing. RECOMP, on the other hand,\ncompresses documents into concise summaries, focusing on selecting only the most pertinent content\nfor the generation process. These methods streamline the content generation workflow by ensuring\nthat only relevant and supportive information is\nutilized, thereby improving the overall quality and\nrelevance of the generated content.\n6 Generation\n6.1 Enhancing\nDSP (Khattab et al., 2022) introduces a framework\ndesigned to generate multiple retrieval queries to\nsummarize and answer questions, drawing upon information aggregated from various passages. This\nframework employs CombSUM (Fox and Shaw,\n1994) to calculate a cumulative probability score\nfor passages across different retrieval lists, facilitating the compilation of a comprehensive response\nfrom multiple sources.\nPRCA (Yang et al., 2023a) outlines a RewardDriven Stage, wherein the distilled context is refined based on feedback from the generator. Utilizing reinforcement learning, this stage adjusts\nthe parameters of PRCA according to the rewards\nreceived for providing relevant context. The objective is to fine-tune the extracted context to meet\nthe specific requirements of the generator, thereby\noptimizing the generation process.\nREPLUG (Shi et al., 2023) proposes a method\nfor prepending retrieved documents to the input\ncontext before the final prediction by the black-box\nLM. It introduces an ensemble strategy to encode\nretrieved documents in parallel, overcoming the\nlimitations of LM context length and enhancing\naccuracy through the allocation of increased computational resources. This approach improves the\ngeneration process by ensuring that the LM has\naccess to a broader range of relevant information.\nRECITE (Sun et al., 2023) implements a selfconsistency technique, which involves generating\nmultiple recitations independently and employing\na plurality/majority vote system to determine the\nmost appropriate answer. This method is designed\nto increase the reliability and accuracy of the answers, thereby improving the quality and credibility\nof the output.\n6.2 Customization\nThe PKG framework, introduced by (Luo et al.,\n2023), represents an approach to customizing the\noutput of LMs. By generating background knowledge internally using a pre-trained model, PKG\neliminates the need for traditional external retrieval\nprocesses. This method directly integrates domainor task-specific knowledge into the generation step,\nsignificantly enhancing the LM’s capacity to produce responses that are specifically tailored to the\ngiven context or requirements.\nSelf-RAG (Asai et al., 2023) offers a strategy that incorporates reflection tokens within a customizable decoding algorithm. This technique permits dynamic adjustment of the model’s retrieval\nand generation behaviors based on the specific task,\nfacilitating more versatile response generation. Depending on the requirements, this approach can be\ntuned for accuracy or creativity, providing flexibility in generating outputs that meet diverse needs.\nSURGE (Kang et al., 2023) achieves customization through the application of graph-text contrastive learning. This method ensures that the\ngenerated dialogue responses are in tight alignment\nwith the knowledge contained in the retrieved subgraph, yielding responses that are specific, relevant,\nand deeply rooted in the dialogue context. By maintaining consistency between the retrieved knowledge and the generated text, SURGE is capable\nof producing outputs that precisely reflect the detailed knowledge of the subgraph, enhancing the\nrelevance and specificity of the responses.\n7 Comparisons of RAG\n7.1 The Comprehensive Summary of RAG\nTable 1 presents a detailed analysis of the RAG\nstudies discussed in this paper. The analysis shows\nthat the majority of these studies have utilized external data sources to enrich the content of LLMs.\nA preference for multiple-hop over single-hop retrieval was noted, indicating that iterative search\nrounds generally yield superior results. In other\nwords, most methods employ dense retrieval to secure higher quality candidate documents. Compared to modifying datasets in the pre-retrieval\nstage, more studies focus on manipulating the query\nto improve retrieval performance. Additionally,\nthere is a significant emphasis on optimizing the\nretrieval phase, highlighting its crucial role in the\nresearch. However, there seems to be a scarcity\nof studies concentrating on customization in the\ngeneration stage, pointing to this as a potential area\nfor future exploration. Overall, while the goal of\nRAG is to enhance the response quality of LLMs,\ngreater efforts have been directed towards improving retrieval aspects.\n7.2 Retriever and Generator\nIn RAG, the retriever and the generator are the\nprimary components. Table 2 summarizes the retrievers and generators used in the studies discussed\nin this paper. It is clear from the table that while\nmost generators utilize advanced language models,\na significant number of retrievers still employ the\ntraditional BM25 due to its efficiency. The method\nof retrieval is a crucial aspect in RAG, highlighting the importance of exploring ways to enhance\nretrieval performance without compromising efficiency. Similarly, not many studies have adopted\npowerful LLMs such as LLaMA2, GPT-3.5, or\nGPT-4 as their generators. LLMs like T5 remain\npopular, yet fundamental models like BERT and\nTransformers are rarely used in 2023. Compared\nto generators, it is evident that not many IR-based\nLLMs are used in retrievers, indicating a promising\ndirection for developing such models in the future.\n8 Evaluation in RAG\nTo understand the effectiveness of LMs in generating more accurate, relevant, and robust responses\nby leveraging external knowledge, the evaluation\nof RAG systems has become a significant research\narea. With the popularity of dialogue-based interactions, recent works have been focused on assessing\nthe performance of RAG models on such downstream tasks using established metrics like Exact\nMatch (EM) and F1 scores. Furthermore, a wide\narray of datasets has been utilized for this purpose,\nincluding TriviaQA (Joshi et al., 2017), HotpotQA\n(Yang et al., 2018), FEVER (Thorne et al., 2018),\nNatural Questions (Kwiatkowski et al., 2019), Wizard of Wikipedia (Dinan et al., 2019), and T-REX\n(ElSahar et al., 2018).\nHowever, evaluation solely from the perspective of downstream tasks falls short in addressing\nthe evolving needs of RAG development. Recent\nresearch has introduced various frameworks and\nbenchmarks that aim to evaluate these systems\nacross multiple dimensions, including the quality\nof the generated text, the relevance of retrieved\ndocuments, and the model’s resilience to misinformation, as shown in Table 3. These evaluations focus on assessing specific capabilities such as noise\nrobustness, negative prompting, information integration, and counterfactual robustness, highlighting the complex challenges faced by RAG systems\nin practical applications. The continuous development of evaluation frameworks and metrics is\ncrucial for advancing the field, broadening the applicability of RAG systems, and ensuring they meet\nthe demands of a complex and evolving information landscape.\n8.1 Retrieval-based Aspect\nIn information retrieval, the quality of search results is typically evaluated using standard metrics\nsuch as Mean Average Precision (MAP), Precision,\nReciprocal Rank, and Normalized Discounted Cumulative Gain (NDCG) (Radlinski and Craswell,\n2010; Reimers and Gurevych, 2019; Nogueira et al.,\n2019). These metrics primarily assess the relevance\nof retrieved documents to a given query.\nRetrieval-based Metrics in RAG focus on the effectiveness of retrieving relevant information to\nsupport generation tasks. These include Accuracy, which measures the precision of retrieved\ndocuments in providing correct information for answering queries, and Rejection Rate (Chen et al.,\n2023b), assessing a system’s ability to decline answering when no relevant information is found.\nAdditionally, Error Detection Rate (Chen et al.,\n2023b) evaluates the model’s capability to identify\nand disregard incorrect or misleading information\nfrom retrieved documents. Context Relevance is\nanother essential metric, assessing the pertinence\nof the retrieved documents to the query. It’s vital to\nensure the information used to generate responses\nis directly related to the query’s context. Faithfulness (Shahul et al., 2023) measures the accuracy\nwith which the generated content reflects the information in the retrieved documents, ensuring that\nthe generation process with no misinformation.\n8.2 Generation-based Aspect\nEvaluating the quality of text produced by LLMs\ninvolves analyzing their performance on various\ndownstream tasks using standard metrics. These\nmetrics assess linguistic quality, coherence, accuracy, and the extent to which the generated text\nreflects ground-truth data. Linguistic quality and\ncoherence are evaluated through metrics such as\nBLEU (Papineni et al., 2002), which measures fluency and similarity to human-produced text, and\nROUGE-L (Lin, 2004), which quantifies the overlap with reference summaries to gauge the text’s\ncapacity to encapsulate main ideas and phrases.\nAccuracy and overlap with ground-truth data are\ngauged using metrics like EM and F1 Score, which\nrespectively determine the percentage of answers\nthat are entirely correct and offer a balanced assessment of precision and recall in retrieving relevant\nanswers while minimizing inaccuracies.\nBeyond these standard metrics, the evaluation\nmay also incorporate task-specific criteria and\nnovel metrics tailored to particular applications.\nFor instance, in dialogue generation, perplexity\nand entropy are used to evaluate response diversity and naturalness. Additionally, metrics such as\nMisleading Rate and Mistake Reappearance Rate\n(Liu et al., 2023) gauge a model’s ability to avoid\nmisinformation and inaccuracies. Other specialized metrics include Answer Relevance (Shahul\net al., 2023), assessing the precision of responses\nto queries; Kendall’s tau (Saad-Falcon et al., 2023),\nfor evaluating the accuracy of RAG system rankings; Micro-F1 (Saad-Falcon et al., 2023), which\nfine-tunes accuracy evaluation in tasks with multiple correct answers; and Prediction Accuracy, directly measuring the alignment of generated answers with expected responses, thereby offering a\ndirect insight into a system’s effectiveness in generating accurate content.\n9 Future Directions\n9.1 Retrieval Quality\nThe integration of RAG into LLMs faces significant\nhurdles due to the vast amounts of unreliable information on the internet, including fake news. This\npresents a challenge for accurately retrieving useful\nknowledge, leading to the unreliable generation of\nresponses by LLMs. As a result, LLMs may generate content based on incorrect information, undermining their reliability. Recent research efforts\nare directed towards enhancing retrieval methods\nto improve the efficiency, scalability, and effectiveness of LLMs in generating accurate and reliable\nresponses.\nDifferentiable Search Indices (Tay et al., 2022)\nand (Bevilacqua et al., 2022b) developed differentiable search indices that integrate the retrieval\nprocess within a Transformer model, enabling direct mapping of text queries to document identifiers.\nThese approaches offer superior performance and\npotential for more efficient and scalable retrieval.\nGenerative Models for Search GERE (Chen\net al., 2022a) can directly generate document titles\nand evidence sentences for fact-verification tasks.\nPARADE (Li et al., 2024) is a method for document\nreranking that aggregates passage representations\ninto a unified document relevance score. Both of\nthem demonstrate significant improvements in retrieval quality over traditional methods.\nFine-tuning Pre-trained Language Models\nRankT5 (Zhuang et al., 2023) is a model that finetunes the T5 framework specifically for text ranking. It leverages ranking losses to optimize performance metrics and exhibits promising zero-shot\nperformance on out-of-domain data.\nNoise Power (Cuconasu et al., 2024) provide a\ncomprehensive analysis of the impact of IR components on RAG systems, revealing that the inclusion\nof irrelevant documents can significantly improve\naccuracy. It challenges conventional retrieval strategies and underscores the potential for developing\nspecialized approaches that integrate retrieval with\nlanguage generation models.\n9.2 Multimodal RAG\nThe multimodal RAG domain has experienced significant growth, highlighting a pivotal advancement\nat the confluence of text and visual comprehension.\nThe introduction of MuRAG (Chen et al., 2022b)\nmarked a breakthrough by amalgamating textual\nand visual information for language generation, establishing a new standard for multimodal datasets.\nThis model showcased the efficacy of utilizing a\nmultimodal memory system to boost the accuracy\nin question-answering and reasoning tasks.\nAfter MuRAG, studies such as REVEAL (Hu\net al., 2023) and Re-Imagen (Chen et al., 2023c)\nhave focused on enhancing visual question answering and text-to-image generation. They achieved\nthis through the incorporation of dynamic retrieval\nmechanisms and the improvement of image fidelity,\nrespectively. These advancements laid the groundwork for further models by researchers like Sarto\net al. (Sarto et al., 2022) for image captioning,\nand Yuan et al. (Yuan et al., 2023) for text-to-audio\ngeneration, broadening the scope of RAG’s application across different modalities and improving the\nquality and realism of the generated outputs. Furthermore, Re-ViLM (Yang et al., 2023b) refined\nimage captioning capabilities through a retrievalaugmented visual language model. By fine-tuning\nmodel parameters and implementing innovative filtering strategies, it has made strides in producing\nmore precise and contextually appropriate captions.\nBy tapping into external resources, these models\nhave provided significant enhancements over traditional benchmarks, highlighting the advantage of\nintegrating diverse sources of knowledge.\n10 Conclusions\nIn this paper, we have presented a comprehensive framework for understanding the RAG domain, highlighting its significance in enhancing\nthe capabilities of LLMs. Through a structured\noverview of RAG, categorizing various methods,\nand an in-depth analysis of its core technologies\nand evaluation methods, this study illuminates the\npath for future research. It identifies crucial areas\nfor improvement and outlines potential directions\nfor advancing RAG applications, especially in textual contexts. This survey aims to elucidate the\ncore concepts of the RAG field from a retrieval\nperspective, and it is intended to facilitate further\nexploration and innovation in the accurate retrieval\nand generation of information.\n11 Limitations\nThis survey comprehensively examines existing\nRAG models, summarizing their core techniques\ninto four main steps from a retrieval perspective. It\nrecognizes that some methods may encompass multiple steps and that decoupling these steps could\npotentially obscure their intrinsic connections. Nevertheless, the primary objective is to simplify the\ncomplexity of the approach, clearly delineating the\nspecific problems it addresses. This allows for a\nclearer identification of areas ripe for further optimization and improvement. Despite the thorough investigation, the rapid evolution of the field and\npage limits mean that certain aspects might not\nhave been fully analyzed and explored, or recent\ndevelopments could have been missed. While the\npaper references evaluation methods that can aid\nin the development of RAG, it also acknowledges\nmature tools like LangChain and LlamaIndex as\nuseful resources. However, the focus of this survey\nis not on detailing the evaluation pipeline or how\nthese tools are specifically used, but rather on illustrating how evaluation aspects can support the\nadvancement of RAG. This choice highlights an\narea for future work, emphasizing the importance\nof methodological clarity and the application of\nevaluation tools in refining and enhancing RAG\nmodels.\nAcknowledgements\nThis work was supported by the Natural Sciences\nand Engineering Research Council (NSERC) of\nCanada and the York Research Chairs (YRC) program.\nAcknowledgements\nThis work was supported by the Natural Sciences\nand Engineering Research Council (NSERC) of\nCanada and the York Research Chairs (YRC) program.\nReferences\nAkari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and\nHannaneh Hajishirzi. 2023. Self-RAG: Learning\nto Retrieve, Generate, and Critique through SelfReflection. arXiv, abs/2310.11511.\nMoshe Berchansky, Peter Izsak, Avi Caciularu, Ido\nDagan, and Moshe Wasserblat. 2023. Optimizing\nRetrieval-augmented Reader Models via Token Elimination. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1506–1524. Association for Computational\nLinguistics.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022a. Autoregressive search engines: Generating\nsubstrings as document identifiers. In Advances in\nNeural Information Processing Systems 35: Annual\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,\nNovember 28 - December 9, 2022.\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick S. H.\nLewis, Scott Yih, Sebastian Riedel, and Fabio Petroni.\n2022b. Autoregressive Search Engines: Generating Substrings as Document Identifiers. In Conference on Neural Information Processing Systems\n(NeurIPS).\nSid Black, Gao Leo, Phil Wang, Connor Leahy,\nand Stella Biderman. 2021. GPT-Neo: Large\nScale Autoregressive Language Modeling with MeshTensorflow.\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\nTrevor Cai, Eliza Rutherford, Katie Millican, George\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\nSaffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen\nSimonyan, Jack W. Rae, Erich Elsen, and Laurent\nSifre. 2022. Improving Language Models by Retrieving from Trillions of Tokens. In International Conference on Machine Learning (ICML), pages 2206–\n2240.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners. In\nConference on Neural Information Processing Systems (NeurIPS), volume abs/2005.14165.\nHoward Chen, Ramakanth Pasunuru, Jason Weston, and\nAsli Celikyilmaz. 2023a. Walking Down the Memory\nMaze: Beyond Context Limit through Interactive\nReading. arXiv, abs/2310.05029.\nJiangui Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan,\nand Xueqi Cheng. 2022a. Gere: Generative Evidence\nRetrieval for Fact Verification. In Proceedings of\nthe 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval.\nACM.\nJiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.\n2023b. Benchmarking large language models in retrieval-augmented generation. arXiv,\nabs/2309.01431.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, and others. 2021. Evaluating\nlarge language models trained on code. arXiv,\nabs/2107.03374.\nWenhu Chen, Hexiang Hu, Xi Chen, Pat Verga,\nand William Cohen. 2022b. Murag: Multimodal\nRetrieval-Augmented Generator for Open Question\nAnswering over Images and Text. In Proceedings\nof the 2022 Conference on Empirical Methods in\nNatural Language Processing (EMNLP).\nWenhu Chen, Hexiang Hu, Chitwan Saharia, and\nWilliam W. Cohen. 2023c. Re-Imagen: RetrievalAugmented Text-to-Image Generator. In International Conference on Learning Representations\n(ICLR).\nZhihong Chen, Feng Jiang, Junying Chen, Tiannan\nWang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao\nLiang, Chen Zhang, Zhiyi Zhang, and others. 2023d.\nPhoenix: Democratizing chatgpt across languages.\narXiv, abs/2304.10453.\nDaixuan Cheng, Shaohan Huang, Junyu Bi, Yuefeng\nZhan, Jianfeng Liu, Yujing Wang, Hao Sun, Furu\nWei, Weiwei Deng, and Qi Zhang. 2023a. Uprise:\nUniversal Prompt Retrieval for Improving Zero-Shot\nEvaluation. In Proceedings of the 2023 Conference\non Empirical Methods in Natural Language Processing, pages 12318–12337. Association for Computational Linguistics.\nXin Cheng, Di Luo, Xiuying Chen, Lemao Liu,\nDongyan Zhao, and Rui Yan. 2023b. Lift Yourself Up: Retrieval-augmented Text Generation with\nSelf-Memory. In Thirty-seventh Conference on\nNeural Information Processing Systems, volume\nabs/2305.02437.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2023. Palm: Scaling Language\nModeling with Pathways. Journal of Machine Learning Research (JMLR), 24:240:1–240:113.\nHyung Won Chung, Le Hou, S. Longpre, Barret\nZoph, Yi Tay, W. Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Webson, S. Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen,\nAakanksha Chowdhery, Dasha Valter, Sharan Narang,\nGaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav\nPetrov, E. Chi, J. Dean, Jacob Devlin, Adam Roberts,\nDenny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling Instruction-Finetuned Language Models. arXiv,\nabs/2210.11416.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised\nCross-lingual Representation Learning at Scale. In\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440–\n8451. Association for Computational Linguistics.\nFlorin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle\nMaarek, Nicola Tonellotto, and Fabrizio Silvestri.\n2024. The Power of Noise: Redefining Retrieval for\nRAG Systems. arXiv, abs/2401.14887.\nZhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo\nNi, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B.\nHall, and Ming-Wei Chang. 2023. Promptagator:\nFew-shot Dense Retrieval From 8 Examples. In International Conference on Learning Representations\n(ICLR).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of Deep\nBidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the\nNorth, pages 4171–4186. Association for Computational Linguistics.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\nFan, Michael Auli, and Jason Weston. 2019. Wizard\nof Wikipedia: Knowledge-Powered Conversational\nAgents. In International Conference on Learning\nRepresentations (ICLR).\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,\nJiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:\nGeneral Language Model Pretraining with Autoregressive Blank Infilling. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers). Association for\nComputational Linguistics.\nHady ElSahar, Pavlos Vougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon S. Hare, Frédérique\nLaforest, and Elena Simperl. 2018. T-REx: A Large\nScale Alignment of Natural Language with Knowledge Base Triples. In International Conference on\nLanguage Resources and Evaluation (LREC).\nZhangyin Feng, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, and Bing Qin. 2023. Retrieval-generation\nsynergy augmented large language models. arXiv,\nabs/2310.05149.\nEdward A. Fox and Joseph A. Shaw. 1994. Combination of multiple searches. In TREC-2: Text retrieval\nconference, 500215, pages 105–108.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimcse: Simple Contrastive Learning of Sentence\nEmbeddings. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, pages 6894–6910. Association for Computational Linguistics.\nMichael Glass, Gaetano Rossiello, Md Faisal Mahbub\nChowdhury, Ankita Naik, Pengshan Cai, and Alfio\nGliozzo. 2022. Re2g: Retrieve, Rerank, Generate.\nIn Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,\npages 2701–2715. Association for Computational\nLinguistics.\nSimon Gottschalk and Elena Demidova. 2018. EventKG: A Multilingual Event-Centric Temporal Knowledge Graph. Springer International Publishing.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\nand Ming-Wei Chang. 2020. Retrieval Augmented\nLanguage Model Pre-Training. In International Conference on Machine Learning (ICML), pages 3929–\n3938.\nWilliam L. Hamilton. 2020. Graph representation learning. Springer International Publishing.\nMicheline Hancock-Beaulieu, Mike Gatford, Xiangji\nHuang, Stephen E. Robertson, Steve Walker, and\nP. W. Williams. 1996. Okapi at TREC-5. In Proceedings of The Fifth Text REtrieval Conference, TREC\n1996, Gaithersburg, Maryland, USA, November 20-\n22, 1996, volume 500-238 of NIST Special Publication. National Institute of Standards and Technology\n(NIST).\nSebastian Hofstätter, Jiecao Chen, Karthik Raman, and\nHamed Zamani. 2023. Fid-light: Efficient and effective retrieval-augmented text generation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information\nRetrieval, pages 1437–1447.\nZiniu Hu, Ahmet Iscen, Chen Sun, Zirui Wang,\nKai-Wei Chang, Yizhou Sun, Cordelia Schmid,\nDavid A. Ross, and Alireza Fathi. 2023. Reveal:\nRetrieval-Augmented Visual-Language Pre-Training\nwith Multi-Source Multimodal Knowledge Memory. In 2023 IEEE/CVF Conference on Computer\nVision and Pattern Recognition (CVPR), pages 23369–\n23379. IEEE.\nJie Huang, Hanyin Shao, Kevin Chen-Chuan Chang,\nJinjun Xiong, and Wen-mei Hwu. 2022. Understanding Jargon: Combining Extraction and Generation\nfor Definition Modeling. In Proceedings of the 2022\nConference on Empirical Methods in Natural Language Processing. Association for Computational\nLinguistics.\nJimmy Xiangji Huang, Jun Miao, and Ben He. 2013.\nHigh performance query expansion using adaptive\nco-training. Inf. Process. Manag., 49(2):441–453.\nWenyu Huang, Mirella Lapata, Pavlos Vougiouklis,\nNikos Papasarantopoulos, and Jeff Z Pan. 2023. Retrieval Augmented Generation with Rich Answer Encoding. Proc. of IJCNLP-AACL, 2023.\nXiangji Huang and Qinmin Hu. 2009. A bayesian learning approach to promoting diversity in ranking for\nbiomedical information retrieval. In Proceedings of\nthe 32nd Annual International ACM SIGIR Conference on Research and Development in Information\nRetrieval, SIGIR 2009, Boston, MA, USA, July 19-23,\n2009, pages 307–314. ACM.\nYizheng Huang and Jimmy Huang. 2024. Exploring\nchatgpt for next-generation information retrieval: Opportunities and challenges. CoRR, abs/2402.11203.\nYizheng Huang and Jimmy X. Huang. 2023. Diversified\nprior knowledge enhanced general language model\nfor biomedical information retrieval. In ECAI 2023 -\n26th European Conference on Artificial Intelligence,\nSeptember 30 - October 4, 2023, Kraków, Poland - Including 12th Conference on Prestigious Applications\nof Intelligent Systems (PAIS 2023), volume 372 of\nFrontiers in Artificial Intelligence and Applications,\npages 1109–1115. IOS Press.\nGautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and\nEdouard Grave. 2022. Unsupervised Dense Information Retrieval with Contrastive Learning. Transactions on Machine Learning Research (TMLR), 2022.\nGautier Izacard and Edouard Grave. 2021. Leveraging\nPassage Retrieval with Generative Models for Open\nDomain Question Answering. In Proceedings of the\n16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,\npages 874–880. Association for Computational Linguistics.\nGautier Izacard, Patrick S. H. Lewis, Maria Lomeli,\nLucas Hosseini, Fabio Petroni, Timo Schick, Jane\nDwivedi-Yu, Armand Joulin, Sebastian Riedel, and\nEdouard Grave. 2023. Atlas: Few-shot Learning with\nRetrieval Augmented Language Models. Journal\nof Machine Learning Research (JMLR), 24:251:1–\n251:43.\nIsrat Jahan, Md. Tahmid Rahman Laskar, Chun Peng,\nand Jimmy Xiangji Huang. 2023. Evaluation of\nchatgpt on biomedical tasks: A zero-shot comparison with fine-tuned generative transformers. CoRR,\nabs/2306.04504.\nBernard J. Jansen, Danielle L. Booth, and Amanda\nSpink. 2009. Patterns of query reformulation during web searching. J. Assoc. Inf. Sci. Technol.,\n60(7):1358–1371.\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,\nDan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Comput.\nSurv., 55(12):248:1–248:38.\nZhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,\nQian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\nCallan, and Graham Neubig. 2023. Active Retrieval\nAugmented Generation. In Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 7969–7992.\nJeff Johnson, Matthijs Douze, and Hervé Jégou. 2021.\nBillion-scale similarity search with gpus. IEEE\nTransactions on Big Data, 7(3):535–547.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601–1611. Association\nfor Computational Linguistics.\nMinki Kang, Jin Myung Kwak, Jinheon Baek,\nand Sung Ju Hwang. 2023. Knowledge\nGraph-Augmented Language Models for\nKnowledge-Grounded Dialogue Generation.\narXiv, abs/2305.18846.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,\nand Wen-tau Yih. 2020. Dense Passage Retrieval for\nOpen-Domain Question Answering. In Conference\non Empirical Methods in Natural Language Processing (EMNLP), pages 6769–6781.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generalization\nthrough Memorization: Nearest Neighbor Language\nModels. In International Conference on Learning\nRepresentations (ICLR).\nO. Khattab, Keshav Santhanam, Xiang Lisa Li, David\nLeo Wright Hall, Percy Liang, Christopher Potts,\nand M. Zaharia. 2022. Demonstrate-Search-Predict:\nComposing retrieval and language models for\nknowledge-intensive NLP. arXiv, abs/2212.14024.\nOmar Khattab and Matei Zaharia. 2020. Colbert - Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proceedings of\nthe 43rd International ACM SIGIR Conference on\nResearch and Development in Information Retrieval,\npages 39–48. ACM.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natural\nQuestions: A Benchmark for Question Answering\nResearch. Transactions of the Association for Computational Linguistics, 7:453–466.\nMd. Tahmid Rahman Laskar, M. Saiful Bari, Mizanur\nRahman, Md Amran Hossen Bhuiyan, Shafiq Joty,\nand Jimmy Xiangji Huang. 2023. A systematic study\nand comprehensive evaluation of chatgpt on benchmark datasets. CoRR, abs/2305.18486.\nMd. Tahmid Rahman Laskar, Enamul Hoque, and\nJimmy X. Huang. 2020. Query focused abstractive\nsummarization via incorporating query relevance and\ntransfer learning with transformer models. In Advances in Artificial Intelligence - 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13-15, 2020, Proceedings,\nvolume 12109 of Lecture Notes in Computer Science,\npages 342–348. Springer.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020a.\nBart: Denoising Sequence-to-Sequence Pre-training\nfor Natural Language Generation, Translation, and\nComprehension. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Linguistics, pages 7871–7880. Association for Computational Linguistics.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\nTim Rocktäschel, Sebastian Riedel, and Douwe\nKiela. 2020b. Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks. In Conference on\nNeural Information Processing Systems (NeurIPS).\nCanjia Li, Andrew Yates, Sean MacAvaney, Ben He,\nand Yingfei Sun. 2024. Parade: Passage Representation Aggregation forDocument Reranking. ACM\nTransactions on Information Systems, 42(2):1–26.\nHuayang Li, Yixuan Su, Deng Cai, Yan Wang, and\nLemao Liu. 2022. A Survey on Retrieval-Augmented\nText Generation. arXiv, abs/2202.01110.\nXingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng\nDing, Shafiq R. Joty, Soujanya Poria, and Lidong\nBing. 2023. Chain-of-Knowledge: Grounding Large\nLanguage Models via Dynamic Knowledge Adapting\nover Heterogeneous Sources. arXiv.\nChin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nSheng-Chieh Lin, Akari Asai, Minghan Li, Barlas\nOguz, Jimmy Lin, Yashar Mehdad, Wen-tau Yih,\nand Xilun Chen. 2023a. How to Train Your Dragon:\nDiverse Augmentation Towards Generalizable Dense\nRetrieval. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 6385–\n6400. Association for Computational Linguistics.\nXi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi,\nMaria Lomeli, Rich James, Pedro Rodriguez, Jacob\nKahn, Gergely Szilvasy, Mike Lewis, and others.\n2023b. Ra-dit: Retrieval-augmented dual instruction tuning. arXiv, abs/2310.01352.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, and Xian Li. 2022. Few-shot Learning with\nMultilingual Generative Language Models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for\nComputational Linguistics.\nYi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen,\nHao Zhou, Fandong Meng, Jie Zhou, and Xu Sun.\n2023. Recall: A Benchmark for LLMs Robustness\nagainst External Counterfactual Knowledge. arXiv,\nabs/2311.08147.\nZiyang Luo, Can Xu, Pu Zhao, Xiubo Geng, Chongyang\nTao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023.\nAugmented Large Language Models with Parametric\nKnowledge Guiding. arXiv, abs/2305.04757.\nXinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,\nand Nan Duan. 2023. Query Rewriting in RetrievalAugmented Large Language Models. In Proceedings\nof the 2023 Conference on Empirical Methods in\nNatural Language Processing, pages 5303–5315. Association for Computational Linguistics.\nYu A. Malkov and D. A. Yashunin. 2020. Efficient\nand robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE\nTransactions on Pattern Analysis and Machine Intelligence, 42(4):824–836.\nChristopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. Introduction to Information Retrieval. Cambridge University Press.\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff\nWu, Long Ouyang, Christina Kim, Christopher\nHesse, Shantanu Jain, Vineet Kosaraju, William\nSaunders, and others. 2021. Webgpt: Browserassisted question-answering with human feedback.\narXiv, abs/2112.09332.\nJianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan,\nKeith Hall, Ming-Wei Chang, and Yinfei Yang. 2022.\nLarge Dual Encoders Are Generalizable Retrievers.\nIn Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages\n9844–9855. Association for Computational Linguistics.\nRodrigo Nogueira, Wei Yang, Kyunghyun Cho, and\nJimmy Lin. 2019. Multi-stage document ranking\nwith BERT. CoRR, abs/1910.14424.\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,\nLama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin,\nSuchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello,\nJake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman,\nTim Brooks, Miles Brundage, Kevin Button, Trevor\nCai, Rosie Campbell, Andrew Cann, Brittany Carey,\nChelsea Carlson, Rory Carmichael, Brooke Chan,\nChe Chang, Fotis Chantzis, Derek Chen, Sully Chen,\nRuby Chen, Jason Chen, Mark Chen, Ben Chess,\nChester Cho, Casey Chu, Hyung Won Chung, Dave\nCummings, Jeremiah Currier, Yunxing Dai, Cory\nDecareaux, Thomas Degry, Noah Deutsch, Damien\nDeville, Arka Dhar, David Dohan, Steve Dowling,\nSheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna\nEloundou, David Farhi, Liam Fedus, Niko Felix,\nSimón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik\nGoel, Tarun Gogineni, Gabriel Goh, Rapha GontijoLopes, Jonathan Gordon, Morgan Grafstein, Scott\nGray, Ryan Greene, Joshua Gross, Shixiang Shane\nGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,\nYuchen He, Mike Heaton, Johannes Heidecke, Chris\nHesse, Alan Hickey, Wade Hickey, Peter Hoeschele,\nBrandon Houghton, Kenny Hsu, Shengli Hu, Xin\nHu, Joost Huizinga, Shantanu Jain, Shawn Jain,\nJoanne Jang, Angela Jiang, Roger Jiang, Haozhun\nJin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo\nJun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak\nKhan, Logan Kilpatrick, Jong Wook Kim, Christina\nKim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros,\nMatt Knight, Daniel Kokotajlo, Łukasz Kondraciuk,\nAndrew Kondrich, Aris Konstantinidis, Kyle Kosic,\nGretchen Krueger, Vishal Kuo, Michael Lampe, Ikai\nLan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy,\nChak Ming Li, Rachel Lim, Molly Lin, Stephanie\nLin, Mateusz Litwin, Theresa Lopez, Ryan Lowe,\nPatricia Lue, Anna Makanju, Kim Malfacini, Sam\nManning, Todor Markov, Yaniv Markovski, Bianca\nMartin, Katie Mayer, Andrew Mayne, Bob McGrew,\nScott Mayer McKinney, Christine McLeavey, Paul\nMcMillan, Jake McNeil, and others. 2023. Gpt-4\nTechnical Report. PREPRINT.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\nJohn Schulman, Jacob Hilton, Fraser Kelton, Luke\nMiller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instructions with human feedback. In Conference on Neural\nInformation Processing Systems (NeurIPS).\nKishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the\n40th Annual Meeting on Association for Computational Linguistics, ACL ’02, page 311–318, USA.\nAssociation for Computational Linguistics.\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with\ngpt-4. arXiv.\nFabio Petroni, Aleksandra Piktus, Angela Fan, Patrick\nLewis, Majid Yazdani, Nicola De Cao, James Thorne,\nYacine Jernite, Vladimir Karpukhin, Jean Maillard,\nVassilis Plachouras, Tim Rocktäschel, and Sebastian\nRiedel. 2021. Kilt: a Benchmark for Knowledge Intensive Language Tasks. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2523–2544. Association for Computational Linguistics.\nFilip Radlinski and Nick Craswell. 2010. Comparing\nthe sensitivity of information retrieval metrics. In\nProceedings of the 33rd International ACM SIGIR\nConference on Research and Development in Information Retrieval, SIGIR ’10, page 667–674, New\nYork, NY, USA. Association for Computing Machinery.\nColin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring\nthe Limits of Transfer Learning with a Unified Textto-Text Transformer. Journal of Machine Learning\nResearch (JMLR), 21:140:1–140:67.\nOri Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-Context Retrieval-Augmented\nLanguage Models. Transactions of the Association\nfor Computational Linguistics, 11:1316–1331.\nOri Ram, Gal Shachaf, Omer Levy, Jonathan Berant,\nand Amir Globerson. 2022. Learning to Retrieve\nPassages without Supervision. In Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence Embeddings using Siamese BERTNetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\n3980–3990. Association for Computational Linguistics.\nStephen Robertson and Hugo Zaragoza. 2009. The\nProbabilistic Relevance Framework: Bm25 and Beyond. Foundations and Trends® in Information Retrieval, 3(4):333–389.\nJon Saad-Falcon, O. Khattab, Christopher Potts, and\nMatei Zaharia. 2023. Ares: An Automated Evaluation Framework for Retrieval-Augmented Generation\nSystems. arXiv, abs/2311.09476.\nSara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita\nCucchiara. 2022. Retrieval-Augmented Transformer\nfor Image Captioning. In International Conference\non Content-based Multimedia Indexing. ACM.\nES Shahul, Jithin James, Luis Espinosa Anke, and\nS. Schockaert. 2023. Ragas: Automated Evaluation of Retrieval Augmented Generation. arXiv,\nabs/2309.15217.\nZhihong Shao, Yeyun Gong, Yelong Shen, Minlie\nHuang, Nan Duan, and Weizhu Chen. 2023. Enhancing Retrieval-Augmented Large Language Models\nwith Iterative Retrieval-Generation Synergy. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9248–9274. Association\nfor Computational Linguistics.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\nWen-tau Yih. 2023. Replug: Retrieval-augmented\nblack-box language models. arXiv, abs/2301.12652.\nZhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and\nDenny Zhou. 2023. Recitation-Augmented Language Models. In International Conference on Learning Representations (ICLR).\nYi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia,\nJason Wei, Xuezhi Wang, Hyung Won Chung, Dara\nBahri, Tal Schuster, Huaixiu Steven Zheng, Denny\nZhou, Neil Houlsby, and Donald Metzler. 2023. Ul2:\nUnifying Language Learning Paradigms. In International Conference on Learning Representations\n(ICLR).\nYi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara\nBahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao,\nJai Prakash Gupta, Tal Schuster, William W. Cohen,\nand Donald Metzler. 2022. Transformer Memory\nas a Differentiable Search Index. In Conference on\nNeural Information Processing Systems (NeurIPS).\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFever: a Large-scale Dataset for Fact Extraction\nand VERification. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers),\npages 809–819. Association for Computational\nLinguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothee Lacroix,\nBaptiste Roziere, Naman Goyal, Eric Hambro, Faisal\nAzhar, and others. 2023a. Llama: Open and efficient\nfoundation language models. arXiv, abs/2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter\nAlbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\nShruti Bhosale, and others. 2023b. Llama 2: Open\nfoundation and fine-tuned chat models. arxiv,\nabs/2307.09288.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\nand Ashish Sabharwal. 2023. Interleaving Retrieval\nwith Chain-of-Thought Reasoning for KnowledgeIntensive Multi-Step Questions. In Proceedings of\nthe 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npages 10014–10037. Association for Computational\nLinguistics.\nAshish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Neural Information Processing Systems, pages 5998–6008.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel R. Bowman. 2019. Superglue: A Stickier Benchmark for General-Purpose Language Understanding Systems. In Conference on Neural Information Processing Systems (NeurIPS), pages 3261–\n3275.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/\nmesh-transformer-jax.\nLiang Wang, Nan Yang, and Furu Wei. 2023a.\nQuery2doc: Query Expansion with Large Language\nModels. In Proceedings of the 2023 Conference on\nEmpirical Methods in Natural Language Processing,\npages 9414–9423. Association for Computational\nLinguistics.\nXintao Wang, Qian Yang, Yongting Qiu, Jiaqing Liang,\nQi He, Zhouhong Gu, Yanghua Xiao, and W. Wang.\n2023b. Knowledgpt: Enhancing Large Language\nModels with Retrieval and Storage Access on Knowledge Bases. arXiv, abs/2308.11761.\nBigScience Workshop, Teven Le Scao, Angela Fan,\nChristopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel\nHesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, and others. 2022. Bloom: A\n176b-parameter open-access multilingual language\nmodel. arXiv, abs/2211.05100.\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\nArnold Overwijk. 2021. Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text\nRetrieval. In International Conference on Learning\nRepresentations (ICLR).\nFangyuan Xu, Weijia Shi, and Eunsol Choi. 2023. Recomp: Improving Retrieval-Augmented LMs with\nCompression and Selective Augmentation. arXiv,\nabs/2310.04408.\nHaoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang,\nNing Cheng, Ming Li, and Jing Xiao. 2023a. Prca:\nFitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable RewardDriven Contextual Adapter. In Proceedings of the\n2023 Conference on Empirical Methods in Natural\nLanguage Processing, pages 5364–5375. Association\nfor Computational Linguistics.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A Dataset for\nDiverse, Explainable Multi-hop Question Answering.\nIn Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages\n2369–2380. Association for Computational Linguistics.\nZhuolin Yang, Wei Ping, Zihan Liu, Vijay Korthikanti,\nWeili Nie, De-An Huang, Linxi Fan, Zhiding Yu,\nShiyi Lan, Bo Li, Mohammad Shoeybi, Ming-Yu\nLiu, Yuke Zhu, Bryan Catanzaro, Chaowei Xiao, and\nAnima Anandkumar. 2023b. Re-ViLM: RetrievalAugmented Visual Language Model for Zero and\nFew-Shot Image Captioning. In Findings of the Association for Computational Linguistics: EMNLP 2023,\npages 11844–11857. Association for Computational\nLinguistics.\nShi Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong,\nPaul N. Bennett, Jianfeng Gao, and Zhiyuan Liu.\n2020. Few-shot generative conversational query\nrewriting. In Proceedings of the 43rd International\nACM SIGIR conference on research and development\nin Information Retrieval, SIGIR 2020, Virtual Event,\nChina, July 25-30, 2020, pages 1933–1936. ACM.\nWenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,\nMingxuan Ju, Soumya Sanyal, Chenguang Zhu,\nMichael Zeng, and Meng Jiang. 2023a. Generate\nrather than Retrieve: Large Language Models are\nStrong Context Generators. In International Conference on Learning Representations (ICLR).\nWenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu,\nQingyun Wang, Heng Ji, and Meng Jiang. 2022. A\nsurvey of knowledge-enhanced text generation. ACM\nComput. Surv., 54(11s):227:1–227:38.\nZichun Yu, Chenyan Xiong, Shi Yu, and Zhiyuan Liu.\n2023b. Augmentation-Adapted Retriever Improves\nGeneralization of Language Models as Generic PlugIn. In Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 2421–2436. Association for\nComputational Linguistics.\nYi Yuan, Haohe Liu, Xubo Liu, Qiushi Huang, Mark D\nPlumbley, and Wenwu Wang. 2023. RetrievalAugmented Text-to-Audio Generation. arXiv,\nabs/2309.08051.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, and others.\n2022. Opt: Open pre-trained transformer language\nmodels. arXiv, abs/2205.01068.\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,\nHeng-Tze Cheng, E. Chi, Quoc V. Le, and Denny\nZhou. 2023. Take a Step Back: Evoking Reasoning\nvia Abstraction in Large Language Models. arXiv,\nabs/2310.06117.\nHonglei Zhuang, Zhen Qin, Rolf Jagerman, Kai Hui,\nJi Ma, Jing Lu, Jianmo Ni, Xuanhui Wang, and\nMichael Bendersky. 2023. Rankt5: Fine-Tuning T5\nfor Text Ranking with Ranking Losses. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information\nRetrieval. ACM.']",I don't know.,0.0,0.0,0.00043975373790677223,0.0,0.0
What did the goblins say?,No answer,"['Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 ""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 'Space Babies\n\nOriginal Airdate: 11 May 2024\n\n[Tardis]\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\nRUBY: Who are you?\nDOCTOR: I\'m the Doctor. You don\'t have to stand over there. Come and have a look. It\'s called the Tardis.\n(Snaps his fingers and the lighting changes.)\nRUBY: Ooo! Nice! But hold on. I can\'t call you Doctor. No, I want to know your name.\nDOCTOR: Yeah, that\'s er... that\'s tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They\'d use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you\'re a doctor, but you\'re... the police?\nDOCTOR: Police box. No. No, no, no, no, that\'s a disguise.\nRUBY: Oh.\nDOCTOR: Inside, it\'s a Time and Space machine, but outside, it\'s like a chameleon, \'cos once I landed in 1963 and they used to have police boxes on street corners.\nRUBY: 1963?\nDOCTOR: Yep.\nRUBY: Okay. Ooo, jukebox. I like that.\nDOCTOR: Mmm.\nRUBY: Okay, so, back to the planet.\nDOCTOR: My world was called Gallifrey.\nRUBY: Gallifrey? And where\'s that?\nDOCTOR: Gone! Ruby, it\'s gone. It\'s gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\nDOCTOR: Let\'s have a random landing.\nRUBY: Whoa!\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\nRUBY: No!\nDOCTOR: Really.\nRUBY: No, you\'ve got to be k... You are kidding. Don\'t be so ridiculous. Are there dinosaurs out there?\nDOCTOR: I don\'t know. Go and have a look.\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\nDOCTOR: Well, that\'s not going to happen, is it? Who steps on butterflies? You\'d literally have to be like, ""Wait. Come \'ere, butterfly! ""Come \'ere, \'ave it!""\n\n[Prehistoric Earth]\n\nRUBY: Oh, my God. That... that\'s so beautiful.\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we\'ve moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\n(A boot steps on a butterfly.)\nDOCTOR: Oh!\n(Ruby is no longer a human.)\nRUBATHON: What\'s wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\nDOCTOR: But...\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let\'s try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let\'s go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.\nRUBY: Ah, six!\nDOCTOR: Six! Ah! Five numbers! I like it!\n(The Tardis travels the Vortex.)\n\n[Space station]\n\nRUBY: But we\'re indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\nDOCTOR: We\'ve got to visit them one day.\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\nDOCTOR: Oh, it\'s, er... it\'s broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\nRUBY: Oh, it stinks\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\nRUBY: No, you\'ve made it worse.\n(Something snarls nearby. They both jump.)\nDOCTOR: No, that is worse.\nRUBY: Is that a monster?\nDOCTOR: No. No, don\'t be silly, Ruby. There\'s no such thing as monsters, there\'s just... just creatures you haven\'t met yet. Hi there.\n(The creature roars.)\nRUBY: Run?\nDOCTOR: Run! Run! Run!\n(They and the monster are visible on monitors as they run down passages.)\nDOCTOR: Come on! In here, in here, in here, in here.\nRUBY: But...now we\'re trapped! Now we\'re trapped! Push the button! Doctor!\nDOCTOR: Okay.\n(The tiny one-person lift takes them up. The Doctor\'s hand is over Ruby\'s eyes.)\nDOCTOR: Oh, yeah, yeah.\n(The lift abruptly arrives.)\n\n[Birth Zone 6]\n\nDOCTOR: The question is, why did I run?\nRUBY: \'Cos it was scary.\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn\'t run fast enough. I was like whoosh!\nRUBY: Well, it\'d help if we knew where we were.\nDOCTOR: Yet again, push the button.\n(The lights come on so they can see all the glassware, containing...)\nDOCTOR: Oh. Oh, we\'re on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\nRUBY: I was going to say the same thing to you.\nDOCTOR: We\'ve gone from baby to baby. I\'m not saying things are connected, and yet... things connect.\nRUBY: Well, I\'m the one looking for my parents, and you\'ve got a Time and Space machine. So this place grows babies. What for? Food?\nDOCTOR: Food? What? What?! Food? They\'re not tomatoes!\nRUBY: Well, excuse me. There\'s a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don\'t know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday. I don\'t have a people. I don\'t have a home. But I don\'t have a job, either. I don\'t have a boss, or taxes or rent or bills to pay. I don\'t have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\nRUBY: So where\'s this, then?\nDOCTOR: Oh, er...\n(Calls it up on a screen.)\nDOCTOR: Huh. Planet Pacifico del Rio.\nRUBY: Oh, that\'s in English. They speak English here? English exists?\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It\'s got a perception filter, so it helps you fit into every time and place.\nRUBY: Right, and my mum, she\'s long gone now.\nDOCTOR: Can I see your phone?\nRUBY: Yes.\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\nRUBY: What?\nDOCTOR: Carla. Phone her.\nRUBY: But...\nDOCTOR: Your mum, Ruby. Call your mum.\n\n[Ruby\'s home / Birth Zone 6]\n\nCARLA: Well? What is it now?\nRUBY: Mum?\nCARLA: Yes, Mum, obviously. You\'ve just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\nRUBY: Yeah. Yes, I will... I\'ll, er... I\'ll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\n\n[Birth Zone 6]\n\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That\'s the best signal ever. How much does that cost?\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It\'s calm up here, but underneath it is seething, just like downstairs with that creature. There\'s got to be a crew or a captain...\n(Enter a child in a motorised push-chair.)\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I\'ve opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can\'t...\nDOCTOR: Hi.\nRUBY: You all right?\nERIC: But... you. Oh. We\'ve been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we\'re not...\nERIC: Boys-oh-boys, I\'ve got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They\'re here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we\'ve been doing. Make them proud.\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\nMARCEL?: My job is to keep the pipes clean. I\'m proud of the pipes.\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\nSANDRA?: And I pull this string and that string. I\'m not sure what they do, but I pull them very hard.\nERIC: And I made this for you. It\'s a little flower.\nRUBY: Thank you.\nPOPPY: I\'m Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you\'d come back for us one day. We waited.\nDOCTOR: Right. You\'re not supposed to be running this place. This isn\'t Baby World. You got left behind when the adults... ..vamoosed?\nPOPPY: We took over. We were very brave.\nRUBY: Right. That\'s great. That\'s, oh, that\'s good. That\'s amazing. You\'ve done a really great job.\nDOCTOR: I\'m sorry, Poppy, I\'m so sorry, but we are not your mummy and daddy. I wish we were, but we\'re not.\nERIC: They left us. Where did they go?\nRUBY: I don\'t know, darling, but... I\'m Ruby and this... this is the Doctor. And we\'re your friends. Yeah, got you. I\'ve got you, I\'ve got you, I\'ve got you, I\'ve got you.\n(She picks up Eric from his pushchair.)\nBABIES: And me! And me! And me! And me!\nDOCTOR: Oh, gosh.\nBABIES: And me! And me!\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\nPOPPY: Never.\nDOCTOR: Oh. Oh, baby, it\'s okay. Come here, it\'s okay. It\'s okay, it\'s okay. Shh-shh-shh. Aww, never had a hug.\nRUBY: Come on, you can all have a hug.\n(Later, with everyone back in their pushchairs.)\nPOPPY: Did I get things wrong, Doctor\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don\'t know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\nPOPPY: But are we wrong?\nDOCTOR: What do you mean?\nPOPPY: We\'re not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That\'s okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don\'t know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That\'s it, P-P-P-P-Pop. But the point is, is that it doesn\'t matter where I come from, because I am absolutely lovely, aren\'t I?\n(Poppy yawns.)\nDOCTOR: That wasn\'t rhetorical, Pops.\nPOPPY: Yes, you are.\nDOCTOR: And do you want to know my secret? There\'s no one like me in the whole wide universe. No one like me exists, and that\'s true of everyone.\nIt\'s not a problem, Captain Pops. It\'s a superpower. High five. Yeah.\nPOPPY: Yeah!\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\nRUBY: So you\'re Eric. And you\'re Tasha. And Ruben. And then there\'s Saltine and Boo.\nERIC: I love you, Ruby.\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\nERIC: We\'ve got Nanny. Say hello, Nanny.\nNAN-E: Good afternoon, children, and welcome to our new visitors.\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I\'m the Doctor, and this is Ruby.\nNAN-E: We have visitors, children.\nERIC: Nanny!\nNAN-E: Noses must be blown. Activate nose-blow.\nDOCTOR: Er...\nNAN-E: One, two, three and... blow.\n(Mechanical hands on the pushchairs put handkerchiefs to the babies\' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\nRUBY: Oh, can\'t wait to see that.\nDOCTOR: Right. So it\'s you lot? It\'s Nan-E And downstairs, is that your pet dog?\n(Everyone screams and cries.)\nERIC: That\'s not a doggo.\nRUBY: What is it then, Eric?\nERIC: The Bogeyman.\nRUBY: Shush, shush, shush. Shush, shush, shush.\nDOCTOR: No. Gosh.\nERIC: We don\'t like the Bogeyman.\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\nDOCTOR: Bogeyman!\nRUBY: No, stop it! No, stop it! Nan-E, tell them there\'s no such thing as the Bogeyman.\nNAN-E: Nan-E is scared of the Bogeyman.\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I\'m sorry, I\'m sorry. I\'m sorry, babies. Space babies. I\'m sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what\'s that?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: That\'s on this floor. What is it?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\nNAN-E: Oh, for God\'s sakes, 3-5-7. Come on!\nRUBY: Where do you think you\'re going?\nDOCTOR: Portal 3-5-7!\nRUBY: Right. Great. Ok. Coming!\n\n[Corridor]\n\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That\'s like your... purpose?\nDOCTOR: No, no, I\'m just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum\'s still waiting for me.\nDOCTOR: Back home, on your birthday. Yeah, it\'s strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don\'t know anything about your birth mother or your father? They didn\'t leave a note or a scrap of paper...?\nRUBY: Nothing. I was... I was just left.\nDOCTOR: By the church.\nRUBY: In the snow.\nDOCTOR: On Ruby Road.\n(The Doctor sees a figure point at him by the church.)\nRUBY: Doctor...\nDOCTOR: What?\nRUBY: It\'s snowing. Okay, what just happened? I said snow, and we\'ve got... ..snowflakes.\nDOCTOR: It\'s like a memory just came through, from the day that you were born.\nRUBY: But how? Is this the sort of thing that happens with time travel?\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\nRUBY: Then what does it mean?\nDOCTOR: I don\'t know.\n(The snow has stopped.)\nDOCTOR: Oh, I thought my birth was crazy...\nRUBY: Oh, yeah.\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\n(A door opens.)\nJOCELYN: I said Portal 3-5-7. Don\'t just stand there yapping, you pair of idiots. Get inside!\nRUBY: Who\'s she?\nDOCTOR: Nan-E. Ha!\nRUBY: Oh.\n\n[Portal 357]\n\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I\'m signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I\'d like to say for the record, the company\'s actions are appalling. I will be launching an appeal against this as soon as we\'re home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It\'s the recession. The government closed the Babystation to save money, but the law says it\'s illegal to stop the birth machine.\n(Another leak, another thump with the wrench.)\nJOCELYN: But how did you arrive? Have you got a way out of here?\nDOCTOR: I\'ve got a ship, yeah, it\'s er... What is your name - sorry, Nan-E?\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don\'t know how this place works.\n(The Doctor plugs his sonic into the computer.)\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\nJOCELYN: Thank you. Wanna swap?\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they\'re born, they don\'t look after them?\nJOCELYN: It\'s a very strange planet.\nRUBY: It\'s not that strange.\nDOCTOR: But you stayed behind.\nJOCELYN: I couldn\'t leave them. And I tried with this place. But I\'m not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It\'s a mess. And I\'ve been all on my own, watching the kids, for six years.\nDOCTOR: But I don\'t understand. They are gorgeous. Why would you hide?\nJOCELYN: Cos I don\'t want to see them die. And I don\'t want them to see me die. \'Cos that\'s how bad it is. This is a closed station. There\'s only so much air. There\'s only so much food. The last thing I\'ll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\nRUBY: Can\'t you fly somewhere else?\nJOCELYN: What do you mean, fly?\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can\'t move. It\'s just stuck in orbit, which is a shame, because this is a nice little system.\nJOCELYN: The fifth planet out, Mondo Caroon, that\'s a DuBarryDuPlessy world.\nDOCTOR: Oh, that\'s good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\nRUBY: Oh. Well, can\'t we call them for help?\nJOCELYN: They don\'t go and fetch refugees. That\'s the fate of every refugee in the universe. You physically have to turn up on someone else\'s shore. And we can\'t move.\nDOCTOR: But now you have a ship. Plenty of room. It\'s called the Tardis. The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don\'t know?\nJOCELYN: It\'s nothing to do with me. It\'s not part of the manifest. It\'s not like anything I\'ve ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it\'s terrifying.\nDOCTOR: Yeah, but I\'ve met a million ugly bugs. I\'m an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you\'ve got babies, you\'ve got a nanny, and you\'ve got the Bogeyman. You\'ve literally got a monster living down below. It\'s a children\'s story come to life.\nDOCTOR: And every story has its hero.\n(They spot someone on the screen.)\nRUBY: That\'s Eric. Is that Eric?\nJOCELYN: Eric, get out of there.\n\n[Space station]\n\nNAN-E: Eric, please vacate this area.\n\n[Portal 357]\n\nDOCTOR: Oh, is that how it works?\nJOCELYN: Nan-E filter. Eric, get out now.\n\n[Space station]\n\nNAN-E: Eric will leave immediately.\nERIC: No, Nanny! I\'m being brave.\n\n[Portal 357]\n\nJOCELYN: Eric, for God\'s sake, run!\n\n[Space station]\n\nNAN-E: Eric, invoking the deity, accelerate perambulation.\nERIC: I\'m doing what Ruby said.\n\n[Portal 357]\n\nRUBY: What?\n\n[Space station]\n\nERIC: I love Ruby, and she said there\'s no such thing as the Bogeyman. So I\'m going to find the naughty doggo and tell him off.\n(He meets the Bogeyman.)\nERIC: But I\'m so scared.\n\n[Portal 357]\n\nRUBY: Oh, my God, it\'s my fault!\n\n[Birth Zone 6]\n\nRUBY: Eric, I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming!\n\n[Space station]\n\n(Ruby and the Doctor take the little lift down, and find Eric\'s pushchair fallen over.)\nRUBY: Oh.\nDOCTOR: Nan-E, where\'s the Bogeyman?\n\n[Portal 357]\n\nJOCELYN: It\'s about 400 metres north-west of you. But still no sign of Eric. I can\'t get a proper fix. I told you, these systems are a crock of...\n\n[Space station]\n\nNAN-E: ..waste products.\nDOCTOR: Mind your language, Nan-E.\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\nDOCTOR: Yes.\nRUBY: Okay, right.\nDOCTOR: Yes. Yes, yes.\n(They pick up things to hit the pipework with and move off.)\nRUBY: Bogeyman! Bogeyman!\nBOTH: Bogeyman! Bogeyman!\n\n[Portal 357]\n\nJOCELYN: It\'s moving. It\'s heard you.\n\n[Space station]\n\nRUBY: Okay, nice plan, but what now?\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. \'Cos I can detect...\n(In a locker.)\nDOCTOR: Space baby! Oh, Eric.\nRUBY: We\'ve got you, we\'ve got you.\nDOCTOR: Oh, you poor thing. It\'s okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It\'s all right, it\'s all right. It\'s all right, it\'s all right, it\'s all right. All right, all right. It\'s all right.\nRUBY: It\'s okay, it\'s okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don\'t you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It\'s a dead end.\n(The Bogeyman is there.)\nDOCTOR: Whoa! It\'s okay, it\'s okay. You\'re okay.\n(The Bogeyman is attacked by flames. It runs away.)\nPOPPY: Babies to the rescue!\nDOCTOR: Ha! Space babies!\nRUBY: Babies with a flame-thrower!\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\n(He whistles up Eric\'s pushchair.)\nRUBY: Okay, let\'s get you in here, come on. Let\'s get you in there. Nan-E, tell them what to do.\nNAN-E: Children will return to the upper levels or have no expletive dinner.\nBABIES: Goodbye.\nDOCTOR: Okay, er, you... you go with them. I\'ve got to stay here. Not just for the Tardis, but I\'ve got to find out what that thing is.\nRUBY: If that\'s you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\n(They head back through the stinky area.)\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\n\n[Portal 357]\n\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don\'t know how it even exists.\n\n[Space station]\n\nRUBY: And that was six years ago?\nDOCTOR: Shh-shh-shh.\nRUBY: Oh. That\'s the same time the babies were born.\nDOCTOR: It\'s leaving... some sort of spoor. Man, that\'s a good word. Spoor.\nNAN-E: What the bleep-bleep is that?\nRUBY: Oh, Jocelyn, turn the filter off.\n\n[Portal 357]\n\nJOCELYN: What is that stuff?\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\nJOCELYN: The machine\'s got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\n\n[Space station]\n\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\n(She slips then gets dribbled on from a pipe outlet.)\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don\'t call me Rubes!\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let\'s make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We\'ve been saying it all along. It\'s all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It\'s like a story. The teaching software, it told a story.\nDOCTOR: It invented the Bogeyman.\nRUBY: For the babies.\nDOCTOR: For the space babies.\nRUBY: The machine is literal, like a computer. It literally said, ""Babies need fiction, they need stories, they need monsters.""\nDOCTOR: Yes. That is why I\'m so scared. It\'s all deliberate, it\'s infrasound. The Bogeyman is roaring at 17 hertz, that\'s the exact pitch designed to make you scared. It\'s scary because it\'s meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\nRUBY: What.\nDOCTOR: Oh, Ruby.\nRUBY: What?\nDOCTOR: Oh, man.\nRUBY: Tell me what it is.\nDOCTOR: I can\'t.\nRUBY: Doctor!\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\nRUBY: I don\'t know.\nDOCTOR: The machine is literal, and the name is Bogeyman.\nRUBY: So?\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\nRUBY: What?\nDOCTOR: All of this is bogeys.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: No wonder it was shedding its skin. Doesn\'t everyone?\nRUBY: No, no, no, no.\nDOCTOR: It\'s snot.\nRUBY: It\'s not.\nDOCTOR: Oh, Ruby, it is a living sneeze!\nRUBY: But it\'s in my...\nDOCTOR: I know.\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don\'t laugh!\nDOCTOR: Sorry. Oh, isn\'t the universe mad?\nRUBY: Oh yeah, it just made a monster out of snot.\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\n(The monster is in front of them.)\nRUBY: Bogeyman.\nDOCTOR: Run. Run! Go!\n(A barrier blocks their path.)\nDOCTOR: No, no, no, no!\n\n[Portal 357]\n\nJOCELYN: Don\'t worry, it\'s me. Turn right. It\'s your device. It\'s calibrated. It\'s brilliant! I\'ve got control at last. Now trust me. Turn right!\nDOCTOR [on screen]: This isn\'t the way to the lift!\nJOCELYN: Keep going.\n(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I\'m coming, I\'m coming!\n\n[Portal 357]\n\nJOCELYN: It\'s catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I\'ve got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It\'s an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn! I... She\'s got the sonic. Jocelyn, Jocelyn!\nCOMPUTER: Oxygen field at 10%.\nDOCTOR: Okay, okay, okay, okay. We haven\'t got time. Stop Jocelyn, yeah?\nRUBY: Wait...\nDOCTOR: Left, second right, next left, you\'ll get to the lift.\nRUBY: What about you?\nDOCTOR: Left, second right, next left!\nRUBY: Right, okay.\n(She runs off.)\n\n[Control room]\n\nCOMPUTER: Oxygen field at 9%.\nPOPPY: You\'re hurting him.\nERIC: Stop it, Nanny. Stop it!\nCOMPUTER: Oxygen field at 8%.\n\n[Airlock door]\n\nDOCTOR [memory]: I am the last of the Time Lords.\nRUBY [memory]: How do you keep going?\nDOCTOR [memory]: For days like this. I\'m the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\nDOCTOR: The only one of its kind.\nCOMPUTER: Oxygen field at 7%.\n(The Doctor opens the airlock door and holds it open with his body.)\nCOMPUTER: Oxygen field at 6%.\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\nCOMPUTER: Oxygen field at 3%.\nDOCTOR: Push...the button.\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\n\n[Portal 357]\n\n(Ruby runs in and grabs the sonic.)\nJOCELYN: No!\nRUBY: That\'s what you do, Jocelyn. You save them all.\nCOMPUTER: Oxygen field at 1%.\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\nRUBY: You save them all. Come here. It\'s okay, it\'s okay.\n(Jocelyn cries in Ruby\'s arms.)\n\n[Control room]\n\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\nERIC: Nanny was really naughty.\nJOCELYN: I know, and I\'m so sorry. All of you. I was just... on my own for such a very long time.\nERIC: We still love you, Nanny.\nBABIES: Yay! We do!\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\nBABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can\'t get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? \'Cos the system went wrong, and that\'s where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\nDOCTOR: Oh, set sail for your new home. Baby World!\nRUBY: Come here now. Are you happy now, Eric?\nERIC: I\'m very, very happy. I love you, Ruby.\n\n[Outside the Tardis]\n\nRUBY: So that was a normal day for you, then?\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\nRUBY: What for?\nDOCTOR: I have the whole universe at my fingertips, and I\'m all on my own. So I\'d love it if you came with me.\nRUBY: To what, just travel?\nDOCTOR: No job. No boss. Just fun.\nRUBY: We did almost die.\nDOCTOR: Yes. But we lived so much, too.\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\nDOCTOR: Yes?\nRUBY: Yes.\nDOCTOR: Yes?\nRUBY: Yes. Oh, my God.\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\nRUBY: Come on in. Follow me.\nDOCTOR: Oh, come on.\n\n[Tardis]\n\nRUBY: Right, mate, let me tell you where we\'re gonna go.\nDOCTOR: Except...\nRUBY: Oh, terms and conditions.\nDOCTOR: There is one thing that I can never do, Ruby. And that\'s take you to that church on Ruby Road that Christmas. Absolutely never.\nRUBY: But you\'ve got a time machine.\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother\'s story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can\'t. And I won\'t.\nRUBY: Well, that\'s a pity. \'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\n\n[Ruby\'s home]\n\nCARLA: (on phone) And Ruby phoned, she said, ""I love you,"" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What\'s that noise?\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\nCHERRY: What the blinking flip?\n(Tardis door opens.)\nRUBY: Hiya, Mummy.\nCARLA: But... what are you doing? And what the hell is that? What\'s it done to my kitchen?\n\n[Tardis]\n\nRUBY [OC]: Hey! Come and say hello!\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\n(He sonicks up a quick DNA scan of Ruby Sunday.)\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\n(He doesn\'t wait for the results of the scan.)']",I don't know.,0.0,0.0,0.0006968641114982578,0.0,0.875
What relgion are the members of the Hoss family?,No answer,"['Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.'
 '‘The Zone Of Interest’ Ending Explained & Film Summary: What Happens To Rudolf And Hedwig Hoss?\nPUBLISHED\n\nFEBRUARY 21, 2024\nBY\nSOURYA SUR ROY\n0COMMENTS\nThe Zone Of Interest Ending Explained Film Summary Hedwig Ross, Rudolph Ross\nCredits: A24\nThe Zone of Interest is a new historical drama film by English filmmaker Jonathan Glazer that manages to recreate a terrible moment from history with a unique and devastating effect. Loosely adapted from Martin Amis’ novel of the same name, the film’s plot follows the Hoss family, who live right beside the Auschwitz concentration camp, going about their usual lives with no concern for the terrible crimes being committed right outside. The Zone of Interest is all about subtle, indirect expressions that are poignant enough to pierce through the visual layer, successfully making the viewer all the more uncomfortable with every passing minute.\n\nSpoiler Alert\n\nPlot Summary: What Is The Film About?\nThe Zone of Interest opens with a noticeably long black screen, with only a soft sound being eerily stretched in the background, perhaps preparing us for what is to unfold on screen over the next hundred or so minutes. When the visuals come on, though, there is nothing unusual or out of the ordinary, as a family is seen spending some personal time by the forested banks of a river. This is a secluded spot reserved only for the family, and it seems to be their most common way of spending leisure time. As the girls are led by a nanny through the bushes, possibly for some lesson in gardening and wildlife, the boys jump into the river along with their father. Sometime later, the family reunites and leaves the riverbank, driving away in two black, sinister-looking cars. On that very night, the father of the house is seen going around, switching off all the lights, before going to bed.\n\nWhile there is really nothing odd in this whole presentation of a family spending a day with themselves, the chilling reality of the matter is revealed when the film introduces the particular lot. The family is that of Rudolf Hoss, a notorious real figure from history, infamous for being a distinguished SS officer and the commander of the Auschwitz concentration camp. Most of the entire film, and the whole of the opening scene, actually takes place in Auschwitz, meaning that the leisurely picnic of the big family literally took place only a few miles away from the spot of the ongoing genocide. This is the very premise of The Zone of Interest, for it shows the tumultuous time of history from the perspective of the Hoss family, mainly the patriarch Rudolf and his wife, Hedwig.\n\nThe couple lives in an idyllic resort with their two sons and three daughters, the youngest still a baby, right on the other side of the high walls of the concentration camp. Despite the inhuman torture and killing going on right outside the walls that separate their lives, the Hoss family members are not perturbed by the matter at all. Instead, they are rather accustomed to Auschwitz, cherishing their time and accepting it as their new home.\n\nHow Does The Film Powerfully Present The Harrowing Events Of The Holocaust?\nThe most remarkable thing about The Zone of Interest is how it manages to say so much without directly saying it, combining the visual and the aural through a unique dissonance. With regards to the visuals, meaning scenes that play out to take forward the mostly simple and common story, the camera hardly ever leaves the confines of the host house. While some exceptions take place towards the latter part of the film, when Rudolf is transferred to a different concentration camp and he is seen at his new post, almost no scene of the camp in Auschwitz is seen. But the audio track picks up on numerous cries, lashes, and sounds that clearly come from the outside world but are heavily ignored. There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf’s family and his subordinates celebrate the man’s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers. But nobody seems to notice, or rather, everyone pretends to look through the entire matter, as if nothing shocking is in the works. Rudolf is also seen meeting with a businessman in his house, who comes to show the commander plans and designs for a new, more effective gas chamber that he wants to build for his government. Rudolf goes through the plans without any hesitation and then also reports about this businessman’s portfolio to his higher authorities, convinced that sturdier and better-designed gas chambers are needed to take his beloved nation and his government forward. The Zone of Interest does not really differentiate between evil-doers and those supporting such evil, but Rudolf is definitely in the first category, as he clearly enjoys the torture and killing of people.\n\nWhat comes as even a bigger shock is the reaction of his wife, Hedwig, for she does not react to any of these massacres either. Rather, the woman is extremely accustomed to the life of the commander’s wife, and she enjoys the perks it brings along. She often receives luxury and expensive items that have been taken away from the prisoners, and on one particular occasion, she is seen receiving a fancy fur coat, since the Nazis did not differentiate between the rich and the poor among their targets. Hedwig immediately throws the coat on her body and tries it out in front of the mirror, only to realize that there is still lipstick lying inside one of the pockets. The presence of the lipstick would obviously be a bold reminder to anyone of the previous owner of the coat and the atrocious torture she must be subjected to at present. However, Hedwig has been wired to not think like that, and instead of any guilt or remorse, she feels rather excited to try on the lipstick, which is now hers as well.\n\nHedwig maintains a calm and composed nature, without any worry in the world, as she focuses on her gardening and getting a pool built for her children in their compound. The thick, dark smoke from the chimneys of the gas chambers on one side and from the steam engine train that brings in Jewish prisoners every day on the other does not affect the woman at all. The irony of the matter is all the more glaring when Hedwig is absolutely livid that her husband has to be transferred away from Auschwitz. She decides to stay back at the place along with her children because she is unwilling to uproot the life she had built there, including the fancy garden and the greenhouse, and shift somewhere else, which is probably too cold for her comfort as well. The fact that thousands were being faced with worse persecution and millions more would be uprooted, killed, or left disbanded very easily eludes her thought. In this regard, Jonathan Glazer’s film is a really fascinating note on not just the Holocaust but also the effect of systematized violence and the tendency of the masses to side with the oppressors in any given scenario.\n\nThe Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people. As soon as Rudolf finds a skull and some ashes in the river that he and his sons were bathing in, he scurries back to his house, and the children are scrubbed clean with utmost precision. In another instance, it is suggested that Rudolf forces himself upon a helpless prisoner woman, but he ensures that he scrubs his private parts before retiring for the night.\n\nThe only exception to the unaffected response by the entire family is by Hedwig’s mother, who finds it bizarre that her daughter, her husband, and their children can really live at such a place. The elderly woman definitely has no sympathies for the prisoners, though, but she is rather unable to live with so many signs and reminders of death all around. The stench of burning human bodies and the ash flying around keep her up all night, but the very same elements are like playthings for the two young boys who still lay awake in their room. On a similar night, filled with reminders of the ongoing genocide, Hedwig is seen asking Rudolf to take her on a romantic trip, in the most romantic conversation between the couple in the film. Ultimately, the mother leaves the house unannounced very early the next morning, only leaving behind a note for her daughter. Hedwig simply tosses the note into her furnace insignificantly, almost insulted that someone would find her beloved home distasteful or discomforting. Even after Rudolf leaves for Oranienburg, Hedwig stays at their Auschwitz house with the children.\n\nWhat Do The Scenes In Infrared Signify?\nThe Zone of Interest also sparsely presents a few scenes, in which an unacquainted young girl is seen going around Auschwitz, hiding apples and other meager food items inside the trenches. She is clearly doing this extremely dangerous work only to help the prisoners and ease their suffering in whatever little way she can. But interestingly, these scenes are in infrared, or negative, although only as long as the girl is in the outside world. As soon as she returns home, the visuals turn normal, then switch to infrared when she or her mother step out on the balcony. The family is revealed to be Polish locals who have no interest in Nazi ideals and dream of liberation one day. However, the mere fact that the family is still alive, irrespective of whether they are Jewish or not, suggests that they also have to work as collaborators for the Nazis to a certain degree. This was definitely the case with numerous non-Jews during the Nazi occupation who had to work for the horrific authorities despite not wanting to. Going by that logic, the significance of the use of infrared might be in stating how the family cannot be themselves as soon as they step out of their house or into the open balcony as well. Although the girl takes on the dangerous responsibility of helping the prisoners, she still cannot express her true self in public, leading to her being shown in infrared. Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the “normal” people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest‘s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions. In the middle of these two instances, The Zone of Interest briefly moves to modern times, and various reminders of the Holocaust are seen being maintained at the Auschwitz-Birkenau State Museum, right before the place is opened to public visitors. The last scene returns to the past once more, and Rudolf is seen feeling slightly odd, as if someone is watching him, as he continues down the stairs.\n\nThe Zone of Interest‘s ending scene seems to suggest that deep in his conscience, Rudolf Hoss does know that his actions can only make one retch, and almost like a fortune-teller, he has an uneasy feeling that his legacy will go down terribly in history. The scene of the museum is a fast jolt back to the right perspective, which had been missing throughout the film. Throughout the entire duration of The Zone of Interest, Rudolf, his family, and his professional associates had all been extremely invested in hiding the evidence and changing the narrative, but ultimately, the thousands of shoes or the torn, ragged uniforms still exist as reminders of the horrible genocide.'
 'Space Babies\n\nOriginal Airdate: 11 May 2024\n\n[Tardis]\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\nRUBY: Who are you?\nDOCTOR: I\'m the Doctor. You don\'t have to stand over there. Come and have a look. It\'s called the Tardis.\n(Snaps his fingers and the lighting changes.)\nRUBY: Ooo! Nice! But hold on. I can\'t call you Doctor. No, I want to know your name.\nDOCTOR: Yeah, that\'s er... that\'s tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They\'d use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you\'re a doctor, but you\'re... the police?\nDOCTOR: Police box. No. No, no, no, no, that\'s a disguise.\nRUBY: Oh.\nDOCTOR: Inside, it\'s a Time and Space machine, but outside, it\'s like a chameleon, \'cos once I landed in 1963 and they used to have police boxes on street corners.\nRUBY: 1963?\nDOCTOR: Yep.\nRUBY: Okay. Ooo, jukebox. I like that.\nDOCTOR: Mmm.\nRUBY: Okay, so, back to the planet.\nDOCTOR: My world was called Gallifrey.\nRUBY: Gallifrey? And where\'s that?\nDOCTOR: Gone! Ruby, it\'s gone. It\'s gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\nDOCTOR: Let\'s have a random landing.\nRUBY: Whoa!\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\nRUBY: No!\nDOCTOR: Really.\nRUBY: No, you\'ve got to be k... You are kidding. Don\'t be so ridiculous. Are there dinosaurs out there?\nDOCTOR: I don\'t know. Go and have a look.\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\nDOCTOR: Well, that\'s not going to happen, is it? Who steps on butterflies? You\'d literally have to be like, ""Wait. Come \'ere, butterfly! ""Come \'ere, \'ave it!""\n\n[Prehistoric Earth]\n\nRUBY: Oh, my God. That... that\'s so beautiful.\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we\'ve moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\n(A boot steps on a butterfly.)\nDOCTOR: Oh!\n(Ruby is no longer a human.)\nRUBATHON: What\'s wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\nDOCTOR: But...\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let\'s try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let\'s go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.\nRUBY: Ah, six!\nDOCTOR: Six! Ah! Five numbers! I like it!\n(The Tardis travels the Vortex.)\n\n[Space station]\n\nRUBY: But we\'re indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\nDOCTOR: We\'ve got to visit them one day.\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\nDOCTOR: Oh, it\'s, er... it\'s broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\nRUBY: Oh, it stinks\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\nRUBY: No, you\'ve made it worse.\n(Something snarls nearby. They both jump.)\nDOCTOR: No, that is worse.\nRUBY: Is that a monster?\nDOCTOR: No. No, don\'t be silly, Ruby. There\'s no such thing as monsters, there\'s just... just creatures you haven\'t met yet. Hi there.\n(The creature roars.)\nRUBY: Run?\nDOCTOR: Run! Run! Run!\n(They and the monster are visible on monitors as they run down passages.)\nDOCTOR: Come on! In here, in here, in here, in here.\nRUBY: But...now we\'re trapped! Now we\'re trapped! Push the button! Doctor!\nDOCTOR: Okay.\n(The tiny one-person lift takes them up. The Doctor\'s hand is over Ruby\'s eyes.)\nDOCTOR: Oh, yeah, yeah.\n(The lift abruptly arrives.)\n\n[Birth Zone 6]\n\nDOCTOR: The question is, why did I run?\nRUBY: \'Cos it was scary.\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn\'t run fast enough. I was like whoosh!\nRUBY: Well, it\'d help if we knew where we were.\nDOCTOR: Yet again, push the button.\n(The lights come on so they can see all the glassware, containing...)\nDOCTOR: Oh. Oh, we\'re on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\nRUBY: I was going to say the same thing to you.\nDOCTOR: We\'ve gone from baby to baby. I\'m not saying things are connected, and yet... things connect.\nRUBY: Well, I\'m the one looking for my parents, and you\'ve got a Time and Space machine. So this place grows babies. What for? Food?\nDOCTOR: Food? What? What?! Food? They\'re not tomatoes!\nRUBY: Well, excuse me. There\'s a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don\'t know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday. I don\'t have a people. I don\'t have a home. But I don\'t have a job, either. I don\'t have a boss, or taxes or rent or bills to pay. I don\'t have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\nRUBY: So where\'s this, then?\nDOCTOR: Oh, er...\n(Calls it up on a screen.)\nDOCTOR: Huh. Planet Pacifico del Rio.\nRUBY: Oh, that\'s in English. They speak English here? English exists?\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It\'s got a perception filter, so it helps you fit into every time and place.\nRUBY: Right, and my mum, she\'s long gone now.\nDOCTOR: Can I see your phone?\nRUBY: Yes.\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\nRUBY: What?\nDOCTOR: Carla. Phone her.\nRUBY: But...\nDOCTOR: Your mum, Ruby. Call your mum.\n\n[Ruby\'s home / Birth Zone 6]\n\nCARLA: Well? What is it now?\nRUBY: Mum?\nCARLA: Yes, Mum, obviously. You\'ve just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\nRUBY: Yeah. Yes, I will... I\'ll, er... I\'ll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\n\n[Birth Zone 6]\n\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That\'s the best signal ever. How much does that cost?\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It\'s calm up here, but underneath it is seething, just like downstairs with that creature. There\'s got to be a crew or a captain...\n(Enter a child in a motorised push-chair.)\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I\'ve opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can\'t...\nDOCTOR: Hi.\nRUBY: You all right?\nERIC: But... you. Oh. We\'ve been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we\'re not...\nERIC: Boys-oh-boys, I\'ve got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They\'re here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we\'ve been doing. Make them proud.\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\nMARCEL?: My job is to keep the pipes clean. I\'m proud of the pipes.\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\nSANDRA?: And I pull this string and that string. I\'m not sure what they do, but I pull them very hard.\nERIC: And I made this for you. It\'s a little flower.\nRUBY: Thank you.\nPOPPY: I\'m Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you\'d come back for us one day. We waited.\nDOCTOR: Right. You\'re not supposed to be running this place. This isn\'t Baby World. You got left behind when the adults... ..vamoosed?\nPOPPY: We took over. We were very brave.\nRUBY: Right. That\'s great. That\'s, oh, that\'s good. That\'s amazing. You\'ve done a really great job.\nDOCTOR: I\'m sorry, Poppy, I\'m so sorry, but we are not your mummy and daddy. I wish we were, but we\'re not.\nERIC: They left us. Where did they go?\nRUBY: I don\'t know, darling, but... I\'m Ruby and this... this is the Doctor. And we\'re your friends. Yeah, got you. I\'ve got you, I\'ve got you, I\'ve got you, I\'ve got you.\n(She picks up Eric from his pushchair.)\nBABIES: And me! And me! And me! And me!\nDOCTOR: Oh, gosh.\nBABIES: And me! And me!\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\nPOPPY: Never.\nDOCTOR: Oh. Oh, baby, it\'s okay. Come here, it\'s okay. It\'s okay, it\'s okay. Shh-shh-shh. Aww, never had a hug.\nRUBY: Come on, you can all have a hug.\n(Later, with everyone back in their pushchairs.)\nPOPPY: Did I get things wrong, Doctor\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don\'t know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\nPOPPY: But are we wrong?\nDOCTOR: What do you mean?\nPOPPY: We\'re not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That\'s okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don\'t know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That\'s it, P-P-P-P-Pop. But the point is, is that it doesn\'t matter where I come from, because I am absolutely lovely, aren\'t I?\n(Poppy yawns.)\nDOCTOR: That wasn\'t rhetorical, Pops.\nPOPPY: Yes, you are.\nDOCTOR: And do you want to know my secret? There\'s no one like me in the whole wide universe. No one like me exists, and that\'s true of everyone.\nIt\'s not a problem, Captain Pops. It\'s a superpower. High five. Yeah.\nPOPPY: Yeah!\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\nRUBY: So you\'re Eric. And you\'re Tasha. And Ruben. And then there\'s Saltine and Boo.\nERIC: I love you, Ruby.\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\nERIC: We\'ve got Nanny. Say hello, Nanny.\nNAN-E: Good afternoon, children, and welcome to our new visitors.\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I\'m the Doctor, and this is Ruby.\nNAN-E: We have visitors, children.\nERIC: Nanny!\nNAN-E: Noses must be blown. Activate nose-blow.\nDOCTOR: Er...\nNAN-E: One, two, three and... blow.\n(Mechanical hands on the pushchairs put handkerchiefs to the babies\' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\nRUBY: Oh, can\'t wait to see that.\nDOCTOR: Right. So it\'s you lot? It\'s Nan-E And downstairs, is that your pet dog?\n(Everyone screams and cries.)\nERIC: That\'s not a doggo.\nRUBY: What is it then, Eric?\nERIC: The Bogeyman.\nRUBY: Shush, shush, shush. Shush, shush, shush.\nDOCTOR: No. Gosh.\nERIC: We don\'t like the Bogeyman.\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\nDOCTOR: Bogeyman!\nRUBY: No, stop it! No, stop it! Nan-E, tell them there\'s no such thing as the Bogeyman.\nNAN-E: Nan-E is scared of the Bogeyman.\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I\'m sorry, I\'m sorry. I\'m sorry, babies. Space babies. I\'m sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what\'s that?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: That\'s on this floor. What is it?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\nNAN-E: Oh, for God\'s sakes, 3-5-7. Come on!\nRUBY: Where do you think you\'re going?\nDOCTOR: Portal 3-5-7!\nRUBY: Right. Great. Ok. Coming!\n\n[Corridor]\n\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That\'s like your... purpose?\nDOCTOR: No, no, I\'m just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum\'s still waiting for me.\nDOCTOR: Back home, on your birthday. Yeah, it\'s strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don\'t know anything about your birth mother or your father? They didn\'t leave a note or a scrap of paper...?\nRUBY: Nothing. I was... I was just left.\nDOCTOR: By the church.\nRUBY: In the snow.\nDOCTOR: On Ruby Road.\n(The Doctor sees a figure point at him by the church.)\nRUBY: Doctor...\nDOCTOR: What?\nRUBY: It\'s snowing. Okay, what just happened? I said snow, and we\'ve got... ..snowflakes.\nDOCTOR: It\'s like a memory just came through, from the day that you were born.\nRUBY: But how? Is this the sort of thing that happens with time travel?\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\nRUBY: Then what does it mean?\nDOCTOR: I don\'t know.\n(The snow has stopped.)\nDOCTOR: Oh, I thought my birth was crazy...\nRUBY: Oh, yeah.\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\n(A door opens.)\nJOCELYN: I said Portal 3-5-7. Don\'t just stand there yapping, you pair of idiots. Get inside!\nRUBY: Who\'s she?\nDOCTOR: Nan-E. Ha!\nRUBY: Oh.\n\n[Portal 357]\n\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I\'m signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I\'d like to say for the record, the company\'s actions are appalling. I will be launching an appeal against this as soon as we\'re home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It\'s the recession. The government closed the Babystation to save money, but the law says it\'s illegal to stop the birth machine.\n(Another leak, another thump with the wrench.)\nJOCELYN: But how did you arrive? Have you got a way out of here?\nDOCTOR: I\'ve got a ship, yeah, it\'s er... What is your name - sorry, Nan-E?\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don\'t know how this place works.\n(The Doctor plugs his sonic into the computer.)\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\nJOCELYN: Thank you. Wanna swap?\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they\'re born, they don\'t look after them?\nJOCELYN: It\'s a very strange planet.\nRUBY: It\'s not that strange.\nDOCTOR: But you stayed behind.\nJOCELYN: I couldn\'t leave them. And I tried with this place. But I\'m not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It\'s a mess. And I\'ve been all on my own, watching the kids, for six years.\nDOCTOR: But I don\'t understand. They are gorgeous. Why would you hide?\nJOCELYN: Cos I don\'t want to see them die. And I don\'t want them to see me die. \'Cos that\'s how bad it is. This is a closed station. There\'s only so much air. There\'s only so much food. The last thing I\'ll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\nRUBY: Can\'t you fly somewhere else?\nJOCELYN: What do you mean, fly?\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can\'t move. It\'s just stuck in orbit, which is a shame, because this is a nice little system.\nJOCELYN: The fifth planet out, Mondo Caroon, that\'s a DuBarryDuPlessy world.\nDOCTOR: Oh, that\'s good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\nRUBY: Oh. Well, can\'t we call them for help?\nJOCELYN: They don\'t go and fetch refugees. That\'s the fate of every refugee in the universe. You physically have to turn up on someone else\'s shore. And we can\'t move.\nDOCTOR: But now you have a ship. Plenty of room. It\'s called the Tardis. The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don\'t know?\nJOCELYN: It\'s nothing to do with me. It\'s not part of the manifest. It\'s not like anything I\'ve ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it\'s terrifying.\nDOCTOR: Yeah, but I\'ve met a million ugly bugs. I\'m an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you\'ve got babies, you\'ve got a nanny, and you\'ve got the Bogeyman. You\'ve literally got a monster living down below. It\'s a children\'s story come to life.\nDOCTOR: And every story has its hero.\n(They spot someone on the screen.)\nRUBY: That\'s Eric. Is that Eric?\nJOCELYN: Eric, get out of there.\n\n[Space station]\n\nNAN-E: Eric, please vacate this area.\n\n[Portal 357]\n\nDOCTOR: Oh, is that how it works?\nJOCELYN: Nan-E filter. Eric, get out now.\n\n[Space station]\n\nNAN-E: Eric will leave immediately.\nERIC: No, Nanny! I\'m being brave.\n\n[Portal 357]\n\nJOCELYN: Eric, for God\'s sake, run!\n\n[Space station]\n\nNAN-E: Eric, invoking the deity, accelerate perambulation.\nERIC: I\'m doing what Ruby said.\n\n[Portal 357]\n\nRUBY: What?\n\n[Space station]\n\nERIC: I love Ruby, and she said there\'s no such thing as the Bogeyman. So I\'m going to find the naughty doggo and tell him off.\n(He meets the Bogeyman.)\nERIC: But I\'m so scared.\n\n[Portal 357]\n\nRUBY: Oh, my God, it\'s my fault!\n\n[Birth Zone 6]\n\nRUBY: Eric, I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming!\n\n[Space station]\n\n(Ruby and the Doctor take the little lift down, and find Eric\'s pushchair fallen over.)\nRUBY: Oh.\nDOCTOR: Nan-E, where\'s the Bogeyman?\n\n[Portal 357]\n\nJOCELYN: It\'s about 400 metres north-west of you. But still no sign of Eric. I can\'t get a proper fix. I told you, these systems are a crock of...\n\n[Space station]\n\nNAN-E: ..waste products.\nDOCTOR: Mind your language, Nan-E.\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\nDOCTOR: Yes.\nRUBY: Okay, right.\nDOCTOR: Yes. Yes, yes.\n(They pick up things to hit the pipework with and move off.)\nRUBY: Bogeyman! Bogeyman!\nBOTH: Bogeyman! Bogeyman!\n\n[Portal 357]\n\nJOCELYN: It\'s moving. It\'s heard you.\n\n[Space station]\n\nRUBY: Okay, nice plan, but what now?\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. \'Cos I can detect...\n(In a locker.)\nDOCTOR: Space baby! Oh, Eric.\nRUBY: We\'ve got you, we\'ve got you.\nDOCTOR: Oh, you poor thing. It\'s okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It\'s all right, it\'s all right. It\'s all right, it\'s all right, it\'s all right. All right, all right. It\'s all right.\nRUBY: It\'s okay, it\'s okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don\'t you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It\'s a dead end.\n(The Bogeyman is there.)\nDOCTOR: Whoa! It\'s okay, it\'s okay. You\'re okay.\n(The Bogeyman is attacked by flames. It runs away.)\nPOPPY: Babies to the rescue!\nDOCTOR: Ha! Space babies!\nRUBY: Babies with a flame-thrower!\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\n(He whistles up Eric\'s pushchair.)\nRUBY: Okay, let\'s get you in here, come on. Let\'s get you in there. Nan-E, tell them what to do.\nNAN-E: Children will return to the upper levels or have no expletive dinner.\nBABIES: Goodbye.\nDOCTOR: Okay, er, you... you go with them. I\'ve got to stay here. Not just for the Tardis, but I\'ve got to find out what that thing is.\nRUBY: If that\'s you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\n(They head back through the stinky area.)\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\n\n[Portal 357]\n\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don\'t know how it even exists.\n\n[Space station]\n\nRUBY: And that was six years ago?\nDOCTOR: Shh-shh-shh.\nRUBY: Oh. That\'s the same time the babies were born.\nDOCTOR: It\'s leaving... some sort of spoor. Man, that\'s a good word. Spoor.\nNAN-E: What the bleep-bleep is that?\nRUBY: Oh, Jocelyn, turn the filter off.\n\n[Portal 357]\n\nJOCELYN: What is that stuff?\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\nJOCELYN: The machine\'s got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\n\n[Space station]\n\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\n(She slips then gets dribbled on from a pipe outlet.)\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don\'t call me Rubes!\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let\'s make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We\'ve been saying it all along. It\'s all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It\'s like a story. The teaching software, it told a story.\nDOCTOR: It invented the Bogeyman.\nRUBY: For the babies.\nDOCTOR: For the space babies.\nRUBY: The machine is literal, like a computer. It literally said, ""Babies need fiction, they need stories, they need monsters.""\nDOCTOR: Yes. That is why I\'m so scared. It\'s all deliberate, it\'s infrasound. The Bogeyman is roaring at 17 hertz, that\'s the exact pitch designed to make you scared. It\'s scary because it\'s meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\nRUBY: What.\nDOCTOR: Oh, Ruby.\nRUBY: What?\nDOCTOR: Oh, man.\nRUBY: Tell me what it is.\nDOCTOR: I can\'t.\nRUBY: Doctor!\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\nRUBY: I don\'t know.\nDOCTOR: The machine is literal, and the name is Bogeyman.\nRUBY: So?\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\nRUBY: What?\nDOCTOR: All of this is bogeys.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: No wonder it was shedding its skin. Doesn\'t everyone?\nRUBY: No, no, no, no.\nDOCTOR: It\'s snot.\nRUBY: It\'s not.\nDOCTOR: Oh, Ruby, it is a living sneeze!\nRUBY: But it\'s in my...\nDOCTOR: I know.\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don\'t laugh!\nDOCTOR: Sorry. Oh, isn\'t the universe mad?\nRUBY: Oh yeah, it just made a monster out of snot.\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\n(The monster is in front of them.)\nRUBY: Bogeyman.\nDOCTOR: Run. Run! Go!\n(A barrier blocks their path.)\nDOCTOR: No, no, no, no!\n\n[Portal 357]\n\nJOCELYN: Don\'t worry, it\'s me. Turn right. It\'s your device. It\'s calibrated. It\'s brilliant! I\'ve got control at last. Now trust me. Turn right!\nDOCTOR [on screen]: This isn\'t the way to the lift!\nJOCELYN: Keep going.\n(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I\'m coming, I\'m coming!\n\n[Portal 357]\n\nJOCELYN: It\'s catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I\'ve got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It\'s an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn! I... She\'s got the sonic. Jocelyn, Jocelyn!\nCOMPUTER: Oxygen field at 10%.\nDOCTOR: Okay, okay, okay, okay. We haven\'t got time. Stop Jocelyn, yeah?\nRUBY: Wait...\nDOCTOR: Left, second right, next left, you\'ll get to the lift.\nRUBY: What about you?\nDOCTOR: Left, second right, next left!\nRUBY: Right, okay.\n(She runs off.)\n\n[Control room]\n\nCOMPUTER: Oxygen field at 9%.\nPOPPY: You\'re hurting him.\nERIC: Stop it, Nanny. Stop it!\nCOMPUTER: Oxygen field at 8%.\n\n[Airlock door]\n\nDOCTOR [memory]: I am the last of the Time Lords.\nRUBY [memory]: How do you keep going?\nDOCTOR [memory]: For days like this. I\'m the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\nDOCTOR: The only one of its kind.\nCOMPUTER: Oxygen field at 7%.\n(The Doctor opens the airlock door and holds it open with his body.)\nCOMPUTER: Oxygen field at 6%.\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\nCOMPUTER: Oxygen field at 3%.\nDOCTOR: Push...the button.\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\n\n[Portal 357]\n\n(Ruby runs in and grabs the sonic.)\nJOCELYN: No!\nRUBY: That\'s what you do, Jocelyn. You save them all.\nCOMPUTER: Oxygen field at 1%.\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\nRUBY: You save them all. Come here. It\'s okay, it\'s okay.\n(Jocelyn cries in Ruby\'s arms.)\n\n[Control room]\n\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\nERIC: Nanny was really naughty.\nJOCELYN: I know, and I\'m so sorry. All of you. I was just... on my own for such a very long time.\nERIC: We still love you, Nanny.\nBABIES: Yay! We do!\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\nBABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can\'t get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? \'Cos the system went wrong, and that\'s where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\nDOCTOR: Oh, set sail for your new home. Baby World!\nRUBY: Come here now. Are you happy now, Eric?\nERIC: I\'m very, very happy. I love you, Ruby.\n\n[Outside the Tardis]\n\nRUBY: So that was a normal day for you, then?\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\nRUBY: What for?\nDOCTOR: I have the whole universe at my fingertips, and I\'m all on my own. So I\'d love it if you came with me.\nRUBY: To what, just travel?\nDOCTOR: No job. No boss. Just fun.\nRUBY: We did almost die.\nDOCTOR: Yes. But we lived so much, too.\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\nDOCTOR: Yes?\nRUBY: Yes.\nDOCTOR: Yes?\nRUBY: Yes. Oh, my God.\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\nRUBY: Come on in. Follow me.\nDOCTOR: Oh, come on.\n\n[Tardis]\n\nRUBY: Right, mate, let me tell you where we\'re gonna go.\nDOCTOR: Except...\nRUBY: Oh, terms and conditions.\nDOCTOR: There is one thing that I can never do, Ruby. And that\'s take you to that church on Ruby Road that Christmas. Absolutely never.\nRUBY: But you\'ve got a time machine.\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother\'s story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can\'t. And I won\'t.\nRUBY: Well, that\'s a pity. \'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\n\n[Ruby\'s home]\n\nCARLA: (on phone) And Ruby phoned, she said, ""I love you,"" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What\'s that noise?\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\nCHERRY: What the blinking flip?\n(Tardis door opens.)\nRUBY: Hiya, Mummy.\nCARLA: But... what are you doing? And what the hell is that? What\'s it done to my kitchen?\n\n[Tardis]\n\nRUBY [OC]: Hey! Come and say hello!\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\n(He sonicks up a quick DNA scan of Ruby Sunday.)\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\n(He doesn\'t wait for the results of the scan.)']",I don't know.,1.0,0.0,0.0007656967840735069,0.0,0.0
What are the key topics of this article?,"The key topics of this article are: ""why prioritizing impact matters not just for managers, but also ICs""; ""why focusing on impact is hard""; ""how to maximize your impact""; and ""how to overcome common challenges in driving real impact"".","['Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 'Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.'
 ""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""]","The key topics of the article include:

1. **Alan Wake 2 Overview**: Information about the game, its release date, platforms, and gameplay mechanics.
2. **Plot Summary**: A detailed synopsis of the game's storyline, including the main characters, their journeys, and the supernatural elements involved.
3. **Gameplay Mechanics**: Description of the gameplay style, including the survival-horror elements and the dual campaigns of the protagonists.
4. **Development History**: Insights into the development process of Alan Wake 2, including its connection to previous games in the franchise and the involvement of Remedy Entertainment.
5. **Reception**: Information on the critical acclaim and awards received by the game.
6. **Expansion Content**: Details about the DLCs and additional content planned for the game.
7. **Trivia and Easter Eggs**: Fun facts and references related to the game and its characters. 

Additionally, there are mentions of the game's connection to the broader Remedy Connected Universe and its narrative ties to other titles like Control.",1.0,0.8639474342221701,0.016474464579901153,0.0,0.0
What data did was used to test the prototype?,Grace Hopper's Wikipedia page and Alan Turing's Wikipedia page were used to test the prototype.,"[""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 'Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 'The best sci-fi and fantasy books of 2023\nIt’s been a stellar year in speculative fiction\n\nBy Nicole Clark, Sadie Gennis, and Polygon Staff  Updated Dec 8, 2023, 10:00am EST  34 Comments / 34 New\nIf you buy something from a Polygon link, Vox Media may earn a commission. See our ethics statement.\n\nIt’s been another banner year for science fiction and fantasy books. Many of our favorites once again blur the line between sci-fi and fantasy, but this year was a particular standout for books blurring the line between SFF and other genres. This includes everything from historical fiction — both speculative histories and Westerns — to fable retellings to intergenerational sagas in translation.\n\nThough we seem to have crested the wave of pandemic novels, that sense of dread and discoloration has lingered, written into novels of new forms. There’s a preponderance of post-post-apocalyptic science fiction unpacking lofty ideas like sentience and humanity, often set on different planets or among the stars. It has also been a standout year for supernatural horrors and thrillers, particularly ones that mix queer longing with a dose of body horror. Last but not least, it’s been a great year for kissing books set in fantastical worlds.\n\nRELATED\n\nLooking for more recs? Here are our favorite books of 2022\nSo jump in and take your pick. Whichever direction you head in, it will be sure to grip you — and make you think. This list is in reverse chronological order, so the newest releases are listed first. We updated this list throughout 2023, sometimes retroactively adding in entries that we missed from earlier in the year. We’ve also included our favorite runners-up.\n\nHONORABLE MENTIONS\nEmily Wilde’s Encyclopaedia of Faeries by Heather Fawcett, Victory City by Salman Rushdie, The Crane Husband by Kelly Barnhill, The Mimicking of Known Successes by Malka Older, Monstrilio by Gerardo Sámano Córdova, White Cat, Black Dog by Kelly Link, Divine Rivals by Rebecca Ross, Our Hideous Progeny by C.E. McGill, The Cheat Code (Wisdom Revolution #3) by Misba, The Deep Sky by Yume Kitasei, Silver Nitrate by Silvia Moreno-Garcia, Vampires of El Norte by Isabel Cañas, Prophet by Sin Blaché and Helen Macdonald, Terrace Story by Hilary Leichter, Her Radiant Curse by Elizabeth Lim, Starling House by Alix E. Harrow, System Collapse (The Murderbot Diaries #7) by Martha Wells, Dark Heir (Dark Rise #2) by C.S. Pacat\n\nCover image for Ed Park’s Same Bed Different Dreams, a split image between what looks like Earth and Mars.\nImage: Random House\nSAME BED DIFFERENT DREAMS BY ED PARK\nSame Bed Different Dreams is a remarkable achievement, and not for the faint of heart. Through three storylines, the book creates a kind of speculative history of Korea, with an emphasis on World War II and Japan’s colonial rule and aftermath (and, crucially, the United States’ involvement). One story thread builds out a hefty alternative history of the Korean Provisional Government’s role and reach. Another story thread focuses on a Black Korean War vet who wrote a sci-fi epic series called 2333, which is later adapted into a video game. And yet another story thread has a more futuristic flavor, focusing on a has-been writer who now works for a tech company called GLOAT. These threads periodically intersect — for example, GLOAT ends up owning the rights to 2333, and turns it into a kind of edutainment.\n\nIf it sounds like there’s a lot going on, it’s because there is. And it’s made even denser by the author’s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking — like a character’s dog who can’t stop “archiving” by burying found manuscript pages, the fact that GLOAT employees truly don’t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what’s real and what’s Ed Park’s “alternate history” in sections with realistic-sounding combinations of fact and fiction.\n\nIt’s got the same ambitious patchwork as Jennifer Egan’s The Candy House and Namwali Serpell’s The Old Drift. Critics have compared it to everything from David Mitchell’s Cloud Atlas to David Foster Wallace’s Infinite Jest. There’s also, of course, books within the book. It’s a fever dream of a thing, and one I’d heartily recommend, but perhaps with a notebook in hand or some sticky notes to help track the references. (Or perhaps, as I did, just letting the wave of information roll over you, until you’re left with a vast impression and a desire to reread.) —Nicole Clark\n\nCover image for Kylie Lee Baker’s The Scarlet Alchemist, featuring a woman in a red outfit with a large crown set against a dark skyline.\nImage: Inkyard Press\nTHE SCARLET ALCHEMIST (THE SCARLET ALCHEMIST #1) BY KYLIE LEE BAKER\nDo not go into The Scarlet Alchemist expecting typical YA fare. What Kylie Lee Baker delivers is a story of visceral brutality, interlaced with elements of Chinese history and thoughtful meditations on family, race, and belonging. It’s a book that can turn your stomach as easily as it can break your heart.\n\nSet in an alternate Tang dynasty, the novel follows Zilan, a profoundly talented young alchemist who travels to the capital in hopes of landing a coveted position in the royal service. But being a poor, half Scotian girl means the odds are stacked inordinately high against her in the imperial service exams — and that’s before her skills with the illegal art of resurrection catch the prince’s attention and pull her into a dangerous political game. While the premise seems familiar (underdog competes in trials, falls into star-crossed romance), Baker’s skills with immersive world-building, knotty characters, and genuinely gruesome horror make The Scarlet Alchemist a dazzling and singular tale that left me rushing to read her back catalog. —Sadie Gennis\n\nCover image of C Pam Zhang’s Land of Milk and Honey, featuring rollicking hills of white, blue, and yellow.\nImage: Riverhead\nLAND OF MILK AND HONEY BY C PAM ZHANG\nAfter I read How Much of These Hills is Gold in 2020, C Pam Zhang became an instant must-read author in my household. Land of Milk and Honey is entirely unlike her debut — where her debut’s language was sparse and pointed, this book is florid and indulgent — though similar in the extent to which it transported me somewhere entirely new, and more than a little threatening.\n\nIn Land of Milk and Honey the climate apocalypse has rendered fresh produce, at scale, a thing of the past — which is to say a provision of the extremely rich. The protagonist, listless and hungry, applies for a job as a private chef for a mysterious family in the Italian Alps (those who live around it call it “\u200b\u200bla terra di latte e miele”). While there, she unravels the family’s true intentions, while making them delicious meals from rare ingredients.\n\nZhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient — and sometimes the cruelty of that ingredient’s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. —N. Clark\n\nCover image for Megan Kamalei Kakimoto’s Every Drop is a Man’s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN’S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind. Each story weaves together Hawaiian mythology and the everyday lives of the Hawaiian and mixed-race Japanese women who live there.\n\nThese stories range from fabulism to science fiction, all speculative fiction in their own way. In one story, a woman’s encounter with a wild pig ends up foreshadowing a complicated pregnancy later in her life. In another story, a Brazilian waxing company allows people to pay for hairless skin by giving up personality traits. In another story, the narrator falls for a woman who lives with her family — in one of numerous queer stories in the collection — but has to cope with that woman’s decision to return to “what remains of Kaua’i” and join their protests.\n\nThe author’s own words, published in The Guardian, sum it up best: “There is a mythical idealisation of the islands of Hawaii as paradise, peace in the tropics; some even call it a modern utopia. Yet this flattening of Hawaii to a postcard image divests our homeland of its culture and colour, reducing us to a place and history that is easily digestible. But we are not easily digestible, and our stories are not meant to be easy for you.” —N. Clark\n\nCover image for Shelley Parker-Chan’s He Who Drowned the World, a painted image of ships on a yellow sea, with the moon looming over them.\nImage: Tor\nHE WHO DROWNED THE WORLD (THE RADIANT EMPEROR #2) BY SHELLEY PARKER-CHAN\nAn alternate history of the founding of the Ming dynasty, He Who Drowned the World shifts between four tragically ambitious figures willing to pay any price to materialize their destiny, whether that’s revenge on the empire or crowning themselves the ruler of it. They pursue these goals with unshakeable inertia, doing endlessly cruel and sadistic actions with only the occasional doubts as to whether happiness could be possible if they chose a different path.\n\nThis is a relentlessly brutal sequel, and there’s a hopelessness that weighs heavy throughout the book. But Parker-Chan’s penetrating ability to bring empathy and nuance into even the darkest corners of humanity sparks an undeniable connection with these characters, whose self-destructive natures would otherwise be too hard to bear witness to. He Who Drowned the World is a dark and difficult read, yet Parker-Chan’s prose is so brilliant, her character work so complex, that I still found myself sad to leave this world behind. —SG\n\nCover image for M.A. Carricks’s Labyrinth’s Heart, featuring a mask-wearing figure with purple wings sprouting out of the top of the mask.\nImage: Orbit\nLABYRINTH’S HEART (ROOK & ROSE #3) BY M.A. CARRICK\nOne of my favorite fantasy series of the past five years, Rook & Rose is an intricately layered trilogy where there are so many secrets, schemes, and conspiracies that at times it’s admittedly difficult to keep track of them all. Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth’s Heart. (Ren alone was juggling four different identities at the novel’s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series’ end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth’s Heart that feel like they were precisely crafted to cater to fans, but here’s the thing: I don’t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nadežra after a two-year wait. While things may have been tied up a bit too neatly for my usual tastes, that didn’t stop me from whipping through pages and smiling the whole way through. Sometimes it’s nice to simply soak in a happy ending rather than bathe in the bittersweet. —SG\n\nCover art for Kiersten White’s Mister Magic, which features a melting television against a pink background.\nImage: Del Rey Books\nMISTER MAGIC BY KIERSTEN WHITE\nThe latest fantasy-with-an-irresistible-pop-premise from the author of Hide, Mister Magic revolves around a children’s TV show no viewer can forget … or prove it ever existed in the first place. There are no official records of it, no YouTube videos or merchandise or passed-around VHS tapes, and any discussion of it on the internet rapidly disappears. But the people who remember seeing it are convinced the special effects were remarkably vivid and realistic. They agree the central concept is unnerving: a creepy magician-figure leading a group of children in imagination-games aimed at teaching some decidedly non-standard lessons about embracing conformity and meekness. And they’re all sure that something horrible happened while they were watching, though they can’t agree on what.\n\nA reunion between five of the former child cast members, taking place 30 years after the show ended, slowly unravels its mysteries, which are even weirder than the description above suggests. Mister Magic is a startling dark fantasy with a lot of foreboding, foreshadowing, and eerie twists. At heart, though, it’s also an incisive story about the kinds of people who revel in control over other people’s lives, and about what an act of rebellion imagination can be. —Tasha Robinson\n\nCover image for Rebekah Bergman’s The Museum of Human History, featuring a painted image of a naked figure with a red cloud over the top of their head.\nImage: Tin House\nTHE MUSEUM OF HUMAN HISTORY BY REBEKAH BERGMAN\nA poetic reflection on memory, loss, and connection, The Museum of Human History is a stunning debut reminiscent of the work of Emily St. John Mandel. Slipping backward and forward in time, this introspective mosaic weaves between an identical twin whose sister fell asleep at age 8 and has never aged in the 25 years since, a museum director who questions his place within the family legacy, a widower who lost his most cherished memories as a result of an anti-aging treatment, and others equally struggling with the passage of time. There is a lyrical detachment in Bergman’s prose that leaves you feeling like you’re watching events unfold through a pane of thick glass, never fully able to connect with the characters, yet you remain helplessly transfixed by the haunting cycle they’re caught in. It’s an incredibly melancholy book, but the kind of aching sadness you’re happy to sink into. —SG\n\nCover image for Sara Hashem’s The Jasad Heir, featuring what looks like statues of a snake,, a bull, and a griffin.\nImage: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n“Arin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.” This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I’ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens’ innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist’s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl. Using her life as leverage, the calculating Arin strikes a deal with Sylvia to help him capture a group of Jasadi rebels and act as his champion in a series of deadly trials. It’s a familiar setup, but one impeccably done by Hashem, who delivers sharp political intrigue, sparkling banter, and touching friendships on top of Sylvia and Arin’s simmering romance. —SG\n\nCover image for Kritika H. Rao’s The Surviving Sky, featuring a floating island overgrowing with buildings and plant life, above a stormy planet.\nImage: Titan Books\nTHE SURVIVING SKY (THE RAGES TRILOGY #1) BY KRITIKA H. RAO\nAfter I finished The Surviving Sky, I wouldn’t shut up about it and tried (not always successfully) to get everyone I know to read it. So let me try once more, and maybe with less yelling this time:\n\nWith the planet’s surface made unlivable by catastrophic storms, the remains of humanity survive on floating cities constructed of and powered by plants that only a select group of people, known as architects, can control. An archeologist without the ability to traject plants, Ahilya has dedicated her life to finding a way to unshackle humanity’s survival from the architects’ powers and return to the surface. It’s not hard to see why this mission causes friction in her marriage to Iravan, one of the most powerful architects in their city, and one with an arrogance to match his revered status. Though estranged, Ahilya and Iravan come together to help clear his name after he’s accused of pushing his powers dangerously far, an accusation, which if proved true, carries dire consequences for the architect.\n\nBut the deeper they look into trajection and its risks, the more Ahilya and Iravan realize they don’t actually know much about where their people – and their powers – came from. And as the floating cities begin to sink toward the earthrages below, the race to save their civilization may also be the end of society as it stands, as Ahilya and Iravan uncover long-buried truths that previous generations worked hard to keep hidden.\n\nSo did I do it? Did I convince you to read this Hindu philosophy-inspired debut with some of the most inventive world-building and one of the most complex romances I’ve read in years? Please say yes. You’ll be doing us both a favor. —SG\n\nCover image for Alexander Darwin’s The Combat Codes, which features a metallic dragon against a black background.\nImage: Orbit\nTHE COMBAT CODES AND GRIEVAR’S BLOOD (THE COMBAT CODES SAGA #1-2) BY ALEXANDER DARWIN\nIn the world of The Combat Codes, war no longer exists as it used to. Neither does justice — both concepts have been replaced by proxies who fight on behalf of nations or individuals, solving disputes with their fists.\n\nAlexander Darwin’s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic “magical school for gifted youngsters” situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books’ excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar’s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can’t wait for the conclusion next year. —Pete Volk\n\nCover image for Katie Williams’ My Murder, showing a woman’s face peering outside of red vertical lines.\nImage: Riverhead Books\nMY MURDER BY KATIE WILLIAMS\nFans of Sarah Gailey’s The Echo Wife won’t want to miss My Murder, which shares some key elements and themes with Gailey’s novel while also taking them in a unique direction. In a near-future with only a few light sci-fi elements, Lou has been resurrected along with a handful of other women murdered by a single serial killer. The politics of resurrection in her world are complicated, and few people qualify. That leaves her and her fellow victims (whose therapy circle recalls Grady Hendrix’s The Final Girl Support Group) a bit at sea as they try to come to terms with their deaths, which none of them can recall, and their new lives as celebrities for all the wrong reasons.\n\nLike The Echo Wife, My Murder ends up thoughtfully exploring issues around women subjected to violent men — not just the personal and internal response, but the society that shapes that violence, and responds to it in ways that raise endless questions. The victims all respond to their deaths differently, questioning their culpability and the possible failures that might have made them targets, and navigating their families’ unpredictable responses to their revival. There’s one big mystery at the heart of My Murder, and a whole lot of abrupt and compelling surprises. But at the core, it’s a sci-fi twist on the survivor story, letting some very different people explore what it means to be victimized, and how to reclaim the lives that have been abruptly handed back to them. —TR\n\nCover image for Ann Leckie’s Translation State, a minimalist drawing with red, orange, and green, a silhouette of a person, and circular lines.\nImage: Orbit\nTRANSLATION STATE BY ANN LECKIE\nSet in the same universe as Leckie’s Imperial Radch trilogy, Translation State follows Enae, who leaves hir long-standing isolation for what was supposed to be an interstellar goose chase. After hir demanding grandmaman dies, Enae is given a diplomat title and assigned to investigate a missing Presgr translator no one expects to be found (but that the government still wants the goodwill for pretending to look for). Only, Enae doesn’t just pretend to look; sie discovers sie has quite the knack for investigating the 200-year-old cold case.\n\nThis is how hir path crosses that of Reet, an adopted maintenance worker whose mysterious origins and unsettling impulses might be explained by being the child of the fugitive translator, if you ask Enae, or the last descendant of a lost sovereign line, if you ask one particularly zealous diaspora social group. Rounding out the POV characters is Qven, a young Presgr terrified of their species’ ritual of merging with an elder, a rite of passage which will see Qven’s selfhood entirely dissolved. Enae, Reet, and Qven’s explorations of their own identities wind up having interplanetary consequences, but it’s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I’m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie’s world. So don’t hesitate to jump into Translation State if you’re – like me – new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. —SG\n\nCover image for Rita Chang-Eppig’s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.\nImage: Bloomsbury Publishing\nDEEP AS THE SKY, RED AS THE SEA BY RITA CHANG-EPPIG\nI still remember standing in my local bookstore, struck by the cover of this book, and reading the summary. It had me at “Chinese pirate queen.”\n\nIn Deep as the Sky, Red as the Sea, Chang-Eppig writes a historical fantasy about Shek Yeung, a fearsome Chinese pirate who must navigate her fleet after the death of her powerful husband. She marries her late husband’s second-in-command, with the promise of bearing an heir, in order to retain power over the fleet — and stay a major player as the Chinese Emperor seeks to rid the waters of piracy.\n\nThe book isn’t paced like a thriller, so don’t make the mistake of assuming so when you start it. It’s equal parts historical exposition, strategy, and warfare — and it especially excels in its characterization of a complicated woman forced to make difficult decisions and sacrifices in order to protect her power. Fantasy can put its villains and heroes on pedestals, but Deep as the Sky, Red as the Sea never errs in its very human portrayal of Shek Yeung, and how deftly she must play this game of political chess for survival. I was riveted. —N. Clark\n\nCover art for Emma Törzs’ Ink Blood Sister Scribe, featuring a dripping pen growing out of the bottom of a tree against a purple background.\nImage: William Morrow\nINK BLOOD SISTER SCRIBE BY EMMA TÖRZS\nThere’s nothing cozier than a magical book about the magic of books — though this tale bends a little darker, and tells a story about witchcraft and complicated family dynamics. In Ink Blood Sister Scribe, two estranged sisters come together to solve the mystery of their family, and prevent further tragedies. In this world, blood can be concocted into ink — wielded by scribes for the creation of books with arcane powers — though the creation of such books drains a scribe’s health. When others read these books, they create magic; willing flowers to bloom, or making magical carpets that can fly in the air.\n\nInk Blood Sister Scribe is the perfect sister thriller to read in one sitting. It doesn’t reinvent the wheel, but it doesn’t need to — it simply delivers on a wonderfully entertaining premise. —N. Clark\n\nCover art for Martha Wells’ Witch King, featuring a person running across the cover while wearing a cloak and dress fitting for a fantasy setting.\nImage: Tor\nWITCH KING BY MARTHA WELLS\nIn an era where a lot of fantasy fans value quick or cozy reads, Martha Wells’ Witch King feels like a gauntlet thrown at readers’ feet. It’s a complex, meaty fantasy that opens well into what a more linear book would consider the third act, as Kai, the witch king of the title, is exhumed from a watery grave and starts exploring who betrayed him and trapped him there. Readers have to learn everything about Kai’s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a “witch king” is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells’ Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them. Wells packs Witch King with a lot of audacious, expansive world-building for a standalone novel (albeit one that could easily invite sequels or prequels), but what makes Witch King an enjoyable read instead of a frustrating one is the way all the book’s complications and surprises are filtered through Kai’s vivid inner life, giving readers something to hold onto as they’re untangling the puzzlebox aspects of this cleverly structured novel. —TR\n\nCover image for Justin Lee Anderson’s The Lost War, featuring five figures walking through white grass after emerging from a dark green forest. Three of the figures wear green cloaks, while two wear white.\nImage: Orbit\nTHE LOST WAR (THE EIDYN SAGA #1) BY JUSTIN LEE ANDERSON\nOriginally self-published in 2019, The Lost War is a traditional fantasy adventure that follows a rag-tag group of strangers on a mission across a war-torn country, fighting monsters and uncovering mysteries along the way. Despite the strong buzz leading up to the novel’s expanded publication by Orbit this year, I found myself hesitant to pick it up since it seemed so similar to many books I’ve read before. But while it’s true The Lost War doesn’t rewrite the genre – it’s filled with well-worn tropes and classic adventurer archetypes – Anderson’s skillful execution left me completely charmed. There is a real Dungeons and Dragons feel to The Lost War, and though the characters are familiar (the honorable paladin, the hard-drinking haunted soldier), Anderson does a fantastic job developing unique dynamics between the party members that vault the book beyond the sum of its parts. And it all builds up to a massive twist at the end that completely upends your understanding of what you’ve read and any previous expectations for where the second book will go. The delightfully unexpected ending once again has the fantasy community buzzing ahead of Anderson’s next release – only this time I’m right there with them. —SG\n\nCover image for Moniquill Blackgoose’s To Shape a Dragon’s Breath, a red cover with flowers and a dragon’s head/mask on it.\nImage: Del Rey\nTO SHAPE A DRAGON’S BREATH (NAMPESHIWEISIT #1) BY MONIQUILL BLACKGOOSE\nTo Shape a Dragon’s Breath’s description hooked me immediately: It’s got dragons, a magic school, and a strong teenage main character. Moniquill Blackgoose has taken several different fantasy tropes and created a fantasy novel that’s unlike anything I’ve read; To Shape a Dragon’s Breath is set in an evolving steampunk world as Anglish settlers push the Indigenous Masquapaug people out of their land and onto a remote island. Dragons had long been important cultural touchstones to the Indigenous people, but colonization has, too, pushed them away. To Shape a Dragon’s Breath begins as 15-year-old Anequs finds a dragon egg — the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon’s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon’s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered — they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way. Where To Shape a Dragon’s Breath really shines is in that growing relationship between Anequs and Kasaqua; the partnership — and power for both that comes with it — is in stark contrast to the Anglish ways. Bonus: To Shape a Dragon’s Breath has well-written, complex bisexual and neurodivergent characters, too. —Nicole Carpenter\n\nCover image for Melvin Burgess’s Loki, a black cover with a black snake wrapped around gold letters with the title.\nImage: Pegasus\nLOKI BY MELVIN BURGESS\nMelvin Burgess has spent a career writing confrontationally frank children’s literature like Junk, his 1990s book about heroin-addicted teenagers. His first adult book, published at age 69, is a blistering, transgressive, and hugely entertaining reframing of the Norse myths, as told by the most unreliable narrator imaginable: Loki himself, the god of tricks, inventions, and political intrigue. But what does reliable mean, anyway, in the mutable world of myth? Burgess paints Loki (or rather, has him paint himself, as he addresses the reader directly in first person) as an eternal outsider, shaking his head sagely at the follies of the gods, and challenging their might-is-right order. But of course, that’s what he’d want us to think. Burgess’ best trick, though, is the way he rolls together the deeply weird, muddy, shape-shifting mystery of the tales themselves with a bracing modernity in characterization and language, somehow without one clashing with the other. In doing so he brings the wild, ancient power of the Norse myths to vivid life. —Oli Welsh\n\nCover image for Nana Kwame Adjei-Brenyah’s Chain-Gang All-Stars, featuring a scythe chopping through the words with a bright yellow background.\nImage: Pantheon Books\nCHAIN-GANG ALL-STARS BY NANA KWAME ADJEI-BRENYAH\nIn Chain-Gang All-Stars, prison inmates fight to the death in a series of gladiatorial matches — and all of it is televised to a hungry audience. It’s a program called CAPE, the Criminal Action Penal Entertainment, which promises freedom to inmates who survive three years of its brutality. The average life expectancy for anyone who enters is three months. Within this system, Loretta Thurwar and Hammara Stacker (called Hurricane Staxxx by her fans) emerge as two frontrunners.\n\nThis National Book Award finalist takes on the viciousness of the carceral system, with more than a bit of The Hunger Games’ DNA sprinkled in. “Hard action” fans salivate over matches, a self-obsessed announcer resents the fact that contestants don’t offer more banter, and the women who top the leaderboards become sex symbols in pop culture. But where other fight-to-the-death dystopias — among the greats, like Battle Royale or Lord of the Flies — spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn’t entertaining because it wasn’t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply “slavery by another name,” showing all manner of menial labor the contestants are forced to perform. In 2022, the ACLU reported that inmates made between 13 and 52 cents an hour, and sometimes nothing.\n\nCritics have said this book is an “act of protest” but that it doesn’t “straightforwardly preach,” or that it’s more entertaining than “an attempt to convince its readers of the case for prison abolition has any right to be.” I understand why you’d want to say this book is “fun” despite an abolitionist message, especially in a political climate where radical writing is often appreciated only as a teaching tool. But I think that kind of delineation undercuts Adjei-Brenyah’s talent as a novelist, and his skill in heightening the real as a form of storytelling. I’d call it thrilling, over calling it fun. And the fact that it is thrilling is inextricable from its openly abolitionist values — it’s the very knowledge of real life that Adjei-Brenyah wields to craft suspense. —N. Clark\n\nCover image for Rebecca Yarros’ Fourth Wing, which features a circle image behind black text, with clouds and some flying creatures.\nImage: Entangled\nFOURTH WING BY REBECCA YARROS\nThis action-packed, fantasy romance feels like a grown up version of all of my favorite young adult books. It’s got all of the fun nostalgic tropes — a magical school, deadly trials, dragon riding, and a love triangle between the main character, a golden retriever love interest, and a misunderstood emo rival — but it’s also extremely horny, as all fun fantasy romance must be.\n\nViolet Sorrengail is thrown into a series of trials in order to prove whether she can be a dragon rider. There are a few problems with this: she trained as a scribe, never thought she’d be thrust into danger, and she also must deal with Xaden Riorson, her sworn enemy (wink). She also manages a joint condition, which leaves her in chronic pain — a fact the book handles gracefully. In one of my favorite climactic moments of the book, Violet is given a mobility device to help her with her trials; those close to her remind her that it doesn’t diminish her power, but is a tool like any other, and one that allows her to flourish. I’m thrilled to read the next installment, when it comes out in November. —N. Clark\n\nCover art for Adrian Tchaikovsky’s Lords of Uncreation, which shows a spaceship approaching what looks like a space battle next to a planet, with exploding orbs in space and a lot of spaceships in the distance.\nImage: Orbit\nLORDS OF UNCREATION (THE FINAL ARCHITECTURE #3) BY ADRIAN TCHAIKOVSKY\nReading the Final Architecture series, I had to accept long ago that I would never fully grasp the nuances of some of its central concepts, even if I understood them on an instinctual level.\n\nThis acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on – at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God’s crew.\n\nThis is not to say that Tchaikovsky does not deliver an incredibly satisfying conclusion to the mysteries of unspace (he does!). But what I’ll remember most is how he crafted the perfect emotional resolution to this intellectually intricate tale that left me in tears and has stayed with me since. —SG\n\nLead art for Justin Cronin’s The Ferryman, which pictures a cloudy sky over the horizon, as a single sail boat sits on the water.\nImage: Ballantine Books\nTHE FERRYMAN BY JUSTIN CRONIN\nProctor Bennett is a ferryman, whose duty is to guide unhappy citizens from the utopian Propersa to the Nursery, where they retire their old selves before returning in younger bodies with no memories of their former lives. But when Proctor is assigned to retire his own father, the troubling encounter sends him careening off the path of conformity. He begins questioning prescribed truths and confronting the darker side of Prospera, which runs off the work of a disenfranchised support staff whose discontent is building towards a revolution that pulls Proctor into its orbit.\n\nThough this premise may feel familiar, The Ferryman is anything but. This tightly-wound, atmospheric thriller weaves together layers of knotted mystery with Proctor’s haunting POV as he grapples with his relationship to grief, happiness, family, and identity. It’s a sharply complex mystery with a cinematic quality to it. Throughout reading, I couldn’t help but fan-cast who would star in a Christopher Nolan adaptation of it. But even if you aren’t an Inception fan, it’ll be easy to become immersed in The Ferryman’s distinct dystopian world. —SG\n\nCover image for Emily Tesh’s Some Desperate Glory, featuring a woman walking confidently in front of a wall opening to reveal a planetary body.\nImage: Tor\nSOME DESPERATE GLORY BY EMILY TESH\nAround September, as the pile of unpainted plastic miniatures here in my home office began to get particularly deep, I suddenly ran out of Warhammer 40,000 Black Library audiobooks by Games Workshop that I was the least bit interested in listening to. That’s when I stumbled upon Some Desperate Glory by Emily Tesh. Billed as a space opera told from the perspective of one of humanity’s last genetically engineered super soldiers, I fell for the premise hook, line, and sinker. Then, about 50 pages in, I let it sucker-punch me right in the gut.\n\nWith Some Desperate Glory, Tesh has envisioned a deeply affecting reality where the children of a subjugated, war-torn race slowly come to realize that they have been lied to — manipulated into an amoral war of vengeance without end. Tesh shows incredible restraint throughout, reeling out a thick and binding thread of painful realizations from deep within the main character, Kyr. After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest – and a new fixture in the canon of queer science fiction. —Charlie Hall\n\nCover image for Jade Song’s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book — for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid. But she is tethered to land by her human ambition: By the parents who constantly push her to achieve, and by a swim coach who pays inappropriate attention to her — pushing her to swim faster times, while also making her feel uncomfortable in her skin.\n\nRen’s steadfast belief in being a mermaid feels both like a flight of fancy, and increasingly like a means of dissociating from the horrors of everyday life. Being a young girl is hard enough without having to contend with the high expectations of parents, the predation of adult men, and the casual racism of peers. Jade Song’s writing is gruesomely lyrical, contrasting the sublime with the deeply disturbing. There were several points where this book almost made me throw up, and I mean that as a high compliment. —N. Clark\n\nA Black woman stands alone in a field, her face covered by shadow, in the cover art for Lone Women by Victor LaValle.\nImage: One World\nLONE WOMEN BY VICTOR LAVALLE\nAdelaide Henry is traveling to Montana, where she plans on making a new life as a homesteader — leaving the flames of her California home, and the bodies of her parents, behind. But she has a heavy weight to carry. She lugs an enormous steam trunk wherever she goes; whenever the trunk opens, people around her die. In 1915, Montana is in the middle of a homestead boom, and though Adelaide aims to make a new start, not everyone is welcoming to a Black woman traveling alone.\n\nVictor LaValle mixes horror and fantasy in this expertly paced tale. It’s satisfyingly bloody, while making incisive commentary on the price of being an outsider. The Western genre has long fixated on the white imagination, perhaps occasionally making space for the early struggle of the suffragettes. But LaValle’s vision of history emphasizes just how powerful white women are in upholding the interests of their white husbands, and how far these women will go to protect the societal structures that put them in proximity to power. Lone Women also examines how shame, and the family unit, ultimately uphold these unspoken rules — ostracizing those who might otherwise find community support.\n\nThis book was so good that I am now reading my way through every interview LaValle has given on the Lone Women press circuit, too, and then reading every book he references. What a gift! —N. Clark\n\nCover image of Nathan Ballingrud’s The Strange, depicting a diner on Mars.\nImage: Gallery/Saga Press\nTHE STRANGE BY NATHAN BALLINGRUD\nNathan Ballingrud’s debut novel was added to my TBR pile after seeing it marketed as a blend of Ray Bradbury’s The Martian Chronicles and Charles Portis’ True Grit. I’m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp’s mother unknown. When a thief steals Annabelle’s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what’s hers and see justice served. The longer Annabelle’s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can’t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.\n\nAnnabelle can be vengeful and cruel, and though I often disagreed with her choices, Ballingrud makes it impossible not to understand and empathize with her. Annabelle Crisp isn’t a hero and she isn’t a villain, but she is an outstanding protagonist in a wonderfully original sci-fi tale. —SG\n\nCover image for Moses Ose Utomi’s The Lies of the Ajungo, featuring a figure walking upside down on mounds of sand as a castle lurks in front.\nImage: Tor\nTHE LIES OF THE AJUNGO (THE FOREVER DESERT #1) BY MOSES OSE UTOMI\nIn his debut novella, Moses Ose Utomi wields his precise prose to tell a dark, visceral fable about a young boy from the City of Lies, a metropolis reliant on the brutal Ajungo Empire for their supply of water. But the cost of this trade is high: At 13, every child of the City of Lies has their tongue cut out and sent to the Ajungo.\n\nEven with this gruesome tithe, the Ajungo send barely enough water for the population to survive, and far from what they’d need to do so comfortably, let alone thrive. Shortly before his thirteenth birthday, the brave Tutu sets out on a dangerous journey to save his mother and the city by finding their own water supply. As Tutu explores the outside world for the first time, his perception of truth and history is challenged, and he comes to understand how the decisions and deceptions of those in power rewrite the past and shape the future to uphold those with privilege and foster compliance in those who don’t. —SG\n\nCover image for Edward Ashton’s Antimatter Blues, A Mickey7 Novel. It features an astronaut from behind on a rocky planet, looking out at another planet in the distance.\nImage: St. Martin’s Press\nANTIMATTER BLUES BY EDWARD ASHTON\nEdward Ashton’s sequel to Mickey 7, the 2022 novel Parasite director Bong Joon-ho is adapting as a movie starring Robert Pattinson, takes up two years after the first book left off, with “Expendable”-status planetary colonist Mickey still on the outs with the leadership of his struggling colony after a gutsy bluff he made to ensure his own survival. The sixth clone of the original Mickey, who accepted life as a disposable body for suicide missions in exchange for a ticket to space, Mickey 7 has walked off that job. His ongoing draw on the colony’s resources is only tolerated because he’s exaggerated his diplomatic connections with the local aliens. Then the base commander orders him to do something impossible, or the entire colony will die.\n\nAntimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity’s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn’t a pleasant book to read: A lot of Mickey’s co-colonists are bigots, most of them are indifferent to anyone else’s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he’s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity. —TR\n\nCover image for Samantha Shannon’s A Day of Fallen Night, a colorful image with a a dragon swirling around it\nImage: Bloomsbury\nA DAY OF FALLEN NIGHT (THE ROOTS OF CHAOS #0) BY SAMANTHA SHANNON\nSamantha Shannon’s A Day of Fallen Night is her second book in the Roots of Chaos series, but a prequel to The Priory of the Orange Tree. Like The Priory of the Orange Tree, A Day of Fallen Night is an epic, far-flung fantasy novel set in a world of magic and dragons. A Day of Fallen Night is set hundreds of years before The Priory of the Orange Tree, and follows several of the original book’s ancestors as the world fears the return of an evil wyrm, the Nameless One. You don’t have to have read The Priory of the Orange Tree to enjoy A Day of Fallen Night; in fact, it’s likely a good place to start if you’ve been interested in reading Shannon’s original, massive fantasy book. Of course, this is a slow-burn 800-page book that precedes another 800-page book, so it’s definitely a time investment regardless of the path.\n\nThough A Day of Fallen Night deals with a world-shaping, cataclysmic threat and widespread political machinations, the book is rooted within four characters from around the book’s world: Sabran, Glorian, Dumai, and Tunuva Melim. The stories of these characters intertwine as their regional beliefs tied to wyrms and dragons conflict, muddying up the necessary collaboration in fighting off the looming threat. In between all that catastrophe, Shannon gives the women of the book rich stories of personal relationships, sacrifice, and conflicting feelings. Motherhood and bodily autonomy are also strong themes throughout the book; both Sabran and Glorian (mother and daughter) have their bodily autonomy tied to the fate of their region.\n\nIt’s not easy to describe A Day of Fallen Night in a short blurb — it does so many things and goes so many places. Shannon’s created a series that has the scale of The Lord of the Rings, wrapped up in a world of queer, female power. The Roots of Chaos, as a whole, is one of my favorite fantasy series ever. —N. Carpenter\n\nCover image for Mariana Enriquez’s Our Share of Night, featuring a red hand with long yellow fingernails.\nImage: Hogarth Press\nOUR SHARE OF NIGHT BY MARIANA ENRÍQUEZ\nThis literary tome defies categorization, so I’ll paint a scene instead: A father (Juan) whisks his son (Gaspar) away on a trip. Juan is mercurial; at turns terrifying and violent, at turns bewilderingly tender, nearly infinite in love. But he is a closed book. And if you think you’ve seen his hands elongate, spindly fingers yielding to piercing claws — well no, you didn’t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family’s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel’s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enríquez writes next, it’s an absolute joy to experience her work. —N. Clark\n\nCover image for Annalee Newitz’s The Terraformers, which features a futuristic cityscape with lush greenery.\nImage: Tor Books\nTHE TERRAFORMERS BY ANNALEE NEWITZ\nThe Terraformers concerns itself with one question: As a species evolves, what behaviors stick around? Set more than 50,000 years in the future (yes, you read that number right), The Terraformers details the process of terraforming and developing a privatized planet into a tourism joint for the super rich. Technology has advanced in barely fathomable ways, allowing, for instance, the extension of human-level intelligence to animals and robots. But some aspects of society might seem familiar: Real estate developers who jack up rent with no warning? Local governments that abhor public transit? That every video call still has one person who can’t get the camera to work?\n\nEqual parts prescient and absurd, The Terraformers splits its story over three novellas, each 700 years apart. One of those stars a sentient train who teams up with an investigative journalist ... who also happens to be a cat ... who’s also trying to prove this ostensibly privatized planet is in fact public land. Written by a leading science journalist of our era (author Annalee Newitz is the founder of io9 and has written for basically every major science publication under our sun), The Terraformers is unexpectedly one of the most accurate representations of the journalistic process I’ve ever read. And it all culminates in an undeniable stance: That capitalistic power must still be held in check by the truth. Even 50,000 years in the future, a free press is among society’s most essential facets. The more things change... —Ari Notis\n\nThe cover image of Adrian Tchaikovsky’s Children of Memory, which depicts a spaceship approaching a large orange planet.\nImage: Orbit\nCHILDREN OF MEMORY (CHILDREN OF TIME #3) BY ADRIAN TCHAIKOVSKY\nAdrian Tchaikovsky’s highly anticipated third book in the Children of Time trilogy once again delves into some of science fiction’s headiest topics. There are parallels to earlier installments — Tchaikovsky once again uses another hyper-intelligent animal species to examine the idea of what being “alive” really means. But he also takes readers somewhere completely and utterly new, outside the scope of the previous titles, and incredibly difficult to describe without spoiling the premise entirely.\n\nAll I can say is hold on for the ride. This is an author who dives head first into Asimov-esque ideas, and who is willing to take the plot in fanciful directions. I still can’t believe that I have recommended a book about sentient spider colonies to so many friends, but here we are. This finale is worth your time. —N. Clark']",I don't know.,0.0,0.0,0.0012484394506866417,0.0,0.0
When did mushroom trees stop dropping wood?,Mushrrom trees stopped dropping wood in patch 1.4.0.,"[""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 ""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 'manicfesto proposals\n26m tonnes of waste plastic bottles are discarded every year in the UK of which only 45% are recycled. The Loony Party has the answer.. Stop making them..\n\nBefore you ask…We have found an alternative. Its called glass.\n\nSome of our Proposals for other elections\nAlong with the existing Government policy for levelling up the North with the South             we will provide free Spirit Levels to all\n\nWe will reduce inflation by giving everyone free pins.\n\nTo make trains safer, we will fit them all with cushions on the front.\n\nAny possible schemes thought up by Government, Council , NHS etc,  such as closure of Hosptitals, workplace parking levy etc will be preceded with a Public Consultation which we will then ignore.\n\nWe will combat corruption in public life by taking part in it openly, we will                              introduce the Board of Bribery who will set standardised rates?. #sleaze for the many not just the few\n\nWe propose to prevent identity theft instantly by calling everyone Chris.\n\nAll political and electoral leaflets will be printed on soft paper so that it may be recycled in the appropriate manner.\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce                   pregnancy from nine to seven months ?\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.\n\nWith Government helped finance, AstraZeneca should buy out Pfizer, then, as we would have the rights to Viagra, the economy may stay up longer.\n\nRedundant Red Phones boxes will be converted to bijou accommodation to ease the housing shortage.\n\nTo make things fairer we will introduce a Court of Human Lefts.\n\nGeneral Election 2022 Manicfesto\nGeneral Election 2022 Manicfesto  —— For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nOnce in Government, we will replace the Foreign Secretary with a British one!\n\nWaitng Lists\n\nWe will reduce hospital waiting lists by using a smaller font.\n\nImmigration\n\nWe will reduce net migration by making sure that any nets are secured more firmly to the ground.\n\nInflation\n\nWe will reduce inflation by giving everyone free pins\n\nGovernment Policy\n\nWhen formulating Policies the Government relies heavily on Expert Advise. Remember  – Experts built the Titanic\n\nThe Loony Party will also take into account the opinion of “Dave on Facebook”\n\nEnergy Policy\n\nWe will get rid of the Energy Price Cap and replace it with a Top Hat (This will also help our Millenery Industry)\n2. We will get rid of all Standing Charges. (We are quite capable of sitting down and freezing to death)\n3. All the hot air spoken in Parliament will be redirected to the Gas Distribution Networks.\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P’s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 ½ hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don’t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy’s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\n\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nGeneral Election 2019 Manicfesto\nGeneral Election 2019 Manicfesto  —— For the Manic, Not the Few\n\nWe pledge to fight this election on an invisible platform so that people cannot see the floors in our policies.\n\nStressful times in the House\nIn order to calm down the passions and stresses currently exhibited in Parliament, the Loony Party would make all M.P’s have half an hours compulsory Tai chi everyday.\nThis would counteract the other 23 ½ hours Chi Ting they do for the rest of the time\n\nCorruption\n\nWe in The Loony Party are quite willing to accept bribes , and inducements from the Government in exchange that we don’t stand in the election.\nWe will combat corruption in public life by taking part in it openly, we will also introduce the Board of Bribery who will set standardised rates?\nNorthern Powerhouse\n\nThe Loony party will invest millions in the Northern Powerhouse.\nFor clarification all parties agree that, as normal, the North starts at Hadrians Wall and ends where Scotland starts\n\nBrexit\n\nThe Border in Northern Ireland would be made out of sponge to prevent a Hard Border\nWe will renegotiate to stay and lead the E.U and then sack the other 27 countries\nIdentity Theft\n\nWe propose to prevent identity theft instantly by calling everyone Dave.\n\nPlay Grounds\n\nWe will redevelop Playgrounds for all age groups.\n\nCivil Service\n\nThe Civil Service will be extended to all branches of government, because a little politeness goes a long way.\n\nCulture\n\nThe British Museum should have a Daddy’s section alongside the current Mummy exhibition.??\n\nTransport\n\nWe will rename the current Oyster cards, ‘Sardine Cards’ to better reflect the experience when travelling on public transport\n2. We will only paint yellow lines where you CAN park. Potholes deeper than 3 inches will be marked with a yellow plastic duck .\nElections\n\nAll political and electoral leaflets will be printed on soft Toilet paper so that it may be recycled in the appropriate manner. ??\n\nNHS\n\nIn an effort to reduce the problems faced by the NHS , it is proposed to reduce pregnancy from nine to seven months ?\n\nAnimal Welfare\n\nTo protect pets and people of a nervous disposition we would introduce silent fireworks.?\n\nPolicies\nWe encourage everyone, even current politicians, to submit ideas to our world famous #Manicfesto! The following are some of the most recent from our wonderful Twitter followers…\n\nOnce in Government, anyone applying for 7 figure salary positions with the World Health Organisation or as Govt Health Advisors, will have to answer 15 correct questions on “WHO wants to be a Millionaire”.\nIn Brexit Trade Deals: Germany will be required to pay for treatment of Measles, and Spain will be required to pay for cases of Spanish Flu. The French will pay for all accidents resulting from kissing & broken letters & the Dutch will split all future expenses 50/50.\nWe will place in law measures to stop panic buying as COVID19 restrictions take hold. Shoppers will only be permitted to buy one panic per person.\nIt is evident that the 10pm pub curfew is not working , We propose that pubs ask people to leave in alphabetical order.\nShamefully Lord Sutch has never been allowed to take his place in the House of Lords. Nor were Duke Ellington, Count Basie or Lord Rockingham We will end this discrimination against musicians.\nTo unite the population, we will surround the UK with a large cardboard box so people can be both in and/or out of the EU. This will be known as Schrodinger’s Brexit.\nTo get more children reading, fish and chips will once again be wrapped in newspaper.\nOnce in Government we will introduce the Ministry of Clarity. The role of this Ministry will ensure that only the clearest clarity is made clear and the unclear clarity is cleared out. We hope that our position on this is now clear to all.\nIn Government, we will complete a 5 year Parliament in only 4 years. This policy not only ensures a 20% saving for the public purse but also gives everyone in the UK a year off from listening to our politicians.\nThe MOT is an annual test to ensure that your car is roadworthy. We will introduce a ROT, an annual test to make sure all roads are car worthy.\nAnd from 1st January 2021, passports will be issued in the colour of political voting. Tories will be Blue, Labour will be Red, Greens will be green. Official Loonies will have leopard spots, and Lib Dem’s will be invisible.\nChinners\n\nForeign Policy\nWe will Admit Shamima Begum back to the country only when she accepts Screaming Lord Sutch as her saviour.\n\nMinistry of Info\nWe will create a New Ministry of Information. It shall consist of the former board of directors of Cambridge Analytica. They already know everything.\n\nBrexit Proposals\nWe will Send Noel Edmonds to negotiate Brexit because he understands Deal or No Deal.\nThere will be no need for a backstop to the Brexit negotiations. We’ll have Alec Stewart as wicket-keeper.\nJames Wallace\n\nEducational Funding\nThe Loony Party proposes that all Schools would have a Jumble sale or fete or other fundraising event at least twice per month to help raise funds for those little extras. . . such as Desks, Books, paper, pens , etc\nR.U. Seerius\n\nPensions – triple lock\nIn keeping with the Labour Party’s latest bid to get one or two pensioners to vote for them they have brought out a new policy guaranteeing the Triple lock on pensions until 2025 if they get voted in.\nThe Loony party of course will go one better and buy a padlock, and as its now safer than a bank,  new mattresses for all pensioners on less than 20p per week.\nR.U. Seerius']",I don't know.,0.0,0.0,0.0017921146953405018,0.0,0.0
What do keybullet kin drop?,Keybullet kin drop a key upon death.,"[""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 ""How to Maximize Your Impact as a Data Scientist\n\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\n\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\n\n\nImage by author\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\n\nIn this post I’ll go over the following:\nWhy prioritizing impact matters not just for managers, but also ICs\nWhy focusing on impact is hard\nHow to maximize your impact\nHow to overcome common challenges in driving real impact\nLet’s dive in.\n\nGet an email whenever Torsten Walbaum publishes.\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\nmedium.com\n\nWhy should I focus on impact; isn’t that my manager’s job?\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\n\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\nWhy isn’t everyone doing this?\nBecause it’s hard.\n\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\n\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\n\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\n\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\n\nHow can I become more impact-focused?\nStep 1: Understand what impact looks like for your role and measure your success accordingly\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\n\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\n\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\n\n\nImage by author\nDid your work change anything for the better for your business partners? E.g.:\n\nDid your analysis change the roll-out strategy of the new product?\nDid your model improve forecast accuracy?\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\nDid your work help move the needle on downstream business metrics? E.g.:\n\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\n\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\n\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\n\nStep 2: Ensure your work solves a real business problem\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\n\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\n\nSo what can you do?\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\n\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\n\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\n\nStep 3: Ensure there is buy-in for your work\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\n\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\n\nNeed to understand whose support you need, and\nGet them onboard from the get-go\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\n\nStep 4: Focus your time on the highest-impact thing\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\n\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\n\nAd-hoc requests vs. strategic work\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\n\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\n\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\n\n\nImage by author\nDon’t cry over spilled milk\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\n\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\n\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\n\nThings to watch out for (“impact killers”)\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\n\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\nCommon Challenges and How to Address Them\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\n\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\n\n\nImage by author\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\n\n1. You create a comprehensive analysis but nobody is acting on it\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\n\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\n\n2. You ran an experiment but nobody is using the results\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\n\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\n\nHow should they think about the statistical significance or lack thereof?\nIs the observed lift good compared to other changes you tested and shipped?\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\n\n3. You built a predictive model, but the team you built it for is not using it\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\n\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\n\nSolution: It’s all about involving stakeholders in the process and building trust.\n\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\nDemystify the output; for example, you can extract the top model features and explain them\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\n\n4. You created a dashboard but nobody is looking at it\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\n\nThe dashboard doesn’t directly address an urgent business use case\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\nThe dashboard is complex and your users don’t understand how to get what they need\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\n\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\n\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\n\nClosing Thoughts\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\n\nAnd isn’t it nice when your work actually feels like it moves the needle?\n\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.""
 'Space Babies\n\nOriginal Airdate: 11 May 2024\n\n[Tardis]\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\nRUBY: Who are you?\nDOCTOR: I\'m the Doctor. You don\'t have to stand over there. Come and have a look. It\'s called the Tardis.\n(Snaps his fingers and the lighting changes.)\nRUBY: Ooo! Nice! But hold on. I can\'t call you Doctor. No, I want to know your name.\nDOCTOR: Yeah, that\'s er... that\'s tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They\'d use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you\'re a doctor, but you\'re... the police?\nDOCTOR: Police box. No. No, no, no, no, that\'s a disguise.\nRUBY: Oh.\nDOCTOR: Inside, it\'s a Time and Space machine, but outside, it\'s like a chameleon, \'cos once I landed in 1963 and they used to have police boxes on street corners.\nRUBY: 1963?\nDOCTOR: Yep.\nRUBY: Okay. Ooo, jukebox. I like that.\nDOCTOR: Mmm.\nRUBY: Okay, so, back to the planet.\nDOCTOR: My world was called Gallifrey.\nRUBY: Gallifrey? And where\'s that?\nDOCTOR: Gone! Ruby, it\'s gone. It\'s gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\nDOCTOR: Let\'s have a random landing.\nRUBY: Whoa!\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\nRUBY: No!\nDOCTOR: Really.\nRUBY: No, you\'ve got to be k... You are kidding. Don\'t be so ridiculous. Are there dinosaurs out there?\nDOCTOR: I don\'t know. Go and have a look.\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\nDOCTOR: Well, that\'s not going to happen, is it? Who steps on butterflies? You\'d literally have to be like, ""Wait. Come \'ere, butterfly! ""Come \'ere, \'ave it!""\n\n[Prehistoric Earth]\n\nRUBY: Oh, my God. That... that\'s so beautiful.\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we\'ve moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\n(A boot steps on a butterfly.)\nDOCTOR: Oh!\n(Ruby is no longer a human.)\nRUBATHON: What\'s wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\nDOCTOR: But...\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\nRUBATHON: What are you doing?\nDOCTOR: Nothing, just...\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\nRUBY: Am I missing summat?\nDOCTOR: Nothing. Let\'s try that again, okay?\nRUBY: Thank you.\nDOCTOR: Yeah. Yeah, yeah, yeah.\n\n[Tardis]\n\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let\'s go forward. Give me a number. Give me a year.\nRUBY: Er, two.\nDOCTOR: Two.\nRUBY: One.\nDOCTOR: One.\nRUBY: Five.\nDOCTOR: Five.\nRUBY: Oh.\nDOCTOR: Oh.\nRUBY: Ah, six!\nDOCTOR: Six! Ah! Five numbers! I like it!\n(The Tardis travels the Vortex.)\n\n[Space station]\n\nRUBY: But we\'re indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\nDOCTOR: We\'ve got to visit them one day.\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\nDOCTOR: Oh, it\'s, er... it\'s broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\nRUBY: Oh, it stinks\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\nRUBY: No, you\'ve made it worse.\n(Something snarls nearby. They both jump.)\nDOCTOR: No, that is worse.\nRUBY: Is that a monster?\nDOCTOR: No. No, don\'t be silly, Ruby. There\'s no such thing as monsters, there\'s just... just creatures you haven\'t met yet. Hi there.\n(The creature roars.)\nRUBY: Run?\nDOCTOR: Run! Run! Run!\n(They and the monster are visible on monitors as they run down passages.)\nDOCTOR: Come on! In here, in here, in here, in here.\nRUBY: But...now we\'re trapped! Now we\'re trapped! Push the button! Doctor!\nDOCTOR: Okay.\n(The tiny one-person lift takes them up. The Doctor\'s hand is over Ruby\'s eyes.)\nDOCTOR: Oh, yeah, yeah.\n(The lift abruptly arrives.)\n\n[Birth Zone 6]\n\nDOCTOR: The question is, why did I run?\nRUBY: \'Cos it was scary.\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn\'t run fast enough. I was like whoosh!\nRUBY: Well, it\'d help if we knew where we were.\nDOCTOR: Yet again, push the button.\n(The lights come on so they can see all the glassware, containing...)\nDOCTOR: Oh. Oh, we\'re on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\nRUBY: I was going to say the same thing to you.\nDOCTOR: We\'ve gone from baby to baby. I\'m not saying things are connected, and yet... things connect.\nRUBY: Well, I\'m the one looking for my parents, and you\'ve got a Time and Space machine. So this place grows babies. What for? Food?\nDOCTOR: Food? What? What?! Food? They\'re not tomatoes!\nRUBY: Well, excuse me. There\'s a big hungry thing downstairs.\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don\'t know, goes mad and bans kissing.\nRUBY: So these babies are human, yeah?\nDOCTOR: Yep, grown for a colony world.\nRUBY: And a colony world is not Earth?\nDOCTOR: Hey. Okay, one last time, push the button.\n(And a shield retracts to reveal that they are in orbit.)\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\nDOCTOR: Yeah.\nRUBY: How do you keep going?\nDOCTOR: For days like this, Ruby Sunday. I don\'t have a people. I don\'t have a home. But I don\'t have a job, either. I don\'t have a boss, or taxes or rent or bills to pay. I don\'t have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\nRUBY: So where\'s this, then?\nDOCTOR: Oh, er...\n(Calls it up on a screen.)\nDOCTOR: Huh. Planet Pacifico del Rio.\nRUBY: Oh, that\'s in English. They speak English here? English exists?\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It\'s got a perception filter, so it helps you fit into every time and place.\nRUBY: Right, and my mum, she\'s long gone now.\nDOCTOR: Can I see your phone?\nRUBY: Yes.\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\nRUBY: What?\nDOCTOR: Carla. Phone her.\nRUBY: But...\nDOCTOR: Your mum, Ruby. Call your mum.\n\n[Ruby\'s home / Birth Zone 6]\n\nCARLA: Well? What is it now?\nRUBY: Mum?\nCARLA: Yes, Mum, obviously. You\'ve just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\nRUBY: Yeah. Yes, I will... I\'ll, er... I\'ll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\n\n[Birth Zone 6]\n\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That\'s the best signal ever. How much does that cost?\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It\'s calm up here, but underneath it is seething, just like downstairs with that creature. There\'s got to be a crew or a captain...\n(Enter a child in a motorised push-chair.)\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I\'ve opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can\'t...\nDOCTOR: Hi.\nRUBY: You all right?\nERIC: But... you. Oh. We\'ve been waiting for an awfully long time. Mummy! Daddy!\nDOCTOR: Oh, no.\nRUBY: No, no. No, darling, we\'re not...\nERIC: Boys-oh-boys, I\'ve got to tell everybody Mummy and Daddy are here.\n(Leaves the room.)\nRUBY: A baby farm. Run by babies.\nDOCTOR: Ha-ha! Space babies!\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\n\n[Control room]\n\nERIC: They\'re here. They came at last. Mummy and Daddy are here.\n(All the crew are in electric pushchairs.)\nBABIES: Mummy and Daddy! They came back!\nDOCTOR: Hello, space babies.\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\nDOCTOR: Oh.\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we\'ve been doing. Make them proud.\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\nMARCEL?: My job is to keep the pipes clean. I\'m proud of the pipes.\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\nSANDRA?: And I pull this string and that string. I\'m not sure what they do, but I pull them very hard.\nERIC: And I made this for you. It\'s a little flower.\nRUBY: Thank you.\nPOPPY: I\'m Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you\'d come back for us one day. We waited.\nDOCTOR: Right. You\'re not supposed to be running this place. This isn\'t Baby World. You got left behind when the adults... ..vamoosed?\nPOPPY: We took over. We were very brave.\nRUBY: Right. That\'s great. That\'s, oh, that\'s good. That\'s amazing. You\'ve done a really great job.\nDOCTOR: I\'m sorry, Poppy, I\'m so sorry, but we are not your mummy and daddy. I wish we were, but we\'re not.\nERIC: They left us. Where did they go?\nRUBY: I don\'t know, darling, but... I\'m Ruby and this... this is the Doctor. And we\'re your friends. Yeah, got you. I\'ve got you, I\'ve got you, I\'ve got you, I\'ve got you.\n(She picks up Eric from his pushchair.)\nBABIES: And me! And me! And me! And me!\nDOCTOR: Oh, gosh.\nBABIES: And me! And me!\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\nPOPPY: Never.\nDOCTOR: Oh. Oh, baby, it\'s okay. Come here, it\'s okay. It\'s okay, it\'s okay. Shh-shh-shh. Aww, never had a hug.\nRUBY: Come on, you can all have a hug.\n(Later, with everyone back in their pushchairs.)\nPOPPY: Did I get things wrong, Doctor\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don\'t know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\nPOPPY: But are we wrong?\nDOCTOR: What do you mean?\nPOPPY: We\'re not meant to be like this. Did we grow up wrong?\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\nPOPPY: But Mummy and Daddy left us.\nDOCTOR: That\'s okay. Mine did, too.\nPOPPY: What happened?\nDOCTOR: Well, I was found.\nPOPPY: Hooray!\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\nPOPPY: I don\'t know.\nDOCTOR: The Time Lords.\nPOPPY: Ooo.\nDOCTOR: Can you say it like me?\nPOPPY: The Time Lords.\nDOCTOR: That\'s it, P-P-P-P-Pop. But the point is, is that it doesn\'t matter where I come from, because I am absolutely lovely, aren\'t I?\n(Poppy yawns.)\nDOCTOR: That wasn\'t rhetorical, Pops.\nPOPPY: Yes, you are.\nDOCTOR: And do you want to know my secret? There\'s no one like me in the whole wide universe. No one like me exists, and that\'s true of everyone.\nIt\'s not a problem, Captain Pops. It\'s a superpower. High five. Yeah.\nPOPPY: Yeah!\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\nRUBY: So you\'re Eric. And you\'re Tasha. And Ruben. And then there\'s Saltine and Boo.\nERIC: I love you, Ruby.\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\nERIC: We\'ve got Nanny. Say hello, Nanny.\nNAN-E: Good afternoon, children, and welcome to our new visitors.\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I\'m the Doctor, and this is Ruby.\nNAN-E: We have visitors, children.\nERIC: Nanny!\nNAN-E: Noses must be blown. Activate nose-blow.\nDOCTOR: Er...\nNAN-E: One, two, three and... blow.\n(Mechanical hands on the pushchairs put handkerchiefs to the babies\' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\nRUBY: Oh, can\'t wait to see that.\nDOCTOR: Right. So it\'s you lot? It\'s Nan-E And downstairs, is that your pet dog?\n(Everyone screams and cries.)\nERIC: That\'s not a doggo.\nRUBY: What is it then, Eric?\nERIC: The Bogeyman.\nRUBY: Shush, shush, shush. Shush, shush, shush.\nDOCTOR: No. Gosh.\nERIC: We don\'t like the Bogeyman.\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\nDOCTOR: Bogeyman!\nRUBY: No, stop it! No, stop it! Nan-E, tell them there\'s no such thing as the Bogeyman.\nNAN-E: Nan-E is scared of the Bogeyman.\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\n(Puts it on monitor. The babies wail.)\nRUBY: Doctor, turn it off.\nDOCTOR: Okay.\nRUBY: No, listen to me. Listen to me.\nDOCTOR: I\'m sorry, I\'m sorry. I\'m sorry, babies. Space babies. I\'m sorry.\nPOPPY: Oh, Ruby...\n(The Doctor finds a headset and puts it on, then works a computer.)\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\nNAN-E: Portal 3-5-7.\nDOCTOR: Okay, what\'s that?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: That\'s on this floor. What is it?\nNAN-E: Access Portal 3-5-7.\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\nNAN-E: Oh, for God\'s sakes, 3-5-7. Come on!\nRUBY: Where do you think you\'re going?\nDOCTOR: Portal 3-5-7!\nRUBY: Right. Great. Ok. Coming!\n\n[Corridor]\n\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That\'s like your... purpose?\nDOCTOR: No, no, I\'m just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum\'s still waiting for me.\nDOCTOR: Back home, on your birthday. Yeah, it\'s strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don\'t know anything about your birth mother or your father? They didn\'t leave a note or a scrap of paper...?\nRUBY: Nothing. I was... I was just left.\nDOCTOR: By the church.\nRUBY: In the snow.\nDOCTOR: On Ruby Road.\n(The Doctor sees a figure point at him by the church.)\nRUBY: Doctor...\nDOCTOR: What?\nRUBY: It\'s snowing. Okay, what just happened? I said snow, and we\'ve got... ..snowflakes.\nDOCTOR: It\'s like a memory just came through, from the day that you were born.\nRUBY: But how? Is this the sort of thing that happens with time travel?\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\nRUBY: Then what does it mean?\nDOCTOR: I don\'t know.\n(The snow has stopped.)\nDOCTOR: Oh, I thought my birth was crazy...\nRUBY: Oh, yeah.\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\n(A door opens.)\nJOCELYN: I said Portal 3-5-7. Don\'t just stand there yapping, you pair of idiots. Get inside!\nRUBY: Who\'s she?\nDOCTOR: Nan-E. Ha!\nRUBY: Oh.\n\n[Portal 357]\n\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I\'m signing off under protest and wish to condemn this course of action.\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I\'d like to say for the record, the company\'s actions are appalling. I will be launching an appeal against this as soon as we\'re home.\n(Jocelyn fixes a gas leak with a blow from a wrench.)\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\n(Played by Susan Twist. She keeps turning up, does this woman.)\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\nJOCELYN: It\'s the recession. The government closed the Babystation to save money, but the law says it\'s illegal to stop the birth machine.\n(Another leak, another thump with the wrench.)\nJOCELYN: But how did you arrive? Have you got a way out of here?\nDOCTOR: I\'ve got a ship, yeah, it\'s er... What is your name - sorry, Nan-E?\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don\'t know how this place works.\n(The Doctor plugs his sonic into the computer.)\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\nJOCELYN: Thank you. Wanna swap?\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they\'re born, they don\'t look after them?\nJOCELYN: It\'s a very strange planet.\nRUBY: It\'s not that strange.\nDOCTOR: But you stayed behind.\nJOCELYN: I couldn\'t leave them. And I tried with this place. But I\'m not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It\'s a mess. And I\'ve been all on my own, watching the kids, for six years.\nDOCTOR: But I don\'t understand. They are gorgeous. Why would you hide?\nJOCELYN: Cos I don\'t want to see them die. And I don\'t want them to see me die. \'Cos that\'s how bad it is. This is a closed station. There\'s only so much air. There\'s only so much food. The last thing I\'ll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\nRUBY: Can\'t you fly somewhere else?\nJOCELYN: What do you mean, fly?\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can\'t move. It\'s just stuck in orbit, which is a shame, because this is a nice little system.\nJOCELYN: The fifth planet out, Mondo Caroon, that\'s a DuBarryDuPlessy world.\nDOCTOR: Oh, that\'s good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\nRUBY: Oh. Well, can\'t we call them for help?\nJOCELYN: They don\'t go and fetch refugees. That\'s the fate of every refugee in the universe. You physically have to turn up on someone else\'s shore. And we can\'t move.\nDOCTOR: But now you have a ship. Plenty of room. It\'s called the Tardis. The trouble is, between us and the ship is the Bogeyman.\nJOCELYN: What is that thing?\nBOTH: You don\'t know?\nJOCELYN: It\'s nothing to do with me. It\'s not part of the manifest. It\'s not like anything I\'ve ever seen.\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\nJOCELYN: Because it\'s terrifying.\nDOCTOR: Yeah, but I\'ve met a million ugly bugs. I\'m an ugly bug. That thing made me run, and I just wonder why.\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you\'ve got babies, you\'ve got a nanny, and you\'ve got the Bogeyman. You\'ve literally got a monster living down below. It\'s a children\'s story come to life.\nDOCTOR: And every story has its hero.\n(They spot someone on the screen.)\nRUBY: That\'s Eric. Is that Eric?\nJOCELYN: Eric, get out of there.\n\n[Space station]\n\nNAN-E: Eric, please vacate this area.\n\n[Portal 357]\n\nDOCTOR: Oh, is that how it works?\nJOCELYN: Nan-E filter. Eric, get out now.\n\n[Space station]\n\nNAN-E: Eric will leave immediately.\nERIC: No, Nanny! I\'m being brave.\n\n[Portal 357]\n\nJOCELYN: Eric, for God\'s sake, run!\n\n[Space station]\n\nNAN-E: Eric, invoking the deity, accelerate perambulation.\nERIC: I\'m doing what Ruby said.\n\n[Portal 357]\n\nRUBY: What?\n\n[Space station]\n\nERIC: I love Ruby, and she said there\'s no such thing as the Bogeyman. So I\'m going to find the naughty doggo and tell him off.\n(He meets the Bogeyman.)\nERIC: But I\'m so scared.\n\n[Portal 357]\n\nRUBY: Oh, my God, it\'s my fault!\n\n[Birth Zone 6]\n\nRUBY: Eric, I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming! I\'m coming!\n\n[Space station]\n\n(Ruby and the Doctor take the little lift down, and find Eric\'s pushchair fallen over.)\nRUBY: Oh.\nDOCTOR: Nan-E, where\'s the Bogeyman?\n\n[Portal 357]\n\nJOCELYN: It\'s about 400 metres north-west of you. But still no sign of Eric. I can\'t get a proper fix. I told you, these systems are a crock of...\n\n[Space station]\n\nNAN-E: ..waste products.\nDOCTOR: Mind your language, Nan-E.\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\nDOCTOR: Yes.\nRUBY: Okay, right.\nDOCTOR: Yes. Yes, yes.\n(They pick up things to hit the pipework with and move off.)\nRUBY: Bogeyman! Bogeyman!\nBOTH: Bogeyman! Bogeyman!\n\n[Portal 357]\n\nJOCELYN: It\'s moving. It\'s heard you.\n\n[Space station]\n\nRUBY: Okay, nice plan, but what now?\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. \'Cos I can detect...\n(In a locker.)\nDOCTOR: Space baby! Oh, Eric.\nRUBY: We\'ve got you, we\'ve got you.\nDOCTOR: Oh, you poor thing. It\'s okay.\nRUBY: I know, I know. I know.\n\n[Portal 357]\n\nJOCELYN: Not west, I meant east.\n\n[Space station]\n\nDOCTOR: Go, go. It\'s all right, it\'s all right. It\'s all right, it\'s all right, it\'s all right. All right, all right. It\'s all right.\nRUBY: It\'s okay, it\'s okay.\nDOCTOR: All right.\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\n\n[Portal 357]\n\nJOCELYN: Don\'t you touch them, you...\n\n[Space station]\n\nNAN-E: ..illegitimate person.\nDOCTOR: Go! Go. It\'s a dead end.\n(The Bogeyman is there.)\nDOCTOR: Whoa! It\'s okay, it\'s okay. You\'re okay.\n(The Bogeyman is attacked by flames. It runs away.)\nPOPPY: Babies to the rescue!\nDOCTOR: Ha! Space babies!\nRUBY: Babies with a flame-thrower!\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\n(He whistles up Eric\'s pushchair.)\nRUBY: Okay, let\'s get you in here, come on. Let\'s get you in there. Nan-E, tell them what to do.\nNAN-E: Children will return to the upper levels or have no expletive dinner.\nBABIES: Goodbye.\nDOCTOR: Okay, er, you... you go with them. I\'ve got to stay here. Not just for the Tardis, but I\'ve got to find out what that thing is.\nRUBY: If that\'s you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\n(They head back through the stinky area.)\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\n\n[Portal 357]\n\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don\'t know how it even exists.\n\n[Space station]\n\nRUBY: And that was six years ago?\nDOCTOR: Shh-shh-shh.\nRUBY: Oh. That\'s the same time the babies were born.\nDOCTOR: It\'s leaving... some sort of spoor. Man, that\'s a good word. Spoor.\nNAN-E: What the bleep-bleep is that?\nRUBY: Oh, Jocelyn, turn the filter off.\n\n[Portal 357]\n\nJOCELYN: What is that stuff?\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\nJOCELYN: The machine\'s got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\n\n[Space station]\n\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\n(She slips then gets dribbled on from a pipe outlet.)\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don\'t call me Rubes!\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let\'s make sense of this thing. Ah, according to the machine... Oh.\nRUBY: What?\nDOCTOR: It has been right in front of us. We\'ve been saying it all along. It\'s all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\nRUBY: It grew the Bogeyman.\nDOCTOR: Yes!\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\nRUBY: It\'s like a story. The teaching software, it told a story.\nDOCTOR: It invented the Bogeyman.\nRUBY: For the babies.\nDOCTOR: For the space babies.\nRUBY: The machine is literal, like a computer. It literally said, ""Babies need fiction, they need stories, they need monsters.""\nDOCTOR: Yes. That is why I\'m so scared. It\'s all deliberate, it\'s infrasound. The Bogeyman is roaring at 17 hertz, that\'s the exact pitch designed to make you scared. It\'s scary because it\'s meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\nRUBY: What.\nDOCTOR: Oh, Ruby.\nRUBY: What?\nDOCTOR: Oh, man.\nRUBY: Tell me what it is.\nDOCTOR: I can\'t.\nRUBY: Doctor!\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\nRUBY: I don\'t know.\nDOCTOR: The machine is literal, and the name is Bogeyman.\nRUBY: So?\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\nRUBY: What?\nDOCTOR: All of this is bogeys.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: Yes.\nRUBY: No.\nDOCTOR: No wonder it was shedding its skin. Doesn\'t everyone?\nRUBY: No, no, no, no.\nDOCTOR: It\'s snot.\nRUBY: It\'s not.\nDOCTOR: Oh, Ruby, it is a living sneeze!\nRUBY: But it\'s in my...\nDOCTOR: I know.\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don\'t laugh!\nDOCTOR: Sorry. Oh, isn\'t the universe mad?\nRUBY: Oh yeah, it just made a monster out of snot.\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\n(The monster is in front of them.)\nRUBY: Bogeyman.\nDOCTOR: Run. Run! Go!\n(A barrier blocks their path.)\nDOCTOR: No, no, no, no!\n\n[Portal 357]\n\nJOCELYN: Don\'t worry, it\'s me. Turn right. It\'s your device. It\'s calibrated. It\'s brilliant! I\'ve got control at last. Now trust me. Turn right!\nDOCTOR [on screen]: This isn\'t the way to the lift!\nJOCELYN: Keep going.\n(She unlocks doors remotely.)\n\n[Space station]\n\nRUBY: Ah!\nDOCTOR: Go, go, go, go!\nRUBY: I\'m coming, I\'m coming!\n\n[Portal 357]\n\nJOCELYN: It\'s catching up!\n\n[Space station]\n\nRUBY: Coming!\n(A door slides closed between them and the Bogeyman.)\nDOCTOR: Whoa!\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\n\n[Portal 357]\n\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\nJOCELYN: You can tell me later. Once I\'ve got rid of it. I will protect my children and blast that thing into space!\n\n[Airlock door]\n\nDOCTOR: It\'s an airlock.\n(The Bogeyman is hanging on for dear life.)\nDOCTOR: It is one of the children, Jocelyn! I... She\'s got the sonic. Jocelyn, Jocelyn!\nCOMPUTER: Oxygen field at 10%.\nDOCTOR: Okay, okay, okay, okay. We haven\'t got time. Stop Jocelyn, yeah?\nRUBY: Wait...\nDOCTOR: Left, second right, next left, you\'ll get to the lift.\nRUBY: What about you?\nDOCTOR: Left, second right, next left!\nRUBY: Right, okay.\n(She runs off.)\n\n[Control room]\n\nCOMPUTER: Oxygen field at 9%.\nPOPPY: You\'re hurting him.\nERIC: Stop it, Nanny. Stop it!\nCOMPUTER: Oxygen field at 8%.\n\n[Airlock door]\n\nDOCTOR [memory]: I am the last of the Time Lords.\nRUBY [memory]: How do you keep going?\nDOCTOR [memory]: For days like this. I\'m the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\nDOCTOR: The only one of its kind.\nCOMPUTER: Oxygen field at 7%.\n(The Doctor opens the airlock door and holds it open with his body.)\nCOMPUTER: Oxygen field at 6%.\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\nCOMPUTER: Oxygen field at 3%.\nDOCTOR: Push...the button.\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\n\n[Portal 357]\n\n(Ruby runs in and grabs the sonic.)\nJOCELYN: No!\nRUBY: That\'s what you do, Jocelyn. You save them all.\nCOMPUTER: Oxygen field at 1%.\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\nRUBY: You save them all. Come here. It\'s okay, it\'s okay.\n(Jocelyn cries in Ruby\'s arms.)\n\n[Control room]\n\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\nERIC: Nanny was really naughty.\nJOCELYN: I know, and I\'m so sorry. All of you. I was just... on my own for such a very long time.\nERIC: We still love you, Nanny.\nBABIES: Yay! We do!\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\nBABIES: Yay!\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\nBABIES: Wow!\nDOCTOR: The world of Mondo Caroon. But... but you can\'t get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\nBABIES: Huh?\nDOCTOR: Huh? \'Cos the system went wrong, and that\'s where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\nJOCELYN: Nan-E filter.\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\nDOCTOR: Oh, set sail for your new home. Baby World!\nRUBY: Come here now. Are you happy now, Eric?\nERIC: I\'m very, very happy. I love you, Ruby.\n\n[Outside the Tardis]\n\nRUBY: So that was a normal day for you, then?\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\nRUBY: What for?\nDOCTOR: I have the whole universe at my fingertips, and I\'m all on my own. So I\'d love it if you came with me.\nRUBY: To what, just travel?\nDOCTOR: No job. No boss. Just fun.\nRUBY: We did almost die.\nDOCTOR: Yes. But we lived so much, too.\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\nDOCTOR: Yes?\nRUBY: Yes.\nDOCTOR: Yes?\nRUBY: Yes. Oh, my God.\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\nRUBY: Come on in. Follow me.\nDOCTOR: Oh, come on.\n\n[Tardis]\n\nRUBY: Right, mate, let me tell you where we\'re gonna go.\nDOCTOR: Except...\nRUBY: Oh, terms and conditions.\nDOCTOR: There is one thing that I can never do, Ruby. And that\'s take you to that church on Ruby Road that Christmas. Absolutely never.\nRUBY: But you\'ve got a time machine.\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother\'s story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can\'t. And I won\'t.\nRUBY: Well, that\'s a pity. \'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\n\n[Ruby\'s home]\n\nCARLA: (on phone) And Ruby phoned, she said, ""I love you,"" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What\'s that noise?\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\nCHERRY: What the blinking flip?\n(Tardis door opens.)\nRUBY: Hiya, Mummy.\nCARLA: But... what are you doing? And what the hell is that? What\'s it done to my kitchen?\n\n[Tardis]\n\nRUBY [OC]: Hey! Come and say hello!\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\n(He sonicks up a quick DNA scan of Ruby Sunday.)\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\n(He doesn\'t wait for the results of the scan.)']",I don't know.,0.0,0.0,0.0006770480704129993,0.0,0.0
What kind of gun does the bandana bullet kin use?,The bandana bullet kin wields a machine pistol.,"['Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.'
 ""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 'Recipes\nThis page includes code snippets or “recipes” for a variety of common tasks. Use them as building blocks or examples when making your own notebooks.\n\nIn these recipes, each code block represents a cell.\n\nControl Flow\nShow an output conditionally\nUse cases. Hide an output until a condition is met (e.g., until algorithm parameters are valid), or show different outputs depending on the value of a UI element or some other Python object\n\nRecipe.\n\nUse an if expression to choose which output to show.\n\n# condition is a boolean, True of False\ncondition = True\n""condition is True"" if condition else None\nRun a cell on a timer\nUse cases.\n\nLoad new data periodically, and show updated plots or other outputs. For example, in a dashboard monitoring a training run, experiment trial, real-time weather data, …\n\nRun a job periodically\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a mo.ui.refresh timer that fires once a second:\n\nrefresh = mo.ui.refresh(default_interval=""1s"")\n# This outputs a timer that fires once a second\nrefresh\nReference the timer by name to make this cell run once a second\n\nimport random\n\n# This cell will run once a second!\nrefresh\n\nmo.md(""#"" + """" * random.randint(1, 10))\nRequire form submission before sending UI value\nUse cases. UI elements automatically send their values to the Python when they are interacted with, and run all cells referencing the elements. This makes marimo notebooks responsive, but it can be an issue when the downstream cells are expensive, or when the input (such as a text box) needs to be filled out completely before it is considered valid. Forms let you gate submission of UI element values on manual confirmation, via a button press.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a submittable form.\n\nform = mo.ui.text(label=""Your name"").form()\nform\nGet the value of the form.\n\nform.value\nStop execution of a cell and its descendants\nUse cases. For example, don’t run a cell or its descendants if a form is unsubmitted.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a submittable form.\n\nform = mo.ui.text(label=""Your name"").form()\nform\nUse mo.stop to stop execution when the form is unsubmitted.\n\nmo.stop(form.value is None, mo.md(""Submit the form to continue""))\n\nmo.md(f""Hello, {form.value}!"")\nGrouping UI elements together\nCreate an array of UI elements\nUse cases. In order to synchronize UI elements between the frontend and backend (Python), marimo requires you to assign UI elements to global variables. But sometimes you don’t know the number of elements to make until runtime: for example, maybe you want o make a list of sliders, and the number of sliders to make depends on the value of some other UI element.\n\nYou might be tempted to create a Python list of UI elements, such as l = [mo.ui.slider(1, 10) for i in range(number.value)]: however, this won’t work, because the sliders are not bound to global variables.\n\nFor such cases, marimo provides the “higher-order” UI element mo.ui.array, which lets you make a new UI element out of a list of UI elements: l = mo.ui.array([mo.ui.slider(1, 10) for i in range(number.value)]). The value of an array element is a list of the values of the elements it wraps (in this case, a list of the slider values). Any time you interact with any of the UI elements in the array, all cells referencing the array by name (in this case, “l”) will run automatically.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.array to group together many UI elements into a list.\n\nimport random\n\n# instead of random.randint, in your notebook you\'d use the value of\n# an upstream UI element or other Python object\narray = mo.ui.array([mo.ui.text() for i in range(random.randint(1, 10))])\narray\nGet the value of the UI elements using array.value\n\narray.value\nCreate a dictionary of UI elements\nUse cases. Same as for creating an array of UI elements, but lets you name each of the wrapped elements with a string key.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.dictionary to group together many UI elements into a list.\n\nimport random\n\n# instead of random.randint, in your notebook you\'d use the value of\n# an upstream UI element or other Python object\ndictionary = mo.ui.dictionary({str(i): mo.ui.text() for i in range(random.randint(1, 10))})\ndictionary\nGet the value of the UI elements using dictionary.value\n\ndictionary.value\nEmbed a dynamic number of UI elements in another output\nUse cases. When you want to embed a dynamic number of UI elements in other outputs (like tables or markdown).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nGroup the elements with mo.ui.dictionary or mo.ui.array, then retrieve them from the container and display them elsewhere.\n\nimport random\n\nn_items = random.randint(2, 5)\n\n# Create a dynamic number of elements using `mo.ui.dictionary` and\n# `mo.ui.array`\nelements = mo.ui.dictionary(\n    {\n        ""checkboxes"": mo.ui.array([mo.ui.checkbox() for _ in range(n_items)]),\n        ""texts"": mo.ui.array(\n            [mo.ui.text(placeholder=""task ..."") for _ in range(n_items)]\n        ),\n    }\n)\n\nmo.md(\n    f""""""\n    Here\'s a TODO list of {n_items} items\\n\\n\n    """"""\n    + ""\\n\\n"".join(\n        # Iterate over the elements and embed them in markdown\n        [\n            f""{checkbox} {text}""\n            for checkbox, text in zip(\n                elements[""checkboxes""], elements[""texts""]\n            )\n        ]\n    )\n)\nGet the value of the elements\n\nelements.value\nCreate a hstack (or vstack) of UI elements with on_change handlers\nUse cases. Arrange a dynamic number of UI elements in a hstack or vstack, for example some number of buttons, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate buttons in mo.ui.array and pass them to hstack – a regular Python list won’t work. Make sure to assign the array to a global variable.\n\nimport random\n\n\n# Create a state object that will store the index of the\n# clicked button\nget_state, set_state = mo.state(None)\n\n# Create an mo.ui.array of buttons - a regular Python list won\'t work.\nbuttons = mo.ui.array(\n    [\n        mo.ui.button(\n            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)\n        )\n        for i in range(random.randint(2, 5))\n    ]\n)\n\nmo.hstack(buttons)\nGet the state value\n\nget_state()\nCreate a table column of buttons with on_change handlers\nUse cases. Arrange a dynamic number of UI elements in a column of a table, and execute some side-effect when an element is interacted with, e.g. when a button is clicked.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate buttons in mo.ui.array and pass them to mo.ui.table. Make sure to assign the table and array to global variables\n\nimport random\n\n\n# Create a state object that will store the index of the\n# clicked button\nget_state, set_state = mo.state(None)\n\n# Create an mo.ui.array of buttons - a regular Python list won\'t work.\nbuttons = mo.ui.array(\n    [\n        mo.ui.button(\n            label=""button "" + str(i), on_change=lambda v, i=i: set_state(i)\n        )\n        for i in range(random.randint(2, 5))\n    ]\n)\n\n# Put the buttons array into the table\ntable = mo.ui.table(\n    {\n        ""Action"": [""Action Name""] * len(buttons),\n        ""Trigger"": list(buttons),\n    }\n)\ntable\nGet the state value\n\nget_state()\nCreate a form with multiple UI elements\nUse cases. Combine multiple UI elements into a form so that submission of the form sends all its elements to Python.\n\nRecipe.\n\nImport packages.\n\nimport marimo as mo\nUse mo.ui.form and Html.batch to create a form with multiple elements.\n\nform = mo.md(\n   r""""""\n   Choose your algorithm parameters:\n\n   - $\\epsilon$: {epsilon}\n   - $\\delta$: {delta}\n   """"""\n).batch(epsilon=mo.ui.slider(0.1, 1, step=0.1), delta=mo.ui.number(1, 10)).form()\nform\nGet the submitted form value.\n\nform.value\nWorking with buttons\nCreate a button that triggers computation when clicked\nUse cases. To trigger a computation on button click and only on button click, use mo.ui.run_button().\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a run button\n\nbutton = mo.ui.run_button()\nbutton\nRun something only if the button has been clicked.\n\nmo.stop(not button.value, ""Click \'run\' to generate a random number"")\n\nimport random\nrandom.randint(0, 1000)\nCreate a counter button\nUse cases. A counter button, i.e. a button that counts the number of times it has been clicked, is a helpful building block for reacting to button clicks (see other recipes in this section).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nUse mo.ui.button and its on_click argument to create a counter button.\n\n# Initialize the button value to 0, increment it on every click\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nGet the button value\n\nbutton.value\nCreate a toggle button\nUse cases. Toggle between two states using a button with a button that toggles between True and False. (Tip: you can also just use mo.ui.switch.)\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nUse mo.ui.button and its on_click argument to create a toggle button.\n\n# Initialize the button value to False, flip its value on every click.\nbutton = mo.ui.button(value=False, on_click=lambda value: not value)\nbutton\nToggle between two outputs using the button value.\n\nmo.md(""True!"") if button.value else mo.md(""False!"")\nRe-run a cell when a button is pressed\nUse cases. For example, you have a cell showing a random sample of data, and you want to resample on button press.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a button without a value, to function as a trigger.\n\nbutton = mo.ui.button()\nbutton\nReference the button in another cell.\n\n# the button acts as a trigger: every time it is clicked, this cell is run\nbutton\n\n# Replace with your custom lgic\nimport random\nrandom.randint(0, 100)\nRun a cell when a button is pressed, but not before\nUse cases. Wait for confirmation before executing downstream cells (similar to a form).\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a counter button.\n\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nOnly execute when the count is greater than 0.\n\n# Don\'t run this cell if the button hasn\'t been clicked, using mo.stop.\n# Alternatively, use an if expression.\nmo.stop(button.value == 0)\n\nmo.md(f""The button was clicked {button.value} times"")\nReveal an output when a button is pressed\nUse cases. Incrementally reveal a user interface.\n\nRecipe.\n\nImport packages\n\nimport marimo as mo\nCreate a counter button.\n\nbutton = mo.ui.button(value=0, on_click=lambda count: count + 1)\nbutton\nShow an output after the button is clicked.\n\nmo.md(""#"" + """" * button.value) if button.value > 0 else None\nCaching\nCache expensive computations\nUse case. Because marimo runs cells automatically as code and UI elements change, it can be helpful to cache expensive intermediate computations. For example, perhaps your notebook computes t-SNE, UMAP, or PyMDE embeddings, and exposes their parameters as UI elements. Caching the embeddings for different configurations of the elements would greatly speed up your notebook.\n\nRecipe.\n\nUse functools to cache function outputs given inputs.\n\nimport functools\n\n@functools.cache\ndef compute_predictions(problem_parameters):\n   # replace with your own function/parameters\n   ...\nWhenever compute_predictions is called with a value of problem_parameters it has not seen, it will compute the predictions and store them in a cache. The next time it is called with the same parameters, instead of recomputing the predictions, it will return the previously computed value from the cache.\n\nSee our best practices guide to learn more.']",Bandana Bullet Kin wield Machine Pistols.,1.0,0.9410655347106635,0.001440922190201729,0.9999999999,1.0
Who wrote 'Divine Rivals'?,Rebecca Ross wrote 'Divine Rivals'.,"['The best sci-fi and fantasy books of 2023\nIt’s been a stellar year in speculative fiction\n\nBy Nicole Clark, Sadie Gennis, and Polygon Staff  Updated Dec 8, 2023, 10:00am EST  34 Comments / 34 New\nIf you buy something from a Polygon link, Vox Media may earn a commission. See our ethics statement.\n\nIt’s been another banner year for science fiction and fantasy books. Many of our favorites once again blur the line between sci-fi and fantasy, but this year was a particular standout for books blurring the line between SFF and other genres. This includes everything from historical fiction — both speculative histories and Westerns — to fable retellings to intergenerational sagas in translation.\n\nThough we seem to have crested the wave of pandemic novels, that sense of dread and discoloration has lingered, written into novels of new forms. There’s a preponderance of post-post-apocalyptic science fiction unpacking lofty ideas like sentience and humanity, often set on different planets or among the stars. It has also been a standout year for supernatural horrors and thrillers, particularly ones that mix queer longing with a dose of body horror. Last but not least, it’s been a great year for kissing books set in fantastical worlds.\n\nRELATED\n\nLooking for more recs? Here are our favorite books of 2022\nSo jump in and take your pick. Whichever direction you head in, it will be sure to grip you — and make you think. This list is in reverse chronological order, so the newest releases are listed first. We updated this list throughout 2023, sometimes retroactively adding in entries that we missed from earlier in the year. We’ve also included our favorite runners-up.\n\nHONORABLE MENTIONS\nEmily Wilde’s Encyclopaedia of Faeries by Heather Fawcett, Victory City by Salman Rushdie, The Crane Husband by Kelly Barnhill, The Mimicking of Known Successes by Malka Older, Monstrilio by Gerardo Sámano Córdova, White Cat, Black Dog by Kelly Link, Divine Rivals by Rebecca Ross, Our Hideous Progeny by C.E. McGill, The Cheat Code (Wisdom Revolution #3) by Misba, The Deep Sky by Yume Kitasei, Silver Nitrate by Silvia Moreno-Garcia, Vampires of El Norte by Isabel Cañas, Prophet by Sin Blaché and Helen Macdonald, Terrace Story by Hilary Leichter, Her Radiant Curse by Elizabeth Lim, Starling House by Alix E. Harrow, System Collapse (The Murderbot Diaries #7) by Martha Wells, Dark Heir (Dark Rise #2) by C.S. Pacat\n\nCover image for Ed Park’s Same Bed Different Dreams, a split image between what looks like Earth and Mars.\nImage: Random House\nSAME BED DIFFERENT DREAMS BY ED PARK\nSame Bed Different Dreams is a remarkable achievement, and not for the faint of heart. Through three storylines, the book creates a kind of speculative history of Korea, with an emphasis on World War II and Japan’s colonial rule and aftermath (and, crucially, the United States’ involvement). One story thread builds out a hefty alternative history of the Korean Provisional Government’s role and reach. Another story thread focuses on a Black Korean War vet who wrote a sci-fi epic series called 2333, which is later adapted into a video game. And yet another story thread has a more futuristic flavor, focusing on a has-been writer who now works for a tech company called GLOAT. These threads periodically intersect — for example, GLOAT ends up owning the rights to 2333, and turns it into a kind of edutainment.\n\nIf it sounds like there’s a lot going on, it’s because there is. And it’s made even denser by the author’s Pynchonian sense of humor. Some of its best moments are utterly weird or feel like the writer was smirking — like a character’s dog who can’t stop “archiving” by burying found manuscript pages, the fact that GLOAT employees truly don’t know what the acronym stands for, or the idea that Marilyn Monroe is a member of the Korean Provisional Government. These absurd bits only make it harder to comb apart what’s real and what’s Ed Park’s “alternate history” in sections with realistic-sounding combinations of fact and fiction.\n\nIt’s got the same ambitious patchwork as Jennifer Egan’s The Candy House and Namwali Serpell’s The Old Drift. Critics have compared it to everything from David Mitchell’s Cloud Atlas to David Foster Wallace’s Infinite Jest. There’s also, of course, books within the book. It’s a fever dream of a thing, and one I’d heartily recommend, but perhaps with a notebook in hand or some sticky notes to help track the references. (Or perhaps, as I did, just letting the wave of information roll over you, until you’re left with a vast impression and a desire to reread.) —Nicole Clark\n\nCover image for Kylie Lee Baker’s The Scarlet Alchemist, featuring a woman in a red outfit with a large crown set against a dark skyline.\nImage: Inkyard Press\nTHE SCARLET ALCHEMIST (THE SCARLET ALCHEMIST #1) BY KYLIE LEE BAKER\nDo not go into The Scarlet Alchemist expecting typical YA fare. What Kylie Lee Baker delivers is a story of visceral brutality, interlaced with elements of Chinese history and thoughtful meditations on family, race, and belonging. It’s a book that can turn your stomach as easily as it can break your heart.\n\nSet in an alternate Tang dynasty, the novel follows Zilan, a profoundly talented young alchemist who travels to the capital in hopes of landing a coveted position in the royal service. But being a poor, half Scotian girl means the odds are stacked inordinately high against her in the imperial service exams — and that’s before her skills with the illegal art of resurrection catch the prince’s attention and pull her into a dangerous political game. While the premise seems familiar (underdog competes in trials, falls into star-crossed romance), Baker’s skills with immersive world-building, knotty characters, and genuinely gruesome horror make The Scarlet Alchemist a dazzling and singular tale that left me rushing to read her back catalog. —Sadie Gennis\n\nCover image of C Pam Zhang’s Land of Milk and Honey, featuring rollicking hills of white, blue, and yellow.\nImage: Riverhead\nLAND OF MILK AND HONEY BY C PAM ZHANG\nAfter I read How Much of These Hills is Gold in 2020, C Pam Zhang became an instant must-read author in my household. Land of Milk and Honey is entirely unlike her debut — where her debut’s language was sparse and pointed, this book is florid and indulgent — though similar in the extent to which it transported me somewhere entirely new, and more than a little threatening.\n\nIn Land of Milk and Honey the climate apocalypse has rendered fresh produce, at scale, a thing of the past — which is to say a provision of the extremely rich. The protagonist, listless and hungry, applies for a job as a private chef for a mysterious family in the Italian Alps (those who live around it call it “\u200b\u200bla terra di latte e miele”). While there, she unravels the family’s true intentions, while making them delicious meals from rare ingredients.\n\nZhang sensuously describes all pleasures of the tongue, moving from descriptions of lapping of culinary delicacies to the folds of the flesh. Food feels hyperreal, with an emphasis on the texture and taste of every ingredient — and sometimes the cruelty of that ingredient’s procurement. The same can be said of its scenes depicting queer intimacy; that texture and taste take precedent, and the cruelties of human emotion, too. Even after I finished, I was hungry for more. —N. Clark\n\nCover image for Megan Kamalei Kakimoto’s Every Drop is a Man’s Nightmare, featuring a red and yellow flower against a painted backdrop.\nImage: Bloomsbury\nEVERY DROP IS A MAN’S NIGHTMARE BY MEGAN KAMALEI KAKIMOTO\nThis short story collection initially caught my attention with its cover, which depicts a woman springing up from the center of a corpse flower, like a stalk standing against the wind. Each story weaves together Hawaiian mythology and the everyday lives of the Hawaiian and mixed-race Japanese women who live there.\n\nThese stories range from fabulism to science fiction, all speculative fiction in their own way. In one story, a woman’s encounter with a wild pig ends up foreshadowing a complicated pregnancy later in her life. In another story, a Brazilian waxing company allows people to pay for hairless skin by giving up personality traits. In another story, the narrator falls for a woman who lives with her family — in one of numerous queer stories in the collection — but has to cope with that woman’s decision to return to “what remains of Kaua’i” and join their protests.\n\nThe author’s own words, published in The Guardian, sum it up best: “There is a mythical idealisation of the islands of Hawaii as paradise, peace in the tropics; some even call it a modern utopia. Yet this flattening of Hawaii to a postcard image divests our homeland of its culture and colour, reducing us to a place and history that is easily digestible. But we are not easily digestible, and our stories are not meant to be easy for you.” —N. Clark\n\nCover image for Shelley Parker-Chan’s He Who Drowned the World, a painted image of ships on a yellow sea, with the moon looming over them.\nImage: Tor\nHE WHO DROWNED THE WORLD (THE RADIANT EMPEROR #2) BY SHELLEY PARKER-CHAN\nAn alternate history of the founding of the Ming dynasty, He Who Drowned the World shifts between four tragically ambitious figures willing to pay any price to materialize their destiny, whether that’s revenge on the empire or crowning themselves the ruler of it. They pursue these goals with unshakeable inertia, doing endlessly cruel and sadistic actions with only the occasional doubts as to whether happiness could be possible if they chose a different path.\n\nThis is a relentlessly brutal sequel, and there’s a hopelessness that weighs heavy throughout the book. But Parker-Chan’s penetrating ability to bring empathy and nuance into even the darkest corners of humanity sparks an undeniable connection with these characters, whose self-destructive natures would otherwise be too hard to bear witness to. He Who Drowned the World is a dark and difficult read, yet Parker-Chan’s prose is so brilliant, her character work so complex, that I still found myself sad to leave this world behind. —SG\n\nCover image for M.A. Carricks’s Labyrinth’s Heart, featuring a mask-wearing figure with purple wings sprouting out of the top of the mask.\nImage: Orbit\nLABYRINTH’S HEART (ROOK & ROSE #3) BY M.A. CARRICK\nOne of my favorite fantasy series of the past five years, Rook & Rose is an intricately layered trilogy where there are so many secrets, schemes, and conspiracies that at times it’s admittedly difficult to keep track of them all. Because of that, there were a lot of loose ends to tie up in the anticipated conclusion, Labyrinth’s Heart. (Ren alone was juggling four different identities at the novel’s start.) So imagine my surprise when I discovered M.A. Carrick not only managed to leave no question unanswered by the series’ end, but wrapped up even the most complicated storylines in big, bright bows.\n\nThere are elements of Labyrinth’s Heart that feel like they were precisely crafted to cater to fans, but here’s the thing: I don’t really care. Carrick created such a lush world populated by lovable characters, an interesting magic system, and a lived-in cultural history that I was just happy to be back in Nadežra after a two-year wait. While things may have been tied up a bit too neatly for my usual tastes, that didn’t stop me from whipping through pages and smiling the whole way through. Sometimes it’s nice to simply soak in a happy ending rather than bathe in the bittersweet. —SG\n\nCover art for Kiersten White’s Mister Magic, which features a melting television against a pink background.\nImage: Del Rey Books\nMISTER MAGIC BY KIERSTEN WHITE\nThe latest fantasy-with-an-irresistible-pop-premise from the author of Hide, Mister Magic revolves around a children’s TV show no viewer can forget … or prove it ever existed in the first place. There are no official records of it, no YouTube videos or merchandise or passed-around VHS tapes, and any discussion of it on the internet rapidly disappears. But the people who remember seeing it are convinced the special effects were remarkably vivid and realistic. They agree the central concept is unnerving: a creepy magician-figure leading a group of children in imagination-games aimed at teaching some decidedly non-standard lessons about embracing conformity and meekness. And they’re all sure that something horrible happened while they were watching, though they can’t agree on what.\n\nA reunion between five of the former child cast members, taking place 30 years after the show ended, slowly unravels its mysteries, which are even weirder than the description above suggests. Mister Magic is a startling dark fantasy with a lot of foreboding, foreshadowing, and eerie twists. At heart, though, it’s also an incisive story about the kinds of people who revel in control over other people’s lives, and about what an act of rebellion imagination can be. —Tasha Robinson\n\nCover image for Rebekah Bergman’s The Museum of Human History, featuring a painted image of a naked figure with a red cloud over the top of their head.\nImage: Tin House\nTHE MUSEUM OF HUMAN HISTORY BY REBEKAH BERGMAN\nA poetic reflection on memory, loss, and connection, The Museum of Human History is a stunning debut reminiscent of the work of Emily St. John Mandel. Slipping backward and forward in time, this introspective mosaic weaves between an identical twin whose sister fell asleep at age 8 and has never aged in the 25 years since, a museum director who questions his place within the family legacy, a widower who lost his most cherished memories as a result of an anti-aging treatment, and others equally struggling with the passage of time. There is a lyrical detachment in Bergman’s prose that leaves you feeling like you’re watching events unfold through a pane of thick glass, never fully able to connect with the characters, yet you remain helplessly transfixed by the haunting cycle they’re caught in. It’s an incredibly melancholy book, but the kind of aching sadness you’re happy to sink into. —SG\n\nCover image for Sara Hashem’s The Jasad Heir, featuring what looks like statues of a snake,, a bull, and a griffin.\nImage: Orbit Books\nTHE JASAD HEIR (THE SCORCHED THRONE #1) BY SARA HASHEM\n“Arin of Nizahl was maddeningly elegant. I wanted to cut him open and compare our bones to understand why his gave him grace and mine gave me back pain.” This was the line that absolutely sold me on The Jasad Heir, an irresistible enemies-to-lovers fantasy that reminded me why I’ll never quit this genre.\n\nHeadstrong Sylvia is the presumed dead heir of Jasad, a kingdom that was destroyed by the neighboring Nizahl and saw its citizens’ innate magic outlawed. Sylvia managed to carve out a relatively normal life for herself as a chemist’s apprentice, but everything falls apart after she accidentally reveals her magic to the heir of Nizahl. Using her life as leverage, the calculating Arin strikes a deal with Sylvia to help him capture a group of Jasadi rebels and act as his champion in a series of deadly trials. It’s a familiar setup, but one impeccably done by Hashem, who delivers sharp political intrigue, sparkling banter, and touching friendships on top of Sylvia and Arin’s simmering romance. —SG\n\nCover image for Kritika H. Rao’s The Surviving Sky, featuring a floating island overgrowing with buildings and plant life, above a stormy planet.\nImage: Titan Books\nTHE SURVIVING SKY (THE RAGES TRILOGY #1) BY KRITIKA H. RAO\nAfter I finished The Surviving Sky, I wouldn’t shut up about it and tried (not always successfully) to get everyone I know to read it. So let me try once more, and maybe with less yelling this time:\n\nWith the planet’s surface made unlivable by catastrophic storms, the remains of humanity survive on floating cities constructed of and powered by plants that only a select group of people, known as architects, can control. An archeologist without the ability to traject plants, Ahilya has dedicated her life to finding a way to unshackle humanity’s survival from the architects’ powers and return to the surface. It’s not hard to see why this mission causes friction in her marriage to Iravan, one of the most powerful architects in their city, and one with an arrogance to match his revered status. Though estranged, Ahilya and Iravan come together to help clear his name after he’s accused of pushing his powers dangerously far, an accusation, which if proved true, carries dire consequences for the architect.\n\nBut the deeper they look into trajection and its risks, the more Ahilya and Iravan realize they don’t actually know much about where their people – and their powers – came from. And as the floating cities begin to sink toward the earthrages below, the race to save their civilization may also be the end of society as it stands, as Ahilya and Iravan uncover long-buried truths that previous generations worked hard to keep hidden.\n\nSo did I do it? Did I convince you to read this Hindu philosophy-inspired debut with some of the most inventive world-building and one of the most complex romances I’ve read in years? Please say yes. You’ll be doing us both a favor. —SG\n\nCover image for Alexander Darwin’s The Combat Codes, which features a metallic dragon against a black background.\nImage: Orbit\nTHE COMBAT CODES AND GRIEVAR’S BLOOD (THE COMBAT CODES SAGA #1-2) BY ALEXANDER DARWIN\nIn the world of The Combat Codes, war no longer exists as it used to. Neither does justice — both concepts have been replaced by proxies who fight on behalf of nations or individuals, solving disputes with their fists.\n\nAlexander Darwin’s debut novel effectively builds a world around this core concept, bringing it to life with compelling characters and locations (including a classic “magical school for gifted youngsters” situation). The Combat Codes follows Cego, a young abandoned boy skilled at fighting, and Murray, a washed-up former fighter now tasked with scouting the next generation of combatants, whose discovery of Cego changes his entire world.\n\nDarwin is also a Brazilian jiu-jitsu practitioner and teacher, and uses that experience in the books’ excellent fight sequences. His evocative and visceral descriptions not only deliver excitement and suspense in this underdog story; they build your understanding of the characters through how they fight. The Combat Codes and its equally fun sequel, Grievar’s Blood, which adds new exciting characters and points-of-view, are the first two parts of a planned trilogy, and I can’t wait for the conclusion next year. —Pete Volk\n\nCover image for Katie Williams’ My Murder, showing a woman’s face peering outside of red vertical lines.\nImage: Riverhead Books\nMY MURDER BY KATIE WILLIAMS\nFans of Sarah Gailey’s The Echo Wife won’t want to miss My Murder, which shares some key elements and themes with Gailey’s novel while also taking them in a unique direction. In a near-future with only a few light sci-fi elements, Lou has been resurrected along with a handful of other women murdered by a single serial killer. The politics of resurrection in her world are complicated, and few people qualify. That leaves her and her fellow victims (whose therapy circle recalls Grady Hendrix’s The Final Girl Support Group) a bit at sea as they try to come to terms with their deaths, which none of them can recall, and their new lives as celebrities for all the wrong reasons.\n\nLike The Echo Wife, My Murder ends up thoughtfully exploring issues around women subjected to violent men — not just the personal and internal response, but the society that shapes that violence, and responds to it in ways that raise endless questions. The victims all respond to their deaths differently, questioning their culpability and the possible failures that might have made them targets, and navigating their families’ unpredictable responses to their revival. There’s one big mystery at the heart of My Murder, and a whole lot of abrupt and compelling surprises. But at the core, it’s a sci-fi twist on the survivor story, letting some very different people explore what it means to be victimized, and how to reclaim the lives that have been abruptly handed back to them. —TR\n\nCover image for Ann Leckie’s Translation State, a minimalist drawing with red, orange, and green, a silhouette of a person, and circular lines.\nImage: Orbit\nTRANSLATION STATE BY ANN LECKIE\nSet in the same universe as Leckie’s Imperial Radch trilogy, Translation State follows Enae, who leaves hir long-standing isolation for what was supposed to be an interstellar goose chase. After hir demanding grandmaman dies, Enae is given a diplomat title and assigned to investigate a missing Presgr translator no one expects to be found (but that the government still wants the goodwill for pretending to look for). Only, Enae doesn’t just pretend to look; sie discovers sie has quite the knack for investigating the 200-year-old cold case.\n\nThis is how hir path crosses that of Reet, an adopted maintenance worker whose mysterious origins and unsettling impulses might be explained by being the child of the fugitive translator, if you ask Enae, or the last descendant of a lost sovereign line, if you ask one particularly zealous diaspora social group. Rounding out the POV characters is Qven, a young Presgr terrified of their species’ ritual of merging with an elder, a rite of passage which will see Qven’s selfhood entirely dissolved. Enae, Reet, and Qven’s explorations of their own identities wind up having interplanetary consequences, but it’s the way Leckie gives weight to the small moments, both personal and shared, that make this book sing.\n\nThough I’m sure there are layers that only those familiar with the Imperial Radch trilogy will notice and appreciate, the standalone Translation State and its rich exploration of self-identification and personhood serve as a fantastic introduction to Leckie’s world. So don’t hesitate to jump into Translation State if you’re – like me – new to Radch and simply drawn to a thrilling mystery where the most intimate emotions can fuel a universal upheaval. —SG\n\nCover image for Rita Chang-Eppig’s Deep as the Sky, Red as the Sea, with facial features set against a crashing wave.\nImage: Bloomsbury Publishing\nDEEP AS THE SKY, RED AS THE SEA BY RITA CHANG-EPPIG\nI still remember standing in my local bookstore, struck by the cover of this book, and reading the summary. It had me at “Chinese pirate queen.”\n\nIn Deep as the Sky, Red as the Sea, Chang-Eppig writes a historical fantasy about Shek Yeung, a fearsome Chinese pirate who must navigate her fleet after the death of her powerful husband. She marries her late husband’s second-in-command, with the promise of bearing an heir, in order to retain power over the fleet — and stay a major player as the Chinese Emperor seeks to rid the waters of piracy.\n\nThe book isn’t paced like a thriller, so don’t make the mistake of assuming so when you start it. It’s equal parts historical exposition, strategy, and warfare — and it especially excels in its characterization of a complicated woman forced to make difficult decisions and sacrifices in order to protect her power. Fantasy can put its villains and heroes on pedestals, but Deep as the Sky, Red as the Sea never errs in its very human portrayal of Shek Yeung, and how deftly she must play this game of political chess for survival. I was riveted. —N. Clark\n\nCover art for Emma Törzs’ Ink Blood Sister Scribe, featuring a dripping pen growing out of the bottom of a tree against a purple background.\nImage: William Morrow\nINK BLOOD SISTER SCRIBE BY EMMA TÖRZS\nThere’s nothing cozier than a magical book about the magic of books — though this tale bends a little darker, and tells a story about witchcraft and complicated family dynamics. In Ink Blood Sister Scribe, two estranged sisters come together to solve the mystery of their family, and prevent further tragedies. In this world, blood can be concocted into ink — wielded by scribes for the creation of books with arcane powers — though the creation of such books drains a scribe’s health. When others read these books, they create magic; willing flowers to bloom, or making magical carpets that can fly in the air.\n\nInk Blood Sister Scribe is the perfect sister thriller to read in one sitting. It doesn’t reinvent the wheel, but it doesn’t need to — it simply delivers on a wonderfully entertaining premise. —N. Clark\n\nCover art for Martha Wells’ Witch King, featuring a person running across the cover while wearing a cloak and dress fitting for a fantasy setting.\nImage: Tor\nWITCH KING BY MARTHA WELLS\nIn an era where a lot of fantasy fans value quick or cozy reads, Martha Wells’ Witch King feels like a gauntlet thrown at readers’ feet. It’s a complex, meaty fantasy that opens well into what a more linear book would consider the third act, as Kai, the witch king of the title, is exhumed from a watery grave and starts exploring who betrayed him and trapped him there. Readers have to learn everything about Kai’s world as his story unfolds in multiple intertwined timelines. That includes figuring out what a “witch king” is, unwrapping the layers of what Kai actually is and why it matters. It also means being introduced to a wide variety of allies and enemies while alternately flashing back to how he met them, and slowly coming to understand the dense political machinations that shaped all their lives in the past and present.\n\nAs with Wells’ Murderbot books and her Books of the Raksura series in particular, part of the draw here is a powerful, skilled protagonist whose biggest struggles are often internal. Kai has a lot of intense emotional responses to the world, but lacks the tools to understand what to do with those feelings, or who to trust with them. Wells packs Witch King with a lot of audacious, expansive world-building for a standalone novel (albeit one that could easily invite sequels or prequels), but what makes Witch King an enjoyable read instead of a frustrating one is the way all the book’s complications and surprises are filtered through Kai’s vivid inner life, giving readers something to hold onto as they’re untangling the puzzlebox aspects of this cleverly structured novel. —TR\n\nCover image for Justin Lee Anderson’s The Lost War, featuring five figures walking through white grass after emerging from a dark green forest. Three of the figures wear green cloaks, while two wear white.\nImage: Orbit\nTHE LOST WAR (THE EIDYN SAGA #1) BY JUSTIN LEE ANDERSON\nOriginally self-published in 2019, The Lost War is a traditional fantasy adventure that follows a rag-tag group of strangers on a mission across a war-torn country, fighting monsters and uncovering mysteries along the way. Despite the strong buzz leading up to the novel’s expanded publication by Orbit this year, I found myself hesitant to pick it up since it seemed so similar to many books I’ve read before. But while it’s true The Lost War doesn’t rewrite the genre – it’s filled with well-worn tropes and classic adventurer archetypes – Anderson’s skillful execution left me completely charmed. There is a real Dungeons and Dragons feel to The Lost War, and though the characters are familiar (the honorable paladin, the hard-drinking haunted soldier), Anderson does a fantastic job developing unique dynamics between the party members that vault the book beyond the sum of its parts. And it all builds up to a massive twist at the end that completely upends your understanding of what you’ve read and any previous expectations for where the second book will go. The delightfully unexpected ending once again has the fantasy community buzzing ahead of Anderson’s next release – only this time I’m right there with them. —SG\n\nCover image for Moniquill Blackgoose’s To Shape a Dragon’s Breath, a red cover with flowers and a dragon’s head/mask on it.\nImage: Del Rey\nTO SHAPE A DRAGON’S BREATH (NAMPESHIWEISIT #1) BY MONIQUILL BLACKGOOSE\nTo Shape a Dragon’s Breath’s description hooked me immediately: It’s got dragons, a magic school, and a strong teenage main character. Moniquill Blackgoose has taken several different fantasy tropes and created a fantasy novel that’s unlike anything I’ve read; To Shape a Dragon’s Breath is set in an evolving steampunk world as Anglish settlers push the Indigenous Masquapaug people out of their land and onto a remote island. Dragons had long been important cultural touchstones to the Indigenous people, but colonization has, too, pushed them away. To Shape a Dragon’s Breath begins as 15-year-old Anequs finds a dragon egg — the first to be spotted in the area in generations. Anequs is named a Nampeshiweisit, or a dragon rider, as the community helps raise and hatch the dragon’s egg.\n\nThe colonizing nation quickly finds out and forces Anequs and her dragon into the Anglish dragon school; if she resists, the dragon will be eliminated. To Shape a Dragon’s Breath is about the growing relationship between her and her dragon Kasaqua, but also about her resistance to the Anglish traditions relating to dragons. The Anglish treat dragons as something to be conquered — they use them as tools and weapons, whereas the Indigenous people have historically partnered with dragons for a relationship built on both tradition and respect.\n\nThat partnership means Anequs now has the power to take on colonialism and racism in a new way. Where To Shape a Dragon’s Breath really shines is in that growing relationship between Anequs and Kasaqua; the partnership — and power for both that comes with it — is in stark contrast to the Anglish ways. Bonus: To Shape a Dragon’s Breath has well-written, complex bisexual and neurodivergent characters, too. —Nicole Carpenter\n\nCover image for Melvin Burgess’s Loki, a black cover with a black snake wrapped around gold letters with the title.\nImage: Pegasus\nLOKI BY MELVIN BURGESS\nMelvin Burgess has spent a career writing confrontationally frank children’s literature like Junk, his 1990s book about heroin-addicted teenagers. His first adult book, published at age 69, is a blistering, transgressive, and hugely entertaining reframing of the Norse myths, as told by the most unreliable narrator imaginable: Loki himself, the god of tricks, inventions, and political intrigue. But what does reliable mean, anyway, in the mutable world of myth? Burgess paints Loki (or rather, has him paint himself, as he addresses the reader directly in first person) as an eternal outsider, shaking his head sagely at the follies of the gods, and challenging their might-is-right order. But of course, that’s what he’d want us to think. Burgess’ best trick, though, is the way he rolls together the deeply weird, muddy, shape-shifting mystery of the tales themselves with a bracing modernity in characterization and language, somehow without one clashing with the other. In doing so he brings the wild, ancient power of the Norse myths to vivid life. —Oli Welsh\n\nCover image for Nana Kwame Adjei-Brenyah’s Chain-Gang All-Stars, featuring a scythe chopping through the words with a bright yellow background.\nImage: Pantheon Books\nCHAIN-GANG ALL-STARS BY NANA KWAME ADJEI-BRENYAH\nIn Chain-Gang All-Stars, prison inmates fight to the death in a series of gladiatorial matches — and all of it is televised to a hungry audience. It’s a program called CAPE, the Criminal Action Penal Entertainment, which promises freedom to inmates who survive three years of its brutality. The average life expectancy for anyone who enters is three months. Within this system, Loretta Thurwar and Hammara Stacker (called Hurricane Staxxx by her fans) emerge as two frontrunners.\n\nThis National Book Award finalist takes on the viciousness of the carceral system, with more than a bit of The Hunger Games’ DNA sprinkled in. “Hard action” fans salivate over matches, a self-obsessed announcer resents the fact that contestants don’t offer more banter, and the women who top the leaderboards become sex symbols in pop culture. But where other fight-to-the-death dystopias — among the greats, like Battle Royale or Lord of the Flies — spin a more fantastical yarn, Chain-Gang All-Stars is aimed right at the heart of the all-too-real cruelties of our existing for-profit penal system.\n\nEarly in the book, Thurwar kills a 16-year-old boy in a gladiator match. Fans in the stands lament not the death of the boy, but the idea that the fight wasn’t entertaining because it wasn’t a fair matchup. In a footnote, Adjei-Brenyah writes of George Stinney Jr., a 14-year-old Black boy who was convicted for murder and executed in 1944. Chain-Gang All-Stars also illustrates the ways in which imprisonment is simply “slavery by another name,” showing all manner of menial labor the contestants are forced to perform. In 2022, the ACLU reported that inmates made between 13 and 52 cents an hour, and sometimes nothing.\n\nCritics have said this book is an “act of protest” but that it doesn’t “straightforwardly preach,” or that it’s more entertaining than “an attempt to convince its readers of the case for prison abolition has any right to be.” I understand why you’d want to say this book is “fun” despite an abolitionist message, especially in a political climate where radical writing is often appreciated only as a teaching tool. But I think that kind of delineation undercuts Adjei-Brenyah’s talent as a novelist, and his skill in heightening the real as a form of storytelling. I’d call it thrilling, over calling it fun. And the fact that it is thrilling is inextricable from its openly abolitionist values — it’s the very knowledge of real life that Adjei-Brenyah wields to craft suspense. —N. Clark\n\nCover image for Rebecca Yarros’ Fourth Wing, which features a circle image behind black text, with clouds and some flying creatures.\nImage: Entangled\nFOURTH WING BY REBECCA YARROS\nThis action-packed, fantasy romance feels like a grown up version of all of my favorite young adult books. It’s got all of the fun nostalgic tropes — a magical school, deadly trials, dragon riding, and a love triangle between the main character, a golden retriever love interest, and a misunderstood emo rival — but it’s also extremely horny, as all fun fantasy romance must be.\n\nViolet Sorrengail is thrown into a series of trials in order to prove whether she can be a dragon rider. There are a few problems with this: she trained as a scribe, never thought she’d be thrust into danger, and she also must deal with Xaden Riorson, her sworn enemy (wink). She also manages a joint condition, which leaves her in chronic pain — a fact the book handles gracefully. In one of my favorite climactic moments of the book, Violet is given a mobility device to help her with her trials; those close to her remind her that it doesn’t diminish her power, but is a tool like any other, and one that allows her to flourish. I’m thrilled to read the next installment, when it comes out in November. —N. Clark\n\nCover art for Adrian Tchaikovsky’s Lords of Uncreation, which shows a spaceship approaching what looks like a space battle next to a planet, with exploding orbs in space and a lot of spaceships in the distance.\nImage: Orbit\nLORDS OF UNCREATION (THE FINAL ARCHITECTURE #3) BY ADRIAN TCHAIKOVSKY\nReading the Final Architecture series, I had to accept long ago that I would never fully grasp the nuances of some of its central concepts, even if I understood them on an instinctual level.\n\nThis acceptance set me up well for Lords of Uncreation, which revolves around concepts that even the characters find impossible to understand, and whose minds may literally break if they try to. Like looking directly into the sun, confronting the blurred space between the real and unreal (as well as the eldritch terrors that lurk within) poses a grave threat to those doing so head-on – at least to anyone other than weary intermediary Idris Tellemier, whose risk is merely reduced rather than eliminated. But the characters Adrian Tchaikovsky has populated this world with are so grounded, so emotionally rich, and so vibrant that the details of the brain-bending threats lurking within unspace become secondary to their impact on the lives of and relationships between the Vulture God’s crew.\n\nThis is not to say that Tchaikovsky does not deliver an incredibly satisfying conclusion to the mysteries of unspace (he does!). But what I’ll remember most is how he crafted the perfect emotional resolution to this intellectually intricate tale that left me in tears and has stayed with me since. —SG\n\nLead art for Justin Cronin’s The Ferryman, which pictures a cloudy sky over the horizon, as a single sail boat sits on the water.\nImage: Ballantine Books\nTHE FERRYMAN BY JUSTIN CRONIN\nProctor Bennett is a ferryman, whose duty is to guide unhappy citizens from the utopian Propersa to the Nursery, where they retire their old selves before returning in younger bodies with no memories of their former lives. But when Proctor is assigned to retire his own father, the troubling encounter sends him careening off the path of conformity. He begins questioning prescribed truths and confronting the darker side of Prospera, which runs off the work of a disenfranchised support staff whose discontent is building towards a revolution that pulls Proctor into its orbit.\n\nThough this premise may feel familiar, The Ferryman is anything but. This tightly-wound, atmospheric thriller weaves together layers of knotted mystery with Proctor’s haunting POV as he grapples with his relationship to grief, happiness, family, and identity. It’s a sharply complex mystery with a cinematic quality to it. Throughout reading, I couldn’t help but fan-cast who would star in a Christopher Nolan adaptation of it. But even if you aren’t an Inception fan, it’ll be easy to become immersed in The Ferryman’s distinct dystopian world. —SG\n\nCover image for Emily Tesh’s Some Desperate Glory, featuring a woman walking confidently in front of a wall opening to reveal a planetary body.\nImage: Tor\nSOME DESPERATE GLORY BY EMILY TESH\nAround September, as the pile of unpainted plastic miniatures here in my home office began to get particularly deep, I suddenly ran out of Warhammer 40,000 Black Library audiobooks by Games Workshop that I was the least bit interested in listening to. That’s when I stumbled upon Some Desperate Glory by Emily Tesh. Billed as a space opera told from the perspective of one of humanity’s last genetically engineered super soldiers, I fell for the premise hook, line, and sinker. Then, about 50 pages in, I let it sucker-punch me right in the gut.\n\nWith Some Desperate Glory, Tesh has envisioned a deeply affecting reality where the children of a subjugated, war-torn race slowly come to realize that they have been lied to — manipulated into an amoral war of vengeance without end. Tesh shows incredible restraint throughout, reeling out a thick and binding thread of painful realizations from deep within the main character, Kyr. After grappling with my personal love for the grim darkness of the far future for quite a few years now, this book helped me come to terms with how much I despise those tropes even as I find myself drawn toward them time and time again.\n\nSome Desperate Glory is, in my opinion, required reading for anyone who has ever painted a Space Marine in earnest – and a new fixture in the canon of queer science fiction. —Charlie Hall\n\nCover image for Jade Song’s Chlorine, featuring a large fin in the ocean waves.\nImage: William Morrow & Company\nCHLORINE BY JADE SONG\nI think I have been waiting my whole life for this book — for someone to write adolescence like the body horror it is, with all of the cultural specificity of being a Chinese American girl, simply bursting at the seams with sapphic longing. Chlorine stars Ren Yu, a swimmer who believes that she is a mermaid. But she is tethered to land by her human ambition: By the parents who constantly push her to achieve, and by a swim coach who pays inappropriate attention to her — pushing her to swim faster times, while also making her feel uncomfortable in her skin.\n\nRen’s steadfast belief in being a mermaid feels both like a flight of fancy, and increasingly like a means of dissociating from the horrors of everyday life. Being a young girl is hard enough without having to contend with the high expectations of parents, the predation of adult men, and the casual racism of peers. Jade Song’s writing is gruesomely lyrical, contrasting the sublime with the deeply disturbing. There were several points where this book almost made me throw up, and I mean that as a high compliment. —N. Clark\n\nA Black woman stands alone in a field, her face covered by shadow, in the cover art for Lone Women by Victor LaValle.\nImage: One World\nLONE WOMEN BY VICTOR LAVALLE\nAdelaide Henry is traveling to Montana, where she plans on making a new life as a homesteader — leaving the flames of her California home, and the bodies of her parents, behind. But she has a heavy weight to carry. She lugs an enormous steam trunk wherever she goes; whenever the trunk opens, people around her die. In 1915, Montana is in the middle of a homestead boom, and though Adelaide aims to make a new start, not everyone is welcoming to a Black woman traveling alone.\n\nVictor LaValle mixes horror and fantasy in this expertly paced tale. It’s satisfyingly bloody, while making incisive commentary on the price of being an outsider. The Western genre has long fixated on the white imagination, perhaps occasionally making space for the early struggle of the suffragettes. But LaValle’s vision of history emphasizes just how powerful white women are in upholding the interests of their white husbands, and how far these women will go to protect the societal structures that put them in proximity to power. Lone Women also examines how shame, and the family unit, ultimately uphold these unspoken rules — ostracizing those who might otherwise find community support.\n\nThis book was so good that I am now reading my way through every interview LaValle has given on the Lone Women press circuit, too, and then reading every book he references. What a gift! —N. Clark\n\nCover image of Nathan Ballingrud’s The Strange, depicting a diner on Mars.\nImage: Gallery/Saga Press\nTHE STRANGE BY NATHAN BALLINGRUD\nNathan Ballingrud’s debut novel was added to my TBR pile after seeing it marketed as a blend of Ray Bradbury’s The Martian Chronicles and Charles Portis’ True Grit. I’m always dubious about marketing comparisons, but was thrilled when The Strange delivered on this high promise.\n\nIn an alternate history where humanity colonized Mars in the early 1900s, the red planet has lost all communication with Earth, leaving the fate of 14-year-old Annabelle Crisp’s mother unknown. When a thief steals Annabelle’s sole voice recording of her mom, she and her beloved Kitchen Engine, Watson, set off into the desert to retrieve what’s hers and see justice served. The longer Annabelle’s adventure goes on, the more she loses perspective and drifts away from righteousness in dogged pursuit of her own selfish desires. Struggling to comprehend that the world can’t be divided into binaries like right or wrong and black or white, Annabelle converts her fear into anger, lashing out and harming those around her, including those providing aid.\n\nAnnabelle can be vengeful and cruel, and though I often disagreed with her choices, Ballingrud makes it impossible not to understand and empathize with her. Annabelle Crisp isn’t a hero and she isn’t a villain, but she is an outstanding protagonist in a wonderfully original sci-fi tale. —SG\n\nCover image for Moses Ose Utomi’s The Lies of the Ajungo, featuring a figure walking upside down on mounds of sand as a castle lurks in front.\nImage: Tor\nTHE LIES OF THE AJUNGO (THE FOREVER DESERT #1) BY MOSES OSE UTOMI\nIn his debut novella, Moses Ose Utomi wields his precise prose to tell a dark, visceral fable about a young boy from the City of Lies, a metropolis reliant on the brutal Ajungo Empire for their supply of water. But the cost of this trade is high: At 13, every child of the City of Lies has their tongue cut out and sent to the Ajungo.\n\nEven with this gruesome tithe, the Ajungo send barely enough water for the population to survive, and far from what they’d need to do so comfortably, let alone thrive. Shortly before his thirteenth birthday, the brave Tutu sets out on a dangerous journey to save his mother and the city by finding their own water supply. As Tutu explores the outside world for the first time, his perception of truth and history is challenged, and he comes to understand how the decisions and deceptions of those in power rewrite the past and shape the future to uphold those with privilege and foster compliance in those who don’t. —SG\n\nCover image for Edward Ashton’s Antimatter Blues, A Mickey7 Novel. It features an astronaut from behind on a rocky planet, looking out at another planet in the distance.\nImage: St. Martin’s Press\nANTIMATTER BLUES BY EDWARD ASHTON\nEdward Ashton’s sequel to Mickey 7, the 2022 novel Parasite director Bong Joon-ho is adapting as a movie starring Robert Pattinson, takes up two years after the first book left off, with “Expendable”-status planetary colonist Mickey still on the outs with the leadership of his struggling colony after a gutsy bluff he made to ensure his own survival. The sixth clone of the original Mickey, who accepted life as a disposable body for suicide missions in exchange for a ticket to space, Mickey 7 has walked off that job. His ongoing draw on the colony’s resources is only tolerated because he’s exaggerated his diplomatic connections with the local aliens. Then the base commander orders him to do something impossible, or the entire colony will die.\n\nAntimatter Blues is knottier than the first book in the series, with more to take in about the ethics of survival and humanity’s predisposition toward xenophobia and selfish, self-serving behavior. It sure isn’t a pleasant book to read: A lot of Mickey’s co-colonists are bigots, most of them are indifferent to anyone else’s suffering, and at times, the book reads as though Earth deliberately sent all the worst people into space, the better to be free of them. Even Mickey himself is, at absolute minimum, generally more focused on his own safety and comfort than on the horrific results of some of his choices. But as soon as he’s placed in what seems like an unsurvivable situation, that dynamic leads to high drama, and Antimatter Blues becomes a breathless book rocketing to a surprising conclusion. Prepare to feel sorry for various alien races who have to deal with icky humanity. —TR\n\nCover image for Samantha Shannon’s A Day of Fallen Night, a colorful image with a a dragon swirling around it\nImage: Bloomsbury\nA DAY OF FALLEN NIGHT (THE ROOTS OF CHAOS #0) BY SAMANTHA SHANNON\nSamantha Shannon’s A Day of Fallen Night is her second book in the Roots of Chaos series, but a prequel to The Priory of the Orange Tree. Like The Priory of the Orange Tree, A Day of Fallen Night is an epic, far-flung fantasy novel set in a world of magic and dragons. A Day of Fallen Night is set hundreds of years before The Priory of the Orange Tree, and follows several of the original book’s ancestors as the world fears the return of an evil wyrm, the Nameless One. You don’t have to have read The Priory of the Orange Tree to enjoy A Day of Fallen Night; in fact, it’s likely a good place to start if you’ve been interested in reading Shannon’s original, massive fantasy book. Of course, this is a slow-burn 800-page book that precedes another 800-page book, so it’s definitely a time investment regardless of the path.\n\nThough A Day of Fallen Night deals with a world-shaping, cataclysmic threat and widespread political machinations, the book is rooted within four characters from around the book’s world: Sabran, Glorian, Dumai, and Tunuva Melim. The stories of these characters intertwine as their regional beliefs tied to wyrms and dragons conflict, muddying up the necessary collaboration in fighting off the looming threat. In between all that catastrophe, Shannon gives the women of the book rich stories of personal relationships, sacrifice, and conflicting feelings. Motherhood and bodily autonomy are also strong themes throughout the book; both Sabran and Glorian (mother and daughter) have their bodily autonomy tied to the fate of their region.\n\nIt’s not easy to describe A Day of Fallen Night in a short blurb — it does so many things and goes so many places. Shannon’s created a series that has the scale of The Lord of the Rings, wrapped up in a world of queer, female power. The Roots of Chaos, as a whole, is one of my favorite fantasy series ever. —N. Carpenter\n\nCover image for Mariana Enriquez’s Our Share of Night, featuring a red hand with long yellow fingernails.\nImage: Hogarth Press\nOUR SHARE OF NIGHT BY MARIANA ENRÍQUEZ\nThis literary tome defies categorization, so I’ll paint a scene instead: A father (Juan) whisks his son (Gaspar) away on a trip. Juan is mercurial; at turns terrifying and violent, at turns bewilderingly tender, nearly infinite in love. But he is a closed book. And if you think you’ve seen his hands elongate, spindly fingers yielding to piercing claws — well no, you didn’t.\n\nSlow, dreadful, and razor-sharp, Our Share of Night charts a family’s desperate attempt at escaping the clutches of a death cult in Argentina. Its members seek the secrets of immortality, and many are willing to pay any price to obtain it. Set in 1981, the novel’s supernatural terrors intertwine with those of the Dirty War, the authoritarian violence offering cover for the cult to operate uninhibited.\n\nI will read anything Mariana Enríquez writes next, it’s an absolute joy to experience her work. —N. Clark\n\nCover image for Annalee Newitz’s The Terraformers, which features a futuristic cityscape with lush greenery.\nImage: Tor Books\nTHE TERRAFORMERS BY ANNALEE NEWITZ\nThe Terraformers concerns itself with one question: As a species evolves, what behaviors stick around? Set more than 50,000 years in the future (yes, you read that number right), The Terraformers details the process of terraforming and developing a privatized planet into a tourism joint for the super rich. Technology has advanced in barely fathomable ways, allowing, for instance, the extension of human-level intelligence to animals and robots. But some aspects of society might seem familiar: Real estate developers who jack up rent with no warning? Local governments that abhor public transit? That every video call still has one person who can’t get the camera to work?\n\nEqual parts prescient and absurd, The Terraformers splits its story over three novellas, each 700 years apart. One of those stars a sentient train who teams up with an investigative journalist ... who also happens to be a cat ... who’s also trying to prove this ostensibly privatized planet is in fact public land. Written by a leading science journalist of our era (author Annalee Newitz is the founder of io9 and has written for basically every major science publication under our sun), The Terraformers is unexpectedly one of the most accurate representations of the journalistic process I’ve ever read. And it all culminates in an undeniable stance: That capitalistic power must still be held in check by the truth. Even 50,000 years in the future, a free press is among society’s most essential facets. The more things change... —Ari Notis\n\nThe cover image of Adrian Tchaikovsky’s Children of Memory, which depicts a spaceship approaching a large orange planet.\nImage: Orbit\nCHILDREN OF MEMORY (CHILDREN OF TIME #3) BY ADRIAN TCHAIKOVSKY\nAdrian Tchaikovsky’s highly anticipated third book in the Children of Time trilogy once again delves into some of science fiction’s headiest topics. There are parallels to earlier installments — Tchaikovsky once again uses another hyper-intelligent animal species to examine the idea of what being “alive” really means. But he also takes readers somewhere completely and utterly new, outside the scope of the previous titles, and incredibly difficult to describe without spoiling the premise entirely.\n\nAll I can say is hold on for the ride. This is an author who dives head first into Asimov-esque ideas, and who is willing to take the plot in fanciful directions. I still can’t believe that I have recommended a book about sentient spider colonies to so many friends, but here we are. This finale is worth your time. —N. Clark'
 ""Why do we need to regulate the use of Artificial Intelligence?\nThe potential benefits of Artificial Intelligence (AI) for our societies are manifold from improved medical care to better education. Faced with the rapid technological development of AI, the EU decided to act as one to harness these opportunities.\n\nThe EU AI Act is the world's first comprehensive AI law. It aims to address risks to health, safety and fundamental rights. The regulation also protects democracy, rule of law and the environment.\n\nWhile most AI systems will pose low to no risk, certain AI systems create risks that need to be addressed to avoid undesirable outcomes.\n\nFor example, the opacity of many algorithms may create uncertainty and hamper the effective enforcement of the existing legislation on safety and fundamental rights. Responding to these challenges, legislative action was needed to ensure a well-functioning internal market for AI systems where both benefits and risks are adequately addressed.\n\nThis includes applications such as biometric identification systems or AI decisions touching on important personal interests, such as in the areas of recruitment, education, healthcare, or law enforcement.\n\nRecent advancements in AI gave rise to ever more powerful Generative AI. So-called “general-purpose AI models” that are being integrated in numerous AI systems are becoming too important for the economy and society not to be regulated. In light of potential systemic risks, the EU puts in place effective rules and oversight.\n\nWhich risks will the new AI rules address?\nThe uptake of AI systems has a strong potential to bring societal benefits, economic growth and enhance EU innovation and global competitiveness. However, in certain cases, the specific characteristics of certain AI systems may create new risks related to user safety and fundamental rights. Some powerful AI models that are being widely used could even pose systemic risks.\n\nThis leads to legal uncertainty for companies and potentially slower uptake of AI technologies by businesses and citizens, due to the lack of trust. Disparate regulatory responses by national authorities would risk fragmenting the internal market.\n\nTo whom does the AI Act apply?\nThe legal framework will apply to both public and private actors inside and outside the EU as long as the AI system is placed on the Union market or its use affects people located in the EU.\n\nIt can concern both providers (e.g. a developer of a CV-screening tool) and deployers of high-risk AI systems (e.g. a bank buying this screening toolImporters of AI systems will also have to ensure that the foreign provider has already carried out the appropriate conformity assessment procedure, bears a European Conformity (CE) marking and is accompanied by the required documentation and instructions of use.\n\nIn addition, certain obligations are foreseen for providers of general-purpose AI models, including large generative AI models.\n\nProviders of free and open-source models are exempted from most of these obligations. This exemption does not cover obligations for providers of general purpose AI models with systemic risks.\n\nObligations also do not apply to research, development and prototyping activities preceding the release on the market, and the regulation furthermore does not apply to AI systems that are exclusively for military, defence or national security purposes, regardless of the type of entity carrying out those activities.\n\nWhat are the risk categories?\nThe Commission proposes a risk–based approach, with four levels of risk for AI systems, as well as an identification of risks specific to general purpose models:\n\nMinimal risk: All other AI systems can be developed and used subject to the existing legislation without additional legal obligations. The vast majority of AI systems currently used or likely to be used in the EU fall into this category. Voluntarily, providers of those systems may choose to apply the requirements for trustworthy AI and adhere to voluntary codes of conduct.\nHigh-risk: A limited number of AI systems defined in the proposal, potentially creating an adverse impact on people's safety or their fundamental rights (as protected by the EU Charter of Fundamental Rights), are considered to be high-risk. Annexed to the Act is the list of high-risk AI systems, which can be reviewed to align with the evolution of AI use cases.\nThese also include safety components of products covered by sectorial Union legislation. They will always be considered high-risk when subject to third-party conformity assessment under that sectorial legislation.\nUnacceptable risk: A very limited set of particularly harmful uses of AI that contravene EU values because they violate fundamental rights and will therefore be banned:\nSocial scoring for public and private purposes;\nExploitation of vulnerabilities of persons, use of subliminal techniques;\nReal-time remote biometric identification in publicly accessible spaces by law enforcement, subject to narrow exceptions (see below);\nBiometric categorisation of natural persons based on biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs or sexual orientation. Filtering of datasets based on biometric data in the area of law enforcement will still be possible;\nIndividual predictive policing;\nEmotion recognition in the workplace and education institutions, unless for medical or safety reasons (i.e. monitoring the tiredness levels of a pilot);\nUntargeted scraping of internet or CCTV for facial images to build-up or expand databases.\nSpecific Transparency risk: For certain AI systems specific transparency requirements are imposed, for example where there is a clear risk of manipulation (e.g. via the use of chatbots). Users should be aware that they are interacting with a machine.\nIn addition, the AI Act considers systemic risks which could arise from general-purpose AI models, including large generative AI models. These can be used for a variety of tasks and are becoming the basis for many AI systems in the EU. Some of these models could carry systemic risks if they are very capable or widely used. For example, powerful models could cause serious accidents or be misused for far-reaching cyberattacks. Many individuals could be affected if a model propagates harmful biases across many applications.\n\nHow do I know whether an AI system is high-risk?\nTogether with a clear definition of ‘high-risk', the Act sets out a solid methodology that helps identifying high-risk AI systems within the legal framework. This aims to provide legal certainty for businesses and other operators.\n\nThe risk classification is based on the intended purpose of the AI system, in line with the existing EU product safety legislation. It means that the classification of the risk depends on the function performed by the AI system and on the specific purpose and modalities for which the system is used.\n\nAnnexed to the Act is a list of use cases which are considered to be high-risk. The Commission will ensure that this list is kept up to date and relevant. Systems on the high-risk list, that perform narrow procedural tasks, improve the result of previous human activities, do not influence human decisions or do purely preparatory tasks are not considered high-risk. However, an AI system shall always be considered high-risk if it performs profiling of natural persons.\n\nWhat are the obligations for providers of high-risk AI systems?\nBefore placing a high-risk AI system on the EU market or otherwise putting it into service, providers must subject it to a conformity assessment. This will allow them to demonstrate that their system complies with the mandatory requirements for trustworthy AI (e.g. data quality, documentation and traceability, transparency, human oversight, accuracy, cybersecurity and robustness). This assessment has to be repeated if the system or its purpose are substantially modified.\n\nAI systems being safety components of products covered by sectorial Union legislation will always be deemed high-risk when subject to third-party conformity assessment under that sectorial legislation. Also, for biometric systems a third-party conformity assessment is always required.\n\nProviders of high-risk AI systems will also have to implement quality and risk management systems to ensure their compliance with the new requirements and minimise risks for users and affected persons, even after a product is placed on the market.\n\nHigh-risk AI systems that are deployed by public authorities or entities acting on their behalf will have to be registered in a public EU database, unless those systems are used for law enforcement and migration. The latter will have to be registered in a non-public part of the database that will be only accessible to relevant supervisory authorities.\n\nMarket surveillance authorities will support post-market monitoring through audits and by offering providers the possibility to report on serious incidents or breaches of fundamental rights obligations of which they have become aware. Any market surveillance authority may authorise placing on the market of specific high-risk AI for exceptional reasons.\n\nIn case of a breach, the requirements will allow national authorities to have access to the information needed to investigate whether the use of the AI system complied with the law.\n\nWhat are examples for high-risk use cases as defined in Annex III?\nCertain critical infrastructures for instance in the fields of road traffic and the supply of water, gas, heating and electricity;\nEducation and vocational training, e.g. to evaluate learning outcomes and steer the learning process and monitoring of cheating;\nEmployment, workers management and access to self-employment, e.g. to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates;\nAccess to essential private and public services and benefits (e.g. healthcare), creditworthiness evaluation of natural persons, and risk assessment and pricing in relation to life and health insurance;\nCertain systems used in the fields of law enforcement, border control, administration of justice and democratic processes;\nEvaluation and classification of emergency calls;\nBiometric identification, categorisation and emotion recognition systems (outside the prohibited categories);\nRecommender systems of very large online platforms are not included, as they are already covered in other legislation (DMA/DSA).\nHow are general-purpose AI models being regulated?\nGeneral-purpose AI models, including large generative AI models, can be used for a variety of tasks. Individual models may be integrated into a large number of AI systems.\n\nIt is important that a provider wishing to build upon a general-purpose AI model has all the necessary information to make sure its system is safe and compliant with the AI Act.\n\nTherefore, the AI Act obliges providers of such models to disclose certain information to downstream system providers. Such transparency enables a better understanding of these models.\n\nModel providers additionally need to have policies in place to ensure that that they respect copyright law when training their models.\n\nIn addition, some of these models could pose systemic risks, because they are very capable or widely used.\n\nFor now, general purpose AI models that were trained using a total computing power of more than 10^25 FLOPs are considered to carry systemic risks, given that models trained with larger compute tend to be more powerful. The AI Office (established within the Commission) may update this threshold in light of technological advances, and may furthermore in specific cases designate other models as such based on further criteria (e.g. number of users, or the degree of autonomy of the model).\n\nProviders of models with systemic risks are therefore mandated to assess and mitigate risks, report serious incidents, conduct state-of-the-art tests and model evaluations, ensure cybersecurity and provide information on the energy consumption of their models.\n\nFor this, they are asked to engage with the European AI Office to draw up Codes of Conduct as the central tool to detail out the rules in cooperation with other experts. A scientific panel will play a central role in overseeing general-purpose AI models.\n\nWhy is 10^25 FLOPs an appropriate threshold for GPAI with systemic risks?\nThis threshold captures the currently most advanced GPAI models, namely OpenAI's GPT-4 and likely Google DeepMind's Gemini.\n\nThe capabilities of the models above this threshold are not yet well enough understood. They could pose systemic risks, and therefore it is reasonable to subject their providers to the additional set of obligations.\n\nFLOP is a first proxy for model capabilities, and the exact FLOP threshold can be updated upwards or downwards by the European AI Office, e.g. in the light of progress in objectively measuring model capabilities and of developments in the computing power needed for a given performance level.\n\nThe AI Act can be amended to update the FLOP threshold (by means of a delegated act).\n\nIs the AI Act future-proof?\nThe Regulation introduces different level of risks and provides clear definitions, including for GPAI.\n\nThe legislation sets result-oriented requirements for high-risk AI systems but leaves the concrete technical solutions and operationalisation primarily to industry-driven standards that will ensure that the legal framework is flexible to be adapted to different use cases and to enable new technological solutions.\n\nIn addition, the AI Act can be amended by delegated and implementing acts, including to update the FLOP threshold (delegated act), to add criteria for classifying the GPAI models as presenting systemic risks (delegated act), to amend modalities to establish regulatory sandboxes and elements of the real-world testing plan (implementing acts).\n\nHow does the AI Act regulate biometric identification?\nThe use of real-time remote biometric identification in publicly accessible spaces (i.e. facial recognition using CCTV) for law enforcement purposes is prohibited, unless used in one of the following cases:\n\nLaw enforcement activities related to 16 specified crimes;\nTargeted search for specific victims, abduction, trafficking and sexual exploitation of human beings, and missing persons; or\nThe prevention of threat to the life or physical safety of persons or response to the present or foreseeable threat of a terror attack.\nThe list of the 16 crimes contains:\n\nTerrorism;\nTrafficking in human beings;\nSexual exploitation of children and child sexual abuse material;\nIllicit trafficking in narcotic drugs and psychotropic substances;\nIllicit trafficking in weapons, munitions and explosives;\nMurder;\nGrievous bodily injury;\nIllicit trade in human organs and tissue;\nIllicit trafficking in nuclear or radioactive materials;\nKidnapping, illegal restraint and hostage-taking;\nCrimes within the jurisdiction of the International Criminal Court;\nUnlawful seizure of aircraft/ships;\nRape;\nEnvironmental crime;\nOrganised or armed robbery;\nSabotage, participation in a criminal organisation involved in one or more crimes listed above.\nReal-time remote biometric identification by law enforcement authorities would be subject to prior authorisation by a judicial or independent administrative authority whose decision is binding. In case of urgency, authorisation can be done within 24 hours; if the authorisation is rejected all data and output needs to be deleted.\n\nIt would need to be preceded by prior fundamental rights impact assessment and should be notified to the relevant market surveillance authority and the data protection authority. In case of urgency, the use of the system may be commenced without the registration.\n\nUsage of AI systems for post remote biometric identification (identification of persons in previously collected video material) of persons under investigation requires prior authorisation by a judicial authority or an independent administrative authority, and notification of the data protection and market surveillance authority.\n\nWhy are particular rules needed for remote biometric identification?\nBiometric identification can take different forms. It can be used for user authentication i.e. to unlock a smartphone or for verification/authentication at border crossings to check a person's identity against his/her travel documents (one-to-one matching).\n\nBiometric identification could also be used remotely, for identifying people in a crowd, where for example an image of a person is checked against a database (one-to-many matching).\n\nAccuracy of systems for facial recognition can vary significantly based on a wide range of factors, such as camera quality, light, distance, database, algorithm, and the subject's ethnicity, age or gender. The same applies for gait and voice recognition and other biometric systems. Highly advanced systems are continuously reducing their false acceptance rates.\n\nWhile a 99% accuracy rate may sound good in general, it is considerably risky when the result leads to the suspicion of an innocent person. Even a 0.1% error rate is a lot if it concerns tens of thousands of people.\n\nHow do the rules protect fundamental rights?\nThere is already a strong protection for fundamental rights and for non-discrimination in place at EU and Member State level, but complexity and opacity of certain AI applications (‘black boxes') pose a problem.\n\nA human-centric approach to AI means to ensure AI applications comply with fundamental rights legislation. Accountability and transparency requirements for the use of high-risk AI systems, combined with improved enforcement capacities, will ensure that legal compliance is factored in at the development stage.\n\nWhere breaches occur, such requirements will allow national authorities to have access to the information needed to investigate whether the use of AI complied with EU law.\n\nMoreover, the AI Act requires that deployers that are bodies governed by public law or private operators providing public services and operators providing high-risk systems to conduct a fundamental rights impact assessment.\n\nWhat is a fundamental rights impact assessment? Who has to conduct such an assessment, and when?\nThe use of a high-risk AI system may produce an impact on fundamental rights. Therefore, deployers that are bodies governed by public law or private operators providing public services, and operators providing high-risk systems shall perform an assessment of the impact on fundamental rights and notify the national authority of the results.\n\nThe assessment shall consist of a description of the deployer's processes in which the high-risk AI system will be used, of the period of time and frequency in which the high-risk AI system is intended to be used, of the categories of natural persons and groups likely to be affected by its use in the specific context, of the specific risks of harm likely to impact the affected categories of persons or group of persons, a description of the implementation of human oversight measures and of measures to be taken in case of the materialization of the risks.\n\nIf the provider already met this obligation through the data protection impact assessment, the fundamental rights impact assessment shall be conducted in conjunction with that data protection impact assessment.\n\nHow does this regulation address racial and gender bias in AI?\nIt is very important that AI systems do not create or reproduce bias. Rather, when properly designed and used, AI systems can contribute to reduce bias and existing structural discrimination, and thus lead to more equitable and non-discriminatory decisions (e.g. in recruitment).\n\nThe new mandatory requirements for all high-risk AI systems will serve this purpose. AI systems must be technically robust to guarantee that the technology is fit for purpose and false positive/negative results are not disproportionately affecting protected groups (e.g. racial or ethnic origin, sex, age etc.).\n\nHigh-risk systems will also need to be trained and tested with sufficiently representative datasets to minimise the risk of unfair biases embedded in the model and ensure that these can be addressed through appropriate bias detection, correction and other mitigating measures.\n\nThey must also be traceable and auditable, ensuring that appropriate documentation is kept, including of the data used to train the algorithm that would be key in ex post investigations.\n\nCompliance system before and after they are placed on the market will have to ensure these systems are regularly monitored and potential risks are promptly addressed.\n\nWhen will the AI Act be fully applicable?\nFollowing its adoption by the European Parliament and the Council, the AI Act shall enter into force on the twentieth day following that of its publication in the official Journal. It will be fully applicable 24 months after entry into force, with a graduated approach as follows:\n\n6 months after entry into force, Member States shall phase out prohibited systems;\n12 months: obligations for general purpose AI governance become applicable;\n24 months: all rules of the AI Act become applicable including obligations for high-risk systems defined in Annex III (list of high-risk use cases);\n36 months: obligations for high-risk systems defined in Annex II (list of Union harmonisation legislation) apply.\nHow will the AI Act be enforced?\nMember States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities to supervise the application and implementation, as well as carry out market surveillance activities.\n\nTo increase efficiency and to set an official point of contact with the public and other counterparts, each Member State should designate one national supervisory authority, which will also represent the country in the European Artificial Intelligence Board.\n\nAdditional technical expertise will be provided by an advisory forum, representing a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia.\n\nIn addition, the Commission will establish a new European AI Office, within the Commission, which will supervise general-purpose AI models, cooperate with the European Artificial Intelligence Board and be supported by a scientific panel of independent experts.\n\nWhy is a European Artificial Intelligence Board needed and what will it do?\nThe European Artificial Intelligence Board comprises high-level representatives of competent national supervisory authorities, the European Data Protection Supervisor, and the Commission. Its role is to facilitate a smooth, effective and harmonised implementation of the new AI Regulation.\n\nThe Board will issue recommendations and opinions to the Commission regarding high-risk AI systems and on other aspects relevant for the effective and uniform implementation of the new rules. Finally, it will also support standardisation activities in the area.\n\nWhat are the tasks of the European AI Office?\nThe AI Office has as its mission to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence in a centralised structure.\n\nIn particular, the AI Office shall enforce and supervise the new rules for general purpose AI models. This includes drawing up codes of practice to detail out rules, its role in classifying models with systemic risks and monitoring the effective implementation and compliance with the Regulation. The latter is facilitated by the powers to request documentation, conduct model evaluations, investigate upon alerts and request providers to take corrective action.\n\nThe AI Office shall ensure coordination regarding artificial intelligence policy and collaboration between involved Union institutions, bodies and agencies as well as with experts and stakeholders. In particular, it will provide a strong link with the scientific community to support the enforcement, serve as international reference point for independent experts and expert organisations and facilitate exchange and collaboration with similar institutions across the globe.\n\nWhat is the difference between the AI Board, AI Office, Advisory Forum and Scientific Panel of independent experts?\nThe AI Board has extended tasks in advising and assisting the Commission and the Member States.\n\nThe AI Office is to be established within the Commission and shall work to develop Union expertise and capabilities in the field of artificial intelligence and to contribute to the implementation of Union legislation of artificial intelligence. Particularly, the AI Office shall enforce and supervise the new rules for general purpose AI models.\n\nThe Advisory Forum will consist of a balanced selection of stakeholders, including industry, start-ups, SMEs, civil society and academia. It shall be established to advise and provide technical expertise to the Board and the Commission, with members appointed by the Board among stakeholders.\n\nThe Scientific Panel of independent experts supports the implementation and enforcement of the Regulation as regards GPAI models and systems, and the Member States would have access to the pool of experts.\n\nWhat are the penalties for infringement?\nWhen AI systems are put on the market or in use that do not respect the requirements of the Regulation, Member States will have to lay down effective, proportionate and dissuasive penalties, including administrative fines, in relation to infringements and communicate them to the Commission.\n\nThe Regulation sets out thresholds that need to be taken into account:\n\nUp to €35m or 7% of the total worldwide annual turnover of the preceding financial year (whichever is higher) for infringements on prohibited practices or non-compliance related to requirements on data;\nUp to €15m or 3% of the total worldwide annual turnover of the preceding financial year for non-compliance with any of the other requirements or obligations of the Regulation, including infringement of the rules on general-purpose AI models;\nUp to €7.5m or 1.5% of the total worldwide annual turnover of the preceding financial year for the supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request;\nFor each category of infringement, the threshold would be the lower of the two amounts for SMEs and the higher for other companies.\nIn order to harmonise national rules and practices in setting administrative fines, the Commission, counting on the advice of the Board, will draw up guidelines.\n\nAs EU Institutions, agencies or bodies should lead by example, they will also be subject to the rules and to possible penalties; the European Data Protection Supervisor will have the power to impose fines to them.\n\nWhat can individuals do that are affected by a rule violation?\nThe AI Act foresees a right to lodge a complaint with a national authority. On this basis national authorities can launch market surveillance activities, following the procedures of the market surveillance regulations.\n\nAdditionally, the proposed AI Liability Directive aims to provide persons seeking compensation for damage caused by high-risk AI systems with effective means to identify potentially liable persons and obtain relevant evidence for a damage claim. For this purpose, the proposed Directive provides for the disclosure of evidence about specific high-risk AI systems that are suspected of having caused damage.\n\nMoreover, the revised Product Liability Directive will ensure that compensation is available to individuals who suffer death, personal injury or property damage that is caused by a defective product in the Union and clarify that AI systems and products that integrate AI systems are also covered by existing rules.\n\nHow do the voluntary codes of conduct for high-risk AI systems work?\nProviders of non-high-risk applications can ensure that their AI system is trustworthy by developing their own voluntary codes of conduct or adhering to codes of conduct adopted by other representative associations.\n\nThese will apply simultaneously with the transparency obligations for certain AI systems.\n\nThe Commission will encourage industry associations and other representative organisations to adopt voluntary codes of conduct.\n\nHow do the codes of practice for general purpose AI models work?\nThe Commission invites providers of general-purpose AI models and other experts to jointly work on a code of practice.\n\nOnce developed and approved for this purpose, these codes can be used by the providers of general-purpose AI models to demonstrate compliance with the relevant obligations from the AI Act, following the example of the GDPR.\n\nThis is especially relevant to detail out the rules for providers of general-purpose AI model with systemic risks, to ensure future-proof and effective rules for risk assessment and mitigation as well as other obligations.\n\nDoes the AI Act contain provisions regarding environmental protection and sustainability?\nThe objective of the AI proposal is to address risks to safety and fundamental rights, including the fundamental right to a high-level environmental protection. Environment is also one of the explicitly mentioned and protected legal interests.\n\nThe Commission is asked to request European standardisation organisations a standardisation deliverable on reporting and documentation processes to improve AI systems resource performance, such as reduction of energy and other resources consumption of the high-risk AI system during its lifecycle, and on energy efficient development of general-purpose AI models.\n\nFurthermore, the Commission by two years after the date of application of the Regulation and every four years thereafter, is asked to submit a report on the review of the progress on the development of standardisation deliverables on energy efficient development of general-purpose models and asses the need for further measures or actions, including binding measures or actions.\n\nIn addition, providers of general purpose AI models, which are trained on large data amounts and therefore prone to high energy consumption, are required to disclose energy consumption.\n\nThe Commission is asked to develop an appropriate methodology for this assessment.\n\nIn case of general purpose AI models with systemic risks, energy efficiency furthermore needs to be assessed.\n\nHow can the new rules support innovation?\nThe regulatory framework can enhance the uptake of AI in two ways. On the one hand, increasing users' trust will increase the demand for AI used by companies and public authorities. On the other hand, by increasing legal certainty and harmonising rules, AI providers will access bigger markets, with products that users and consumers appreciate and purchase. Rules will apply only where strictly needed and in a way that minimises the burden for economic operators, with a light governance structure.\n\nThe AI Act further enables the creation of regulatory sandboxes and real world testing, which provide a controlled environment to test innovative technologies for a limited time, thereby fostering innovation by companies, SMEs and start-ups in compliance with the AI Act. These, together with other measures such as the additional Networks of AI Excellence Centres and the Public-Private Partnership on Artificial Intelligence, Data and Robotics, and access to Digital Innovation Hubs and Testing and Experimentation Facilities will help build the right framework conditions for companies to develop and deploy AI.\n\nReal world testing of High-Risk AI systems can be conducted for a maximum of 6 months (which can be prolonged by another 6 months). Prior to testing, a plan needs to be drawn up and submitted it to the market surveillance authority, which has to approve of the plan and specific testing conditions, with default tacit approval if no answer has been given within 30 days. Testing may be subject to unannounced inspections by the authority.\n\nReal world testing can only be conducted given specific safeguards, e.g. users of the systems under real world testing have to provide informed consent, the testing must not have any negative effect on them, outcomes need to be reversible or disregardable, and their data needs to be deleted after conclusion of the testing. Special protection is to be granted to vulnerable groups, i.e. due to their age, physical or mental disability.\n\nBesides the AI Act, how will the EU facilitate and support innovation in AI?\nThe EU's approach to Artificial Intelligence is based on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and the protection of fundamental rights. People and businesses should be able to enjoy the benefits of AI while feeling safe and protected. The European AI Strategy aims at making the EU a world-class hub for AI and ensuring that AI is human-centric and trustworthy. In April 2021, the Commission presented its AI package, including: (1) a review of the Coordinated Plan on Artificial Intelligence and (2) its proposal for a regulation laying down harmonised rules on AI.\n\nWith the Coordinated Plan on AI the European Commission has adopted a comprehensive strategy to promote the development and adoption of AI in Europe. It focuses on creating enabling conditions for AI development and uptake, ensuring excellence thrives from the lab to the market, increasing the trustworthiness of AI, and building strategic leadership in high-impact sectors.\n\nThe Commission aims to leverage the activities of Member States by coordinating and harmonizing their efforts, to foster a cohesive and synergistic approach towards AI development and adoption. The Commission also put in place the European AI Alliance platform, which brings together stakeholders from academia, industry, and civil society to exchange knowledge and insights on AI policies.\n\nMoreover, the Coordinated plans foresees several measures that aim to unlock data resources, foster critical computing capacity, increase research capacities, support a European network of Testing and Experimentation Facilities (TEFS) and support SMEs through European Digital Innovation Hubs (EDIHs).\n\nWhat is the international dimension of the EU's approach?\nThe AI Act and the Coordinated Plan on AI are part of the efforts of the European Union to be a global leader in the promotion of trustworthy AI at international level. AI has become an area of strategic importance at the crossroads of geopolitics, commercial stakes and security concerns.\n\nCountries around the world are choosing to use AI as a way to signal their desires for technical advancement due to its utility and potential. AI regulation is only emerging and the EU will take actions to foster the setting of global AI standards in close collaboration with international partners in line with the rules-based multilateral system and the values it upholds. The EU intends to deepen partnerships, coalitions and alliances with EU partners (e.g. Japan, the US, India, Canada, South Korea, Singapore, or the Latin American and Caribbean region) as well as multilateral (e.g. OECD, G7 and G20) and regional organisations (e.g. Council of Europe).\n\n*Updated on 14/12/2023""
 '‘The Zone Of Interest’ Ending Explained & Film Summary: What Happens To Rudolf And Hedwig Hoss?\nPUBLISHED\n\nFEBRUARY 21, 2024\nBY\nSOURYA SUR ROY\n0COMMENTS\nThe Zone Of Interest Ending Explained Film Summary Hedwig Ross, Rudolph Ross\nCredits: A24\nThe Zone of Interest is a new historical drama film by English filmmaker Jonathan Glazer that manages to recreate a terrible moment from history with a unique and devastating effect. Loosely adapted from Martin Amis’ novel of the same name, the film’s plot follows the Hoss family, who live right beside the Auschwitz concentration camp, going about their usual lives with no concern for the terrible crimes being committed right outside. The Zone of Interest is all about subtle, indirect expressions that are poignant enough to pierce through the visual layer, successfully making the viewer all the more uncomfortable with every passing minute.\n\nSpoiler Alert\n\nPlot Summary: What Is The Film About?\nThe Zone of Interest opens with a noticeably long black screen, with only a soft sound being eerily stretched in the background, perhaps preparing us for what is to unfold on screen over the next hundred or so minutes. When the visuals come on, though, there is nothing unusual or out of the ordinary, as a family is seen spending some personal time by the forested banks of a river. This is a secluded spot reserved only for the family, and it seems to be their most common way of spending leisure time. As the girls are led by a nanny through the bushes, possibly for some lesson in gardening and wildlife, the boys jump into the river along with their father. Sometime later, the family reunites and leaves the riverbank, driving away in two black, sinister-looking cars. On that very night, the father of the house is seen going around, switching off all the lights, before going to bed.\n\nWhile there is really nothing odd in this whole presentation of a family spending a day with themselves, the chilling reality of the matter is revealed when the film introduces the particular lot. The family is that of Rudolf Hoss, a notorious real figure from history, infamous for being a distinguished SS officer and the commander of the Auschwitz concentration camp. Most of the entire film, and the whole of the opening scene, actually takes place in Auschwitz, meaning that the leisurely picnic of the big family literally took place only a few miles away from the spot of the ongoing genocide. This is the very premise of The Zone of Interest, for it shows the tumultuous time of history from the perspective of the Hoss family, mainly the patriarch Rudolf and his wife, Hedwig.\n\nThe couple lives in an idyllic resort with their two sons and three daughters, the youngest still a baby, right on the other side of the high walls of the concentration camp. Despite the inhuman torture and killing going on right outside the walls that separate their lives, the Hoss family members are not perturbed by the matter at all. Instead, they are rather accustomed to Auschwitz, cherishing their time and accepting it as their new home.\n\nHow Does The Film Powerfully Present The Harrowing Events Of The Holocaust?\nThe most remarkable thing about The Zone of Interest is how it manages to say so much without directly saying it, combining the visual and the aural through a unique dissonance. With regards to the visuals, meaning scenes that play out to take forward the mostly simple and common story, the camera hardly ever leaves the confines of the host house. While some exceptions take place towards the latter part of the film, when Rudolf is transferred to a different concentration camp and he is seen at his new post, almost no scene of the camp in Auschwitz is seen. But the audio track picks up on numerous cries, lashes, and sounds that clearly come from the outside world but are heavily ignored. There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf’s family and his subordinates celebrate the man’s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers. But nobody seems to notice, or rather, everyone pretends to look through the entire matter, as if nothing shocking is in the works. Rudolf is also seen meeting with a businessman in his house, who comes to show the commander plans and designs for a new, more effective gas chamber that he wants to build for his government. Rudolf goes through the plans without any hesitation and then also reports about this businessman’s portfolio to his higher authorities, convinced that sturdier and better-designed gas chambers are needed to take his beloved nation and his government forward. The Zone of Interest does not really differentiate between evil-doers and those supporting such evil, but Rudolf is definitely in the first category, as he clearly enjoys the torture and killing of people.\n\nWhat comes as even a bigger shock is the reaction of his wife, Hedwig, for she does not react to any of these massacres either. Rather, the woman is extremely accustomed to the life of the commander’s wife, and she enjoys the perks it brings along. She often receives luxury and expensive items that have been taken away from the prisoners, and on one particular occasion, she is seen receiving a fancy fur coat, since the Nazis did not differentiate between the rich and the poor among their targets. Hedwig immediately throws the coat on her body and tries it out in front of the mirror, only to realize that there is still lipstick lying inside one of the pockets. The presence of the lipstick would obviously be a bold reminder to anyone of the previous owner of the coat and the atrocious torture she must be subjected to at present. However, Hedwig has been wired to not think like that, and instead of any guilt or remorse, she feels rather excited to try on the lipstick, which is now hers as well.\n\nHedwig maintains a calm and composed nature, without any worry in the world, as she focuses on her gardening and getting a pool built for her children in their compound. The thick, dark smoke from the chimneys of the gas chambers on one side and from the steam engine train that brings in Jewish prisoners every day on the other does not affect the woman at all. The irony of the matter is all the more glaring when Hedwig is absolutely livid that her husband has to be transferred away from Auschwitz. She decides to stay back at the place along with her children because she is unwilling to uproot the life she had built there, including the fancy garden and the greenhouse, and shift somewhere else, which is probably too cold for her comfort as well. The fact that thousands were being faced with worse persecution and millions more would be uprooted, killed, or left disbanded very easily eludes her thought. In this regard, Jonathan Glazer’s film is a really fascinating note on not just the Holocaust but also the effect of systematized violence and the tendency of the masses to side with the oppressors in any given scenario.\n\nThe Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people. As soon as Rudolf finds a skull and some ashes in the river that he and his sons were bathing in, he scurries back to his house, and the children are scrubbed clean with utmost precision. In another instance, it is suggested that Rudolf forces himself upon a helpless prisoner woman, but he ensures that he scrubs his private parts before retiring for the night.\n\nThe only exception to the unaffected response by the entire family is by Hedwig’s mother, who finds it bizarre that her daughter, her husband, and their children can really live at such a place. The elderly woman definitely has no sympathies for the prisoners, though, but she is rather unable to live with so many signs and reminders of death all around. The stench of burning human bodies and the ash flying around keep her up all night, but the very same elements are like playthings for the two young boys who still lay awake in their room. On a similar night, filled with reminders of the ongoing genocide, Hedwig is seen asking Rudolf to take her on a romantic trip, in the most romantic conversation between the couple in the film. Ultimately, the mother leaves the house unannounced very early the next morning, only leaving behind a note for her daughter. Hedwig simply tosses the note into her furnace insignificantly, almost insulted that someone would find her beloved home distasteful or discomforting. Even after Rudolf leaves for Oranienburg, Hedwig stays at their Auschwitz house with the children.\n\nWhat Do The Scenes In Infrared Signify?\nThe Zone of Interest also sparsely presents a few scenes, in which an unacquainted young girl is seen going around Auschwitz, hiding apples and other meager food items inside the trenches. She is clearly doing this extremely dangerous work only to help the prisoners and ease their suffering in whatever little way she can. But interestingly, these scenes are in infrared, or negative, although only as long as the girl is in the outside world. As soon as she returns home, the visuals turn normal, then switch to infrared when she or her mother step out on the balcony. The family is revealed to be Polish locals who have no interest in Nazi ideals and dream of liberation one day. However, the mere fact that the family is still alive, irrespective of whether they are Jewish or not, suggests that they also have to work as collaborators for the Nazis to a certain degree. This was definitely the case with numerous non-Jews during the Nazi occupation who had to work for the horrific authorities despite not wanting to. Going by that logic, the significance of the use of infrared might be in stating how the family cannot be themselves as soon as they step out of their house or into the open balcony as well. Although the girl takes on the dangerous responsibility of helping the prisoners, she still cannot express her true self in public, leading to her being shown in infrared. Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the “normal” people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest‘s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions. In the middle of these two instances, The Zone of Interest briefly moves to modern times, and various reminders of the Holocaust are seen being maintained at the Auschwitz-Birkenau State Museum, right before the place is opened to public visitors. The last scene returns to the past once more, and Rudolf is seen feeling slightly odd, as if someone is watching him, as he continues down the stairs.\n\nThe Zone of Interest‘s ending scene seems to suggest that deep in his conscience, Rudolf Hoss does know that his actions can only make one retch, and almost like a fortune-teller, he has an uneasy feeling that his legacy will go down terribly in history. The scene of the museum is a fast jolt back to the right perspective, which had been missing throughout the film. Throughout the entire duration of The Zone of Interest, Rudolf, his family, and his professional associates had all been extremely invested in hiding the evidence and changing the narrative, but ultimately, the thousands of shoes or the torn, ragged uniforms still exist as reminders of the horrible genocide.']",'Divine Rivals' was written by Rebecca Ross.,1.0,1.0000000000000007,0.001282051282051282,0.9999999999,1.0
What happens on day 2?,"After a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area.

You encounter 2 ropers seeking the next burrowed entrance left by the Kryn.","['Alan Wake 2\nWhy the hell did you kill Casey? What the hell were you thinking, man?\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\nYou have been warned...\n\n""This story... is a monster. And monsters wear many faces.""\n― Alan Wake\n\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in ""The Final Draft"" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\'s story. ""The Final Draft"" was released on December 11, 2023.\n\nPatch notes for Alan Wake 2 updates can be found here.\n\n\nContents\n1\tSynopsis\n2\tPlot\n3\tChapter List\n3.1\tThe Final Draft\n3.2\tExpansion 1: Night Springs\n4\tGameplay\n5\tDevelopment\n5.1\tInitial development\n5.2\tRemedy Connected Universe\n5.3\tOfficial development\n6\tReception\n7\tTrivia\n8\tGallery\n8.1\tOfficial Images\n8.2\tConcept art\n8.3\tConcept art (earlier iteration)\n9\tVideos\n10\tSources\nSynopsis\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\n\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\n\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\n\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\n― Epic Games Store page description\nPlot\nSee also: Alan Wake, Alan Wake\'s American Nightmare, and Control\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\n\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the ""Cult of the Tree"". In addition to Nightingale\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\'s corpse, but it suddenly reanimates, in search of the ""Clicker"", and escapes the morgue after Breaker mysteriously vanishes.\n\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a ""Taken"", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\n\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called ""In Between With Mr. Door"", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\'s investigation of the ""Cult of the Word"" led by Alan\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\n\nBack in the present, Alan explains that he wrote a new novel, ""Return"", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that ""Return"" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\n\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality ""Return"" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\n\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\'s ending of ""Return"", perpetuating the loop.\n\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\n\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for ""Return"". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\n\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through ""ascension."" Alan then revives from his gunshot wound and says, ""It\'s not a loop, it\'s a spiral.""\n\nIn the ""Final Draft"" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\'s call connects, confirming Logan\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\n\nChapter List\nThe chapters/parts listed here are played in the following order:\nPrologue: The Cult\nReturn 1: Invitation\nReturn 2: The Heart\nInitiation 1: Late Night\nInitiation 2: Casey\nInitiation 3: Haunting\nPlayers have the choice to play the following of Alan and Saga\'s chronological chapters/parts in any order they wish:\nReturn 3: Local Girl\nReturn 4: No Chance\nReturn 5: Old Gods\nReturn 6: Scratch\nInitiation 4: We Sing\nInitiation 5: Room 665\nInitiation 6: Return\nInitiation 7: Masks\nInitiation 8: Zane\'s Film\nThe chapters/parts listed here are past the point of no return and are played in the following order:\nReturn 7: Summoning\nInitiation 9: Gone\nReturn 8: Deerfest\nReturn 9: Come Home\nThe Final Draft\nRemedy released a New Game Plus update to the game on December 11th, 2023 named ""The Final Draft"".\n\nExpansion 1: Night Springs\nSet as ""episodes"" of the Night Springs TV show, these can be played in any order the player wishes.\n\nNumber One Fan\nNorth Star\nTime Breaker\nGameplay\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a ""critical state."" Players also encounter various puzzles and locked boxes that they\'ll need to solve in order to obtain upgraded gear.\n\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\n\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\n\nWhilst Saga\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own ""mind palaces"" to help progress their stories, with Alan having his Writer\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\n\nDevelopment\nInitial development\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when ""Alan Wake 2"" was shown on the Artist Althea Suarez Gata\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\'s American Nightmare, the credits to the game also then indicated that ""Alan Wake\'s journey through the night will continue"".\n\nAlso in 2012, Sam Lake tweeted a link to a ""Blogspot"" called ""This House of Dreams."" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man ""wearing a funny jacket with old-fashioned elbow patches"" and that he wanted ""to turn all the lights on."" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain ""alanwake2.com"" was also reserved by Remedy Entertainment.\n\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\'t announced. He revealed that the time just wasn\'t right yet, but mentioned he had not given up on the franchise.\n\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, ""It\'s hard to guess,"" but that he would ""love to do that"".\n\nRemedy Connected Universe\nEaster eggs in Remedy\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an ""Altered World Event"" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\n\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for ""Altered World Event,"" they also resemble Alan\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\n\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, ""Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.""[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\n\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\'s narration, seemed to indicate Remedy\'s next game could be a follow up to Alan Wake.\n\nOfficial development\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\'s new publishing initiative. The games were said to be part of ""the same franchise"". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that ""I\'ve heard that Remedy is going to be making Alan Wake 2,"" as part of the Remedy-Epic deal. Grubb went on to say that the game ""should kind of be the follow-up that fans of that series want,"" but that there\'s little extra information and no word on an official announcement.\n\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\n\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\n\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\n\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\n\nReception\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\n\nThe game went on to win more awards in Finland and around the world.\n\nTrivia\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\'s edition were announced.\nThe second entry in Remedy\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'
 '‘The Zone Of Interest’ Ending Explained & Film Summary: What Happens To Rudolf And Hedwig Hoss?\nPUBLISHED\n\nFEBRUARY 21, 2024\nBY\nSOURYA SUR ROY\n0COMMENTS\nThe Zone Of Interest Ending Explained Film Summary Hedwig Ross, Rudolph Ross\nCredits: A24\nThe Zone of Interest is a new historical drama film by English filmmaker Jonathan Glazer that manages to recreate a terrible moment from history with a unique and devastating effect. Loosely adapted from Martin Amis’ novel of the same name, the film’s plot follows the Hoss family, who live right beside the Auschwitz concentration camp, going about their usual lives with no concern for the terrible crimes being committed right outside. The Zone of Interest is all about subtle, indirect expressions that are poignant enough to pierce through the visual layer, successfully making the viewer all the more uncomfortable with every passing minute.\n\nSpoiler Alert\n\nPlot Summary: What Is The Film About?\nThe Zone of Interest opens with a noticeably long black screen, with only a soft sound being eerily stretched in the background, perhaps preparing us for what is to unfold on screen over the next hundred or so minutes. When the visuals come on, though, there is nothing unusual or out of the ordinary, as a family is seen spending some personal time by the forested banks of a river. This is a secluded spot reserved only for the family, and it seems to be their most common way of spending leisure time. As the girls are led by a nanny through the bushes, possibly for some lesson in gardening and wildlife, the boys jump into the river along with their father. Sometime later, the family reunites and leaves the riverbank, driving away in two black, sinister-looking cars. On that very night, the father of the house is seen going around, switching off all the lights, before going to bed.\n\nWhile there is really nothing odd in this whole presentation of a family spending a day with themselves, the chilling reality of the matter is revealed when the film introduces the particular lot. The family is that of Rudolf Hoss, a notorious real figure from history, infamous for being a distinguished SS officer and the commander of the Auschwitz concentration camp. Most of the entire film, and the whole of the opening scene, actually takes place in Auschwitz, meaning that the leisurely picnic of the big family literally took place only a few miles away from the spot of the ongoing genocide. This is the very premise of The Zone of Interest, for it shows the tumultuous time of history from the perspective of the Hoss family, mainly the patriarch Rudolf and his wife, Hedwig.\n\nThe couple lives in an idyllic resort with their two sons and three daughters, the youngest still a baby, right on the other side of the high walls of the concentration camp. Despite the inhuman torture and killing going on right outside the walls that separate their lives, the Hoss family members are not perturbed by the matter at all. Instead, they are rather accustomed to Auschwitz, cherishing their time and accepting it as their new home.\n\nHow Does The Film Powerfully Present The Harrowing Events Of The Holocaust?\nThe most remarkable thing about The Zone of Interest is how it manages to say so much without directly saying it, combining the visual and the aural through a unique dissonance. With regards to the visuals, meaning scenes that play out to take forward the mostly simple and common story, the camera hardly ever leaves the confines of the host house. While some exceptions take place towards the latter part of the film, when Rudolf is transferred to a different concentration camp and he is seen at his new post, almost no scene of the camp in Auschwitz is seen. But the audio track picks up on numerous cries, lashes, and sounds that clearly come from the outside world but are heavily ignored. There is only one brief scene in which we are shown a side-angled close-up of Rudolf while he is at his workplace, which is a camp intended to kill Jews by the thousands. Indeed, the man is shot looking at the work he is rather proud of doing, amidst thick smoke bellowing out and loud cries and shrieks of helpless people. Rudolf certainly has no reservations about overseeing a genocide, but the film particularly shines with respect to how it uses the very usual to highlight the horrific context in the backdrop.\n\nEarly on in the film, Rudolf’s family and his subordinates celebrate the man’s birthday with a fancy cake, and all the Nazi soldiers come to his house to greet him. This merrymaking literally takes place all while hundreds, if not thousands, of families, are kept locked in the concentration camps and forced into the gas chambers. But nobody seems to notice, or rather, everyone pretends to look through the entire matter, as if nothing shocking is in the works. Rudolf is also seen meeting with a businessman in his house, who comes to show the commander plans and designs for a new, more effective gas chamber that he wants to build for his government. Rudolf goes through the plans without any hesitation and then also reports about this businessman’s portfolio to his higher authorities, convinced that sturdier and better-designed gas chambers are needed to take his beloved nation and his government forward. The Zone of Interest does not really differentiate between evil-doers and those supporting such evil, but Rudolf is definitely in the first category, as he clearly enjoys the torture and killing of people.\n\nWhat comes as even a bigger shock is the reaction of his wife, Hedwig, for she does not react to any of these massacres either. Rather, the woman is extremely accustomed to the life of the commander’s wife, and she enjoys the perks it brings along. She often receives luxury and expensive items that have been taken away from the prisoners, and on one particular occasion, she is seen receiving a fancy fur coat, since the Nazis did not differentiate between the rich and the poor among their targets. Hedwig immediately throws the coat on her body and tries it out in front of the mirror, only to realize that there is still lipstick lying inside one of the pockets. The presence of the lipstick would obviously be a bold reminder to anyone of the previous owner of the coat and the atrocious torture she must be subjected to at present. However, Hedwig has been wired to not think like that, and instead of any guilt or remorse, she feels rather excited to try on the lipstick, which is now hers as well.\n\nHedwig maintains a calm and composed nature, without any worry in the world, as she focuses on her gardening and getting a pool built for her children in their compound. The thick, dark smoke from the chimneys of the gas chambers on one side and from the steam engine train that brings in Jewish prisoners every day on the other does not affect the woman at all. The irony of the matter is all the more glaring when Hedwig is absolutely livid that her husband has to be transferred away from Auschwitz. She decides to stay back at the place along with her children because she is unwilling to uproot the life she had built there, including the fancy garden and the greenhouse, and shift somewhere else, which is probably too cold for her comfort as well. The fact that thousands were being faced with worse persecution and millions more would be uprooted, killed, or left disbanded very easily eludes her thought. In this regard, Jonathan Glazer’s film is a really fascinating note on not just the Holocaust but also the effect of systematized violence and the tendency of the masses to side with the oppressors in any given scenario.\n\nThe Hoss children are also equally desensitized to seeing murder and killing around them. The boys play around with toy soldiers, all waging war against invisible enemies. Shockingly, they are also seen collecting and playing with gold teeth, which are literally the remains of people who had been killed in the camp. One of the daughters does seem to feel something odd about their house, or she simply sleepwalks as a habit and sits by the door as if waiting for someone to arrive. Nonetheless, this young girl would also grow accustomed to the situation one day and not find anything strange about it. The Jewish prisoners are allowed to get close to the house and the family, as many of them are given the task of cleaning the boots and bringing supplies to the place. But there is also a clear distinction that the Nazi commander maintains from them, which highlights the pure hatred breeding inside his perspective of the people. As soon as Rudolf finds a skull and some ashes in the river that he and his sons were bathing in, he scurries back to his house, and the children are scrubbed clean with utmost precision. In another instance, it is suggested that Rudolf forces himself upon a helpless prisoner woman, but he ensures that he scrubs his private parts before retiring for the night.\n\nThe only exception to the unaffected response by the entire family is by Hedwig’s mother, who finds it bizarre that her daughter, her husband, and their children can really live at such a place. The elderly woman definitely has no sympathies for the prisoners, though, but she is rather unable to live with so many signs and reminders of death all around. The stench of burning human bodies and the ash flying around keep her up all night, but the very same elements are like playthings for the two young boys who still lay awake in their room. On a similar night, filled with reminders of the ongoing genocide, Hedwig is seen asking Rudolf to take her on a romantic trip, in the most romantic conversation between the couple in the film. Ultimately, the mother leaves the house unannounced very early the next morning, only leaving behind a note for her daughter. Hedwig simply tosses the note into her furnace insignificantly, almost insulted that someone would find her beloved home distasteful or discomforting. Even after Rudolf leaves for Oranienburg, Hedwig stays at their Auschwitz house with the children.\n\nWhat Do The Scenes In Infrared Signify?\nThe Zone of Interest also sparsely presents a few scenes, in which an unacquainted young girl is seen going around Auschwitz, hiding apples and other meager food items inside the trenches. She is clearly doing this extremely dangerous work only to help the prisoners and ease their suffering in whatever little way she can. But interestingly, these scenes are in infrared, or negative, although only as long as the girl is in the outside world. As soon as she returns home, the visuals turn normal, then switch to infrared when she or her mother step out on the balcony. The family is revealed to be Polish locals who have no interest in Nazi ideals and dream of liberation one day. However, the mere fact that the family is still alive, irrespective of whether they are Jewish or not, suggests that they also have to work as collaborators for the Nazis to a certain degree. This was definitely the case with numerous non-Jews during the Nazi occupation who had to work for the horrific authorities despite not wanting to. Going by that logic, the significance of the use of infrared might be in stating how the family cannot be themselves as soon as they step out of their house or into the open balcony as well. Although the girl takes on the dangerous responsibility of helping the prisoners, she still cannot express her true self in public, leading to her being shown in infrared. Another perspective is that the girl and her mother truly stand out in this horrific world solely because of their generous actions. Therefore, in a film like this, in which the Nazis and the enablers are the “normal” people, anyone with any sense of humanity has to be visually differentiated from the Hoss family members.\n\nWhat Happens To Rudolf Hoss?\nDuring The Zone of Interest‘s ending, Rudolf is seen in his Berlin office as he telephones Hedwig and tells her about his excitement for the concentration camps being built. Rudolf had been given the responsibility of overseeing a new Nazi order in which Hungarian Jews were to be arrested and killed. Although Hedwig refuses to be part of this very direct talk of violence, for she prefers such matters to be in the background, the commander still feels thrilled. He is seen walking down the stairs from his office when suddenly bouts of violent retching hit him on two occasions. In the middle of these two instances, The Zone of Interest briefly moves to modern times, and various reminders of the Holocaust are seen being maintained at the Auschwitz-Birkenau State Museum, right before the place is opened to public visitors. The last scene returns to the past once more, and Rudolf is seen feeling slightly odd, as if someone is watching him, as he continues down the stairs.\n\nThe Zone of Interest‘s ending scene seems to suggest that deep in his conscience, Rudolf Hoss does know that his actions can only make one retch, and almost like a fortune-teller, he has an uneasy feeling that his legacy will go down terribly in history. The scene of the museum is a fast jolt back to the right perspective, which had been missing throughout the film. Throughout the entire duration of The Zone of Interest, Rudolf, his family, and his professional associates had all been extremely invested in hiding the evidence and changing the narrative, but ultimately, the thousands of shoes or the torn, ragged uniforms still exist as reminders of the horrible genocide.'
 'Bullet Kin\nBullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal contact damage if the player touches them.\n\nOccasionally, Bullet Kin will have assault rifles, in which case they will rapidly fire 8 bullets towards the player before reloading. When an assault rifle wielding bullet kin appears, there will often be more in the same room.\n\nOn some occasions the player will also encounter incapacitated Bullet Kin lying on the floor. These Bullet Kin are props and disintegrate upon touch. They can be found in mass quantity in Oubliette.\n\nIn the Black Powder Mine, they can also ride Minecarts. In fact, if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in.\n\nTrivia\nBullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s.\nIncapacitated Bullet Kin can be found in the Oublilette and Cannon\'s boss room.\nIn the Oubliette and the boss fight against Agunim, some room props resemble Bullet Kin poking out from inside barrels. This is likely a visual joke on a bullet inside a gun barrel.\nIn the Portuguese translation of the game, they are known as ""Balùnculo"", a portmanteau of the words ""bala"" (bullet) and ""homúnculo"" (homunculus).\nBullet Kin makes a playable appearance in the platform fighting games Indie Pogo and Indie Game Battle.\nBullet Kin is also a crossover skin in the game Riverbond.\nBullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\nVeteran Bullet Kin\nVeteran Bullet Kin are similar to regular Bullet Kin, but have a higher rate of fire, higher shot speed and attempt to predict the player\'s movements. They also run faster than normal Bullet Kin, allowing them to catch up with the player quickly if they attempt to take cover.\n\nThey fire 4 bullets in a row. If the player moves out of sight from one then the Veteran will pause his attack and then fire the remaining bullets once he has caught up.\n\nBandana Bullet Kin\nBandana Bullet Kin behave like regular Bullet Kin, but their fire rate is heavily increased. Bandana Bullet Kin also have a higher magazine size than Bullet Kin that wield AK-47s, making them more relentless.\n\nTrivia\nBandana Bullet Kin wield Machine Pistols.\n\nTanker\nTankers behave like regular Bullet Kin, but have higher health and higher rate of fire. Tankers can be spawned by Treadnaught.\n\nTheir rate of fire is slightly lower than that of Bandana Bullet Kin, but they are just as relentless.\n\nTrivia\nTankers wield AK-47s.\nThe Tanker\'s expression in his Ammonomicon profile resembles that of the Bullet\'s avatar when talking to an NPC.\n\nMinelet\nMinelets behave like regular Bullet Kin, but will occasionally hide under their hard hat, deflecting incoming projectiles. They will then pop out from underneath their hard hat, releasing a ring of bullets in all directions.\n\nTrivia\nMinelets are a possible reference to Mets from the Mega Man series because of their similar behavior. They both hide under their helmets to protect themselves and attack when they emerge.\n\nCardinal\nCardinals behave like regular Bullet Kin, but have 50% higher health and will occasionally pause to shoot a group of 5 bullets that will home in on players.\n\nThough a minor effect, these bullets spin around each other as they travel, similar to Apprentice Gunjurers. This occasionally allows them to slip through corners as only some of the bullets will be destroyed.\n\nTrivia\nAlthough normally seen in the Abbey & Hollow, a single cardinal may be seen in the first floor, tending to a small cemetery filled with gravestones. He is the only enemy in that room.\n""Of the gun"" is a play on the phrase ""of the cloth"", meaning a member of the clergy.\n\nShroomer\nShroomers behave like regular Bullet Kin, but have double health and fire two bullets in a V shape. Their bullets can be avoided by standing still, but this can jeopardise dodging the more accurate projectiles of any accompanying enemies. They may also spawn in Gungeon Proper, though rarely.\n\nTrivia\nShroomers will misfire upon spawning, having to stand up after being spawned.\n\nAshen Bullet Kin\nAshen Bullet Kin have a higher rate of fire and higher shot speed than regular Bullet Kin. They seem to alternate between firing directly at the player and predicting their movements when shooting.\n\nIn some rooms of the Forge, Ashen Bullet Kin have the ability to spawn out of ashen statues, which allows them to catch the player off guard.\n\nTrivia\nThe quote ""Cinder Fella"" is a clear wordplay between ""Cinderella"", the famous fairytale, and ""Fella"" a familiar term for a friend or a person that you consider close.\nThe French traduction of this quote ""Balle au bois dormant"" is also a wordplay between the fairytale ""La belle au bois dormant"" (Sleeping Beauty) and ""Balle"" (Bullet)\nLike its normal counterpart, the Ashen Bullet Kin has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout.\n\nMutant Bullet Kin\nMutant Bullet Kin behave like regular Bullet Kin, but have higher health and will occasionally stop to release a cone of poison creep. They are immune to Poison effects. The cone of poison can only be released horizontally, so attacking from above or below are the safer options.\n\nTrivia\nIts subtitle references Old Faithful, a geyser in Yellowstone National Park.\n\nFallen Bullet Kin\nFallen Bullet Kin walk towards the player, firing spreads of 3 fire-shaped bullets. They leave behind a small patch of fire upon death. Despite this, they are not immune to fire damage.\n\nNotes\nFallen Bullet Kin will leave their pools of fire in the area where they took the blow that killed them. It will not be spawned where their death animation ends.\nTrivia\nFallen Bullet Kin wield Pitchforks.\nThe sounds that Fallen Bullet Kin make are lower pitched versions of regular Bullet Kin.\nThese enemies can also be spawned by Lament Configurum.\nA portrait of a Fallen Bullet Kin can be seen in the Abbey of the True Gun.\nIn the Portuguese translation of the game, they are known as ""Ex-Balùnculo"" (Ex-Bullet Kin), so in that version of the game, it is implied that they are no longer a type of bullet kin, this transformation may have happened through their death, where they were sent to the Sixth Chamber.\n\nKeybullet Kin\nKeybullet Kin run away from the player, and drop a key upon death. However, if the player does not manage to kill them in time, they will disappear.\n\nUnlike other Bullet Kin, Keybullet Kin do not deal contact damage if they run into the player.\n\nJammed Keybullet Kin drop 2 keys instead of 1. These Jammed variations run faster and will take less time to teleport away from the player if they are not destroyed quickly.\n\nIf a Keybullet Kin is knocked into a pit, it will not drop a key.\n\nThe chances for a specific number of Keybullet Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nKeybullet Kin may appear in boss arenas during the Boss Rush.\nKeybullet Kin have a small chance to appear in elevator rooms at the start of a floor.\nKilling 15 Keybullet Kin unlocks the Springheel Boots.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nChance Kin\nChance Kin run away from the player, and drop a random pickup upon death. However, if the player does not manage to kill them in time, they will disappear. Jammed Chance Kins have a chance to drop twice the loot.\n\nThe chances for a specific number of Chance Kin to spawn on a floor are:\n\n0\t1\t2\n50%\t30%\t20%\nTrivia\nChance Kin may appear in boss arenas during Boss Rush.\nChance Kin have a small chance to appear in elevator rooms at the start of the floor.\nThe Chance Kin\'s subtitle is a reference to the common phrase ""No Second Chances.""\nChance Kin block player movement during their death animation.\nChance Kin can appear in the same room as a Keybullet Kin.\nKeybullet Kin and Chance Kin\'s behavior is modeled after the Crystal Lizards from the Souls series and the Wandering Madness from Bloodborne. Both are harmless ""enemies"" that quickly run away from the player—often leading them directly into the path of danger—and despawn after a short time, with the promise of valuable loot if they are killed.\n\nConfirmed\nConfirmed are mysterious cloaked Bullet Kin. They stroll towards the player, occasionally stopping to fire four slithering lines of bullets at the player from under their hoods.\n\nConfirmed do not appear in specific room layouts. Instead, they have a small chance to replace an enemy in any room. Only one Confirmed can appear on each floor.\n\nDefeating ten Confirmed unlocks the Yellow Chamber.\n\nTrivia\nThe splash art for Confirmed show them having dozens of red eye-like bullets residing within their cloaks. This bears resemblance to the High Priest\'s splash art.\nThe Confirmed are referred to by numerous other names in the game\'s code, such as \'Kaliber Cultist\', and \'Faceless Cultist\'.\n\nRed-Caped Bullet Kin\nBullet Kin with red capes will rarely appear in random rooms after at least one Past has been killed. These Bullet Kin do not attack the player, and wander aimlessly. If it is the only enemy remaining in the room and it is left alone for long enough, it will disappear. After this happens 5 times, The Bullet is unlocked, and Red-Caped Bullet Kin stop spawning.\n\nThe chances that one will spawn on the six main floors are as follows:\n\n1\t2\t3\t4\t5\t6\n8%\t8%\t12%\t16%\t20%\t25%\nA floor can only contain a maximum of one caped bullet (with one known exception outlined below). There is a 49.95% chance of one or more Red-Caped Bullet Kin appearing in a full run through the Forge, and a 62.46% chance on a run through Bullet Hell.\n\nTrivia\nRed-Caped Bullet Kin wield Magnums, but do not fire them or point them at the player.\nRed-Caped Bullet Kin do not deal contact damage unless they are jammed.\nRed-Caped Bullet Kin\'s design may be based on The Kid from I Wanna Be The Guy.\nRooms created by the Drill can have a Red-Caped Bullet Kin spawn inside them, even if a Red-Caped Bullet Kin has already appeared on that floor.\nIt\'s possible for Red-Caped Bullet Kin to appear in the Aimless Void and Secret Floors such as the Oubliette.\nRed-Caped Bullet Kin are not attacked by companions.\nRed-Caped Bullet Kin will teleport away if the room contains an enemy that cannot be killed, such as Gunreapers or Dead Blows.']",I don't know.,0.0,0.0,0.0022471910112359553,0.0,0.0
