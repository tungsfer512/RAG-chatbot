{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\llm-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "from typing import Dict, List, Optional, Sequence\n",
    "\n",
    "# import weaviate\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "from langchain_community.vectorstores import Weaviate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.runnables import (\n",
    "    ConfigurableField,\n",
    "    Runnable,\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnablePassthrough,\n",
    "    RunnableSequence,\n",
    "    chain,\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import Client\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from typing import TYPE_CHECKING, Dict, Optional, Sequence\n",
    "\n",
    "from langchain_core.callbacks.manager import Callbacks\n",
    "from langchain_core.documents import BaseDocumentCompressor, Document\n",
    "from langchain_core.pydantic_v1 import Extra, root_validator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_index</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>What items do Rudolf's family take from the Je...</td>\n",
       "      <td>Rudolf's wife, Hedwig, often receives luxury a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_index                                           question  \\\n",
       "3               9  What items do Rudolf's family take from the Je...   \n",
       "\n",
       "                                              answer  \n",
       "3  Rudolf's wife, Hedwig, often receives luxury a...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data_evaluation.csv\")\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY\"\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001928669F150>, search_kwargs={'k': 20, 'threshold': 0.5})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embed_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"./RAG_chatbot/\",\n",
    "    OpenAIEmbeddings(),\n",
    "    allow_dangerous_deserialization=True,\n",
    ")\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20, \"threshold\": 0.5})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# Ensure flashrank is installed\n",
    "try:\n",
    "    from flashrank import Ranker, RerankRequest\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Could not import flashrank python package. \"\n",
    "        \"Please install it with `pip install flashrank`.\"\n",
    "    )\n",
    "\n",
    "# Call update_forward_refs to resolve forward references\n",
    "FlashrankRerank.update_forward_refs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup memory for contextual conversation\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=compression_retriever,\n",
    "    # memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=False,)\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"What did the goblins say?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What did the goblins say?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='Alan Wake 2\\nWhy the hell did you kill Casey? What the hell were you thinking, man?\\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\\nYou have been warned...\\n\\n\"This story... is a monster. And monsters wear many faces.\"\\n― Alan Wake\\n\\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in \"The Final Draft\" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\\'s story. \"The Final Draft\" was released on December 11, 2023.\\n\\nPatch notes for Alan Wake 2 updates can be found here.\\n\\n\\nContents\\n1\\tSynopsis\\n2\\tPlot\\n3\\tChapter List\\n3.1\\tThe Final Draft\\n3.2\\tExpansion 1: Night Springs\\n4\\tGameplay\\n5\\tDevelopment\\n5.1\\tInitial development\\n5.2\\tRemedy Connected Universe\\n5.3\\tOfficial development\\n6\\tReception\\n7\\tTrivia\\n8\\tGallery\\n8.1\\tOfficial Images\\n8.2\\tConcept art\\n8.3\\tConcept art (earlier iteration)\\n9\\tVideos\\n10\\tSources\\nSynopsis\\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\\n\\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\\n\\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\\n\\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\\n― Epic Games Store page description\\nPlot\\nSee also: Alan Wake, Alan Wake\\'s American Nightmare, and Control\\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\\n\\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the \"Cult of the Tree\". In addition to Nightingale\\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\\'s corpse, but it suddenly reanimates, in search of the \"Clicker\", and escapes the morgue after Breaker mysteriously vanishes.\\n\\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a \"Taken\", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\\n\\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called \"In Between With Mr. Door\", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\\'s investigation of the \"Cult of the Word\" led by Alan\\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\\n\\nBack in the present, Alan explains that he wrote a new novel, \"Return\", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that \"Return\" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\\n\\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality \"Return\" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\\n\\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\\'s ending of \"Return\", perpetuating the loop.\\n\\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\\n\\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for \"Return\". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\\n\\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through \"ascension.\" Alan then revives from his gunshot wound and says, \"It\\'s not a loop, it\\'s a spiral.\"\\n\\nIn the \"Final Draft\" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\\'s call connects, confirming Logan\\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\\n\\nChapter List\\nThe chapters/parts listed here are played in the following order:\\nPrologue: The Cult\\nReturn 1: Invitation\\nReturn 2: The Heart\\nInitiation 1: Late Night\\nInitiation 2: Casey\\nInitiation 3: Haunting\\nPlayers have the choice to play the following of Alan and Saga\\'s chronological chapters/parts in any order they wish:\\nReturn 3: Local Girl\\nReturn 4: No Chance\\nReturn 5: Old Gods\\nReturn 6: Scratch\\nInitiation 4: We Sing\\nInitiation 5: Room 665\\nInitiation 6: Return\\nInitiation 7: Masks\\nInitiation 8: Zane\\'s Film\\nThe chapters/parts listed here are past the point of no return and are played in the following order:\\nReturn 7: Summoning\\nInitiation 9: Gone\\nReturn 8: Deerfest\\nReturn 9: Come Home\\nThe Final Draft\\nRemedy released a New Game Plus update to the game on December 11th, 2023 named \"The Final Draft\".\\n\\nExpansion 1: Night Springs\\nSet as \"episodes\" of the Night Springs TV show, these can be played in any order the player wishes.\\n\\nNumber One Fan\\nNorth Star\\nTime Breaker\\nGameplay\\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a \"critical state.\" Players also encounter various puzzles and locked boxes that they\\'ll need to solve in order to obtain upgraded gear.\\n\\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\\n\\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\\n\\nWhilst Saga\\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own \"mind palaces\" to help progress their stories, with Alan having his Writer\\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\\n\\nDevelopment\\nInitial development\\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when \"Alan Wake 2\" was shown on the Artist Althea Suarez Gata\\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\\'s American Nightmare, the credits to the game also then indicated that \"Alan Wake\\'s journey through the night will continue\".\\n\\nAlso in 2012, Sam Lake tweeted a link to a \"Blogspot\" called \"This House of Dreams.\" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man \"wearing a funny jacket with old-fashioned elbow patches\" and that he wanted \"to turn all the lights on.\" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain \"alanwake2.com\" was also reserved by Remedy Entertainment.\\n\\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\\'t announced. He revealed that the time just wasn\\'t right yet, but mentioned he had not given up on the franchise.\\n\\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, \"It\\'s hard to guess,\" but that he would \"love to do that\".\\n\\nRemedy Connected Universe\\nEaster eggs in Remedy\\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an \"Altered World Event\" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\\n\\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for \"Altered World Event,\" they also resemble Alan\\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\\n\\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, \"Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.\"[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\\n\\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\\'s narration, seemed to indicate Remedy\\'s next game could be a follow up to Alan Wake.\\n\\nOfficial development\\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\\'s new publishing initiative. The games were said to be part of \"the same franchise\". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that \"I\\'ve heard that Remedy is going to be making Alan Wake 2,\" as part of the Remedy-Epic deal. Grubb went on to say that the game \"should kind of be the follow-up that fans of that series want,\" but that there\\'s little extra information and no word on an official announcement.\\n\\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\\n\\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\\n\\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\\n\\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\\n\\nReception\\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\\n\\nThe game went on to win more awards in Finland and around the world.\\n\\nTrivia\\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\\'s edition were announced.\\nThe second entry in Remedy\\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).', metadata={'id': 9, 'relevance_score': 0.998835}),\n",
       "  Document(page_content=\"How to Maximize Your Impact as a Data Scientist\\n\\nOne of the hardest pills to swallow as an Individual Contributor (IC) at work is that nobody cares about the hard work you put in. They don’t even care about your output; they care about the impact you drive.\\n\\nWhat’s the difference? Your output is the analysis you deliver, or the lines of code you write. Your impact is the decision your analysis helps the CEO make, or the revenue the new product feature is generating.\\n\\n\\nImage by author\\nIf you want to establish yourself as a high performer and accelerate your career as a Data Scientist, it’s key to focus on impact.\\n\\nIn this post I’ll go over the following:\\nWhy prioritizing impact matters not just for managers, but also ICs\\nWhy focusing on impact is hard\\nHow to maximize your impact\\nHow to overcome common challenges in driving real impact\\nLet’s dive in.\\n\\nGet an email whenever Torsten Walbaum publishes.\\nGet an email whenever Torsten Walbaum publishes. By signing up, you will create a Medium account if you don't already…\\nmedium.com\\n\\nWhy should I focus on impact; isn’t that my manager’s job?\\nOf course you can leave it to your manager to worry about impact. But stepping up comes with some real benefits for your career:\\n\\nReduced frustration & burn-out: Putting a lot of work into a project and then feeling like it didn’t move the needle is one of the most frustrating feelings in any job.\\nPromotions: Promotions are heavily tied to impact. And if you want to become a manager, you’ll need to show that you understand what drives business outcomes and can allocate resources accordingly.\\nInternal opportunities: People around you notice if you are having an outsized impact, and you’ll increase your chances of receiving internal offers. My promotion to Director happened because the CMO noticed my work on the BizOps team and asked me to move into the Marketing org to build out a Strategy & Analytics team.\\nExternal opportunities: Prospective employers don’t focus on what responsibilities you had, but what your impact was. After all, they are trying to figure out how you can help their business.\\nWhy isn’t everyone doing this?\\nBecause it’s hard.\\n\\nWe are used to thinking about inputs and outputs rather than impact in our daily lives (“I went to the gym” or “I did three loads of laundry”) and we carry that mindset over to our jobs.\\n\\nMore importantly, it gives us a sense of control. It’s fully under your control to work hard on the project, and maybe to create the final deliverable, but you can’t guarantee that it will actually move the business forward.\\n\\nIt can also feel like we’re doing someone else’s job. You built the dashboard; now it’s the other team’s problem how they’re going use it and get value from it. You can definitely take this stance; but don’t you want to see your work move the needle?\\n\\nLastly, sometimes it’s unclear what impact even looks like for our role because we feel too disconnected from the business outcomes; I’ll get into this below.\\n\\nHow can I become more impact-focused?\\nStep 1: Understand what impact looks like for your role and measure your success accordingly\\nStop thinking about productivity metrics like “I launched 5 experiments” or “I built this model” and hold yourself accountable to driving impact.\\n\\nBut what does that look like for a Data Scientist? For other roles it’s easy; Account Executives have sales quotas and Growth Marketing Managers have lead generation targets.\\n\\nBut Data Science, at its core, is a function that supports other teams. As a result, there are two levels of impact:\\n\\n\\nImage by author\\nDid your work change anything for the better for your business partners? E.g.:\\n\\nDid your analysis change the roll-out strategy of the new product?\\nDid your model improve forecast accuracy?\\nDoes your dashboard save the team hours every week that they used to spend on manual data pulls?\\nDid your work help move the needle on downstream business metrics? E.g.:\\n\\nYou’re a Marketing Data Scientist? Assume you’re on the hook for hitting lead and opportunity targets, and improving Marketing efficiency\\nYou’re doing Analytics for the Customer Support org? Start obsessing about response times and satisfaction scores.\\nYou don’t have to be solely responsible for something in order to take (partial) credit for it. If you provided the analysis that resulted in a pricing change that saved the company millions, then you deserve part of the credit for that impact.\\n\\nYou might not feel the consequences of missing these downstream targets as immediately as your stakeholders, but since your long-term career trajectory is still tied to driving impact, it helps to adopt this outcome-focused mindset.\\n\\nOnce you start doing this, you’ll notice more inefficiencies you can help address, or new opportunities for growth.\\n\\nStep 2: Ensure your work solves a real business problem\\nYou’ll likely know this situation: Instead of approaching you with a problem, people ask you for a specific deliverable. An analysis, a model, a dashboard.\\n\\nIf you blindly execute what they ask, you might realize too late that it won’t lead to tangible business impact. Maybe the problem they are trying to solve is not that important in the grand scheme of things, or there is a better way to approach it.\\n\\nSo what can you do?\\nAct like an owner. Understand the actual problem behind the request, and ask yourself what business priority this supports.\\n\\nIf you are early in your career then your manager should ideally help with this. But don’t rely on this: Managers don’t always do a perfect job, and you’ll be the one to feel the consequences of badly scoped work.\\n\\nThis requires you to understand company level priorities and the priorities of other orgs and teams. Take notes during All Hands meetings etc. to understand the big picture, and get your hands on other team’s planning materials to get an idea of what they’re trying to accomplish in the next 1–2 quarters.\\n\\nStep 3: Ensure there is buy-in for your work\\nEven if your work directly supports company-level priorities, you’ll be in for a bad time if key stakeholders are not bought in.\\n\\nYou don’t want to be in a situation where you finish the work and then realize that another team is blocking the implementation because they have concerns you didn’t address. To avoid this, you’ll:\\n\\nNeed to understand whose support you need, and\\nGet them onboard from the get-go\\nThis is a complex topic in itself; I’ll write a separate deep dive on how to drive alignment and get buy-in from other teams in the near future.\\n\\nStep 4: Focus your time on the highest-impact thing\\nNo matter what role you’re in, you’re likely juggling multiple priorities. To maximize your impact, you need to ensure you spend the majority of your time on the most important thing.\\n\\nAs with many things, this is easier said than done though, so let’s talk about what that looks like concretely.\\n\\nAd-hoc requests vs. strategic work\\nIt’s easy to get caught up in the craziness of daily business only to realize you didn’t make any progress on the big, strategic project you actually care about.\\n\\nThis is all too common; none of us get to sit in our ivory tower and chip away at our projects undisturbed. Plus, ad-hoc work is impactful, too; while it’s less exciting than strategic projects, it’s what keeps the business running.\\n\\nStill, if you find yourself spending the majority of your time fielding these ad-hoc issues, it’s time to talk to your manager. I’m sure your manager would rather help protect your bandwidth than have you 1) miss your deadlines on your key projects and 2) quit eventually from frustration.\\n\\n\\nImage by author\\nDon’t cry over spilled milk\\nAnother common challenge comes from the sunk cost fallacy. You invested a lot of time into a project, but it doesn’t seem to be going anywhere. Maybe you realized the premise didn’t make as much sense as you thought, or the priorities of the business have changed since you started the work.\\n\\nInstead of talking to your manager and stakeholders about changing the scope of the project or abandoning it altogether, you’re doubling down to get it over the finish line. After all, you don’t want all of your effort to go to waste. Sound familiar?\\n\\nEconomists (and Poker players) figured out a long time ago that this is a dangerous trap. When prioritizing your time, ignore how much effort your already put in and focus on where the next hour of work will yield the most impact.\\n\\nThings to watch out for (“impact killers”)\\nHow do you minimize the odds of wasting time on a project that won’t lead to impact? There are a few warning signs:\\n\\n“Academic” projects: Any time a project is pitched to you along the lines of “This would be interesting to understand” you should be careful; projects that purely improve the understanding of an issue without tying it back to the business are a waste of time and source of frustration in my experience\\nOverly ambitious project scope: At Uber, everyone always wanted to understand what the “best” driver incentive type is. Many people worked on this over the years, but it never led anywhere. There was no simple “one-size-fits-all” answer to this question, and the projects that led to actual impact were much more concrete, tactical optimizations\\nThe customer or deliverable are not defined: If it’s not clear who the end user of your work is (are you doing this for your manager, leadership, or another team?), or you’re unsure what exactly you’re supposed to deliver, it should raise a red flag. This is typically a sign that the project needs more scoping work before someone should start running with it\\nCommon Challenges and How to Address Them\\nWe talked about general frameworks to maximize impact. But how do you make actual, specific projects more impactful?\\n\\nMany times, projects fail close to the finish line. Impact doesn’t materialize automatically, so you need to put in the final bit of work to ensure your work gets adopted. Doing this has an extremely high return on the time you invest since you already did the hard work to produce the deliverable and “only” need to close the loop with stakeholders.\\n\\n\\nImage by author\\nTo make things more tangible, I am going to go through a few types of common deliverables, touch on where they typically fail to create impact and propose what you can do about it:\\n\\n1. You create a comprehensive analysis but nobody is acting on it\\nProblem: This is common with analyses that don’t have a clear recommendation. If you simply outline the data and potential paths forward, you are expecting your audience to do all of the heavy lifting.\\n\\nSolution: Your work starts adding real value for them once you take that work off their plate. Always give a clear recommendation; you can caveat it and show alternatives in the appendix, but you need to take a stance.\\n\\n2. You ran an experiment but nobody is using the results\\nProblem: Many experiments conclude with a metrics read-out by Data Science. More often than not, this is a “metrics dump” with a lot of information, but little interpretation or context.\\n\\nSolution: Help your business partners interpret the results, and tell them how it affects what they care about.\\n\\nHow should they think about the statistical significance or lack thereof?\\nIs the observed lift good compared to other changes you tested and shipped?\\nWhat is your recommendation for next steps? What does the experiment result mean for this person or team specifically?\\nRemember, you are the subject matter expert and shouldn’t expect non-analytical audiences to interpret raw experiment data. Telling your stakeholders what the result means for them will increase chances they will act on it.\\n\\n3. You built a predictive model, but the team you built it for is not using it\\nProblem: When predictive models don’t get used, it’s often because of a lack of trust in the model output.\\n\\nML models themselves tend to be black boxes, and if teams don’t understand how the outputs were generated and whether they are reliable, they are hesitant to rely on them. Even if your model is not using ML and lives in a spreadsheet: If people don’t know how it works, they’ll be suspicious.\\n\\nSolution: It’s all about involving stakeholders in the process and building trust.\\n\\nInvolve stakeholders in the model development from the get-go to get them comfortable and address any concerns early on\\nDemystify the output; for example, you can extract the top model features and explain them\\nSanity-check predictions and compare them to intuition. For example, if you forecast sales but your model predicts a different seasonality pattern from previous years, you’ll need to be able to explain why, or you’ll lose trust. In my experience, this is more impactful than just sharing performance metrics like the accuracy of the model\\nHaving a structured playbook for how to do this will make your life easier, so I’ll cover this in a separate post in the near future.\\n\\n4. You created a dashboard but nobody is looking at it\\nProblem: If a dashboard doesn’t get used, it’s likely one of these things is true:\\n\\nThe dashboard doesn’t directly address an urgent business use case\\nYou didn’t involve your stakeholders along the way (e.g. by sharing mock-ups and drafts for feedback) and the final product is not what they were hoping for\\nThe dashboard is complex and your users don’t understand how to get what they need\\nSolution: To address #1 and #2, start with user research to understand pain points and potential use cases of the dashboard, and involve your stakeholders during development.\\n\\nWith regards to #3, a simpler dashboard that users are comfortable with beats a more advanced one that doesn’t get used. If you cannot (or don’t want to) simplify the dash further, you’ll need to train your users on the functionality and shadow them to understand any points of friction.\\n\\nA dashboard is not done when you ship it for the first time, but needs to be improved over time based on users’ needs and feedback.\\n\\nClosing Thoughts\\nFocusing on impact is scary since we leave the world of controllable inputs behind, but it’s what ultimately gets you promotions and new job opportunities.\\n\\nAnd isn’t it nice when your work actually feels like it moves the needle?\\n\\nFor more hands-on analytics advice, consider following me here on Medium, on LinkedIn or on Substack.\", metadata={'id': 16, 'relevance_score': 0.9981407}),\n",
       "  Document(page_content='Space Babies\\n\\nOriginal Airdate: 11 May 2024\\n\\n[Tardis]\\n(Ruby has walked into the unlocked Tardis at the end of The Church on Ruby Road.)\\nRUBY: Who are you?\\nDOCTOR: I\\'m the Doctor. You don\\'t have to stand over there. Come and have a look. It\\'s called the Tardis.\\n(Snaps his fingers and the lighting changes.)\\nRUBY: Ooo! Nice! But hold on. I can\\'t call you Doctor. No, I want to know your name.\\nDOCTOR: Yeah, that\\'s er... that\\'s tricky, because I was adopted, and the planet that took me in, they were kind of... they were kind of posh. They\\'d use titles like the Doctor, or the Bishop, or the Rani, or the Conquistador. Say Doctor for a thousand years and it becomes my name.\\nRUBY: Okay. The planet. Parking that. Thousand years, double parked. So you\\'re a doctor, but you\\'re... the police?\\nDOCTOR: Police box. No. No, no, no, no, that\\'s a disguise.\\nRUBY: Oh.\\nDOCTOR: Inside, it\\'s a Time and Space machine, but outside, it\\'s like a chameleon, \\'cos once I landed in 1963 and they used to have police boxes on street corners.\\nRUBY: 1963?\\nDOCTOR: Yep.\\nRUBY: Okay. Ooo, jukebox. I like that.\\nDOCTOR: Mmm.\\nRUBY: Okay, so, back to the planet.\\nDOCTOR: My world was called Gallifrey.\\nRUBY: Gallifrey? And where\\'s that?\\nDOCTOR: Gone! Ruby, it\\'s gone. It\\'s gone. They died. There was a genocide, and they died. So the one that was adopted was the only one left. I am the last of the Time Lords. And I am so, so glad to be alive. This thing flies. Do you want to see?\\n(The gravity goes off, the Tardis dematerialises, gravity back on. Never done that before.)\\nDOCTOR: Let\\'s have a random landing.\\nRUBY: Whoa!\\nDOCTOR: Hoo-hoo! Ooo... 150 million years in the past.\\nRUBY: No!\\nDOCTOR: Really.\\nRUBY: No, you\\'ve got to be k... You are kidding. Don\\'t be so ridiculous. Are there dinosaurs out there?\\nDOCTOR: I don\\'t know. Go and have a look.\\nRUBY: Wait! No. Is it safe? What if I change history by stepping on a butterfly or summat?\\nDOCTOR: Well, that\\'s not going to happen, is it? Who steps on butterflies? You\\'d literally have to be like, \"Wait. Come \\'ere, butterfly! \"Come \\'ere, \\'ave it!\"\\n\\n[Prehistoric Earth]\\n\\nRUBY: Oh, my God. That... that\\'s so beautiful.\\nDOCTOR: And Tardis stands for Time And Relative Dimension In Space, huh? So we\\'ve moved location as well. This will be North America. One day, this is Wyoming. A little town called Green River.\\n(A boot steps on a butterfly.)\\nDOCTOR: Oh!\\n(Ruby is no longer a human.)\\nRUBATHON: What\\'s wrong? Did I do something wrong? Because I am Rubathon Blue of the 57th Hemisphere Hatchlings, and I do not do wrong things, Dok-tah.\\nDOCTOR: But...\\nRUBATHON: If you have made an incorrect accusation, I will have to kill you.\\nDOCTOR: No, no, no. Just wait, wait a minute. Just...\\nRUBATHON: What are you doing?\\nDOCTOR: Nothing, just...\\n(He scoops up the butterfly, breathes on it, and it flies off. The human is back.)\\nRUBY: Am I missing summat?\\nDOCTOR: Nothing. Let\\'s try that again, okay?\\nRUBY: Thank you.\\nDOCTOR: Yeah. Yeah, yeah, yeah.\\n\\n[Tardis]\\n\\nDOCTOR: Okay. Controls are new. Completely forgot... the butterfly compensation switch. Good. Right. Yes. Let\\'s go forward. Give me a number. Give me a year.\\nRUBY: Er, two.\\nDOCTOR: Two.\\nRUBY: One.\\nDOCTOR: One.\\nRUBY: Five.\\nDOCTOR: Five.\\nRUBY: Oh.\\nDOCTOR: Oh.\\nRUBY: Ah, six!\\nDOCTOR: Six! Ah! Five numbers! I like it!\\n(The Tardis travels the Vortex.)\\n\\n[Space station]\\n\\nRUBY: But we\\'re indoors. We got through walls. Ah-ha. Is that like a matter transporter, like in Star Trek?\\nDOCTOR: We\\'ve got to visit them one day.\\nRUBY: Hey, but you said the Tardis was like a chameleon, but it still looks like a police box.\\nDOCTOR: Oh, it\\'s, er... it\\'s broken. Most of the universe is knackered, babes. Okay. Come, come, come, come.\\nRUBY: Oh, it stinks\\nDOCTOR: Something is wrong with this place. It is a space station reaching overload. Whoa! Whoa!\\nRUBY: No, you\\'ve made it worse.\\n(Something snarls nearby. They both jump.)\\nDOCTOR: No, that is worse.\\nRUBY: Is that a monster?\\nDOCTOR: No. No, don\\'t be silly, Ruby. There\\'s no such thing as monsters, there\\'s just... just creatures you haven\\'t met yet. Hi there.\\n(The creature roars.)\\nRUBY: Run?\\nDOCTOR: Run! Run! Run!\\n(They and the monster are visible on monitors as they run down passages.)\\nDOCTOR: Come on! In here, in here, in here, in here.\\nRUBY: But...now we\\'re trapped! Now we\\'re trapped! Push the button! Doctor!\\nDOCTOR: Okay.\\n(The tiny one-person lift takes them up. The Doctor\\'s hand is over Ruby\\'s eyes.)\\nDOCTOR: Oh, yeah, yeah.\\n(The lift abruptly arrives.)\\n\\n[Birth Zone 6]\\n\\nDOCTOR: The question is, why did I run?\\nRUBY: \\'Cos it was scary.\\nDOCTOR: It was new. I love meeting new things, so why did it give me the shivers? I couldn\\'t run fast enough. I was like whoosh!\\nRUBY: Well, it\\'d help if we knew where we were.\\nDOCTOR: Yet again, push the button.\\n(The lights come on so they can see all the glassware, containing...)\\nDOCTOR: Oh. Oh, we\\'re on a baby farm. Ha-ha! A parthenogenesis machine. What is it with you and babies?\\nRUBY: I was going to say the same thing to you.\\nDOCTOR: We\\'ve gone from baby to baby. I\\'m not saying things are connected, and yet... things connect.\\nRUBY: Well, I\\'m the one looking for my parents, and you\\'ve got a Time and Space machine. So this place grows babies. What for? Food?\\nDOCTOR: Food? What? What?! Food? They\\'re not tomatoes!\\nRUBY: Well, excuse me. There\\'s a big hungry thing downstairs.\\nDOCTOR: Baby farms boost the population. Sometimes a world goes sterile or... I don\\'t know, goes mad and bans kissing.\\nRUBY: So these babies are human, yeah?\\nDOCTOR: Yep, grown for a colony world.\\nRUBY: And a colony world is not Earth?\\nDOCTOR: Hey. Okay, one last time, push the button.\\n(And a shield retracts to reveal that they are in orbit.)\\nRUBY: We made it. The human race, we survived. We went to the stars. And ten minutes ago, Doctor, just ten minutes ago, you said genocide. Your people are gone.\\nDOCTOR: Yeah.\\nRUBY: How do you keep going?\\nDOCTOR: For days like this, Ruby Sunday. I don\\'t have a people. I don\\'t have a home. But I don\\'t have a job, either. I don\\'t have a boss, or taxes or rent or bills to pay. I don\\'t have a purpose or a cause, or a mission, but I have... ..freedom. And so I keep moving on, to see the next thing, and the next, and the next. And sometimes... it looks even better through your eyes.\\nRUBY: So where\\'s this, then?\\nDOCTOR: Oh, er...\\n(Calls it up on a screen.)\\nDOCTOR: Huh. Planet Pacifico del Rio.\\nRUBY: Oh, that\\'s in English. They speak English here? English exists?\\nDOCTOR: Er, no. No, no, no. Humans all speak one language by this point. A bit like Cantonese. This is what it really looks like, but the Tardis translates. It\\'s got a perception filter, so it helps you fit into every time and place.\\nRUBY: Right, and my mum, she\\'s long gone now.\\nDOCTOR: Can I see your phone?\\nRUBY: Yes.\\nDOCTOR: So, my sonic screwdriver can make the distance between you and Earth 19,000 years or... one phone call.\\nRUBY: What?\\nDOCTOR: Carla. Phone her.\\nRUBY: But...\\nDOCTOR: Your mum, Ruby. Call your mum.\\n\\n[Ruby\\'s home / Birth Zone 6]\\n\\nCARLA: Well? What is it now?\\nRUBY: Mum?\\nCARLA: Yes, Mum, obviously. You\\'ve just ran out the door ten seconds ago. Why are you phoning me? You went like the wind. Where are you going?\\nRUBY: Yeah. Yes, I will... I\\'ll, er... I\\'ll catch up with you in a minute. Bye. Love you. Love you. Merry Christmas!\\n\\n[Birth Zone 6]\\n\\nRUBY: That was my mum, on Christmas Eve. On my birthday, ten minutes ago. That\\'s the best signal ever. How much does that cost?\\nDOCTOR: I want to know what the hell is wrong with this place. Do you see? It\\'s calm up here, but underneath it is seething, just like downstairs with that creature. There\\'s got to be a crew or a captain...\\n(Enter a child in a motorised push-chair.)\\nERIC: This is Eric, reporting from Birth Zone 6. I keep getting these temperature fluctuations. I\\'ve opened up safety valves 10 to 16. Tried cross-matching with the CO2 exchange, but until we get that pressure down, I can\\'t...\\nDOCTOR: Hi.\\nRUBY: You all right?\\nERIC: But... you. Oh. We\\'ve been waiting for an awfully long time. Mummy! Daddy!\\nDOCTOR: Oh, no.\\nRUBY: No, no. No, darling, we\\'re not...\\nERIC: Boys-oh-boys, I\\'ve got to tell everybody Mummy and Daddy are here.\\n(Leaves the room.)\\nRUBY: A baby farm. Run by babies.\\nDOCTOR: Ha-ha! Space babies!\\n(They follow Eric along a corridor with crayon drawings on the lower part of the wall.)\\n\\n[Control room]\\n\\nERIC: They\\'re here. They came at last. Mummy and Daddy are here.\\n(All the crew are in electric pushchairs.)\\nBABIES: Mummy and Daddy! They came back!\\nDOCTOR: Hello, space babies.\\nBABIES: Hello, Daddy. Hi, Daddy. Hello, Daddy!\\nDOCTOR: Oh.\\nPOPPY: Everyone, back to work. Show Mummy and Daddy what a good job we\\'ve been doing. Make them proud.\\n(The controls are jury-rigged with string and wooden pointers so the babies can activate them.)\\nMARCEL?: My job is to keep the pipes clean. I\\'m proud of the pipes.\\nADJANI?: And I keep the oxygen nice and cool. We need oxygen to breathe.\\nSANDRA?: And I pull this string and that string. I\\'m not sure what they do, but I pull them very hard.\\nERIC: And I made this for you. It\\'s a little flower.\\nRUBY: Thank you.\\nPOPPY: I\\'m Captain Poppy and I kept the station running for Mummy and Daddy, because we knew you\\'d come back for us one day. We waited.\\nDOCTOR: Right. You\\'re not supposed to be running this place. This isn\\'t Baby World. You got left behind when the adults... ..vamoosed?\\nPOPPY: We took over. We were very brave.\\nRUBY: Right. That\\'s great. That\\'s, oh, that\\'s good. That\\'s amazing. You\\'ve done a really great job.\\nDOCTOR: I\\'m sorry, Poppy, I\\'m so sorry, but we are not your mummy and daddy. I wish we were, but we\\'re not.\\nERIC: They left us. Where did they go?\\nRUBY: I don\\'t know, darling, but... I\\'m Ruby and this... this is the Doctor. And we\\'re your friends. Yeah, got you. I\\'ve got you, I\\'ve got you, I\\'ve got you, I\\'ve got you.\\n(She picks up Eric from his pushchair.)\\nBABIES: And me! And me! And me! And me!\\nDOCTOR: Oh, gosh.\\nBABIES: And me! And me!\\nDOCTOR: Captain Poppy, when was the last time that you had a hug?\\nPOPPY: Never.\\nDOCTOR: Oh. Oh, baby, it\\'s okay. Come here, it\\'s okay. It\\'s okay, it\\'s okay. Shh-shh-shh. Aww, never had a hug.\\nRUBY: Come on, you can all have a hug.\\n(Later, with everyone back in their pushchairs.)\\nPOPPY: Did I get things wrong, Doctor\\nDOCTOR: Well, according to this, the crew went home. They abandoned ship and they left you guys behind. I don\\'t know why, but they left the birth machine running, so you lot grew up, but you stayed the same size. Baby size. Space babies.\\nPOPPY: But are we wrong?\\nDOCTOR: What do you mean?\\nPOPPY: We\\'re not meant to be like this. Did we grow up wrong?\\nDOCTOR: Oh, Poppy. Oh, Popsicle. Look at me. Look at me. Nobody grows up wrong. You are what you are, and that is magnificent.\\nPOPPY: But Mummy and Daddy left us.\\nDOCTOR: That\\'s okay. Mine did, too.\\nPOPPY: What happened?\\nDOCTOR: Well, I was found.\\nPOPPY: Hooray!\\nDOCTOR: Yeah. Little baby me was left alone in the middle of outer space, and guess who took me in.\\nPOPPY: I don\\'t know.\\nDOCTOR: The Time Lords.\\nPOPPY: Ooo.\\nDOCTOR: Can you say it like me?\\nPOPPY: The Time Lords.\\nDOCTOR: That\\'s it, P-P-P-P-Pop. But the point is, is that it doesn\\'t matter where I come from, because I am absolutely lovely, aren\\'t I?\\n(Poppy yawns.)\\nDOCTOR: That wasn\\'t rhetorical, Pops.\\nPOPPY: Yes, you are.\\nDOCTOR: And do you want to know my secret? There\\'s no one like me in the whole wide universe. No one like me exists, and that\\'s true of everyone.\\nIt\\'s not a problem, Captain Pops. It\\'s a superpower. High five. Yeah.\\nPOPPY: Yeah!\\n(Ruby is dandling Eric, with the other babies in a semi-circle.)\\nRUBY: So you\\'re Eric. And you\\'re Tasha. And Ruben. And then there\\'s Saltine and Boo.\\nERIC: I love you, Ruby.\\nRUBY: Aw, I love you too, Eric. But how do you manage all on your own?\\nERIC: We\\'ve got Nanny. Say hello, Nanny.\\nNAN-E: Good afternoon, children, and welcome to our new visitors.\\nDOCTOR: Oh. Nanomatrix Electroform. Nan-E. Right. Hi, Nan-E. I\\'m the Doctor, and this is Ruby.\\nNAN-E: We have visitors, children.\\nERIC: Nanny!\\nNAN-E: Noses must be blown. Activate nose-blow.\\nDOCTOR: Er...\\nNAN-E: One, two, three and... blow.\\n(Mechanical hands on the pushchairs put handkerchiefs to the babies\\' noses. They blow into them, then the dirty handkies are dropped into a disposal tube.)\\nNAN-E: Well done, children And now, children, back to work. Nappies are changed at 1800 hours.\\nRUBY: Oh, can\\'t wait to see that.\\nDOCTOR: Right. So it\\'s you lot? It\\'s Nan-E And downstairs, is that your pet dog?\\n(Everyone screams and cries.)\\nERIC: That\\'s not a doggo.\\nRUBY: What is it then, Eric?\\nERIC: The Bogeyman.\\nRUBY: Shush, shush, shush. Shush, shush, shush.\\nDOCTOR: No. Gosh.\\nERIC: We don\\'t like the Bogeyman.\\nRUBY: No, no, no. Shush, shush. I did not mean to scare you. There is no such thing as the Bogeyman. That thing was more sort of like a er...\\nDOCTOR: Bogeyman!\\nRUBY: No, stop it! No, stop it! Nan-E, tell them there\\'s no such thing as the Bogeyman.\\nNAN-E: Nan-E is scared of the Bogeyman.\\nDOCTOR: Then what is the Bogeyman doing down there, and why... why is it so scary?\\n(Puts it on monitor. The babies wail.)\\nRUBY: Doctor, turn it off.\\nDOCTOR: Okay.\\nRUBY: No, listen to me. Listen to me.\\nDOCTOR: I\\'m sorry, I\\'m sorry. I\\'m sorry, babies. Space babies. I\\'m sorry.\\nPOPPY: Oh, Ruby...\\n(The Doctor finds a headset and puts it on, then works a computer.)\\nDOCTOR: Right. Nan-E. These babies are trying their best - space babies - but this station is in trouble. You have got a build-up of pressure in Hull 3-B. Something is ramping up down where the Bogeyman lives. And if that continues... baby boom.\\nNAN-E: Portal 3-5-7.\\nDOCTOR: Okay, what\\'s that?\\nNAN-E: Access Portal 3-5-7.\\nDOCTOR: That\\'s on this floor. What is it?\\nNAN-E: Access Portal 3-5-7.\\nDOCTOR: Yeah, it is just a storage unit. What would I need to go there for?\\nNAN-E: Oh, for God\\'s sakes, 3-5-7. Come on!\\nRUBY: Where do you think you\\'re going?\\nDOCTOR: Portal 3-5-7!\\nRUBY: Right. Great. Ok. Coming!\\n\\n[Corridor]\\n\\nRUBY: So, is this what you do, Doctor? I mean, in life? You help? That\\'s like your... purpose?\\nDOCTOR: No, no, I\\'m just, er... helping babies - space babies. Ha! Listening to my hearts. Two hearts. Plural.\\nRUBY: Okay. Two hearts. But what if helping the babies takes six weeks? Or ten years? Because my mum\\'s still waiting for me.\\nDOCTOR: Back home, on your birthday. Yeah, it\\'s strange, your life. You were abandoned, like this lot. If things connect, then you are connecting like crazy. You don\\'t know anything about your birth mother or your father? They didn\\'t leave a note or a scrap of paper...?\\nRUBY: Nothing. I was... I was just left.\\nDOCTOR: By the church.\\nRUBY: In the snow.\\nDOCTOR: On Ruby Road.\\n(The Doctor sees a figure point at him by the church.)\\nRUBY: Doctor...\\nDOCTOR: What?\\nRUBY: It\\'s snowing. Okay, what just happened? I said snow, and we\\'ve got... ..snowflakes.\\nDOCTOR: It\\'s like a memory just came through, from the day that you were born.\\nRUBY: But how? Is this the sort of thing that happens with time travel?\\nDOCTOR: I have been to the ends of time and back, and I have never seen anything like this before.\\nRUBY: Then what does it mean?\\nDOCTOR: I don\\'t know.\\n(The snow has stopped.)\\nDOCTOR: Oh, I thought my birth was crazy...\\nRUBY: Oh, yeah.\\nDOCTOR: Oh... I wonder who she is. Your mother. The memory changed. She was pointing at me.\\n(A door opens.)\\nJOCELYN: I said Portal 3-5-7. Don\\'t just stand there yapping, you pair of idiots. Get inside!\\nRUBY: Who\\'s she?\\nDOCTOR: Nan-E. Ha!\\nRUBY: Oh.\\n\\n[Portal 357]\\n\\nRICO [on screen]: This is Captain Rico Trieste, signing off duty from Babystation Beta, Pacifico date 56-56-22. For the record, I\\'m signing off under protest and wish to condemn this course of action.\\nLUCIA [on screen]: Chief Engineer Lucia Colasanto signing off, 56-56-22. And I\\'d like to say for the record, the company\\'s actions are appalling. I will be launching an appeal against this as soon as we\\'re home.\\n(Jocelyn fixes a gas leak with a blow from a wrench.)\\nGINA [on screen]: This is Comms Officer Gina Scalzi signing off, 56-56-22.\\n(Played by Susan Twist. She keeps turning up, does this woman.)\\nDOCTOR: So the crew went home, and left the babies behind? Space babies.\\nJOCELYN: It\\'s the recession. The government closed the Babystation to save money, but the law says it\\'s illegal to stop the birth machine.\\n(Another leak, another thump with the wrench.)\\nJOCELYN: But how did you arrive? Have you got a way out of here?\\nDOCTOR: I\\'ve got a ship, yeah, it\\'s er... What is your name - sorry, Nan-E?\\nJOCELYN: Jocelyn, Jocelyn Sancerre. I was the on-site accountant. I don\\'t know how this place works.\\n(The Doctor plugs his sonic into the computer.)\\nDOCTOR: Jocelyn, hold on, hold on, hold on. This... this can help. If you leave this to sync up, that should recalibrate the whole shebang.\\nJOCELYN: Thank you. Wanna swap?\\nRUBY: Hang on. So the planet down below refused to stop the babies being born... but once they\\'re born, they don\\'t look after them?\\nJOCELYN: It\\'s a very strange planet.\\nRUBY: It\\'s not that strange.\\nDOCTOR: But you stayed behind.\\nJOCELYN: I couldn\\'t leave them. And I tried with this place. But I\\'m not an engineer. The machine went out of sync, I patched it back, but then the education software ran out of control. It\\'s a mess. And I\\'ve been all on my own, watching the kids, for six years.\\nDOCTOR: But I don\\'t understand. They are gorgeous. Why would you hide?\\nJOCELYN: Cos I don\\'t want to see them die. And I don\\'t want them to see me die. \\'Cos that\\'s how bad it is. This is a closed station. There\\'s only so much air. There\\'s only so much food. The last thing I\\'ll do is give them the air out of Portal 3-5-7. But then... ..then you came along.\\nRUBY: Can\\'t you fly somewhere else?\\nJOCELYN: What do you mean, fly?\\nDOCTOR: Er, space station. Stationary, no engines. This great big thing can\\'t move. It\\'s just stuck in orbit, which is a shame, because this is a nice little system.\\nJOCELYN: The fifth planet out, Mondo Caroon, that\\'s a DuBarryDuPlessy world.\\nDOCTOR: Oh, that\\'s good. DuBarryDuPlessy is a starwide organisation. It means they can take in lots of refugees.\\nRUBY: Oh. Well, can\\'t we call them for help?\\nJOCELYN: They don\\'t go and fetch refugees. That\\'s the fate of every refugee in the universe. You physically have to turn up on someone else\\'s shore. And we can\\'t move.\\nDOCTOR: But now you have a ship. Plenty of room. It\\'s called the Tardis. The trouble is, between us and the ship is the Bogeyman.\\nJOCELYN: What is that thing?\\nBOTH: You don\\'t know?\\nJOCELYN: It\\'s nothing to do with me. It\\'s not part of the manifest. It\\'s not like anything I\\'ve ever seen.\\nDOCTOR: No, nor me. But it reminds me of something. What is it? And what is its skin made of? And why... was I so scared?\\nJOCELYN: Because it\\'s terrifying.\\nDOCTOR: Yeah, but I\\'ve met a million ugly bugs. I\\'m an ugly bug. That thing made me run, and I just wonder why.\\nRUBY: Okay. Thing is, this place is completely mad, but it sort of makes sense. Because you\\'ve got babies, you\\'ve got a nanny, and you\\'ve got the Bogeyman. You\\'ve literally got a monster living down below. It\\'s a children\\'s story come to life.\\nDOCTOR: And every story has its hero.\\n(They spot someone on the screen.)\\nRUBY: That\\'s Eric. Is that Eric?\\nJOCELYN: Eric, get out of there.\\n\\n[Space station]\\n\\nNAN-E: Eric, please vacate this area.\\n\\n[Portal 357]\\n\\nDOCTOR: Oh, is that how it works?\\nJOCELYN: Nan-E filter. Eric, get out now.\\n\\n[Space station]\\n\\nNAN-E: Eric will leave immediately.\\nERIC: No, Nanny! I\\'m being brave.\\n\\n[Portal 357]\\n\\nJOCELYN: Eric, for God\\'s sake, run!\\n\\n[Space station]\\n\\nNAN-E: Eric, invoking the deity, accelerate perambulation.\\nERIC: I\\'m doing what Ruby said.\\n\\n[Portal 357]\\n\\nRUBY: What?\\n\\n[Space station]\\n\\nERIC: I love Ruby, and she said there\\'s no such thing as the Bogeyman. So I\\'m going to find the naughty doggo and tell him off.\\n(He meets the Bogeyman.)\\nERIC: But I\\'m so scared.\\n\\n[Portal 357]\\n\\nRUBY: Oh, my God, it\\'s my fault!\\n\\n[Birth Zone 6]\\n\\nRUBY: Eric, I\\'m coming! I\\'m coming! I\\'m coming! I\\'m coming! I\\'m coming! I\\'m coming!\\n\\n[Space station]\\n\\n(Ruby and the Doctor take the little lift down, and find Eric\\'s pushchair fallen over.)\\nRUBY: Oh.\\nDOCTOR: Nan-E, where\\'s the Bogeyman?\\n\\n[Portal 357]\\n\\nJOCELYN: It\\'s about 400 metres north-west of you. But still no sign of Eric. I can\\'t get a proper fix. I told you, these systems are a crock of...\\n\\n[Space station]\\n\\nNAN-E: ..waste products.\\nDOCTOR: Mind your language, Nan-E.\\nRUNY: Okay, Doctor, if we make a ton of noise, then the Bogeyman will come for us and leave Eric alone, yes?\\nDOCTOR: Yes.\\nRUBY: Okay, right.\\nDOCTOR: Yes. Yes, yes.\\n(They pick up things to hit the pipework with and move off.)\\nRUBY: Bogeyman! Bogeyman!\\nBOTH: Bogeyman! Bogeyman!\\n\\n[Portal 357]\\n\\nJOCELYN: It\\'s moving. It\\'s heard you.\\n\\n[Space station]\\n\\nRUBY: Okay, nice plan, but what now?\\nDOCTOR: I think... if I was very, very little and I knew the Bogeyman was coming... I would need to change my nappy. \\'Cos I can detect...\\n(In a locker.)\\nDOCTOR: Space baby! Oh, Eric.\\nRUBY: We\\'ve got you, we\\'ve got you.\\nDOCTOR: Oh, you poor thing. It\\'s okay.\\nRUBY: I know, I know. I know.\\n\\n[Portal 357]\\n\\nJOCELYN: Not west, I meant east.\\n\\n[Space station]\\n\\nDOCTOR: Go, go. It\\'s all right, it\\'s all right. It\\'s all right, it\\'s all right, it\\'s all right. All right, all right. It\\'s all right.\\nRUBY: It\\'s okay, it\\'s okay.\\nDOCTOR: All right.\\n(The Bogeyman moves off. They come out of hiding, and there it is. They run.)\\n\\n[Portal 357]\\n\\nJOCELYN: Don\\'t you touch them, you...\\n\\n[Space station]\\n\\nNAN-E: ..illegitimate person.\\nDOCTOR: Go! Go. It\\'s a dead end.\\n(The Bogeyman is there.)\\nDOCTOR: Whoa! It\\'s okay, it\\'s okay. You\\'re okay.\\n(The Bogeyman is attacked by flames. It runs away.)\\nPOPPY: Babies to the rescue!\\nDOCTOR: Ha! Space babies!\\nRUBY: Babies with a flame-thrower!\\nDOCTOR: Babies, babies, babies, you did brilliant! You did so great! Space babies, you need to go, okay? Get.. get out of here.\\n(He whistles up Eric\\'s pushchair.)\\nRUBY: Okay, let\\'s get you in here, come on. Let\\'s get you in there. Nan-E, tell them what to do.\\nNAN-E: Children will return to the upper levels or have no expletive dinner.\\nBABIES: Goodbye.\\nDOCTOR: Okay, er, you... you go with them. I\\'ve got to stay here. Not just for the Tardis, but I\\'ve got to find out what that thing is.\\nRUBY: If that\\'s you telling me to leave you on your own, then... Oh, Doctor. Well, come on.\\n(They head back through the stinky area.)\\nDOCTOR: Ooo! Whew! Whew! So how did this begin, Jocelyn?\\n\\n[Portal 357]\\n\\nJOCELYN: First I knew, six years ago, it was like a rattling in the pipes. Then the howling began. By the time I got the cameras working, there it was. The Bogeyman. I don\\'t know how it even exists.\\n\\n[Space station]\\n\\nRUBY: And that was six years ago?\\nDOCTOR: Shh-shh-shh.\\nRUBY: Oh. That\\'s the same time the babies were born.\\nDOCTOR: It\\'s leaving... some sort of spoor. Man, that\\'s a good word. Spoor.\\nNAN-E: What the bleep-bleep is that?\\nRUBY: Oh, Jocelyn, turn the filter off.\\n\\n[Portal 357]\\n\\nJOCELYN: What is that stuff?\\nDOCTOR (on screen): If I could get this to your machine, it could analyse it.\\nJOCELYN: The machine\\'s got a vent in the basement. Follow the corridor. Left, straight ahead, left again.\\n\\n[Space station]\\n\\nDOCTOR: Into the belly of the beast. Yeah, this stuff is slippy, Rubes. Be careful.\\n(She slips then gets dribbled on from a pipe outlet.)\\nRUBY: Oh. Ah. Oh, my God. Oh, this is disgusting. Don\\'t call me Rubes!\\nDOCTOR: Are we almost there, Joce? This gunk stuff is sealing the whole place off. Oh, but never mind, because... Ah! We are right under the parthenogenesis machine. Now, let\\'s make sense of this thing. Ah, according to the machine... Oh.\\nRUBY: What?\\nDOCTOR: It has been right in front of us. We\\'ve been saying it all along. It\\'s all one machine. One up above, and one down below. The one up above grew the babies. The one down below...\\nRUBY: It grew the Bogeyman.\\nDOCTOR: Yes!\\nRUBY: I said this. I told you so. Six years ago, the machine is mother and father to the babies, and mother and father to the Bogeyman.\\nDOCTOR: And why? Because Jocelyn said that the educational software ran out of control, and then you said...\\nRUBY: It\\'s like a story. The teaching software, it told a story.\\nDOCTOR: It invented the Bogeyman.\\nRUBY: For the babies.\\nDOCTOR: For the space babies.\\nRUBY: The machine is literal, like a computer. It literally said, \"Babies need fiction, they need stories, they need monsters.\"\\nDOCTOR: Yes. That is why I\\'m so scared. It\\'s all deliberate, it\\'s infrasound. The Bogeyman is roaring at 17 hertz, that\\'s the exact pitch designed to make you scared. It\\'s scary because it\\'s meant to be. The machine made it tall and big and noisy, and it built it out of... Oh.\\nRUBY: What.\\nDOCTOR: Oh, Ruby.\\nRUBY: What?\\nDOCTOR: Oh, man.\\nRUBY: Tell me what it is.\\nDOCTOR: I can\\'t.\\nRUBY: Doctor!\\nDOCTOR: Ruby, I have travelled the universe and back and seen many, many things. Nothing... is as bad as this. A Bogeyman is made out of what?\\nRUBY: I don\\'t know.\\nDOCTOR: The machine is literal, and the name is Bogeyman.\\nRUBY: So?\\nDOCTOR: Oh, babes. Space babes. We saw it. The nose-blowing. The machine was literal, and so it grew the Bogeyman out of bogeys.\\nRUBY: What?\\nDOCTOR: All of this is bogeys.\\nRUBY: No.\\nDOCTOR: Yes.\\nRUBY: No.\\nDOCTOR: Yes.\\nRUBY: No.\\nDOCTOR: No wonder it was shedding its skin. Doesn\\'t everyone?\\nRUBY: No, no, no, no.\\nDOCTOR: It\\'s snot.\\nRUBY: It\\'s not.\\nDOCTOR: Oh, Ruby, it is a living sneeze!\\nRUBY: But it\\'s in my...\\nDOCTOR: I know.\\nRUBY: Oh, my God! This is the worst thing that has ever happened to anyone! Don\\'t laugh!\\nDOCTOR: Sorry. Oh, isn\\'t the universe mad?\\nRUBY: Oh yeah, it just made a monster out of snot.\\nDOCTOR: Oh, Ruby Sunday, Monday, Tuesday, that is... so funny.\\n(The monster is in front of them.)\\nRUBY: Bogeyman.\\nDOCTOR: Run. Run! Go!\\n(A barrier blocks their path.)\\nDOCTOR: No, no, no, no!\\n\\n[Portal 357]\\n\\nJOCELYN: Don\\'t worry, it\\'s me. Turn right. It\\'s your device. It\\'s calibrated. It\\'s brilliant! I\\'ve got control at last. Now trust me. Turn right!\\nDOCTOR [on screen]: This isn\\'t the way to the lift!\\nJOCELYN: Keep going.\\n(She unlocks doors remotely.)\\n\\n[Space station]\\n\\nRUBY: Ah!\\nDOCTOR: Go, go, go, go!\\nRUBY: I\\'m coming, I\\'m coming!\\n\\n[Portal 357]\\n\\nJOCELYN: It\\'s catching up!\\n\\n[Space station]\\n\\nRUBY: Coming!\\n(A door slides closed between them and the Bogeyman.)\\nDOCTOR: Whoa!\\nRUBY: Yeah, thanks for using us as bait. Just next time ask!\\n\\n[Portal 357]\\n\\nDOCTOR [on screen]: Oh, wait until we tell you what that thing is made of!\\nJOCELYN: You can tell me later. Once I\\'ve got rid of it. I will protect my children and blast that thing into space!\\n\\n[Airlock door]\\n\\nDOCTOR: It\\'s an airlock.\\n(The Bogeyman is hanging on for dear life.)\\nDOCTOR: It is one of the children, Jocelyn! I... She\\'s got the sonic. Jocelyn, Jocelyn!\\nCOMPUTER: Oxygen field at 10%.\\nDOCTOR: Okay, okay, okay, okay. We haven\\'t got time. Stop Jocelyn, yeah?\\nRUBY: Wait...\\nDOCTOR: Left, second right, next left, you\\'ll get to the lift.\\nRUBY: What about you?\\nDOCTOR: Left, second right, next left!\\nRUBY: Right, okay.\\n(She runs off.)\\n\\n[Control room]\\n\\nCOMPUTER: Oxygen field at 9%.\\nPOPPY: You\\'re hurting him.\\nERIC: Stop it, Nanny. Stop it!\\nCOMPUTER: Oxygen field at 8%.\\n\\n[Airlock door]\\n\\nDOCTOR [memory]: I am the last of the Time Lords.\\nRUBY [memory]: How do you keep going?\\nDOCTOR [memory]: For days like this. I\\'m the only one of me in the whole, wide universe. No one else like me exists, and that is true of everyone.\\nDOCTOR: The only one of its kind.\\nCOMPUTER: Oxygen field at 7%.\\n(The Doctor opens the airlock door and holds it open with his body.)\\nCOMPUTER: Oxygen field at 6%.\\n(Then he goes inside, hanging on, with the Bogeyman just beyond reach.)\\nCOMPUTER: Oxygen field at 5%. Oxygen field at 4%.\\n(Then he lets go, and lands on the hull between the open outer door and the big red button.)\\nCOMPUTER: Oxygen field at 3%.\\nDOCTOR: Push...the button.\\nCOMPUTER: Oxygen field at 2%. Venting reverse. Venting reverse.\\n\\n[Portal 357]\\n\\n(Ruby runs in and grabs the sonic.)\\nJOCELYN: No!\\nRUBY: That\\'s what you do, Jocelyn. You save them all.\\nCOMPUTER: Oxygen field at 1%.\\n(The outer airlock door is closed, the air stops rushing out. The Doctor and the Bogeyman drop to the floor.)\\nRUBY: You save them all. Come here. It\\'s okay, it\\'s okay.\\n(Jocelyn cries in Ruby\\'s arms.)\\n\\n[Control room]\\n\\nDOCTOR: Attention! Calling Captain Poppy. Calling all crew. Especially you, Eric. Plus Ruby and Jocelyn Sancerre.\\nERIC: Nanny was really naughty.\\nJOCELYN: I know, and I\\'m so sorry. All of you. I was just... on my own for such a very long time.\\nERIC: We still love you, Nanny.\\nBABIES: Yay! We do!\\nDOCTOR: But-but-but-but-but-but... your favourite monster is fine. Look. Look, look, look, look.\\nBABIES: Yay!\\n(On a monitor, the Bogeyman howls like a wolf, and the babies copy it.)\\nDOCTOR: But listen, listen, babies, space babies, your world is over here.\\nBABIES: Wow!\\nDOCTOR: The world of Mondo Caroon. But... but you can\\'t get there. Got no engines! Except, turns out, that build-up of pressure in Hull 3-B is from you.\\nBABIES: Huh?\\nDOCTOR: Huh? \\'Cos the system went wrong, and that\\'s where it stacked up all your nappies. No wonder it was stinking down there. For six years, a great big pile of sh...\\nJOCELYN: Nan-E filter.\\nDOCTOR: ..shizzle. A zillion metric tonnes of methane, babies. Space babies. But I am going to let it rip!\\n(The waste gets vented in a massive grey cloud, and the space station gets propelled out of orbit.)\\nDOCTOR: Oh, set sail for your new home. Baby World!\\nRUBY: Come here now. Are you happy now, Eric?\\nERIC: I\\'m very, very happy. I love you, Ruby.\\n\\n[Outside the Tardis]\\n\\nRUBY: So that was a normal day for you, then?\\nDOCTOR: No, no. That was extra-special nuts. And you, Ruby Sunday, get this. Your very own Tardis key.\\nRUBY: What for?\\nDOCTOR: I have the whole universe at my fingertips, and I\\'m all on my own. So I\\'d love it if you came with me.\\nRUBY: To what, just travel?\\nDOCTOR: No job. No boss. Just fun.\\nRUBY: We did almost die.\\nDOCTOR: Yes. But we lived so much, too.\\nRUBY: Yes, we did. Yes, we did. Yes, yes, we did. Yep, we did, we did. We did. Yes.\\nDOCTOR: Yes?\\nRUBY: Yes.\\nDOCTOR: Yes?\\nRUBY: Yes. Oh, my God.\\nDOCTOR: Yes? Yes! Yes! Yes! Ruby Sunday said yes!\\nRUBY: Come on in. Follow me.\\nDOCTOR: Oh, come on.\\n\\n[Tardis]\\n\\nRUBY: Right, mate, let me tell you where we\\'re gonna go.\\nDOCTOR: Except...\\nRUBY: Oh, terms and conditions.\\nDOCTOR: There is one thing that I can never do, Ruby. And that\\'s take you to that church on Ruby Road that Christmas. Absolutely never.\\nRUBY: But you\\'ve got a time machine.\\nDOCTOR: If you change one thing, a single snowflake, that could change your birth mother\\'s story and then you would never meet me, none of this would ever happen, and we would fall into the deepest, darkest paradox. Ruby, trust me. I think that snow was a warning. I can\\'t. And I won\\'t.\\nRUBY: Well, that\\'s a pity. \\'Cos I disagree. And if you let me finish... we are going to go see my mum. At Christmas. Right now. Come on.\\n\\n[Ruby\\'s home]\\n\\nCARLA: (on phone) And Ruby phoned, she said, \"I love you,\" and ran off! No word from her since. What sort of Christmas is this? It all started with this man. He called himself the Doctor. Hold on. What\\'s that noise?\\n(The Tardis materialises, making a hole in the kitchen ceiling. Not normal Tardis behaviour, that.)\\nCHERRY: What the blinking flip?\\n(Tardis door opens.)\\nRUBY: Hiya, Mummy.\\nCARLA: But... what are you doing? And what the hell is that? What\\'s it done to my kitchen?\\n\\n[Tardis]\\n\\nRUBY [OC]: Hey! Come and say hello!\\nDOCTOR: Yes. Coming. Tell your mum not to slap me.\\n(He sonicks up a quick DNA scan of Ruby Sunday.)\\nDOCTOR: Yes, now, the people from my world, they use titles like the Bishop, the Pedant, the Sagi-shi. My name was...\\n(He doesn\\'t wait for the results of the scan.)', metadata={'id': 1, 'relevance_score': 0.9976075})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "for i in range(0, len(df)):\n",
    "    print(i)\n",
    "    a = []\n",
    "    question = df.iloc[i, 1]\n",
    "    try:\n",
    "        response = chain.invoke(question)\n",
    "        result = response['result']\n",
    "        source_documents = response['source_documents']\n",
    "        answers.append(result)\n",
    "        string_check = \"\" \n",
    "        for doc in source_documents:\n",
    "            # print(doc[0].page_content)\n",
    "            if doc.page_content not in string_check:\n",
    "                string_check += doc.page_content\n",
    "                a.append(doc.page_content)\n",
    "        contexts.append(a)\n",
    "    except:\n",
    "        contexts.append(\"Error\")\n",
    "        answers.append(\"Error\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['---The Paths through the Underground/Underdark---(9 days of travel)\\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\\n\\nDay 1 goes without issue... sleep.\\n\\nDay 2 – Ropers\\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\\n---ENCOUNTER – Ropers x 2---\\nDay 3 goes without issue...sleep.\\n\\nDay 4 - Kobold Trap\\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\\n\\nThey are no more than 2-3 feet wide, and numerous (dozens).\\n\\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\\n\\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\\n\\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\\n\\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\\n“Loud food! Loud meal!”\\n\\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\\n\\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\\n\\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\\n\\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?',\n",
       "  'llmware\\n\\nBuilding Enterprise RAG Pipelines with Small, Specialized Models\\nllmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\\n\\nllmware has two main components:\\n\\nRAG Pipeline - integrated components for the full lifecycle of connecting knowledge sources to generative AI models; and\\n\\n50+ small, specialized models fine-tuned for key tasks in enterprise process automation, including fact-based question-answering, classification, summarization, and extraction.\\n\\nBy bringing together both of these components, along with integrating leading open source models and underlying technologies, llmware offers a comprehensive set of tools to rapidly build knowledge-based enterprise LLM applications.\\n\\nMost of our examples can be run without a GPU server - get started right away on your laptop.\\n\\nJoin us on Discord | Watch Youtube Tutorials | Explore our Model Families on Huggingface\\n\\nNew to RAG? Check out the Fast Start video series\\n\\nMulti-Model Agents with SLIM Models - Intro-Video\\n\\nIntro to SLIM Function Call Models\\nCan\\'t wait? Get SLIMs right away:\\n\\nfrom llmware.models import ModelCatalog\\n\\nModelCatalog().get_llm_toolkit()  # get all SLIM models, delivered as small, fast quantized tools\\nModelCatalog().tool_test_run(\"slim-sentiment-tool\") # see the model in action with test script included\\nKey features\\nWriting code withllmware is based on a few main concepts:\\n\\nModel Catalog: Access all models the same way with easy lookup, regardless of underlying implementation.\\nLibrary: ingest, organize and index a collection of knowledge at scale - Parse, Text Chunk and Embed.\\nQuery: query libraries with mix of text, semantic, hybrid, metadata, and custom filters.\\nPrompt with Sources: the easiest way to combine knowledge retrieval with a LLM inference.\\nRAG-Optimized Models - 1-7B parameter models designed for RAG workflow integration and running locally.\\nSimple-to-Scale Database Options - integrated data stores from laptop to parallelized cluster.\\nAgents with Function Calls and SLIM Models\\nStart coding - Quick Start for RAG\\nWhat\\'s New?\\n-Best New Small RAG Model - BLING finetune of Phi-3 - \"bling-phi-3-gguf\" - see the video\\n\\n-Web Services with Agent Calls for Financial Research - end-to-end scenario - video and example\\n\\n-Voice Transcription with WhisperCPP - getting_started, using_sample_files, and analysis_use_case with great_speeches_video\\n\\n-Phi-3 GGUF Streaming Local Chatbot with UI - setup your own Phi-3-gguf chatbot on your laptop in minutes - example with video\\n\\n-Small, specialized, function-calling Extract Model - introducing slim-extract - video and example\\n\\n-LLM to Answer Yes/No questions - introducing slim-boolean model - video and example\\n\\n-Natural Language Query to CSV End to End example - using slim-sql model - video and example and now using Custom Tables on Postgres example\\n\\n-Multi-Model Agents with SLIM models - multi-step Agents with SLIMs on CPU - video - example\\n\\n-OCR Embedded Document Images Example - systematically extract text from images embedded in documents example\\n\\n-Enhanced Parser Functions for PDF, Word, Powerpoint and Excel - new text-chunking controls and strategies, extract tables, images, header text - example\\n\\n-Agent Inference Server - set up multi-model Agents over Inference Server example\\n\\n-GGUF - Getting Started - check out examples - GGUF (example) and Videos video\\n\\n-Optimizing Accuracy of RAG Prompts - check out example and videos - part I and part II\\n\\nGetting Started\\nStep 1 - Install llmware - pip3 install llmware or pip3 install \\'llmware[full]\\'\\n\\nnote: starting with v0.3.0, we provide options for a core install (minimal set of dependencies) or full install (adds to the core with wider set of related python libraries).\\nStep 2- Go to Examples - Get Started Fast with 100+ \\'Cut-and-Paste\\' Recipes\\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\\n✍Working with the llmware Github repository\\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\\n\\ngit clone git@github.com:llmware-ai/llmware.git\\nWe have provided a welcome_to_llmware automation script in the root of the repository folder. After cloning:\\n\\nOn Windows command line: .\\\\welcome_to_llmware_windows.sh\\nOn Mac / Linux command line: sh ./welcome_to_llmware.sh\\nAlternatively, if you prefer to complete setup without the welcome automation script, then the next steps include:\\n\\ninstall requirements.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements.txt\\n\\ninstall requirements_extras.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements_extras.txt (Depending upon your use case, you may not need all or any of these installs, but some of these will be used in the examples.)\\n\\nrun examples - copy one or more of the example .py files into the root project path. (We have seen several IDEs that will attempt to run interactively from the nested /example path, and then not have access to the /llmware module - the easy fix is to just copy the example you want to run into the root path).\\n\\ninstall vector db - no-install vector db options include milvus lite, chromadb, faiss and lancedb - which do not require a server install, but do require that you install the python sdk library for that vector db, e.g., pip3 install pymilvus, or pip3 install chromadb. If you look in examples/Embedding, you will see examples for getting started with various vector DB, and in the root of the repo, you will see easy-to-get-started docker compose scripts for installing milvus, postgres/pgvector, mongo, qdrant, neo4j, and redis.\\n\\nNote: we have seen recently issues with Pytorch==2.3 on some platforms - if you run into any issues, we have seen that uninstalling Pytorch and downleveling to Pytorch==2.1 usually solves the problem.\\n\\nData Store Options\\nFast Start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required\\nSpeed + Scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose\\nPostgres: use Postgres for both text collection and vector DB - install with Docker Compose\\nMix-and-Match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)\\nMeet our Models\\nSLIM model series: small, specialized models fine-tuned for function calling and multi-step, multi-model Agent workflows.\\nDRAGON model series: Production-grade RAG-optimized 6-7B parameter models - \"Delivering RAG on ...\" the leading foundation base models.\\nBLING model series: Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models.\\nIndustry BERT models: out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC.\\nGGUF Quantization: we provide \\'gguf\\' and \\'tool\\' versions of many SLIM, DRAGON and BLING models, optimized for CPU deployment.\\nUsing LLMs and setting-up API keys & secrets\\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\\n\\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\\n\\nRoadmap - Where are we going ...\\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.\\n\\nQuestions and discussions are welcome in our github discussions.\\n\\nRelease notes and Change Log\\nSee also additional deployment/install release notes in wheel_archives\\n\\nThursday, June 6 - v0.3.1-WIP\\n\\nAdded module 3 to Fast Start example series examples 7-9 on Agents & Function Calls\\nAdded reranker Jina model for in-memory semantic similarity RAG - see example\\nChanges merged into main branch - expected next pypi release at end of week\\nTuesday, June 4 - v0.3.0\\n\\nAdded support for new Milvus Lite embedded \\'no-install\\' database - see example.\\nAdded two new SLIM models to catalog and agent processes - \\'q-gen\\' and \\'qa-gen\\'\\nUpdated model class instantiation to provide more extensibility to add new classes in different modules\\nNew welcome_to_llmware.sh and welcome_to_llmware_windows.sh fast install scripts\\nEnhanced Model class base with new configurable post_init and register methods\\nCreated InferenceHistory to track global state of all inferences completed\\nMultiple improvements and updates to logging at module level\\nNote: starting with v0.3.0, pip install provides two options - a base minimal install pip3 install llmware which will support most use cases, and a larger install pip3 install \\'llmware[full]\\' with other commonly-used libraries.\\nWednesday, May 22 - v0.2.15\\n\\nImprovements in Model class handling of Pytorch and Transformers dependencies (just-in-time loading, if needed)\\nExpanding API endpoint options and inference server functionality - see new client access options and server_launch\\nSaturday, May 18 - v0.2.14\\n\\nNew OCR image parsing methods with example\\nAdding first part of logging improvements (WIP) in Configs and Models.\\nNew embedding model added to catalog - industry-bert-loans.\\nUpdates to model import methods and configurations.\\nSunday, May 12 - v0.2.13\\n\\nNew GGUF streaming method with basic example and phi3 local chatbot\\nSignificant cleanups in ancillary imports and dependencies to reduce install complexity - note: the updated requirements.txt and setup.py files.\\nDefensive code to provide informative warning of any missing dependencies in specialized parts of the code, e.g., OCR, Web Parser.\\nUpdates of tests, notice and documentation.\\nOpenAIConfigs created to support Azure OpenAI.\\nSunday, May 5 - v0.2.12 Update\\n\\nLaunched \"bling-phi-3\" and \"bling-phi-3-gguf\" in ModelCatalog - newest and most accurate BLING/DRAGON model\\nNew long document summarization method using slim-summary-tool example\\nNew Office (Powerpoint, Word, Excel) sample files example\\nAdded support for Python 3.12\\nDeprecated faiss and replaced with \\'no-install\\' chromadb in Fast Start examples\\nRefactored Datasets, Graph and Web Services classes\\nUpdated Voice parsing with WhisperCPP into Library\\nMonday, April 29 - v0.2.11 Update\\n\\nUpdates to gguf libs for Phi-3 and Llama-3\\nAdded Phi-3 example and Llama-3 example and Quantized Versions to Model Catalog\\nIntegrated WhisperCPP Model class and prebuilt shared libraries - getting-started-example\\nNew voice sample files for testing - example\\nImproved CUDA detection on Windows and safety checks for older Mac OS versions\\nMonday, April 22 - v0.2.10 Update\\n\\nUpdates to Agent class to support Natural Language queries of Custom Tables on Postgres example\\nNew Agent API endpoint implemented with LLMWare Inference Server and new Agent capabilities example\\nTuesday, April 16 - v0.2.9 Update\\n\\nNew CustomTable class to rapidly create custom DB tables in conjunction with LLM-based workflows.\\nEnhanced methods for converting CSV and JSON/JSONL files into DB tables.\\nSee new examples Creating Custom Table example\\nTuesday, April 9 - v0.2.8 Update\\n\\nOffice Parser (Word Docx, Powerpoint PPTX, and Excel XLSX) - multiple improvements - new libs + Python method.\\nIncludes: several fixes, improved text chunking controls, header text extraction and configuration options.\\nGenerally, new office parser options conform with the new PDF parser options.\\nPlease see Office Parsing Configs example\\nWednesday, April 3 - v0.2.7 Update\\n\\nPDF Parser - multiple improvements - new libs + Python methods.\\nIncludes: UTF-8 encoding for European languages.\\nIncludes: Better text chunking controls, header text extraction and configuration options.\\nPlease see PDF Parsing Configs example for more details.\\nNote: deprecating support for aarch64-linux (will use 0.2.6 parsers). Full support going forward for Linux Ubuntu20+ on x86_64 + with CUDA.\\nFriday, March 22 - v0.2.6 Update\\n\\nNew SLIM models: summary, extract, xsum, boolean, tags-3b, and combo sentiment-ner.\\nNew logit and sampling analytics.\\nNew SLIM examples showing how to use the new models.\\nThursday, March 14 - v0.2.5 Update\\n\\nImproved support for GGUF on CUDA (Windows and Linux), with new prebuilt binaries and exception handling.\\nEnhanced model configuration options (sampling, temperature, top logit capture).\\nAdded full back-level support for Ubuntu 20+ with parsers and GGUF engine.\\nSupport for new Anthropic Claude 3 models.\\nNew retrieval methods: document_lookup and aggregate_text.\\nNew model: bling-stablelm-3b-tool - fast, accurate 3b quantized question-answering model - one of our new favorites.\\nWednesday, February 28 - v0.2.4 Update\\n\\nMajor upgrade of GGUF Generative Model class - support for Stable-LM-3B, CUDA build options, and better control over sampling strategies.\\nNote: new GGUF llama.cpp built libs packaged with build starting in v0.2.4.\\nImproved GPU support for HF Embedding Models.\\nFriday, February 16 - v0.2.3 Update\\n\\nAdded 10+ embedding models to ModelCatalog - nomic, jina, bge, gte, ember and uae-large.\\nUpdated OpenAI support >=1.0 and new text-3 embedding models.\\nSLIM model keys and output_values now accessible in ModelCatalog.\\nUpdating encodings to \\'utf-8-sig\\' to better handle txt/csv files with bom.\\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\\n\\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\\n\\nSupported Text Index Databases: MongoDB, Postgres, SQLite\\n\\nOptional\\nDocker\\n\\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.\\n\\nChange Log\\nLatest Updates - 19 Jan 2024 - llmware v0.2.0\\n\\nAdded new database integration options - Postgres and SQlite\\nImproved status update and parser event logging options for parallelized parsing\\nSignificant enhancements to interactions between Embedding + Text collection databases\\nImproved error exception handling in loading dynamic modules\\nLatest Updates - 15 Jan 2024: llmware v0.1.15\\n\\nEnhancements to dual pass retrieval queries\\nExpanded configuration objects and options for endpoint resources\\nLatest Updates - 30 Dec 2023: llmware v0.1.14\\n\\nAdded support for Open Chat inference servers (compatible with OpenAI API)\\nImproved capabilities for multiple embedding models and vector DB configurations\\nAdded docker-compose install scripts for PGVector and Redis vector databases\\nAdded \\'bling-tiny-llama\\' to model catalog\\nLatest Updates - 22 Dec 2023: llmware v0.1.13\\n\\nAdded 3 new vector databases - Postgres (PG Vector), Redis, and Qdrant\\n\\nImproved support for integrating sentence transformers directly in the model catalog\\n\\nImprovements in the model catalog attributes\\n\\nMultiple new Examples in Models & Embeddings, including GGUF, Vector database, and model catalog\\n\\n17 Dec 2023: llmware v0.1.12\\n\\ndragon-deci-7b added to catalog - RAG-finetuned model on high-performance new 7B model base from Deci\\nNew GGUFGenerativeModel class for easy integration of GGUF Models\\nAdding prebuilt llama_cpp / ctransformer shared libraries for Mac M1, Mac x86, Linux x86 and Windows\\n3 DRAGON models packaged as Q4_K_M GGUF models for CPU laptop use (dragon-mistral-7b, dragon-llama-7b, dragon-yi-6b)\\n4 leading open source chat models added to default catalog with Q4_K_M\\n8 Dec 2023: llmware v0.1.11\\n\\nNew fast start examples for high volume Document Ingestion and Embeddings with Milvus.\\nNew LLMWare \\'Pop up\\' Inference Server model class and example script.\\nNew Invoice Processing example for RAG.\\nImproved Windows stack management to support parsing larger documents.\\nEnhancing debugging log output mode options for PDF and Office parsers.\\n30 Nov 2023: llmware v0.1.10\\n\\nWindows added as a supported operating system.\\nFurther enhancements to native code for stack management.\\nMinor defect fixes.\\n24 Nov 2023: llmware v0.1.9\\n\\nMarkdown (.md) files are now parsed and treated as text files.\\nPDF and Office parser stack optimizations which should avoid the need to set ulimit -s.\\nNew llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.\\nNative dependencies (shared libraries and dependencies) now included in repo to faciliate local development.\\nUpdates to the Status class to support PDF and Office document parsing status updates.\\nMinor defect fixes including image block handling in library exports.\\n17 Nov 2023: llmware v0.1.8\\n\\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\\nImproved handling for eos_token_id for llama2 and mistral.\\nImproved support for Hugging Face dynamic loading\\nNew examples with the new llmware DRAGON models.\\n14 Nov 2023: llmware v0.1.7\\n\\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\\nModelCatalog enhancements:\\nOpenAI update to include newly announced ‘turbo’ 4 and 3.5 models.\\nCohere embedding v3 update to include new Cohere embedding models.\\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the “hf=True” flag.\\nAbility to register new model names, within existing model classes, with the register method in ModelCatalog.\\nPrompt enhancements:\\n“evidence_metadata” added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.\\nAPI key can now be passed directly in a prompt.load_model(model_name, api_key = “[my-api-key]”)\\nLLMWareInference Server - Initial delivery:\\nNew Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.\\nLLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.\\n03 Nov 2023: llmware v0.1.6\\n\\nUpdated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.\\nUpdates in python code needed in anticipation of future Windows support.\\n27 Oct 2023: llmware v0.1.5\\n\\nFour new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (llmware BLING models).\\nExpanded options for setting temperature inside a prompt class.\\nImprovement in post processing of Hugging Face model generation.\\nStreamlined loading of Hugging Face generative models into prompts.\\nInitial delivery of a central status class: read/write of embedding status with a consistent interface for callers.\\nEnhanced in-memory dictionary search support for multi-key queries.\\nRemoved trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.\\nMinor defect fixes, updated test scripts, and version update for Werkzeug to address dependency security alert.\\n20 Oct 2023: llmware v0.1.4\\n\\nGPU support for Hugging Face models.\\nDefect fixes and additional test scripts.\\n13 Oct 2023: llmware v0.1.3\\n\\nMongoDB Atlas Vector Search support.\\nSupport for authentication using a MongoDB connection string.\\nDocument summarization methods.\\nImprovements in capturing the model context window automatically and passing changes in the expected output length.\\nDataset card and description with lookup by name.\\nProcessing time added to model inference usage dictionary.\\nAdditional test scripts, examples, and defect fixes.\\n06 Oct 2023: llmware v0.1.1\\n\\nAdded test scripts to the github repository for regression testing.\\nMinor defect fixes and version update of Pillow to address dependency security alert.\\n02 Oct 2023: llmware v0.1.0 Initial release of llmware to open source!!',\n",
       "  'Alan Wake 2\\nWhy the hell did you kill Casey? What the hell were you thinking, man?\\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\\nYou have been warned...\\n\\n\"This story... is a monster. And monsters wear many faces.\"\\n― Alan Wake\\n\\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in \"The Final Draft\" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\\'s story. \"The Final Draft\" was released on December 11, 2023.\\n\\nPatch notes for Alan Wake 2 updates can be found here.\\n\\n\\nContents\\n1\\tSynopsis\\n2\\tPlot\\n3\\tChapter List\\n3.1\\tThe Final Draft\\n3.2\\tExpansion 1: Night Springs\\n4\\tGameplay\\n5\\tDevelopment\\n5.1\\tInitial development\\n5.2\\tRemedy Connected Universe\\n5.3\\tOfficial development\\n6\\tReception\\n7\\tTrivia\\n8\\tGallery\\n8.1\\tOfficial Images\\n8.2\\tConcept art\\n8.3\\tConcept art (earlier iteration)\\n9\\tVideos\\n10\\tSources\\nSynopsis\\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\\n\\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\\n\\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\\n\\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\\n― Epic Games Store page description\\nPlot\\nSee also: Alan Wake, Alan Wake\\'s American Nightmare, and Control\\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\\n\\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the \"Cult of the Tree\". In addition to Nightingale\\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\\'s corpse, but it suddenly reanimates, in search of the \"Clicker\", and escapes the morgue after Breaker mysteriously vanishes.\\n\\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a \"Taken\", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\\n\\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called \"In Between With Mr. Door\", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\\'s investigation of the \"Cult of the Word\" led by Alan\\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\\n\\nBack in the present, Alan explains that he wrote a new novel, \"Return\", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that \"Return\" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\\n\\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality \"Return\" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\\n\\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\\'s ending of \"Return\", perpetuating the loop.\\n\\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\\n\\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for \"Return\". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\\n\\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through \"ascension.\" Alan then revives from his gunshot wound and says, \"It\\'s not a loop, it\\'s a spiral.\"\\n\\nIn the \"Final Draft\" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\\'s call connects, confirming Logan\\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\\n\\nChapter List\\nThe chapters/parts listed here are played in the following order:\\nPrologue: The Cult\\nReturn 1: Invitation\\nReturn 2: The Heart\\nInitiation 1: Late Night\\nInitiation 2: Casey\\nInitiation 3: Haunting\\nPlayers have the choice to play the following of Alan and Saga\\'s chronological chapters/parts in any order they wish:\\nReturn 3: Local Girl\\nReturn 4: No Chance\\nReturn 5: Old Gods\\nReturn 6: Scratch\\nInitiation 4: We Sing\\nInitiation 5: Room 665\\nInitiation 6: Return\\nInitiation 7: Masks\\nInitiation 8: Zane\\'s Film\\nThe chapters/parts listed here are past the point of no return and are played in the following order:\\nReturn 7: Summoning\\nInitiation 9: Gone\\nReturn 8: Deerfest\\nReturn 9: Come Home\\nThe Final Draft\\nRemedy released a New Game Plus update to the game on December 11th, 2023 named \"The Final Draft\".\\n\\nExpansion 1: Night Springs\\nSet as \"episodes\" of the Night Springs TV show, these can be played in any order the player wishes.\\n\\nNumber One Fan\\nNorth Star\\nTime Breaker\\nGameplay\\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a \"critical state.\" Players also encounter various puzzles and locked boxes that they\\'ll need to solve in order to obtain upgraded gear.\\n\\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\\n\\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\\n\\nWhilst Saga\\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own \"mind palaces\" to help progress their stories, with Alan having his Writer\\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\\n\\nDevelopment\\nInitial development\\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when \"Alan Wake 2\" was shown on the Artist Althea Suarez Gata\\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\\'s American Nightmare, the credits to the game also then indicated that \"Alan Wake\\'s journey through the night will continue\".\\n\\nAlso in 2012, Sam Lake tweeted a link to a \"Blogspot\" called \"This House of Dreams.\" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man \"wearing a funny jacket with old-fashioned elbow patches\" and that he wanted \"to turn all the lights on.\" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain \"alanwake2.com\" was also reserved by Remedy Entertainment.\\n\\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\\'t announced. He revealed that the time just wasn\\'t right yet, but mentioned he had not given up on the franchise.\\n\\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, \"It\\'s hard to guess,\" but that he would \"love to do that\".\\n\\nRemedy Connected Universe\\nEaster eggs in Remedy\\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an \"Altered World Event\" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\\n\\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for \"Altered World Event,\" they also resemble Alan\\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\\n\\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, \"Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.\"[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\\n\\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\\'s narration, seemed to indicate Remedy\\'s next game could be a follow up to Alan Wake.\\n\\nOfficial development\\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\\'s new publishing initiative. The games were said to be part of \"the same franchise\". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that \"I\\'ve heard that Remedy is going to be making Alan Wake 2,\" as part of the Remedy-Epic deal. Grubb went on to say that the game \"should kind of be the follow-up that fans of that series want,\" but that there\\'s little extra information and no word on an official announcement.\\n\\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\\n\\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\\n\\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\\n\\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\\n\\nReception\\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\\n\\nThe game went on to win more awards in Finland and around the world.\\n\\nTrivia\\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\\'s edition were announced.\\nThe second entry in Remedy\\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).'],\n",
       " {'query': 'What kind of model is the bling-phi-3 model',\n",
       "  'result': 'The bling-phi-3 model is a small CPU-based RAG-optimized model designed for generative AI applications. It is part of the BLING model series, which consists of small, specialized models fine-tuned for function calling and multi-step, multi-model agent workflows.',\n",
       "  'source_documents': [Document(page_content='---The Paths through the Underground/Underdark---(9 days of travel)\\nWandering through the dark tunnels, the rushing sounds of the underground river begin to fade as it diverges from the cavern. You walk on for miles, the smell of hard water and wet earth. Natural chambers and cavern passways are chained together by the stretches of burrowed earth left in the wake of this massive worm-like creature. Clusters of crystal and other beautiful minerals occasionally line the walls and ceilings of the chambers, glittering with the little light you have to shove back the darkness.\\n\\nDay 1 goes without issue... sleep.\\n\\nDay 2 – Ropers\\nAfter a few miles of winding tunnel, you emerge in a smaller grotto of stalactites and stalagmites dripping with condensation. Unsure if the same underground river, or another water source, is nearby, you can see quite a bit of ground water does funnel down into this area. Seeking the next burrowed entrance left by the Kryn...\\n---ENCOUNTER – Ropers x 2---\\nDay 3 goes without issue...sleep.\\n\\nDay 4 - Kobold Trap\\nPart way into the journey, the path becomes a protracted tunnel, snaking through the rock for hours without end. Eventually, you begin to notice other smaller tunnels intersecting with the burrowed canal. They appear partially ruined by this fresher tunnel, many of them now filled or partially collapsed.\\n\\nThey are no more than 2-3 feet wide, and numerous (dozens).\\n\\nIn some of the rubble, you can find broken tools... a hammer, some soiled leather, a knife.\\n\\nThe tunnel finally seems to open into a small 15-foot high, 30ft long chamber of dirt and rock, where a rather rancid smell lingers. Glancing within, a handful of the smaller tunnels seem to intersect with it, and whomever enters first (if not Cad), their leg is SNARED by a noose and they must make a Dexterity Saving Throw (DC 15) or be lifted into the air to dangle from a small trap (restrained, DC 16 to escape). The snare also drags a cable tied to numerous pans and metal scraps, making a ruckus!\\n\\nChattering and tiny warcrys begin to fill the tunnel from all sides... as dozens of small kobolds rush into the room, and from behind!\\n\\n-ENCOUNTER: Kobolds x 26, Kobold Inventor x 1-\\n“Loud food! Loud meal!”\\n\\nWhen seeing the group, they bark and growl. (if noticed, they appear rather fearful)\\n\\n“You! Give us stuffs! Give us foods! Drop things you have, or we stab stab!”\\n\\nIf asked about tunnel “Big worm eat through! Bring ingoeth! In and out, gone quick, leave mess!”\\n\\nThey must parlay with them, avoiding a battle with a significant trade, or intimidation. Otherwise, a fight ensues! Either way, two kobolds are too scared and freeze up. They are brothers Spurt and Bex, scavenger kobolds. They are timid, but know the tunnels well...ish?', metadata={'id': 16, 'relevance_score': 0.9990386}),\n",
       "   Document(page_content='llmware\\n\\nBuilding Enterprise RAG Pipelines with Small, Specialized Models\\nllmware provides a unified framework for building LLM-based applications (e.g, RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.\\n\\nllmware has two main components:\\n\\nRAG Pipeline - integrated components for the full lifecycle of connecting knowledge sources to generative AI models; and\\n\\n50+ small, specialized models fine-tuned for key tasks in enterprise process automation, including fact-based question-answering, classification, summarization, and extraction.\\n\\nBy bringing together both of these components, along with integrating leading open source models and underlying technologies, llmware offers a comprehensive set of tools to rapidly build knowledge-based enterprise LLM applications.\\n\\nMost of our examples can be run without a GPU server - get started right away on your laptop.\\n\\nJoin us on Discord | Watch Youtube Tutorials | Explore our Model Families on Huggingface\\n\\nNew to RAG? Check out the Fast Start video series\\n\\nMulti-Model Agents with SLIM Models - Intro-Video\\n\\nIntro to SLIM Function Call Models\\nCan\\'t wait? Get SLIMs right away:\\n\\nfrom llmware.models import ModelCatalog\\n\\nModelCatalog().get_llm_toolkit()  # get all SLIM models, delivered as small, fast quantized tools\\nModelCatalog().tool_test_run(\"slim-sentiment-tool\") # see the model in action with test script included\\nKey features\\nWriting code withllmware is based on a few main concepts:\\n\\nModel Catalog: Access all models the same way with easy lookup, regardless of underlying implementation.\\nLibrary: ingest, organize and index a collection of knowledge at scale - Parse, Text Chunk and Embed.\\nQuery: query libraries with mix of text, semantic, hybrid, metadata, and custom filters.\\nPrompt with Sources: the easiest way to combine knowledge retrieval with a LLM inference.\\nRAG-Optimized Models - 1-7B parameter models designed for RAG workflow integration and running locally.\\nSimple-to-Scale Database Options - integrated data stores from laptop to parallelized cluster.\\nAgents with Function Calls and SLIM Models\\nStart coding - Quick Start for RAG\\nWhat\\'s New?\\n-Best New Small RAG Model - BLING finetune of Phi-3 - \"bling-phi-3-gguf\" - see the video\\n\\n-Web Services with Agent Calls for Financial Research - end-to-end scenario - video and example\\n\\n-Voice Transcription with WhisperCPP - getting_started, using_sample_files, and analysis_use_case with great_speeches_video\\n\\n-Phi-3 GGUF Streaming Local Chatbot with UI - setup your own Phi-3-gguf chatbot on your laptop in minutes - example with video\\n\\n-Small, specialized, function-calling Extract Model - introducing slim-extract - video and example\\n\\n-LLM to Answer Yes/No questions - introducing slim-boolean model - video and example\\n\\n-Natural Language Query to CSV End to End example - using slim-sql model - video and example and now using Custom Tables on Postgres example\\n\\n-Multi-Model Agents with SLIM models - multi-step Agents with SLIMs on CPU - video - example\\n\\n-OCR Embedded Document Images Example - systematically extract text from images embedded in documents example\\n\\n-Enhanced Parser Functions for PDF, Word, Powerpoint and Excel - new text-chunking controls and strategies, extract tables, images, header text - example\\n\\n-Agent Inference Server - set up multi-model Agents over Inference Server example\\n\\n-GGUF - Getting Started - check out examples - GGUF (example) and Videos video\\n\\n-Optimizing Accuracy of RAG Prompts - check out example and videos - part I and part II\\n\\nGetting Started\\nStep 1 - Install llmware - pip3 install llmware or pip3 install \\'llmware[full]\\'\\n\\nnote: starting with v0.3.0, we provide options for a core install (minimal set of dependencies) or full install (adds to the core with wider set of related python libraries).\\nStep 2- Go to Examples - Get Started Fast with 100+ \\'Cut-and-Paste\\' Recipes\\nStep 3 - Tutorial Videos - check out our Youtube channel for high-impact 5-10 minute tutorials on the latest examples.\\n✍Working with the llmware Github repository\\nThe llmware repo can be pulled locally to get access to all the examples, or to work directly with the latest version of the llmware code.\\n\\ngit clone git@github.com:llmware-ai/llmware.git\\nWe have provided a welcome_to_llmware automation script in the root of the repository folder. After cloning:\\n\\nOn Windows command line: .\\\\welcome_to_llmware_windows.sh\\nOn Mac / Linux command line: sh ./welcome_to_llmware.sh\\nAlternatively, if you prefer to complete setup without the welcome automation script, then the next steps include:\\n\\ninstall requirements.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements.txt\\n\\ninstall requirements_extras.txt - inside the /llmware path - e.g., pip3 install -r llmware/requirements_extras.txt (Depending upon your use case, you may not need all or any of these installs, but some of these will be used in the examples.)\\n\\nrun examples - copy one or more of the example .py files into the root project path. (We have seen several IDEs that will attempt to run interactively from the nested /example path, and then not have access to the /llmware module - the easy fix is to just copy the example you want to run into the root path).\\n\\ninstall vector db - no-install vector db options include milvus lite, chromadb, faiss and lancedb - which do not require a server install, but do require that you install the python sdk library for that vector db, e.g., pip3 install pymilvus, or pip3 install chromadb. If you look in examples/Embedding, you will see examples for getting started with various vector DB, and in the root of the repo, you will see easy-to-get-started docker compose scripts for installing milvus, postgres/pgvector, mongo, qdrant, neo4j, and redis.\\n\\nNote: we have seen recently issues with Pytorch==2.3 on some platforms - if you run into any issues, we have seen that uninstalling Pytorch and downleveling to Pytorch==2.1 usually solves the problem.\\n\\nData Store Options\\nFast Start: use SQLite3 and ChromaDB (File-based) out-of-the-box - no install required\\nSpeed + Scale: use MongoDB (text collection) and Milvus (vector db) - install with Docker Compose\\nPostgres: use Postgres for both text collection and vector DB - install with Docker Compose\\nMix-and-Match: LLMWare supports 3 text collection databases (Mongo, Postgres, SQLite) and 10 vector databases (Milvus, PGVector-Postgres, Neo4j, Redis, Mongo-Atlas, Qdrant, Faiss, LanceDB, ChromaDB and Pinecone)\\nMeet our Models\\nSLIM model series: small, specialized models fine-tuned for function calling and multi-step, multi-model Agent workflows.\\nDRAGON model series: Production-grade RAG-optimized 6-7B parameter models - \"Delivering RAG on ...\" the leading foundation base models.\\nBLING model series: Small CPU-based RAG-optimized, instruct-following 1B-3B parameter models.\\nIndustry BERT models: out-of-the-box custom trained sentence transformer embedding models fine-tuned for the following industries: Insurance, Contracts, Asset Management, SEC.\\nGGUF Quantization: we provide \\'gguf\\' and \\'tool\\' versions of many SLIM, DRAGON and BLING models, optimized for CPU deployment.\\nUsing LLMs and setting-up API keys & secrets\\nLLMWare is an open platform and supports a wide range of open source and proprietary models. To use LLMWare, you do not need to use any proprietary LLM - we would encourage you to experiment with SLIM, BLING, DRAGON, Industry-BERT, the GGUF examples, along with bringing in your favorite models from HuggingFace and Sentence Transformers.\\n\\nIf you would like to use a proprietary model, you will need to provide your own API Keys. API keys and secrets for models, aws, and pinecone can be set-up for use in environment variables or passed directly to method calls.\\n\\nRoadmap - Where are we going ...\\nInterested in contributing to llmware? Information on ways to participate can be found in our Contributors Guide. As with all aspects of this project, contributing is governed by our Code of Conduct.\\n\\nQuestions and discussions are welcome in our github discussions.\\n\\nRelease notes and Change Log\\nSee also additional deployment/install release notes in wheel_archives\\n\\nThursday, June 6 - v0.3.1-WIP\\n\\nAdded module 3 to Fast Start example series examples 7-9 on Agents & Function Calls\\nAdded reranker Jina model for in-memory semantic similarity RAG - see example\\nChanges merged into main branch - expected next pypi release at end of week\\nTuesday, June 4 - v0.3.0\\n\\nAdded support for new Milvus Lite embedded \\'no-install\\' database - see example.\\nAdded two new SLIM models to catalog and agent processes - \\'q-gen\\' and \\'qa-gen\\'\\nUpdated model class instantiation to provide more extensibility to add new classes in different modules\\nNew welcome_to_llmware.sh and welcome_to_llmware_windows.sh fast install scripts\\nEnhanced Model class base with new configurable post_init and register methods\\nCreated InferenceHistory to track global state of all inferences completed\\nMultiple improvements and updates to logging at module level\\nNote: starting with v0.3.0, pip install provides two options - a base minimal install pip3 install llmware which will support most use cases, and a larger install pip3 install \\'llmware[full]\\' with other commonly-used libraries.\\nWednesday, May 22 - v0.2.15\\n\\nImprovements in Model class handling of Pytorch and Transformers dependencies (just-in-time loading, if needed)\\nExpanding API endpoint options and inference server functionality - see new client access options and server_launch\\nSaturday, May 18 - v0.2.14\\n\\nNew OCR image parsing methods with example\\nAdding first part of logging improvements (WIP) in Configs and Models.\\nNew embedding model added to catalog - industry-bert-loans.\\nUpdates to model import methods and configurations.\\nSunday, May 12 - v0.2.13\\n\\nNew GGUF streaming method with basic example and phi3 local chatbot\\nSignificant cleanups in ancillary imports and dependencies to reduce install complexity - note: the updated requirements.txt and setup.py files.\\nDefensive code to provide informative warning of any missing dependencies in specialized parts of the code, e.g., OCR, Web Parser.\\nUpdates of tests, notice and documentation.\\nOpenAIConfigs created to support Azure OpenAI.\\nSunday, May 5 - v0.2.12 Update\\n\\nLaunched \"bling-phi-3\" and \"bling-phi-3-gguf\" in ModelCatalog - newest and most accurate BLING/DRAGON model\\nNew long document summarization method using slim-summary-tool example\\nNew Office (Powerpoint, Word, Excel) sample files example\\nAdded support for Python 3.12\\nDeprecated faiss and replaced with \\'no-install\\' chromadb in Fast Start examples\\nRefactored Datasets, Graph and Web Services classes\\nUpdated Voice parsing with WhisperCPP into Library\\nMonday, April 29 - v0.2.11 Update\\n\\nUpdates to gguf libs for Phi-3 and Llama-3\\nAdded Phi-3 example and Llama-3 example and Quantized Versions to Model Catalog\\nIntegrated WhisperCPP Model class and prebuilt shared libraries - getting-started-example\\nNew voice sample files for testing - example\\nImproved CUDA detection on Windows and safety checks for older Mac OS versions\\nMonday, April 22 - v0.2.10 Update\\n\\nUpdates to Agent class to support Natural Language queries of Custom Tables on Postgres example\\nNew Agent API endpoint implemented with LLMWare Inference Server and new Agent capabilities example\\nTuesday, April 16 - v0.2.9 Update\\n\\nNew CustomTable class to rapidly create custom DB tables in conjunction with LLM-based workflows.\\nEnhanced methods for converting CSV and JSON/JSONL files into DB tables.\\nSee new examples Creating Custom Table example\\nTuesday, April 9 - v0.2.8 Update\\n\\nOffice Parser (Word Docx, Powerpoint PPTX, and Excel XLSX) - multiple improvements - new libs + Python method.\\nIncludes: several fixes, improved text chunking controls, header text extraction and configuration options.\\nGenerally, new office parser options conform with the new PDF parser options.\\nPlease see Office Parsing Configs example\\nWednesday, April 3 - v0.2.7 Update\\n\\nPDF Parser - multiple improvements - new libs + Python methods.\\nIncludes: UTF-8 encoding for European languages.\\nIncludes: Better text chunking controls, header text extraction and configuration options.\\nPlease see PDF Parsing Configs example for more details.\\nNote: deprecating support for aarch64-linux (will use 0.2.6 parsers). Full support going forward for Linux Ubuntu20+ on x86_64 + with CUDA.\\nFriday, March 22 - v0.2.6 Update\\n\\nNew SLIM models: summary, extract, xsum, boolean, tags-3b, and combo sentiment-ner.\\nNew logit and sampling analytics.\\nNew SLIM examples showing how to use the new models.\\nThursday, March 14 - v0.2.5 Update\\n\\nImproved support for GGUF on CUDA (Windows and Linux), with new prebuilt binaries and exception handling.\\nEnhanced model configuration options (sampling, temperature, top logit capture).\\nAdded full back-level support for Ubuntu 20+ with parsers and GGUF engine.\\nSupport for new Anthropic Claude 3 models.\\nNew retrieval methods: document_lookup and aggregate_text.\\nNew model: bling-stablelm-3b-tool - fast, accurate 3b quantized question-answering model - one of our new favorites.\\nWednesday, February 28 - v0.2.4 Update\\n\\nMajor upgrade of GGUF Generative Model class - support for Stable-LM-3B, CUDA build options, and better control over sampling strategies.\\nNote: new GGUF llama.cpp built libs packaged with build starting in v0.2.4.\\nImproved GPU support for HF Embedding Models.\\nFriday, February 16 - v0.2.3 Update\\n\\nAdded 10+ embedding models to ModelCatalog - nomic, jina, bge, gte, ember and uae-large.\\nUpdated OpenAI support >=1.0 and new text-3 embedding models.\\nSLIM model keys and output_values now accessible in ModelCatalog.\\nUpdating encodings to \\'utf-8-sig\\' to better handle txt/csv files with bom.\\nSupported Operating Systems: MacOS (Metal and x86), Linux (x86 and aarch64), Windows\\n\\nnote on Linux: we test most extensively on Ubuntu 22 and now Ubuntu 20 and recommend where possible\\nif you need another Linux version, please raise an issue - we will prioritize testing and ensure support.\\nSupported Vector Databases: Milvus, Postgres (PGVector), Neo4j, Redis, LanceDB, ChromaDB, Qdrant, FAISS, Pinecone, Mongo Atlas Vector Search\\n\\nSupported Text Index Databases: MongoDB, Postgres, SQLite\\n\\nOptional\\nDocker\\n\\nTo enable the OCR parsing capabilities, install Tesseract v5.3.3 and Poppler v23.10.0 native packages.\\n\\nChange Log\\nLatest Updates - 19 Jan 2024 - llmware v0.2.0\\n\\nAdded new database integration options - Postgres and SQlite\\nImproved status update and parser event logging options for parallelized parsing\\nSignificant enhancements to interactions between Embedding + Text collection databases\\nImproved error exception handling in loading dynamic modules\\nLatest Updates - 15 Jan 2024: llmware v0.1.15\\n\\nEnhancements to dual pass retrieval queries\\nExpanded configuration objects and options for endpoint resources\\nLatest Updates - 30 Dec 2023: llmware v0.1.14\\n\\nAdded support for Open Chat inference servers (compatible with OpenAI API)\\nImproved capabilities for multiple embedding models and vector DB configurations\\nAdded docker-compose install scripts for PGVector and Redis vector databases\\nAdded \\'bling-tiny-llama\\' to model catalog\\nLatest Updates - 22 Dec 2023: llmware v0.1.13\\n\\nAdded 3 new vector databases - Postgres (PG Vector), Redis, and Qdrant\\n\\nImproved support for integrating sentence transformers directly in the model catalog\\n\\nImprovements in the model catalog attributes\\n\\nMultiple new Examples in Models & Embeddings, including GGUF, Vector database, and model catalog\\n\\n17 Dec 2023: llmware v0.1.12\\n\\ndragon-deci-7b added to catalog - RAG-finetuned model on high-performance new 7B model base from Deci\\nNew GGUFGenerativeModel class for easy integration of GGUF Models\\nAdding prebuilt llama_cpp / ctransformer shared libraries for Mac M1, Mac x86, Linux x86 and Windows\\n3 DRAGON models packaged as Q4_K_M GGUF models for CPU laptop use (dragon-mistral-7b, dragon-llama-7b, dragon-yi-6b)\\n4 leading open source chat models added to default catalog with Q4_K_M\\n8 Dec 2023: llmware v0.1.11\\n\\nNew fast start examples for high volume Document Ingestion and Embeddings with Milvus.\\nNew LLMWare \\'Pop up\\' Inference Server model class and example script.\\nNew Invoice Processing example for RAG.\\nImproved Windows stack management to support parsing larger documents.\\nEnhancing debugging log output mode options for PDF and Office parsers.\\n30 Nov 2023: llmware v0.1.10\\n\\nWindows added as a supported operating system.\\nFurther enhancements to native code for stack management.\\nMinor defect fixes.\\n24 Nov 2023: llmware v0.1.9\\n\\nMarkdown (.md) files are now parsed and treated as text files.\\nPDF and Office parser stack optimizations which should avoid the need to set ulimit -s.\\nNew llmware_models_fast_start.py example that allows discovery and selection of all llmware HuggingFace models.\\nNative dependencies (shared libraries and dependencies) now included in repo to faciliate local development.\\nUpdates to the Status class to support PDF and Office document parsing status updates.\\nMinor defect fixes including image block handling in library exports.\\n17 Nov 2023: llmware v0.1.8\\n\\nEnhanced generation performance by allowing each model to specific the trailing space parameter.\\nImproved handling for eos_token_id for llama2 and mistral.\\nImproved support for Hugging Face dynamic loading\\nNew examples with the new llmware DRAGON models.\\n14 Nov 2023: llmware v0.1.7\\n\\nMoved to Python Wheel package format for PyPi distribution to provide seamless installation of native dependencies on all supported platforms.\\nModelCatalog enhancements:\\nOpenAI update to include newly announced ‘turbo’ 4 and 3.5 models.\\nCohere embedding v3 update to include new Cohere embedding models.\\nBLING models as out-of-the-box registered options in the catalog. They can be instantiated like any other model, even without the “hf=True” flag.\\nAbility to register new model names, within existing model classes, with the register method in ModelCatalog.\\nPrompt enhancements:\\n“evidence_metadata” added to prompt_main output dictionaries allowing prompt_main responses to be plug into the evidence and fact-checking steps without modification.\\nAPI key can now be passed directly in a prompt.load_model(model_name, api_key = “[my-api-key]”)\\nLLMWareInference Server - Initial delivery:\\nNew Class for LLMWareModel which is a wrapper on a custom HF-style API-based model.\\nLLMWareInferenceServer is a new class that can be instantiated on a remote (GPU) server to create a testing API-server that can be integrated into any Prompt workflow.\\n03 Nov 2023: llmware v0.1.6\\n\\nUpdated packaging to require mongo-c-driver 1.24.4 to temporarily workaround segmentation fault with mongo-c-driver 1.25.\\nUpdates in python code needed in anticipation of future Windows support.\\n27 Oct 2023: llmware v0.1.5\\n\\nFour new example scripts focused on RAG workflows with small, fine-tuned instruct models that run on a laptop (llmware BLING models).\\nExpanded options for setting temperature inside a prompt class.\\nImprovement in post processing of Hugging Face model generation.\\nStreamlined loading of Hugging Face generative models into prompts.\\nInitial delivery of a central status class: read/write of embedding status with a consistent interface for callers.\\nEnhanced in-memory dictionary search support for multi-key queries.\\nRemoved trailing space in human-bot wrapping to improve generation quality in some fine-tuned models.\\nMinor defect fixes, updated test scripts, and version update for Werkzeug to address dependency security alert.\\n20 Oct 2023: llmware v0.1.4\\n\\nGPU support for Hugging Face models.\\nDefect fixes and additional test scripts.\\n13 Oct 2023: llmware v0.1.3\\n\\nMongoDB Atlas Vector Search support.\\nSupport for authentication using a MongoDB connection string.\\nDocument summarization methods.\\nImprovements in capturing the model context window automatically and passing changes in the expected output length.\\nDataset card and description with lookup by name.\\nProcessing time added to model inference usage dictionary.\\nAdditional test scripts, examples, and defect fixes.\\n06 Oct 2023: llmware v0.1.1\\n\\nAdded test scripts to the github repository for regression testing.\\nMinor defect fixes and version update of Pillow to address dependency security alert.\\n02 Oct 2023: llmware v0.1.0 Initial release of llmware to open source!!', metadata={'id': 12, 'relevance_score': 0.99900186}),\n",
       "   Document(page_content='Alan Wake 2\\nWhy the hell did you kill Casey? What the hell were you thinking, man?\\nThis article or a section of this article will contain full, or partial plot spoilers of an Alan Wake game or any other piece of media related to the franchise.\\nYou have been warned...\\n\\n\"This story... is a monster. And monsters wear many faces.\"\\n― Alan Wake\\n\\nAlan Wake 2 (stylized as Alan Wake II) is a survival-horror video game that released on 27 October 2023 on digital storefronts for the PlayStation 5, Xbox Series X|S and PC through the Epic Games Store. It is the sequel to 2010\\'s Alan Wake. The game had an expansion DLC released on June 8, 2024 called Night Springs and a second expansion DLC, The Lake House, is slated to be released sometime later. The game has four difficulties: Story, Normal, Hard, and Nightmare, the fourth of which is only available in \"The Final Draft\" mode. The Final Draft is a New Game Plus mode for Alan Wake 2, featuring new Manuscript pages, other new collectibles, a new expanded ending, and other changes to the game\\'s story. \"The Final Draft\" was released on December 11, 2023.\\n\\nPatch notes for Alan Wake 2 updates can be found here.\\n\\n\\nContents\\n1\\tSynopsis\\n2\\tPlot\\n3\\tChapter List\\n3.1\\tThe Final Draft\\n3.2\\tExpansion 1: Night Springs\\n4\\tGameplay\\n5\\tDevelopment\\n5.1\\tInitial development\\n5.2\\tRemedy Connected Universe\\n5.3\\tOfficial development\\n6\\tReception\\n7\\tTrivia\\n8\\tGallery\\n8.1\\tOfficial Images\\n8.2\\tConcept art\\n8.3\\tConcept art (earlier iteration)\\n9\\tVideos\\n10\\tSources\\nSynopsis\\nQuote1 A string of ritualistic murders threatens Bright Falls, a small-town community surrounded by Pacific Northwest wilderness. Saga Anderson, an accomplished FBI agent with a reputation for solving impossible cases arrives to investigate the murders. Anderson’s case spirals into a nightmare when she discovers pages of a horror story that starts to come true around her.\\n\\nAlan Wake, a lost writer trapped in a nightmare beyond our world, writes a dark story in an attempt to shape the reality around him and escape his prison. With a dark horror hunting him, Wake is trying to retain his sanity and beat the devil at his own game.\\n\\nAnderson and Wake are two heroes on two desperate journeys in two separate realities, connected at heart in ways neither of them can understand: reflecting each other, echoing each other, and affecting the worlds around them.\\n\\nFueled by the horror story, supernatural darkness invades Bright Falls, corrupting the locals and threatening the loved ones of both Anderson and Wake. Light is their weapon—and their safe haven — against the darkness they face. Trapped in a sinister horror story where there are only victims and monsters, can they break out to be the heroes they need to be? Quote2\\n― Epic Games Store page description\\nPlot\\nSee also: Alan Wake, Alan Wake\\'s American Nightmare, and Control\\nIn 2023, thirteen years after the events of Alan Wake, a naked man emerges from the dark shores of Cauldron Lake, experiencing visions of a man violently screaming before he is found and has his heart cut out by a group of men wearing deer masks.\\n\\nFBI Special Agent Saga Anderson and her partner Alex Casey are dispatched to the town of Bright Falls, Washington to investigate a series of ritualistic murders. They investigate the latest victim, the naked man, who is revealed as former FBI Agent Robert Nightingale. It is believed he was murdered by a group calling themselves the \"Cult of the Tree\". In addition to Nightingale\\'s corpse, Saga finds a mysterious manuscript page that seems to predict the future. While in the town, they encounter Sheriff Tim Breaker, who promises to assist their investigation, as well as waitress Rose Marigold, who recognizes Saga and acts like Saga was a local of the area, despite this being her first visit to the town. She also claims Saga\\'s daughter Logan drowned several years ago, despite being alive in Virginia with her father. At the morgue, Saga then performs an autopsy on Nightingale\\'s corpse, but it suddenly reanimates, in search of the \"Clicker\", and escapes the morgue after Breaker mysteriously vanishes.\\n\\nAs they pursue Nightingale to Cauldron Lake, Saga uses her psychic powers to investigate the scene. Casey reveals he had investigated a murder cult in New York City dedicated to bringing back the missing author Alan Wake by reenacting the murders described in his books, and that Nightingale came to Bright Falls to pursue Alan thirteen years prior. Saga encounters Nightingale, now converted into what the manuscript called a \"Taken\", and is forced to kill him. Saga then finds a very-shaken Alan Wake washed up on the shore of the lake and takes him into custody while also discovering evidence that an organization called the Federal Bureau of Control has a presence in Bright Falls. Saga and Casey take Alan back to the Elderwood Palace Lodge in their field office where he recounts how he escaped from a dream-like dimension called the Dark Place.\\n\\nWhile trapped in the Dark Place, Alan continually tried to find a way to escape. After appearing in a mysterious talk show called \"In Between With Mr. Door\", Alan found an Angel Lamp once belonging to Thomas Zane and connected to the Clicker that, in combination with his writing ability, allowed him to manipulate the Dark Place to better navigate it. Alan began navigating a dark, twisted version of New York City, following the trail of Alex Casey\\'s investigation of the \"Cult of the Word\" led by Alan\\'s evil doppelganger Scratch, who survived his erasure from existence, which brought him through the various scenes of the murders committed by the cult. Along the way, Alan also encountered Breaker, who was searching for the talk show host, Warlin Door, believing him to be responsible for trapping him in the Dark Place. Alan also occasionally made brief contact with Saga, the two of them trading vital information when they could. After believing he had killed Tom Zane, who had gone insane from his captivity inside the Dark Place, Alan was contacted by an alternative version of himself, explaining that his repeated attempts to escape the Dark Place are causing him to experience time loops.\\n\\nBack in the present, Alan explains that he wrote a new novel, \"Return\", that helped him escape the Dark Place. However, Scratch re-edited the manuscript into a horror story now taking effect in reality. Alan warns that Scratch is searching for the Clicker, which is the key he needs to free the malevolent Dark Presence completely, but also the key to permanently defeating it. When one of the manuscript pages mentioning the Cult of the Tree possesses the Clicker, Saga decides to follow its trail in Watery and realizes that \"Return\" has rewritten her past so that her daughter Logan drowned in an accident. Angered that Alan wrote her and Logan into his story, Saga recovers the Clicker, but before she can get it to Alan, agents from the FBC led by Agent Kiran Estevez arrive and apprehend him as well as the Cult leaders, revealed to be town entrepreneurs Ilmo and Jaakko Koskela.\\n\\nWith no other options, Saga goes to the Valhalla Nursing Home and tracks down Odin and Tor Anderson, who know more about the Clicker. As she communicates with them and rescues Tor from a Taken Cynthia Weaver, she learns that Odin and Tor are actually her grand-uncle and grandfather, respectively, and she inherited their seer abilities, allowing her to discern the changes to reality \"Return\" is causing. Odin and Tor also explain that the Clicker does not do anything by itself, but instead dramatically enhances the creative power of the person using it, which is why it is important to Alan and Scratch. Saga then heads back to Bright Falls to get the Clicker to Alan, but finds out that the Alan who escaped Cauldron Lake was actually Scratch. With his identity now exposed, Scratch kills Jaakko and escapes from captivity, attempting to take the Clicker from Saga. He is temporarily thwarted and banished by the FBC.\\n\\nIlmo reveals that he and Jakko formed the cult in order to scare townsfolk away from the dangers of the lake, while they perform their ritual killings on whatever Taken emerges from it, such as Nightingale. Realizing that Alan is still trapped in the Dark Place, Saga enlists the help of Casey, Odin, Tor, and Estevez to carry out a ritual to summon him to the real world. Meanwhile, Alan continues to try and find a way out of the Dark Place, eventually making his way to his old apartment. There, he discovers his wife Alice had been tormented with visions of Scratch, eventually leading to her apparent suicide. In anger, Alan kills who he believes is Scratch, but is actually a version of himself attempting to fix Scratch\\'s ending of \"Return\", perpetuating the loop.\\n\\nBack in the real world, the summoning ritual fails to summon Alan in the current time and instead was responsible for his initial appearance earlier in the story. Both Saga and Alan come to the realization that Alan and Scratch were always the same person, with Scratch being Alan, who is possessed by the Dark Presence at the end of every loop, and thus indirectly responsible for Alice\\'s death. Scratch arrives at the summoning site and Saga is able to banish him from Alan\\'s body, only for Scratch to possess Casey instead, steal the Clicker, and throw Saga into the Dark Place.\\n\\nWith Scratch in possession of the Clicker, Alan concludes that the only way to stop him now is to find the manuscript and write a completely new ending for \"Return\". He returns to his writing room and tries to work out how to write a perfect ending that saves everybody while staying consistent with the horror genre. Meanwhile, trapped in her mind place, Saga fights off the Dark Presence\\'s attempt to overwhelm her with her own negative emotions and self-doubt. Now in the Dark Place proper, she reunites with Breaker, who remains there in his search for Door, heavily implied to be Saga\\'s missing father. She then receives aid from an anonymous woman who directs her to the Clicker and a Bullet of Light. Saga takes the two items and escapes back to the real world by mimicking Door\\'s actions on a manuscript page given to her by Breaker. With the Clicker, Alan is able to banish Scratch from Casey\\'s body. Scratch returns to possessing Alan, and Saga shoots him with the Bullet of Light, seemingly killing him and Scratch. As Casey recovers from his possession, Saga tries to call Logan to confirm her safety, but the scene cuts short before any answer can be heard.\\n\\nIn a post-credits scene, a recording left behind by Alice reveals that she had managed to fully regain her memories of what happened to Alan after consulting with the FBC at the Oldest House. She had tricked Alan into thinking she committed suicide by choosing to return the Dark Place as part of a plan to help him eventually escape, explaining that the only way he can escape the loops is through \"ascension.\" Alan then revives from his gunshot wound and says, \"It\\'s not a loop, it\\'s a spiral.\"\\n\\nIn the \"Final Draft\" ending, Alan realizes that the Bullet of Light was meant to cleanse a part of himself the Dark Presence used to create Scratch, finally killing his doppelgänger for good while finishing the spiral and freeing Alan from the loop. Saga\\'s call connects, confirming Logan\\'s survival, and Alan revives soon after to the surprise of her and Casey, declaring himself the master of not just two worlds, but many.\\n\\nChapter List\\nThe chapters/parts listed here are played in the following order:\\nPrologue: The Cult\\nReturn 1: Invitation\\nReturn 2: The Heart\\nInitiation 1: Late Night\\nInitiation 2: Casey\\nInitiation 3: Haunting\\nPlayers have the choice to play the following of Alan and Saga\\'s chronological chapters/parts in any order they wish:\\nReturn 3: Local Girl\\nReturn 4: No Chance\\nReturn 5: Old Gods\\nReturn 6: Scratch\\nInitiation 4: We Sing\\nInitiation 5: Room 665\\nInitiation 6: Return\\nInitiation 7: Masks\\nInitiation 8: Zane\\'s Film\\nThe chapters/parts listed here are past the point of no return and are played in the following order:\\nReturn 7: Summoning\\nInitiation 9: Gone\\nReturn 8: Deerfest\\nReturn 9: Come Home\\nThe Final Draft\\nRemedy released a New Game Plus update to the game on December 11th, 2023 named \"The Final Draft\".\\n\\nExpansion 1: Night Springs\\nSet as \"episodes\" of the Night Springs TV show, these can be played in any order the player wishes.\\n\\nNumber One Fan\\nNorth Star\\nTime Breaker\\nGameplay\\nSimilar to the original, the game is a third-person shooter, with players using light to burn away the darkness of the enemy and various weapons to fight against the dark forces as well as various cult members. Unlike the first game, which was an action-adventure game, Alan Wake 2 emphasizes survival-horror gameplay. Players have an inventory with limited space, where they will need to conserve their ammo and healing items. Health items themselves consist of med kits and painkillers, with Safe Havens only healing the player to take them out of a \"critical state.\" Players also encounter various puzzles and locked boxes that they\\'ll need to solve in order to obtain upgraded gear.\\n\\nThe game features two distinct campaigns, one where you play as the titular Alan Wake, and one where you play a new protagonist, Saga Anderson. The two campaigns blend together, eventually allowing you to switch between the two at various points, using a dark puddle found in certain Break Rooms if the player wishes, with the two stories both foreshadowing and echoing each other. Eventually though, the player will be required to complete both stories before progressing past a point of no return.\\n\\nSaga’s story takes place in the Pacific Northwest, consisting of three hubs: the small town of Bright Falls, the stunning primordial forest surrounding the mysterious Cauldron Lake, and the run-down town of Watery. Alan\\'s story takes place solely within the Dark Place in a warped version of New York City, with his reality shifting and looping. Similarly to the episodic nature of the original, the narrative is divided into chapters, which each having their own accompanying end song. Between chapters, players are returned to the hubs and are allowed to explore or move to the next chapter at their own pace.\\n\\nWhilst Saga\\'s story involves a lot of talking to various townsfolk around the area in order to progress in her environment, Alan uses an Angel Lamp to allow him to change a scene by transferring light from one area of New York to another. Both characters have their own \"mind palaces\" to help progress their stories, with Alan having his Writer\\'s Room to help change the story and Saga having her Mind Place to help her with her investigations, both of which can be accessed at the press of a button.\\n\\nDevelopment\\nInitial development\\nThroughout 2011 and 2012, several hints had been dropped of a potential sequel to Alan Wake. These hints include when \"Alan Wake 2\" was shown on the Artist Althea Suarez Gata\\'s CV, only for it to be removed on the very same day. Whilst Alan Wake\\'s American Nightmare (though the name was unknown at the time) was revealed not long after this hiccup, fans had been trying to find more evidence of a direct sequel. In Alan Wake\\'s American Nightmare, the credits to the game also then indicated that \"Alan Wake\\'s journey through the night will continue\".\\n\\nAlso in 2012, Sam Lake tweeted a link to a \"Blogspot\" called \"This House of Dreams.\" At first, the site seemed like a mere blog for someone refurbishing a house, but one such blog talks about a dream the blogger had about a man \"wearing a funny jacket with old-fashioned elbow patches\" and that he wanted \"to turn all the lights on.\" This tweet came just days before E3 2012, a gaming expo that reveals and shows brand new content of upcoming releases. People also found that the domain \"alanwake2.com\" was also reserved by Remedy Entertainment.\\n\\nAt the Xbox Event on May 21, 2013, Remedy revealed Quantum Break, which would be an exclusive to the newest Xbox console at the time, Xbox One. On February 2016, it was confirmed that it would also come to PC. Fans were disappointed that Alan Wake 2 wasn\\'t revealed, but some still supported Remedy in their new franchise. A day after the Quantum Break announcement, Sam Lake took to YouTube to talk to the fans about why Alan Wake 2 wasn\\'t announced. He revealed that the time just wasn\\'t right yet, but mentioned he had not given up on the franchise.\\n\\nIn April 2015, Remedy announced that Alan Wake 2 had previously gone into the early stage of development shortly after Alan Wake was released, where a video of prototype demo was also released. While in the stage of showing this demo to publishers, Remedy went into conversations with Microsoft and the project was put on hold indefinitely while Quantum Break went into development. The sequel would have introduced new features, many of which were used in Alan Wake\\'s American Nightmare. When asked about the possibility of an Alan Wake sequel being released in the future, Sam Lake replied, \"It\\'s hard to guess,\" but that he would \"love to do that\".\\n\\nRemedy Connected Universe\\nEaster eggs in Remedy\\'s 2019 game Control revealed that the game shared the same universe as Alan Wake. Two typewritten pages found within the game (and which were said to have been written by Alan Wake himself) heavily imply that almost ten years had passed since Alan\\'s experience in Bright Falls, and that it was not an isolated event, but rather what the Federal Bureau of Control classifies as an \"Altered World Event\" (AWE). In this way, Control revealed additional information about the events involving the Dark Presence, especially given the nature of its own primary enemy, the Hiss.\\n\\nFurthermore, the second DLC for Control, AWE, was released in August 2020. While the letters can simply stand for \"Altered World Event,\" they also resemble Alan\\'s own name. In addition to this, the top half of the cover art depicted a flashlight-wielding person in a dark forest, while the bottom half depicted a second figure surrounded by red, which figures prominently with the Hiss in Control.\\n\\nIn an interview given on May 14, 2020 with VG24/7, Sam Lake commented on this, explaining, \"Through AWE you’ll learn more about the Bureau’s involvement, research, and interest in Alan Wake and the events that took place 10 years ago,” Lake said. “We’re really happy to give fans of the original game a bit more of Alan Wake-related content.\"[1] This suggested a deeper connection, possibly even a future crossover, between the events of Control and Alan Wake.\\n\\nThe plot of AWE confirmed this, tying up some loose ends from the previous Alan Wake entries while also setting up details which would come in a sequel work. In the ending of AWE, an alarm sounds in the Federal Bureau of Control that another AWE appears to be happening again in Bright Falls. This, along with Alan\\'s narration, seemed to indicate Remedy\\'s next game could be a follow up to Alan Wake.\\n\\nOfficial development\\nIn March 2020, Remedy signed a deal with Epic Games to publish two single-player games under Epic\\'s new publishing initiative. The games were said to be part of \"the same franchise\". In March 2021, Remedy CEO Tero Virtala confirmed that they were indeed working on two unannounced project with Epic Games that are part of the same franchise, one smaller scale and one AAA in size. In April 2021, GamesBeat reporter Jeff Grubb told viewers that \"I\\'ve heard that Remedy is going to be making Alan Wake 2,\" as part of the Remedy-Epic deal. Grubb went on to say that the game \"should kind of be the follow-up that fans of that series want,\" but that there\\'s little extra information and no word on an official announcement.\\n\\nOn the 7 September 2021, Alan Wake Remastered was revealed by Sam Lake, of which some people believed to have been the smaller project mentioned in March 2021, and the other AAA from the same franchise was to be Alan Wake 2. With the reveal of Alan Wake Remastered, which indicated Remedy are trying to generate interest in the franchise, a sequel was looking more and more likely.\\n\\nAt The Game Awards 2021, Alan Wake 2 was officially announced for 2023 and would be Remedy\\'s first survival-horror video game. Like Quantum Break and Control, it was announced that Alan Wake 2 would use the Northlight engine and be a third-person game. On a later interview with IGN, Sam Lake revealed that the game would have a Mature 17+ age rating.\\n\\nOn May 24, 2023, Sony hosted a PlayStation Showcase livestream, in which a gameplay trailer for Alan Wake 2 was revealed, with a release date of October 17, 2023. It was revealed that players would control two protagonists within their own campaigns, Alan Wake himself and a new protagonist, Saga Anderson. At Summer Game Fest on June 8, 2023, Sam Lake shared further information on the ways Alan and Saga\\'s campaigns would be connected to each other. Additionally, more gameplay and combat mechanics were shown.\\n\\nOn August 17, 2023, the game was delayed by 10 days to October 27, 2023 to make way for various other games also releasing in October. At Gamescom 2023, Alan Wake\\'s side of the game in the Dark Place was focused on in a new trailer, which was later followed by a lengthy Alan-centric gameplay featured behind closed doors.\\n\\nReception\\nAlan Wake 2 received near universal acclaim from video game critics. Itr received five nominations at the 2023 Golden Joystick Awards and won the Critic\\'s Choice Award. It was nominated for eight awards at The Game Awards 2023, and won for Best Game Direction, Best Narrative, and Best Art Direction.\\n\\nThe game went on to win more awards in Finland and around the world.\\n\\nTrivia\\nIlkka Villi and Matthew Porretta both reprise their role as Alan Wake in the sequel. James McCaffrey reprises his role as Alex Casey, who he previously voiced in the manuscript pages of The Sudden Stop.\\nBrett Madden, who played Alice Wake in the first game, sadly passed away in September 2020. She was memorialized in the credits of the game. Alice was recast in the sequel, now played by Christina Cole.\\nWhile the first game was an action-adventure game that implemented horror elements, Alan Wake 2 is a full-blown survival-horror game.\\nUnlike the first game that was published by Microsoft Studios, the sequel is published by Epic Games Publishing.\\nThe game was initially a digital-only release due to various shifts towards a digital-only market. This was also done to keep the price of the game down at launch. However despite initially saying there were no plans for a physical release, in June 2024 along with a trailer and release date announcement of the first DLC it was revealed that a physical version would be released that October, a year after the digital release. Both a physical version of the digital deluxe version (inclusive of the DLC) and a limited run collector\\'s edition were announced.\\nThe second entry in Remedy\\'s Max Payne series, Max Payne 2: The Fall of Max Payne, also had two playable protagonists (Max Payne and Mona Sax).', metadata={'id': 14, 'relevance_score': 0.99840885})]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[0], answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of model is the bling-phi-3 model</td>\n",
       "      <td>The bling-phi-3 model is the newest and most a...</td>\n",
       "      <td>[---The Paths through the Underground/Underdar...</td>\n",
       "      <td>The bling-phi-3 model is a small CPU-based RAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the advantages and disadvantages of t...</td>\n",
       "      <td>The advantage of BM25 is that it is efficient....</td>\n",
       "      <td>[manicfesto proposals\\n26m tonnes of waste pla...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was Duke Stelmane?</td>\n",
       "      <td>Duke Stelmane was a major figure of the Knight...</td>\n",
       "      <td>[The Emperor is a mind flayer who appears in B...</td>\n",
       "      <td>Duke Stelmane was a major figure associated wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What items do Rudolf's family take from the Je...</td>\n",
       "      <td>Rudolf's wife, Hedwig, often receives luxury a...</td>\n",
       "      <td>[The best sci-fi and fantasy books of 2023\\nIt...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the rules for developing general purp...</td>\n",
       "      <td>General purpose AI models that were trained us...</td>\n",
       "      <td>[Why do we need to regulate the use of Artific...</td>\n",
       "      <td>The AI Act imposes certain obligations on prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What can moss be used for?</td>\n",
       "      <td>Harvesting moss gives 1 foraging exp per moss ...</td>\n",
       "      <td>[Why do we need to regulate the use of Artific...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In what contexts is BERT mentioned?</td>\n",
       "      <td>It is mentioned that for BERT large during tra...</td>\n",
       "      <td>[Why do we need to regulate the use of Artific...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What enemies are encountered in the second enc...</td>\n",
       "      <td>26 kobolds and 1 kobold inventor are encounter...</td>\n",
       "      <td>[Bullet Kin\\nBullet Kin are one of the most co...</td>\n",
       "      <td>In the second encounter, you will face 26 Kobo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What colour is Nan-E?</td>\n",
       "      <td>No answer</td>\n",
       "      <td>[The best sci-fi and fantasy books of 2023\\nIt...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do sets in Python compare to sets in Gleam?</td>\n",
       "      <td>No answer</td>\n",
       "      <td>[How to Maximize Your Impact as a Data Scienti...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Which masked language model was chosen for the...</td>\n",
       "      <td>No answer</td>\n",
       "      <td>[Why do we need to regulate the use of Artific...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What did the goblins say?</td>\n",
       "      <td>No answer</td>\n",
       "      <td>[Alan Wake 2\\nWhy the hell did you kill Casey?...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What relgion are the members of the Hoss family?</td>\n",
       "      <td>No answer</td>\n",
       "      <td>[Bullet Kin\\nBullet Kin are one of the most co...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are the key topics of this article?</td>\n",
       "      <td>The key topics of this article are: \"why prior...</td>\n",
       "      <td>[Alan Wake 2\\nWhy the hell did you kill Casey?...</td>\n",
       "      <td>The key topics of the article include:\\n\\n1. *...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What data did was used to test the prototype?</td>\n",
       "      <td>Grace Hopper's Wikipedia page and Alan Turing'...</td>\n",
       "      <td>[How to Maximize Your Impact as a Data Scienti...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>When did mushroom trees stop dropping wood?</td>\n",
       "      <td>Mushrrom trees stopped dropping wood in patch ...</td>\n",
       "      <td>[How to Maximize Your Impact as a Data Scienti...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What do keybullet kin drop?</td>\n",
       "      <td>Keybullet kin drop a key upon death.</td>\n",
       "      <td>[Why do we need to regulate the use of Artific...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What kind of gun does the bandana bullet kin use?</td>\n",
       "      <td>The bandana bullet kin wields a machine pistol.</td>\n",
       "      <td>[Bullet Kin\\nBullet Kin are one of the most co...</td>\n",
       "      <td>Bandana Bullet Kin wield Machine Pistols.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Who wrote 'Divine Rivals'?</td>\n",
       "      <td>Rebecca Ross wrote 'Divine Rivals'.</td>\n",
       "      <td>[The best sci-fi and fantasy books of 2023\\nIt...</td>\n",
       "      <td>'Divine Rivals' was written by Rebecca Ross.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What happens on day 2?</td>\n",
       "      <td>After a few miles of winding tunnel, you emerg...</td>\n",
       "      <td>[Alan Wake 2\\nWhy the hell did you kill Casey?...</td>\n",
       "      <td>I don't know.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0         What kind of model is the bling-phi-3 model   \n",
       "1   What are the advantages and disadvantages of t...   \n",
       "2                              Who was Duke Stelmane?   \n",
       "3   What items do Rudolf's family take from the Je...   \n",
       "4   What are the rules for developing general purp...   \n",
       "5                          What can moss be used for?   \n",
       "6                 In what contexts is BERT mentioned?   \n",
       "7   What enemies are encountered in the second enc...   \n",
       "8                               What colour is Nan-E?   \n",
       "9     How do sets in Python compare to sets in Gleam?   \n",
       "10  Which masked language model was chosen for the...   \n",
       "11                          What did the goblins say?   \n",
       "12   What relgion are the members of the Hoss family?   \n",
       "13           What are the key topics of this article?   \n",
       "14      What data did was used to test the prototype?   \n",
       "15        When did mushroom trees stop dropping wood?   \n",
       "16                        What do keybullet kin drop?   \n",
       "17  What kind of gun does the bandana bullet kin use?   \n",
       "18                         Who wrote 'Divine Rivals'?   \n",
       "19                             What happens on day 2?   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   The bling-phi-3 model is the newest and most a...   \n",
       "1   The advantage of BM25 is that it is efficient....   \n",
       "2   Duke Stelmane was a major figure of the Knight...   \n",
       "3   Rudolf's wife, Hedwig, often receives luxury a...   \n",
       "4   General purpose AI models that were trained us...   \n",
       "5   Harvesting moss gives 1 foraging exp per moss ...   \n",
       "6   It is mentioned that for BERT large during tra...   \n",
       "7   26 kobolds and 1 kobold inventor are encounter...   \n",
       "8                                           No answer   \n",
       "9                                           No answer   \n",
       "10                                          No answer   \n",
       "11                                          No answer   \n",
       "12                                          No answer   \n",
       "13  The key topics of this article are: \"why prior...   \n",
       "14  Grace Hopper's Wikipedia page and Alan Turing'...   \n",
       "15  Mushrrom trees stopped dropping wood in patch ...   \n",
       "16               Keybullet kin drop a key upon death.   \n",
       "17    The bandana bullet kin wields a machine pistol.   \n",
       "18                Rebecca Ross wrote 'Divine Rivals'.   \n",
       "19  After a few miles of winding tunnel, you emerg...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [---The Paths through the Underground/Underdar...   \n",
       "1   [manicfesto proposals\\n26m tonnes of waste pla...   \n",
       "2   [The Emperor is a mind flayer who appears in B...   \n",
       "3   [The best sci-fi and fantasy books of 2023\\nIt...   \n",
       "4   [Why do we need to regulate the use of Artific...   \n",
       "5   [Why do we need to regulate the use of Artific...   \n",
       "6   [Why do we need to regulate the use of Artific...   \n",
       "7   [Bullet Kin\\nBullet Kin are one of the most co...   \n",
       "8   [The best sci-fi and fantasy books of 2023\\nIt...   \n",
       "9   [How to Maximize Your Impact as a Data Scienti...   \n",
       "10  [Why do we need to regulate the use of Artific...   \n",
       "11  [Alan Wake 2\\nWhy the hell did you kill Casey?...   \n",
       "12  [Bullet Kin\\nBullet Kin are one of the most co...   \n",
       "13  [Alan Wake 2\\nWhy the hell did you kill Casey?...   \n",
       "14  [How to Maximize Your Impact as a Data Scienti...   \n",
       "15  [How to Maximize Your Impact as a Data Scienti...   \n",
       "16  [Why do we need to regulate the use of Artific...   \n",
       "17  [Bullet Kin\\nBullet Kin are one of the most co...   \n",
       "18  [The best sci-fi and fantasy books of 2023\\nIt...   \n",
       "19  [Alan Wake 2\\nWhy the hell did you kill Casey?...   \n",
       "\n",
       "                                               answer  \n",
       "0   The bling-phi-3 model is a small CPU-based RAG...  \n",
       "1                                       I don't know.  \n",
       "2   Duke Stelmane was a major figure associated wi...  \n",
       "3                                       I don't know.  \n",
       "4   The AI Act imposes certain obligations on prov...  \n",
       "5                                       I don't know.  \n",
       "6                                       I don't know.  \n",
       "7   In the second encounter, you will face 26 Kobo...  \n",
       "8                                       I don't know.  \n",
       "9                                       I don't know.  \n",
       "10                                      I don't know.  \n",
       "11                                      I don't know.  \n",
       "12                                      I don't know.  \n",
       "13  The key topics of the article include:\\n\\n1. *...  \n",
       "14                                      I don't know.  \n",
       "15                                      I don't know.  \n",
       "16                                      I don't know.  \n",
       "17          Bandana Bullet Kin wield Machine Pistols.  \n",
       "18       'Divine Rivals' was written by Rebecca Ross.  \n",
       "19                                      I don't know.  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "df=df.rename(columns={\n",
    "    \"answer\": \"ground_truth\"\n",
    "})\n",
    "df['contexts'] = contexts\n",
    "df['answer'] = answers\n",
    "# df['contexts'] = df['contexts'].apply(lambda x: json.loads(x))\n",
    "df = df.iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./RAG_Rank_responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question                              What do keybullet kin drop?\n",
       "ground_truth                 Keybullet kin drop a key upon death.\n",
       "contexts        [Why do we need to regulate the use of Artific...\n",
       "answer                                              I don't know.\n",
       "Name: 16, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[16, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   1%|          | 1/100 [00:08<14:30,  8.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   8%|▊         | 8/100 [00:09<01:25,  1.08it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  10%|█         | 10/100 [00:10<01:08,  1.32it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  12%|█▏        | 12/100 [00:13<01:20,  1.10it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  20%|██        | 20/100 [00:13<00:31,  2.53it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  21%|██        | 21/100 [00:14<00:38,  2.07it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  24%|██▍       | 24/100 [00:16<00:35,  2.13it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  27%|██▋       | 27/100 [00:17<00:31,  2.33it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  31%|███       | 31/100 [00:17<00:18,  3.77it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  34%|███▍      | 34/100 [00:17<00:14,  4.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  36%|███▌      | 36/100 [00:18<00:14,  4.51it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  37%|███▋      | 37/100 [00:19<00:20,  3.03it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  39%|███▉      | 39/100 [00:21<00:36,  1.69it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  40%|████      | 40/100 [00:22<00:41,  1.44it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  43%|████▎     | 43/100 [00:24<00:31,  1.80it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  45%|████▌     | 45/100 [00:25<00:29,  1.85it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  49%|████▉     | 49/100 [00:26<00:25,  1.99it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  55%|█████▌    | 55/100 [00:27<00:14,  3.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  56%|█████▌    | 56/100 [00:28<00:17,  2.50it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  58%|█████▊    | 58/100 [00:29<00:15,  2.78it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  60%|██████    | 60/100 [00:32<00:27,  1.45it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  66%|██████▌   | 66/100 [00:33<00:14,  2.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  70%|███████   | 70/100 [00:34<00:11,  2.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  71%|███████   | 71/100 [00:37<00:16,  1.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  72%|███████▏  | 72/100 [00:38<00:18,  1.55it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  79%|███████▉  | 79/100 [00:39<00:08,  2.41it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  81%|████████  | 81/100 [00:40<00:08,  2.27it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  83%|████████▎ | 83/100 [00:42<00:07,  2.16it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  86%|████████▌ | 86/100 [00:43<00:06,  2.30it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  88%|████████▊ | 88/100 [00:45<00:06,  1.84it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  94%|█████████▍| 94/100 [00:45<00:01,  3.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  97%|█████████▋| 97/100 [00:46<00:00,  3.41it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  98%|█████████▊| 98/100 [00:46<00:00,  2.99it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  99%|█████████▉| 99/100 [00:53<00:01,  1.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 100/100 [05:37<00:00,  3.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.3838, 'answer_relevancy': 0.3611, 'context_relevancy': 0.0033, 'context_precision': 0.2500, 'context_recall': 0.3312}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    llm=llm,\n",
    "    raise_exceptions=False,\n",
    "    callbacks=None,\n",
    "    is_async=False,\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pandas().to_csv('./RAG_Rank_evaluations.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
